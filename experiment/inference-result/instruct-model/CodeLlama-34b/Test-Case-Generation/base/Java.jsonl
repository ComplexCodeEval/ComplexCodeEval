{"id": 0, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  boolean handleRecoveryTask(RecoveryTaskMetadata recoveryTaskMetadata) {\n    LOG.info(\"Started handling the recovery task: {}\", recoveryTaskMetadata);\n    long startTime = System.nanoTime();\n    Timer.Sample taskTimer = Timer.start(meterRegistry);\n\n    PartitionOffsets partitionOffsets =\n        validateKafkaOffsets(\n            adminClient,\n            recoveryTaskMetadata,\n            AstraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic());\n    long offsetsValidatedTime = System.nanoTime();\n    long consumerPreparedTime = 0, messagesConsumedTime = 0, rolloversCompletedTime = 0;\n\n    if (partitionOffsets != null) {\n      RecoveryTaskMetadata validatedRecoveryTask =\n          new RecoveryTaskMetadata(\n              recoveryTaskMetadata.name,\n              recoveryTaskMetadata.partitionId,\n              partitionOffsets.startOffset,\n              partitionOffsets.endOffset,\n              recoveryTaskMetadata.createdTimeEpochMs);\n\n      if (partitionOffsets.startOffset != recoveryTaskMetadata.startOffset\n          || recoveryTaskMetadata.endOffset != partitionOffsets.endOffset) {\n        recoveryRecordsNoLongerAvailable.increment(\n            (partitionOffsets.startOffset - recoveryTaskMetadata.startOffset)\n                + (partitionOffsets.endOffset - recoveryTaskMetadata.endOffset));\n      }\n\n      try {\n        RecoveryChunkManager<LogMessage> chunkManager =\n            RecoveryChunkManager.fromConfig(\n                meterRegistry,\n                searchMetadataStore,\n                snapshotMetadataStore,\n                AstraConfig.getIndexerConfig(),\n                blobFs,\n                AstraConfig.getS3Config());\n\n        // Ingest data in parallel\n        LogMessageWriterImpl logMessageWriterImpl = new LogMessageWriterImpl(chunkManager);\n        AstraKafkaConsumer kafkaConsumer =\n            new AstraKafkaConsumer(\n                makeKafkaConfig(\n                    AstraConfig.getRecoveryConfig().getKafkaConfig(),\n                    validatedRecoveryTask.partitionId),\n                logMessageWriterImpl,\n                meterRegistry);\n\n        kafkaConsumer.prepConsumerForConsumption(validatedRecoveryTask.startOffset);\n        consumerPreparedTime = System.nanoTime();\n        kafkaConsumer.consumeMessagesBetweenOffsetsInParallel(\n            AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS,\n            validatedRecoveryTask.startOffset,\n            validatedRecoveryTask.endOffset);\n        messagesConsumedTime = System.nanoTime();\n        // Wait for chunks to upload.\n        boolean success = chunkManager.waitForRollOvers();\n        rolloversCompletedTime = System.nanoTime();\n        // Close the recovery chunk manager and kafka consumer.\n        kafkaConsumer.close();\n        chunkManager.stopAsync();\n        chunkManager.awaitTerminated(DEFAULT_START_STOP_DURATION);\n        LOG.info(\"Finished handling the recovery task: {}\", validatedRecoveryTask);\n        taskTimer.stop(recoveryTaskTimerSuccess);\n        return success;\n      } catch (Exception ex) {\n        LOG.error(\"Exception in recovery task [{}]: {}\", validatedRecoveryTask, ex);\n        taskTimer.stop(recoveryTaskTimerFailure);\n        return false;\n      } finally {\n        long endTime = System.nanoTime();\n        LOG.info(\n            \"Recovery task {} took {}ms, (subtask times offset validation {}, consumer prep {}, msg consumption {}, rollover {})\",\n            recoveryTaskMetadata,\n            nanosToMillis(endTime - startTime),\n            nanosToMillis(offsetsValidatedTime - startTime),\n            nanosToMillis(consumerPreparedTime - offsetsValidatedTime),\n            nanosToMillis(messagesConsumedTime - consumerPreparedTime),\n            nanosToMillis(rolloversCompletedTime - messagesConsumedTime));\n      }\n    } else {\n      LOG.info(\n          \"Recovery task {} data no longer available in Kafka (validation time {}ms)\",\n          recoveryTaskMetadata,\n          nanosToMillis(offsetsValidatedTime - startTime));\n      recoveryRecordsNoLongerAvailable.increment(\n          recoveryTaskMetadata.endOffset - recoveryTaskMetadata.startOffset + 1);\n      return true;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testShouldHandleRecoveryTask() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testShouldHandleRecoveryTask", "reference": "  @Test\n  public void testShouldHandleRecoveryTask() throws Exception {\n    AstraConfigs.AstraConfig astraCfg = makeAstraConfig(TEST_S3_BUCKET);\n    curatorFramework =\n        CuratorBuilder.build(meterRegistry, astraCfg.getMetadataStoreConfig().getZookeeperConfig());\n\n    // Start recovery service\n    recoveryService = new RecoveryService(astraCfg, curatorFramework, meterRegistry, blobFs);\n    recoveryService.startAsync();\n    recoveryService.awaitRunning(DEFAULT_START_STOP_DURATION);\n\n    // Populate data in  Kafka so we can recover from it.\n    final Instant startTime = Instant.now();\n    produceMessagesToKafka(kafkaServer.getBroker(), startTime, TEST_KAFKA_TOPIC_1, 0);\n\n    SnapshotMetadataStore snapshotMetadataStore = new SnapshotMetadataStore(curatorFramework);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore).size()).isZero();\n    // Start recovery\n    RecoveryTaskMetadata recoveryTask =\n        new RecoveryTaskMetadata(\"testRecoveryTask\", \"0\", 30, 60, Instant.now().toEpochMilli());\n    assertThat(recoveryService.handleRecoveryTask(recoveryTask)).isTrue();\n    List<SnapshotMetadata> snapshots =\n        AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore);\n    assertThat(snapshots.size()).isEqualTo(1);\n    assertThat(blobFs.listFiles(BlobFsUtils.createURI(TEST_S3_BUCKET, \"/\", \"\"), true)).isNotEmpty();\n    assertThat(blobFs.exists(URI.create(snapshots.get(0).snapshotPath))).isTrue();\n    assertThat(blobFs.listFiles(URI.create(snapshots.get(0).snapshotPath), false).length)\n        .isGreaterThan(1);\n    assertThat(getCount(MESSAGES_RECEIVED_COUNTER, meterRegistry)).isEqualTo(31);\n    assertThat(getCount(MESSAGES_FAILED_COUNTER, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_INITIATED, meterRegistry)).isEqualTo(1);\n    assertThat(getCount(ROLLOVERS_COMPLETED, meterRegistry)).isEqualTo(1);\n    assertThat(getCount(ROLLOVERS_FAILED, meterRegistry)).isEqualTo(0);\n  }", "completions": ["  ```\n@Test\npublic void testShouldHandleRecoveryTask() throws Exception {\n    // Set up mocks\n    AdminClient adminClient = mock(AdminClient.class);\n    MeterRegistry meterRegistry = mock(MeterRegistry.class);\n    SearchMetadataStore searchMetadataStore = mock(SearchMetadataStore.class);\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    BlobFs blobFs = mock(BlobFs.class);\n    AstraConfig astraConfig = mock(AstraConfig.class);\n    RecoveryTaskMetadata recoveryTaskMetadata = mock(RecoveryTaskMetadata.class);\n    PartitionOffsets partitionOffsets = mock(PartitionOffsets.class);\n    RecoveryChunkManager<LogMessage> chunkManager = mock(RecoveryChunkManager.class);\n    LogMessageWriterImpl logMessageWriterImpl = mock(LogMessageWriterImpl.class);\n    AstraKafkaConsumer kafkaConsumer = mock(AstraKafkaConsumer.class);\n\n    // Set up expectations\n    when(astraConfig.getRecoveryConfig()).thenReturn(mock(RecoveryConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig()).thenReturn(mock(KafkaConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic()).thenReturn(\"test-topic\");\n    when(recoveryTaskMetadata.name).thenReturn(\"test-task\");\n    when(recoveryTaskMetadata.partitionId).thenReturn(1);\n    when(recoveryTaskMetadata.startOffset).thenReturn(100L);\n    when(recoveryTaskMetadata.endOffset).thenReturn(200L);\n    when(recoveryTaskMetadata.createdTimeEpochMs).thenReturn(1000L);\n    when(partitionOffsets.startOffset).thenReturn(100L);\n    when(partitionOffsets.endOffset).thenReturn(200L);\n    when(chunkManager.waitForRollOvers()).thenReturn(true);\n\n    // Call the method under test\n    boolean result = handleRecoveryTask(recoveryTaskMetadata);\n\n    // Verify the results\n    assertTrue(result);\n    verify(adminClient).close();\n    verify(meterRegistry).close();\n    verify(searchMetadataStore).close();\n    verify(snapshotMetadataStore).close();\n    verify(blobFs).close();\n    verify(astraConfig).close();\n    verify(recoveryTaskMetadata).close();\n    verify(partitionOffsets).close();\n    verify(chunkManager).close();\n    verify(logMessageWriterImpl).close();\n    verify(kafkaConsumer).close();\n}\n```"]}
{"id": 1, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  boolean handleRecoveryTask(RecoveryTaskMetadata recoveryTaskMetadata) {\n    LOG.info(\"Started handling the recovery task: {}\", recoveryTaskMetadata);\n    long startTime = System.nanoTime();\n    Timer.Sample taskTimer = Timer.start(meterRegistry);\n\n    PartitionOffsets partitionOffsets =\n        validateKafkaOffsets(\n            adminClient,\n            recoveryTaskMetadata,\n            AstraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic());\n    long offsetsValidatedTime = System.nanoTime();\n    long consumerPreparedTime = 0, messagesConsumedTime = 0, rolloversCompletedTime = 0;\n\n    if (partitionOffsets != null) {\n      RecoveryTaskMetadata validatedRecoveryTask =\n          new RecoveryTaskMetadata(\n              recoveryTaskMetadata.name,\n              recoveryTaskMetadata.partitionId,\n              partitionOffsets.startOffset,\n              partitionOffsets.endOffset,\n              recoveryTaskMetadata.createdTimeEpochMs);\n\n      if (partitionOffsets.startOffset != recoveryTaskMetadata.startOffset\n          || recoveryTaskMetadata.endOffset != partitionOffsets.endOffset) {\n        recoveryRecordsNoLongerAvailable.increment(\n            (partitionOffsets.startOffset - recoveryTaskMetadata.startOffset)\n                + (partitionOffsets.endOffset - recoveryTaskMetadata.endOffset));\n      }\n\n      try {\n        RecoveryChunkManager<LogMessage> chunkManager =\n            RecoveryChunkManager.fromConfig(\n                meterRegistry,\n                searchMetadataStore,\n                snapshotMetadataStore,\n                AstraConfig.getIndexerConfig(),\n                blobFs,\n                AstraConfig.getS3Config());\n\n        // Ingest data in parallel\n        LogMessageWriterImpl logMessageWriterImpl = new LogMessageWriterImpl(chunkManager);\n        AstraKafkaConsumer kafkaConsumer =\n            new AstraKafkaConsumer(\n                makeKafkaConfig(\n                    AstraConfig.getRecoveryConfig().getKafkaConfig(),\n                    validatedRecoveryTask.partitionId),\n                logMessageWriterImpl,\n                meterRegistry);\n\n        kafkaConsumer.prepConsumerForConsumption(validatedRecoveryTask.startOffset);\n        consumerPreparedTime = System.nanoTime();\n        kafkaConsumer.consumeMessagesBetweenOffsetsInParallel(\n            AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS,\n            validatedRecoveryTask.startOffset,\n            validatedRecoveryTask.endOffset);\n        messagesConsumedTime = System.nanoTime();\n        // Wait for chunks to upload.\n        boolean success = chunkManager.waitForRollOvers();\n        rolloversCompletedTime = System.nanoTime();\n        // Close the recovery chunk manager and kafka consumer.\n        kafkaConsumer.close();\n        chunkManager.stopAsync();\n        chunkManager.awaitTerminated(DEFAULT_START_STOP_DURATION);\n        LOG.info(\"Finished handling the recovery task: {}\", validatedRecoveryTask);\n        taskTimer.stop(recoveryTaskTimerSuccess);\n        return success;\n      } catch (Exception ex) {\n        LOG.error(\"Exception in recovery task [{}]: {}\", validatedRecoveryTask, ex);\n        taskTimer.stop(recoveryTaskTimerFailure);\n        return false;\n      } finally {\n        long endTime = System.nanoTime();\n        LOG.info(\n            \"Recovery task {} took {}ms, (subtask times offset validation {}, consumer prep {}, msg consumption {}, rollover {})\",\n            recoveryTaskMetadata,\n            nanosToMillis(endTime - startTime),\n            nanosToMillis(offsetsValidatedTime - startTime),\n            nanosToMillis(consumerPreparedTime - offsetsValidatedTime),\n            nanosToMillis(messagesConsumedTime - consumerPreparedTime),\n            nanosToMillis(rolloversCompletedTime - messagesConsumedTime));\n      }\n    } else {\n      LOG.info(\n          \"Recovery task {} data no longer available in Kafka (validation time {}ms)\",\n          recoveryTaskMetadata,\n          nanosToMillis(offsetsValidatedTime - startTime));\n      recoveryRecordsNoLongerAvailable.increment(\n          recoveryTaskMetadata.endOffset - recoveryTaskMetadata.startOffset + 1);\n      return true;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testShouldHandleRecoveryTaskFailure() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testShouldHandleRecoveryTaskFailure", "reference": "  @Test\n  public void testShouldHandleRecoveryTaskFailure() throws Exception {\n    String fakeS3Bucket = \"fakeBucket\";\n    AstraConfigs.AstraConfig astraCfg = makeAstraConfig(fakeS3Bucket);\n    curatorFramework =\n        CuratorBuilder.build(meterRegistry, astraCfg.getMetadataStoreConfig().getZookeeperConfig());\n\n    // Start recovery service\n    recoveryService = new RecoveryService(astraCfg, curatorFramework, meterRegistry, blobFs);\n    recoveryService.startAsync();\n    recoveryService.awaitRunning(DEFAULT_START_STOP_DURATION);\n\n    // Populate data in  Kafka so we can recover from it.\n    final Instant startTime = Instant.now();\n    produceMessagesToKafka(kafkaServer.getBroker(), startTime, TEST_KAFKA_TOPIC_1, 0);\n\n    assertThat(s3AsyncClient.listBuckets().get().buckets().size()).isEqualTo(1);\n    assertThat(s3AsyncClient.listBuckets().get().buckets().get(0).name()).isEqualTo(TEST_S3_BUCKET);\n    assertThat(s3AsyncClient.listBuckets().get().buckets().get(0).name())\n        .isNotEqualTo(fakeS3Bucket);\n    SnapshotMetadataStore snapshotMetadataStore = new SnapshotMetadataStore(curatorFramework);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore).size()).isZero();\n\n    // Start recovery\n    RecoveryTaskMetadata recoveryTask =\n        new RecoveryTaskMetadata(\"testRecoveryTask\", \"0\", 30, 60, Instant.now().toEpochMilli());\n    assertThat(recoveryService.handleRecoveryTask(recoveryTask)).isFalse();\n\n    assertThat(s3AsyncClient.listBuckets().get().buckets().size()).isEqualTo(1);\n    assertThat(s3AsyncClient.listBuckets().get().buckets().get(0).name()).isEqualTo(TEST_S3_BUCKET);\n    assertThat(s3AsyncClient.listBuckets().get().buckets().get(0).name())\n        .isNotEqualTo(fakeS3Bucket);\n\n    assertThat(getCount(MESSAGES_RECEIVED_COUNTER, meterRegistry)).isEqualTo(31);\n    assertThat(getCount(MESSAGES_FAILED_COUNTER, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_INITIATED, meterRegistry)).isEqualTo(1);\n    assertThat(getCount(ROLLOVERS_COMPLETED, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_FAILED, meterRegistry)).isEqualTo(1);\n  }", "completions": ["  ```java\n@Test\npublic void testShouldHandleRecoveryTaskFailure() throws Exception {\n    // Set up mocks\n    AdminClient adminClient = mock(AdminClient.class);\n    MeterRegistry meterRegistry = mock(MeterRegistry.class);\n    SearchMetadataStore searchMetadataStore = mock(SearchMetadataStore.class);\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    BlobFs blobFs = mock(BlobFs.class);\n    AstraConfig astraConfig = mock(AstraConfig.class);\n    RecoveryTaskMetadata recoveryTaskMetadata = mock(RecoveryTaskMetadata.class);\n    PartitionOffsets partitionOffsets = mock(PartitionOffsets.class);\n    RecoveryChunkManager<LogMessage> chunkManager = mock(RecoveryChunkManager.class);\n    LogMessageWriterImpl logMessageWriterImpl = mock(LogMessageWriterImpl.class);\n    AstraKafkaConsumer kafkaConsumer = mock(AstraKafkaConsumer.class);\n\n    // Set up expectations\n    when(astraConfig.getRecoveryConfig()).thenReturn(mock(RecoveryConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig()).thenReturn(mock(KafkaConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic()).thenReturn(\"test-topic\");\n    when(recoveryTaskMetadata.name).thenReturn(\"test-task\");\n    when(recoveryTaskMetadata.partitionId).thenReturn(1);\n    when(recoveryTaskMetadata.startOffset).thenReturn(100L);\n    when(recoveryTaskMetadata.endOffset).thenReturn(200L);\n    when(recoveryTaskMetadata.createdTimeEpochMs).thenReturn(1000L);\n    when(partitionOffsets.startOffset).thenReturn(100L);\n    when(partitionOffsets.endOffset).thenReturn(200L);\n    when(chunkManager.waitForRollOvers()).thenReturn(false);\n\n    // Call the method under test\n    boolean result = handleRecoveryTask(recoveryTaskMetadata);\n\n    // Verify the results\n    assertFalse(result);\n    verify(recoveryRecordsNoLongerAvailable).increment(101);\n    verify(kafkaConsumer).close();\n    verify(chunkManager).stopAsync();\n    verify(chunkManager).awaitTerminated(DEFAULT_START_STOP_DURATION);\n}\n```"]}
{"id": 2, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public int migration(String srcTable, List<String> uuids, String targetTable) {\n        if (Objects.isNull(srcTable) || Objects.isNull(targetTable) || CollectionUtils.isEmpty(uuids)) {\n            throw new SwValidationException(\n                    ValidSubject.EVALUATION, \"srcTable, targetTable and uuids must not be null\");\n        }\n        var filter = TableQueryFilter.builder()\n                .operator(Operator.OR)\n                .operands(uuids.stream()\n                                  .map(uuid -> TableQueryFilter.builder()\n                                          .operator(Operator.EQUAL)\n                                          .operands(List.of(\n                                                  new TableQueryFilter.Column(KeyColumn),\n                                                  new TableQueryFilter.Constant(\n                                                          ColumnType.STRING, uuid)\n                                          ))\n                                          .build())\n                                  .collect(Collectors.toList())\n                )\n                .build();\n        return store.migration(DataStoreMigrationRequest.builder()\n                                       .srcTableName(srcTable)\n                                       .targetTableName(targetTable)\n                                       .filter(filter)\n                                       .build()\n        );\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testMigration()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testMigration", "reference": "    @Test\n    public void testMigration() {\n        var srcTable = \"p/1/space/1/eval/summary\";\n        var targetTable = \"p/1/eval/summary\";\n        assertThrows(SwValidationException.class, () ->\n                evaluationRepo.migration(null, List.of(\"uuid1\"), targetTable));\n        assertThrows(SwValidationException.class, () ->\n                evaluationRepo.migration(srcTable, null, targetTable));\n        assertThrows(SwValidationException.class, () ->\n                evaluationRepo.migration(srcTable, List.of(\"uuid1\"), null));\n\n        evaluationRepo.migration(srcTable, List.of(\"uuid1\", \"uuid2\"), targetTable);\n\n        verify(dataStore, times(1)).migration(\n                DataStoreMigrationRequest.builder()\n                        .srcTableName(srcTable)\n                        .targetTableName(targetTable)\n                        .filter(\n                                TableQueryFilter.builder()\n                                        .operator(Operator.OR)\n                                        .operands(List.of(\n                                                TableQueryFilter.builder()\n                                                        .operator(Operator.EQUAL)\n                                                        .operands(List.of(\n                                                                new TableQueryFilter.Column(KeyColumn),\n                                                                new TableQueryFilter.Constant(\n                                                                        ColumnType.STRING, \"uuid1\")))\n                                                        .build(),\n                                                TableQueryFilter.builder()\n                                                        .operator(Operator.EQUAL)\n                                                        .operands(List.of(\n                                                                new TableQueryFilter.Column(KeyColumn),\n                                                                new TableQueryFilter.Constant(\n                                                                        ColumnType.STRING, \"uuid2\")))\n                                                        .build()))\n                                        .build())\n                        .build()\n        );\n    }", "completions": ["  ```\n@Test\npublic void testMigration() {\n    // Set up mocks\n    DataStore store = mock(DataStore.class);\n    TableQueryFilter filter = mock(TableQueryFilter.class);\n    when(filter.getOperator()).thenReturn(Operator.OR);\n    when(filter.getOperands()).thenReturn(List.of(\n            new TableQueryFilter.Column(KeyColumn),\n            new TableQueryFilter.Constant(ColumnType.STRING, \"uuid1\"),\n            new TableQueryFilter.Column(KeyColumn),\n            new TableQueryFilter.Constant(ColumnType.STRING, \"uuid2\")\n    ));\n    when(store.migration(any(DataStoreMigrationRequest.class))).thenReturn(1);\n\n    // Call the method\n    int result = migration(\"srcTable\", List.of(\"uuid1\", \"uuid2\"), \"targetTable\");\n\n    // Verify the result\n    assertEquals(1, result);\n    verify(store).migration(any(DataStoreMigrationRequest.class));\n}\n```"]}
{"id": 3, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void sendData(String database, String table, String content, boolean partitioned) throws Exception {\n        final String loadUrl = String.format(\"http://%s:%s/api/%s/%s/_stream_load?strip_outer_array=true\",\n                DORIS_HOST,\n                DORIS_HTTP_PORT,\n                database,\n                table);\n\n        final HttpClientBuilder httpClientBuilder = HttpClients\n                .custom()\n                .setRedirectStrategy(new DefaultRedirectStrategy() {\n                    @Override\n                    protected boolean isRedirectable(String method) {\n                        return true;\n                    }\n                });\n\n        try (CloseableHttpClient client = httpClientBuilder.build()) {\n            HttpPut put = new HttpPut(loadUrl);\n            StringEntity entity = new StringEntity(content, \"UTF-8\");\n            put.setHeader(HttpHeaders.EXPECT, \"100-continue\");\n            put.setHeader(HttpHeaders.AUTHORIZATION, HttpUtil.basicAuthHeader(DORIS_USER, DORIS_PASSWORD));\n            put.setHeader(\"max_filter_ratio\", \"0.1\");\n            if (partitioned) {\n                SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyyMMdd\");\n                put.setHeader(\"partitions\", \"p\" + simpleDateFormat.format(new Date()));\n            }\n            // the label header is optional, not necessary\n            // use label header can ensure at most once semantics\n            put.setEntity(entity);\n            try (CloseableHttpResponse response = client.execute(put)) {\n                String contentStr = new String(ByteStreams.toByteArray(response.getEntity().getContent()));\n                JsonObject jsonObject = jsonParser.parse(contentStr).getAsJsonObject();\n                log.info(\"result:{}\", contentStr);\n                int statusCode = response.getStatusLine().getStatusCode();\n                // statusCode 200 just indicates that doris be service is ok, not stream load\n                // you should see the output content to find whether stream load is success\n                if (statusCode != HttpStatus.SC_OK || (!jsonObject.get(\"Status\").getAsString().equalsIgnoreCase(\"SUCCESS\") &&\n                        !jsonObject.get(\"Status\").getAsString().equalsIgnoreCase(\"Publish Timeout\"))) {\n                    throw new IOException(\n                            String.format(\"Stream load failed, statusCode=%s load result=%s content=%s\", statusCode, jsonObject.toString(), content));\n                }\n            } catch (Exception e) {\n                log.error(\"error\", e);\n            } finally {\n                client.close();\n            }\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void sendDatasMapTest() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "sendDatasMapTest", "reference": "    @Test\n    public void sendDatasMapTest() throws Exception {\n        String database = \"test\";\n        String tableName = \"doris_test_db\";\n        List<Map<String, Object>> dataList = new ArrayList<>();\n        for (int i = 0; i < 100; i++) {\n            Map<String, Object> data = new HashMap<>();\n            data.put(\"id\", i);\n            data.put(\"name\", \"张三\");\n            data.put(\"message\", \"股东风波的法规的规定翻跟斗广泛的给yryrtytr\");\n            System.out.println(gson.toJson(data));\n            dataList.add(data);\n\n        }\n        dorisStreamLoad.sendData(database, tableName, columnList, dataList);\n    }", "completions": ["  ```\n@Test\npublic void sendDatasMapTest() throws Exception {\n    // Set up mocks\n    HttpClientBuilder httpClientBuilder = mock(HttpClientBuilder.class);\n    CloseableHttpClient client = mock(CloseableHttpClient.class);\n    CloseableHttpResponse response = mock(CloseableHttpResponse.class);\n    HttpEntity entity = mock(HttpEntity.class);\n    StatusLine statusLine = mock(StatusLine.class);\n    JsonParser jsonParser = mock(JsonParser.class);\n    JsonObject jsonObject = mock(JsonObject.class);\n\n    // Set up expectations\n    when(httpClientBuilder.build()).thenReturn(client);\n    when(client.execute(any(HttpPut.class))).thenReturn(response);\n    when(response.getStatusLine()).thenReturn(statusLine);\n    when(statusLine.getStatusCode()).thenReturn(HttpStatus.SC_OK);\n    when(response.getEntity()).thenReturn(entity);\n    when(entity.getContent()).thenReturn(new ByteArrayInputStream(\"{\\\"Status\\\":\\\"SUCCESS\\\"}\".getBytes()));\n    when(jsonParser.parse(anyString())).thenReturn(jsonObject);\n    when(jsonObject.get(\"Status\")).thenReturn(\"SUCCESS\");\n\n    // Call the method under test\n    sendData(\"database\", \"table\", \"content\", true);\n\n    // Verify the results\n    verify(client).execute(any(HttpPut.class));\n    verify(response).getStatusLine();\n    verify(statusLine).getStatusCode();\n    verify(response).getEntity();\n    verify(entity).getContent();\n    verify(jsonParser).parse(anyString());\n    verify(jsonObject).get(\"Status\");\n}\n```"]}
{"id": 4, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_map_of_serializable_key_and_value()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_map_of_serializable_key_and_value", "reference": "    @Test\n    public void should_clone_map_of_serializable_key_and_value() {\n        Map<String, SerializableObject> original = new HashMap<>();\n        original.put(\"key\", new SerializableObject(\"value\"));\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n    @Test\n    public void should_clone_map_of_serializable_key_and_value() {\n        Map<String, Integer> map = new HashMap<>();\n        map.put(\"key1\", 1);\n        map.put(\"key2\", 2);\n        Map<String, Integer> clonedMap = (Map<String, Integer>) clone(map);\n        assertEquals(map, clonedMap);\n        assertNotSame(map, clonedMap);\n    }\n```"]}
{"id": 5, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void encode(String schemaName, long nextTransactionOffset) {\n        if (schemaName == null) {\n            schemaName = UNKNOWN;\n        }\n        this.schemaName = schemaName;\n        this.nextTransactionOffset = nextTransactionOffset;\n        final byte[] payloadBytes = payloadToBytes();\n        final int payloadLength = payloadBytes.length;\n\n        // set logEventHeader\n        int eventSize = eventHeaderLengthVersionGt1 + payloadLength;\n        setLogEventHeader(new LogEventHeader(drc_filter_log_event.getType(), 0, eventSize, nextTransactionOffset)\n        );\n\n        // set payload\n        final ByteBuf payloadByteBuf = PooledByteBufAllocator.DEFAULT.directBuffer(payloadLength);\n        payloadByteBuf.writeBytes(payloadBytes);\n        payloadByteBuf.skipBytes(payloadLength);\n        setPayloadBuf(payloadByteBuf);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void encode()\n```\n### Answer: (use the provided format with backticks)\n", "name": "encode", "reference": "    @Test\n    public void encode() {\n        FilterLogEvent filterLogEvent = new FilterLogEvent();\n        filterLogEvent.encode(\"drc1\", 101);\n        Assert.assertEquals(\"drc1\", filterLogEvent.getSchemaName());\n        Assert.assertEquals(101, filterLogEvent.getNextTransactionOffset());\n\n        ByteBuf headerBuf = filterLogEvent.getLogEventHeader().getHeaderBuf();\n        headerBuf.readerIndex(0);\n        ByteBuf payloadBuf = filterLogEvent.getPayloadBuf();\n        payloadBuf.readerIndex(0);\n        CompositeByteBuf compositeByteBuf = PooledByteBufAllocator.DEFAULT.compositeDirectBuffer();\n        compositeByteBuf.addComponents(true, headerBuf, payloadBuf);\n\n        FilterLogEvent newFilterLogEvent = new FilterLogEvent();\n        newFilterLogEvent.read(compositeByteBuf);\n        compositeByteBuf.release(compositeByteBuf.refCnt());\n        Assert.assertEquals(\"drc1\", newFilterLogEvent.getSchemaName());\n        Assert.assertEquals(101, newFilterLogEvent.getNextTransactionOffset());\n    }", "completions": ["  ```java\n@Test\npublic void encode() {\n    // Set up test data\n    String schemaName = \"test_schema\";\n    long nextTransactionOffset = 100L;\n    byte[] payloadBytes = new byte[] { 0x01, 0x02, 0x03, 0x04 };\n    int payloadLength = payloadBytes.length;\n    int eventSize = eventHeaderLengthVersionGt1 + payloadLength;\n    LogEventHeader logEventHeader = new LogEventHeader(drc_filter_log_event.getType(), 0, eventSize, nextTransactionOffset);\n    ByteBuf payloadByteBuf = PooledByteBufAllocator.DEFAULT.directBuffer(payloadLength);\n    payloadByteBuf.writeBytes(payloadBytes);\n    payloadByteBuf.skipBytes(payloadLength);\n\n    // Call the method under test\n    drc_filter_log_event.encode(schemaName, nextTransactionOffset);\n\n    // Verify the results\n    assertEquals(logEventHeader, drc_filter_log_event.getLogEventHeader());\n    assertEquals(payloadByteBuf, drc_filter_log_event.getPayloadBuf());\n}\n```"]}
{"id": 6, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void put(String path, long position, ByteBuf data) {\n        writeLock.lock();\n        try {\n            int dataLength = data.readableBytes();\n            NavigableMap<Long, Value> cache = path2cache.computeIfAbsent(path, k -> new TreeMap<>());\n            Map.Entry<Long, Value> pos2value = cache.floorEntry(position);\n            long cacheStartPosition;\n            Value value;\n            if (pos2value == null || pos2value.getKey() + pos2value.getValue().dataLength < position) {\n                cacheStartPosition = position;\n                value = Value.EMPTY;\n            } else {\n                cacheStartPosition = pos2value.getKey();\n                value = pos2value.getValue();\n            }\n            // ensure the capacity, if the capacity change then update the cache index\n            int moreCapacity = (int) ((position + dataLength) - (cacheStartPosition + value.blocks.length * (long) blockSize));\n            int newDataLength = (int) (position + dataLength - cacheStartPosition);\n            if (moreCapacity > 0) {\n                int[] blocks = ensureCapacity(cacheStartPosition, moreCapacity);\n                if (blocks == null) {\n                    return;\n                }\n                int[] newBlocks = new int[value.blocks.length + blocks.length];\n                System.arraycopy(value.blocks, 0, newBlocks, 0, value.blocks.length);\n                System.arraycopy(blocks, 0, newBlocks, value.blocks.length, blocks.length);\n                value = new Value(newBlocks, newDataLength);\n            } else {\n                value = new Value(value.blocks, newDataLength);\n            }\n            cache.put(cacheStartPosition, value);\n            lru.put(new Key(path, cacheStartPosition), value);\n\n            // write data to cache\n            ByteBuffer cacheByteBuffer = this.cacheByteBuffer.duplicate();\n            int positionDelta = (int) (position - cacheStartPosition);\n            int written = 0;\n            ByteBuffer[] nioBuffers = data.nioBuffers();\n            int[] blocks = value.blocks;\n            for (ByteBuffer nioBuffer : nioBuffers) {\n                ByteBuf buf = Unpooled.wrappedBuffer(nioBuffer);\n                while (buf.readableBytes() > 0) {\n                    int writePosition = positionDelta + written;\n                    int block = blocks[writePosition / blockSize];\n                    cacheByteBuffer.position(block * blockSize + writePosition % blockSize);\n                    int length = Math.min(buf.readableBytes(), blockSize - writePosition % blockSize);\n                    cacheByteBuffer.put(buf.slice(buf.readerIndex(), length).nioBuffer());\n                    buf.skipBytes(length);\n                    written += length;\n                }\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testMergePut() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testMergePut", "reference": "    @Test\n    public void testMergePut() throws IOException {\n        FileCache fileCache = new FileCache(\"/tmp/file_cache_test\", 10 * 1024, 1024);\n        {\n            CompositeByteBuf buf = Unpooled.compositeBuffer();\n            buf.addComponent(true, genBuf((byte) 1, 500));\n            buf.addComponent(true, genBuf((byte) 2, 500));\n            buf.addComponent(true, genBuf((byte) 3, 500));\n            fileCache.put(\"test\", 3333L, buf);\n        }\n        assertEquals(1, fileCache.path2cache.get(\"test\").size());\n        assertEquals(1500, fileCache.path2cache.get(\"test\").get(3333L).dataLength);\n        {\n            CompositeByteBuf buf = Unpooled.compositeBuffer();\n            buf.addComponent(true, genBuf((byte) 4, 500));\n            buf.addComponent(true, genBuf((byte) 5, 500));\n            buf.addComponent(true, genBuf((byte) 6, 500));\n            fileCache.put(\"test\", 3333L + 1000, buf);\n        }\n        assertEquals(1, fileCache.path2cache.get(\"test\").size());\n        assertEquals(2500, fileCache.path2cache.get(\"test\").get(3333L).dataLength);\n        {\n            CompositeByteBuf buf = Unpooled.compositeBuffer();\n            buf.addComponent(true, genBuf((byte) 7, 500));\n            fileCache.put(\"test\", 3333L + 1000 + 1500, buf);\n        }\n        assertEquals(1, fileCache.path2cache.get(\"test\").size());\n        assertEquals(3000, fileCache.path2cache.get(\"test\").get(3333L).dataLength);\n\n        assertTrue(verify(fileCache.get(\"test\", 3333L, 500).get(), (byte) 1));\n        assertTrue(verify(fileCache.get(\"test\", 3333L + 500, 500).get(), (byte) 2));\n        assertTrue(verify(fileCache.get(\"test\", 3333L + 1000, 500).get(), (byte) 4));\n        assertTrue(verify(fileCache.get(\"test\", 3333L + 1500, 500).get(), (byte) 5));\n        assertTrue(verify(fileCache.get(\"test\", 3333L + 2000, 500).get(), (byte) 6));\n        assertTrue(verify(fileCache.get(\"test\", 3333L + 2500, 500).get(), (byte) 7));\n    }", "completions": ["  ```\n@Test\npublic void testMergePut() throws IOException {\n    // Set up mocks\n    WriteLock writeLock = mock(WriteLock.class);\n    NavigableMap<Long, Value> path2cache = mock(NavigableMap.class);\n    Map.Entry<Long, Value> pos2value = mock(Map.Entry.class);\n    Value value = mock(Value.class);\n    Lru<Key, Value> lru = mock(Lru.class);\n    ByteBuffer cacheByteBuffer = mock(ByteBuffer.class);\n\n    // Set up test data\n    String path = \"test/path\";\n    long position = 100;\n    int dataLength = 10;\n    int blockSize = 10;\n    int moreCapacity = 5;\n    int newDataLength = 15;\n    int[] blocks = new int[] {1, 2, 3};\n    ByteBuf data = Unpooled.buffer(dataLength);\n    for (int i = 0; i < dataLength; i++) {\n        data.writeByte(i);\n    }\n\n    // Set up mock behavior\n    when(writeLock.lock()).thenReturn(null);\n    when(path2cache.computeIfAbsent(path, k -> new TreeMap<>())).thenReturn(path2cache);\n    when(pos2value.getKey()).thenReturn(position);\n    when(pos2value.getValue()).thenReturn(value);\n    when(value.blocks).thenReturn(blocks);\n    when(value.dataLength).thenReturn(dataLength);\n    when(lru.put(new Key(path, position), value)).thenReturn(null);\n    when(cacheByteBuffer.duplicate()).thenReturn(cacheByteBuffer);\n    when(cacheByteBuffer.position(anyInt())).thenReturn(cacheByteBuffer);\n    when(cacheByteBuffer.put(any(ByteBuffer.class))).thenReturn(cacheByteBuffer);\n\n    // Call the method under test\n    put(path, position, data);\n\n    // Verify mock interactions\n    verify(writeLock).lock();\n    verify(path2cache).computeIfAbsent(path, k -> new TreeMap<>());\n    verify(pos2value).getKey();\n    verify(pos2value).getValue();\n    verify(value).blocks;\n    verify(value).dataLength;\n    verify(lru).put(new Key(path, position), value);\n    verify(cacheByteBuffer).duplicate();\n    verify(cacheByteBuffer).position(anyInt());\n    verify(cacheByteBuffer).put(any(ByteBuffer.class));\n}\n```"]}
{"id": 7, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testSearchById()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSearchById", "reference": "  @Test\n  public void testSearchById() {\n    Instant time = Instant.now();\n    loadTestData(time);\n    SearchResult<LogMessage> index =\n        strictLogStore.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"_id:Message1\",\n            time.toEpochMilli(),\n            time.plusSeconds(2).toEpochMilli(),\n            10,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(index.hits.size()).isEqualTo(1);\n  }", "completions": ["  ```java\n@Test\npublic void testSearchById() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any(IndexSearcher.class))).thenReturn(query);\n    CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector = mock(CollectorManager.class);\n    when(topFieldCollector.getLeafCollector(any(LeafReaderContext.class))).thenReturn(mock(TopFieldCollector.class));\n    when(openSearchAdapter.getCollectorManager(any(AggBuilder.class), any(IndexSearcher.class), any(Query.class))).thenReturn(topFieldCollector);\n    ScoreDoc[] hits = new ScoreDoc[1];\n    hits[0] = new ScoreDoc(1, 1.0f);\n    TopFieldDocs topFieldDocs = new TopFieldDocs(1, hits, new SortField(\"id\", SortField.Type.LONG));\n    when(searcher.search(any(Query.class), any(CollectorManager.class))).thenReturn(topFieldDocs);\n    LogMessage logMessage = mock(LogMessage.class);\n    when(logMessage.getId()).thenReturn(1L);\n    when(buildLogMessage(any(IndexSearcher.class), any(ScoreDoc.class))).thenReturn(logMessage);\n\n    // Call the method under test\n    SearchResult<LogMessage> result = search(searcherManager, openSearchAdapter, \"dataset\", \"query\", 0L, 1L, 1, null);\n\n    // Verify the results\n    assertEquals(1, result.getTotalHits());\n    assertEquals(1, result.getHits().size());\n    assertEquals(1L, result.getHits().get(0).getId());\n}\n```"]}
{"id": 8, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public SendStatus sendHtmlMail(String subject, List<String> toList, String username, String agentName, String emailHref, String maiContent) {\n        SendStatus sendStatus = new SendStatus(SEND_STATUS_FALSE, \"\");\n        List<String> notInBlacklistAddress = checkNotInBlacklistAddress(toList,sendStatus);\n        if(CollectionUtils.isEmpty(notInBlacklistAddress)){\n            return sendStatus;\n        }\n        // 读取html模板\n        String html = readHtmlToString(\"mailTemplate.html\");\n\n        // 写入模板内容\n        Document doc = Jsoup.parse(html);\n        doc.getElementById(\"username\").html(username);\n\n        if (StringUtils.isEmpty(agentName)) {\n            sendStatus.setErrorMessage(\"agentName 为空\");\n            return sendStatus;\n        }\n        doc.getElementById(\"sysName\").html(\"Your Agent：\");\n        doc.getElementById(\"agentName\").html(agentName);\n        doc.getElementById(\"mailContent\").html(maiContent);\n        doc.getElementById(\"clickHref\").attr(\"href\", emailHref);\n\n        String result = doc.toString();\n        Properties props = new Properties();\n        props.put(\"mail.smtp.host\", \"\");\n        props.put(\"mail.smtp.auth\", \"true\");\n        props.put(\"mail.smtp.socketFactory.class\", \"javax.net.ssl.SSLSocketFactory\");\n        props.put(\"mail.smtp.socketFactory.fallback\", \"true\");\n        Session session = Session.getDefaultInstance(props);\n        session.setDebug(true);\n\n        Transport transport = null;\n        MimeMessage message = new MimeMessage(session);\n        try {\n            //初始化发送邮件配置\n            this.initMailConfig();\n            message.setFrom(new InternetAddress(this.sendAddress));// 设置发件人的地址\n            InternetAddress[] internetAddressList = getInternetAddress(notInBlacklistAddress);\n            message.setRecipients(Message.RecipientType.TO, internetAddressList);// 设置收件人,并设置其接收类型为TO\n            message.setSubject(subject);// 设置标题\n            message.setContent(result, \"text/html;charset=UTF-8\"); // 设置邮件内容类型为html\n            message.setSentDate(new Date());// 设置发信时间\n            message.saveChanges();// 存储邮件信息\n\n            // 发送邮件\n            transport = session.getTransport(\"smtp\");\n            if (null != port) {\n                transport.connect(host, port, user, password);\n            } else {\n                transport.connect(host, user, password);\n            }\n            transport.sendMessage(message, message.getAllRecipients());\n\n            //发送邮件成功，status置为true\n            sendStatus.setStatus(\"true\");\n        } catch (Exception e) {\n            log.error(\"邮件发送异常\", e);\n            sendStatus.setErrorMessage(e.getMessage());\n        } finally {\n            if (null != transport) {\n                try {\n                    transport.close();//关闭连接\n                } catch (MessagingException e) {\n                    log.error(\"发送邮件 ，transport 关闭异常\", e);\n                }\n            }\n        }\n        return sendStatus;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testSendHtmlMail_subjectNotNull_notInBlacklistAddressIsNull()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSendHtmlMail_subjectNotNull_notInBlacklistAddressIsNull", "reference": "    @Test\n    void testSendHtmlMail_subjectNotNull_notInBlacklistAddressIsNull(){\n        when(blacklistService.inBlacklist(anyString())).thenReturn(true);\n        List<String> addressList = new ArrayList<>();\n        addressList.add(\"test@qq.com\");\n        SendStatus result = mailUtils.sendHtmlMail(\"\",addressList,\"test\",\"test\",\"test\",\"test\");\n        Assertions.assertEquals(\"false\",result.getStatus());\n        Assertions.assertTrue(result.getErrorMessage().contains(\"blacklist\"));\n    }", "completions": ["  ```\n@Test\nvoid testSendHtmlMail_subjectNotNull_notInBlacklistAddressIsNull() {\n    // Arrange\n    String subject = \"Test Subject\";\n    List<String> toList = null;\n    String username = \"Test Username\";\n    String agentName = \"Test Agent\";\n    String emailHref = \"Test Href\";\n    String maiContent = \"Test Content\";\n    SendStatus expectedSendStatus = new SendStatus(SEND_STATUS_FALSE, \"\");\n\n    // Act\n    SendStatus actualSendStatus = sendHtmlMail(subject, toList, username, agentName, emailHref, maiContent);\n\n    // Assert\n    assertEquals(expectedSendStatus, actualSendStatus);\n}\n```"]}
{"id": 9, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_serializable_object()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_serializable_object", "reference": "    @Test\n    public void should_clone_serializable_object() {\n        Object original = new SerializableObject(\"value\");\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n    @Test\n    public void should_clone_serializable_object() {\n        // Given\n        MySerializableObject original = new MySerializableObject(\"foo\", \"bar\");\n\n        // When\n        MySerializableObject clone = (MySerializableObject) clone(original);\n\n        // Then\n        assertNotSame(original, clone);\n        assertEquals(original.getFoo(), clone.getFoo());\n        assertEquals(original.getBar(), clone.getBar());\n    }\n```"]}
{"id": 10, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n\tpublic Embedding embedText(String text) {\n\t\tAssert.hasText(text, \"The text can not be null or empty.\");\n\n\t\t@JsonInclude(Include.NON_NULL)\n\t\trecord EmbeddingResponse(Embedding embedding) {\n\t\t}\n\n\t\tEmbeddingResponse response = this.restClient.post()\n\t\t\t\t.uri(\"/models/{model}:embedText?key={apiKey}\", this.embeddingModel, this.apiKey)\n\t\t\t\t.body(Map.of(\"text\", text))\n\t\t\t\t.retrieve()\n\t\t\t\t.body(EmbeddingResponse.class);\n\n\t\treturn response != null ? response.embedding() : null;\n\t}\n```\n###test function signature:\n```java\n\t@Test\n\tpublic void embedText()\n```\n### Answer: (use the provided format with backticks)\n", "name": "embedText", "reference": "\t@Test\n\tpublic void embedText() {\n\n\t\tvar text = \"Hello, how are you?\";\n\n\t\tEmbedding response = vertexAiPaLm2Api.embedText(text);\n\n\t\tassertThat(response).isNotNull();\n\t\tassertThat(response.value()).hasSize(768);\n\t}", "completions": ["  ```java\n@Test\npublic void embedText() {\n    // Set up\n    String text = \"Hello, world!\";\n    Embedding expectedEmbedding = new Embedding(new float[] {1.0f, 2.0f, 3.0f});\n    when(this.restClient.post()).thenReturn(this.restClient);\n    when(this.restClient.uri(anyString(), anyString(), anyString())).thenReturn(this.restClient);\n    when(this.restClient.body(anyMap())).thenReturn(this.restClient);\n    when(this.restClient.retrieve()).thenReturn(this.restClient);\n    when(this.restClient.body(EmbeddingResponse.class)).thenReturn(new EmbeddingResponse(expectedEmbedding));\n\n    // Call method\n    Embedding actualEmbedding = this.embedText(text);\n\n    // Verify result\n    assertEquals(expectedEmbedding, actualEmbedding);\n}\n```"]}
{"id": 11, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static Optional<Integer> maybeFetchErrorIntervalMs(short errorCode, int intervalMs) {\n        if (errorCode == Errors.NONE.code())\n            return Optional.empty();\n\n        int pushIntervalMs;\n        String reason;\n\n        Errors error = Errors.forCode(errorCode);\n        switch (error) {\n            case INVALID_REQUEST:\n            case INVALID_RECORD:\n            case UNSUPPORTED_VERSION:\n                pushIntervalMs = Integer.MAX_VALUE;\n                reason = \"The broker response indicates the client sent an request that cannot be resolved\"\n                    + \" by re-trying, hence disable telemetry\";\n                break;\n            case UNKNOWN_SUBSCRIPTION_ID:\n            case UNSUPPORTED_COMPRESSION_TYPE:\n                pushIntervalMs = 0;\n                reason = error.message();\n                break;\n            case TELEMETRY_TOO_LARGE:\n            case THROTTLING_QUOTA_EXCEEDED:\n                reason = error.message();\n                pushIntervalMs = (intervalMs != -1) ? intervalMs : ClientTelemetryReporter.DEFAULT_PUSH_INTERVAL_MS;\n                break;\n            default:\n                reason = \"Unwrapped error code\";\n                log.error(\"Error code: {}. Unmapped error for telemetry, disable telemetry.\", errorCode);\n                pushIntervalMs = Integer.MAX_VALUE;\n        }\n\n        log.debug(\"Error code: {}, reason: {}. Push interval update to {} ms.\", errorCode, reason, pushIntervalMs);\n        return Optional.of(pushIntervalMs);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testMaybeFetchErrorIntervalMs()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testMaybeFetchErrorIntervalMs", "reference": "    @Test\n    public void testMaybeFetchErrorIntervalMs() {\n        assertEquals(Optional.empty(), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.NONE.code(), -1));\n        assertEquals(Optional.of(Integer.MAX_VALUE), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.INVALID_REQUEST.code(), -1));\n        assertEquals(Optional.of(Integer.MAX_VALUE), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.INVALID_RECORD.code(), -1));\n        assertEquals(Optional.of(0), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.UNKNOWN_SUBSCRIPTION_ID.code(), -1));\n        assertEquals(Optional.of(0), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.UNSUPPORTED_COMPRESSION_TYPE.code(), -1));\n        assertEquals(Optional.of(ClientTelemetryReporter.DEFAULT_PUSH_INTERVAL_MS), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.TELEMETRY_TOO_LARGE.code(), -1));\n        assertEquals(Optional.of(20000), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.TELEMETRY_TOO_LARGE.code(), 20000));\n        assertEquals(Optional.of(ClientTelemetryReporter.DEFAULT_PUSH_INTERVAL_MS), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.THROTTLING_QUOTA_EXCEEDED.code(), -1));\n        assertEquals(Optional.of(20000), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.THROTTLING_QUOTA_EXCEEDED.code(), 20000));\n        assertEquals(Optional.of(Integer.MAX_VALUE), ClientTelemetryUtils.maybeFetchErrorIntervalMs(Errors.UNKNOWN_SERVER_ERROR.code(), -1));\n    }", "completions": ["  ```\n@Test\npublic void testMaybeFetchErrorIntervalMs() {\n    // Test case 1: errorCode = Errors.NONE.code()\n    Optional<Integer> result1 = maybeFetchErrorIntervalMs(Errors.NONE.code(), 1000);\n    assertFalse(result1.isPresent());\n\n    // Test case 2: errorCode = Errors.INVALID_REQUEST.code()\n    Optional<Integer> result2 = maybeFetchErrorIntervalMs(Errors.INVALID_REQUEST.code(), 1000);\n    assertTrue(result2.isPresent());\n    assertEquals(Integer.MAX_VALUE, result2.get());\n\n    // Test case 3: errorCode = Errors.UNKNOWN_SUBSCRIPTION_ID.code()\n    Optional<Integer> result3 = maybeFetchErrorIntervalMs(Errors.UNKNOWN_SUBSCRIPTION_ID.code(), 1000);\n    assertTrue(result3.isPresent());\n    assertEquals(0, result3.get());\n\n    // Test case 4: errorCode = Errors.TELEMETRY_TOO_LARGE.code()\n    Optional<Integer> result4 = maybeFetchErrorIntervalMs(Errors.TELEMETRY_TOO_LARGE.code(), 1000);\n    assertTrue(result4.isPresent());\n    assertEquals(1000, result4.get());\n\n    // Test case 5: errorCode = Errors.THROTTLING_QUOTA_EXCEEDED.code()\n    Optional<Integer> result5 = maybeFetchErrorIntervalMs(Errors.THROTTLING_QUOTA_EXCEEDED.code(), 1000);\n    assertTrue(result5.isPresent());\n    assertEquals(1000, result5.get());\n\n    // Test case 6: errorCode = Errors.UNSUPPORTED_COMPRESSION_TYPE.code()\n    Optional<Integer> result6 = maybeFetchErrorIntervalMs(Errors.UNSUPPORTED_COMPRESSION_TYPE.code(), 1000);\n    assertTrue(result6.isPresent());\n    assertEquals(0, result6.get());\n\n    // Test case 7: errorCode = Errors.UNKNOWN_SERVER_ERROR.code()\n    Optional<Integer> result7 = maybeFetchErrorIntervalMs(Errors.UNKNOWN_SERVER_ERROR.code(), 1000);\n    assertTrue(result7.isPresent());\n    assertEquals(Integer.MAX_VALUE, result7.get());\n}\n```"]}
{"id": 12, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_non_serializable_object()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_non_serializable_object", "reference": "    @Test\n    public void should_clone_non_serializable_object() {\n        Object original = new NonSerializableObject(\"value\");\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n@Test\npublic void should_clone_non_serializable_object() {\n    // Given\n    NonSerializableObject object = new NonSerializableObject();\n    // When\n    NonSerializableObject clonedObject = (NonSerializableObject) clone(object);\n    // Then\n    assertNotSame(object, clonedObject);\n    assertEquals(object.getClass(), clonedObject.getClass());\n    assertEquals(object.getField(), clonedObject.getField());\n}\n```"]}
{"id": 13, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  public ListenableFuture<Void> queue(ExecuteEntry executeEntry, Poller poller, Duration timeout) {\n    ExecuteOperationMetadata metadata =\n        ExecuteOperationMetadata.newBuilder()\n            .setActionDigest(executeEntry.getActionDigest())\n            .setStdoutStreamName(executeEntry.getStdoutStreamName())\n            .setStderrStreamName(executeEntry.getStderrStreamName())\n            .build();\n    Operation operation =\n        Operation.newBuilder()\n            .setName(executeEntry.getOperationName())\n            .setMetadata(Any.pack(metadata))\n            .build();\n    Digest actionDigest = executeEntry.getActionDigest();\n    ActionKey actionKey = DigestUtil.asActionKey(actionDigest);\n\n    Stopwatch stopwatch = Stopwatch.createStarted();\n    ListenableFuture<Boolean> cachedResultFuture;\n    if (executeEntry.getSkipCacheLookup()) {\n      cachedResultFuture = immediateFuture(false);\n    } else {\n      cachedResultFuture =\n          checkCacheFuture(actionKey, operation, executeEntry.getRequestMetadata());\n    }\n    return transformAsync(\n        cachedResultFuture,\n        (cachedResult) -> {\n          if (cachedResult) {\n            poller.pause();\n            long checkCacheUSecs = stopwatch.elapsed(MICROSECONDS);\n            log.log(\n                Level.FINER,\n                format(\n                    \"ServerInstance(%s): checkCache(%s): %sus elapsed\",\n                    getName(), operation.getName(), checkCacheUSecs));\n            return IMMEDIATE_VOID_FUTURE;\n          }\n          return transformAndQueue(executeEntry, poller, operation, stopwatch, timeout);\n        },\n        operationTransformService);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void queueOperationCompletesOperationWithCachedActionResult() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "queueOperationCompletesOperationWithCachedActionResult", "reference": "  @Test\n  public void queueOperationCompletesOperationWithCachedActionResult() throws Exception {\n    ActionKey actionKey = DigestUtil.asActionKey(Digest.newBuilder().setHash(\"test\").build());\n    ExecuteEntry executeEntry =\n        ExecuteEntry.newBuilder()\n            .setOperationName(\"operation-with-cached-action-result\")\n            .setActionDigest(actionKey.getDigest())\n            .build();\n\n    ActionResult actionResult = ActionResult.getDefaultInstance();\n\n    when(mockBackplane.getActionResult(eq(actionKey))).thenReturn(actionResult);\n\n    Poller poller = mock(Poller.class);\n\n    instance.queue(executeEntry, poller, DEFAULT_TIMEOUT).get();\n\n    verify(mockBackplane, times(1)).putOperation(any(Operation.class), eq(CACHE_CHECK));\n    verify(mockBackplane, never()).putOperation(any(Operation.class), eq(QUEUED));\n    verify(mockBackplane, times(1)).putOperation(any(Operation.class), eq(COMPLETED));\n    verify(poller, atLeastOnce()).pause();\n  }", "completions": ["  ```java\n  @Test\n  public void queueOperationCompletesOperationWithCachedActionResult() throws Exception {\n    // arrange\n    ExecuteEntry executeEntry = mock(ExecuteEntry.class);\n    Poller poller = mock(Poller.class);\n    Duration timeout = mock(Duration.class);\n    ListenableFuture<Boolean> cachedResultFuture = mock(ListenableFuture.class);\n    when(cachedResultFuture.get()).thenReturn(true);\n    when(executeEntry.getSkipCacheLookup()).thenReturn(false);\n    when(executeEntry.getActionDigest()).thenReturn(mock(Digest.class));\n    when(executeEntry.getOperationName()).thenReturn(\"operationName\");\n    when(executeEntry.getRequestMetadata()).thenReturn(mock(RequestMetadata.class));\n    when(executeEntry.getStdoutStreamName()).thenReturn(\"stdoutStreamName\");\n    when(executeEntry.getStderrStreamName()).thenReturn(\"stderrStreamName\");\n    when(poller.pause()).thenReturn(null);\n    when(timeout.get()).thenReturn(mock(Duration.class));\n\n    // act\n    ListenableFuture<Void> result = queue(executeEntry, poller, timeout);\n\n    // assert\n    assertThat(result.get(), is(nullValue()));\n    verify(cachedResultFuture).get();\n    verify(poller).pause();\n    verify(executeEntry).getSkipCacheLookup();\n    verify(executeEntry).getActionDigest();\n    verify(executeEntry).getOperationName();\n    verify(executeEntry).getRequestMetadata();\n    verify(executeEntry).getStdoutStreamName();\n    verify(executeEntry).getStderrStreamName();\n    verify(timeout).get();\n  }\n```"]}
{"id": 14, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  public ListenableFuture<Void> queue(ExecuteEntry executeEntry, Poller poller, Duration timeout) {\n    ExecuteOperationMetadata metadata =\n        ExecuteOperationMetadata.newBuilder()\n            .setActionDigest(executeEntry.getActionDigest())\n            .setStdoutStreamName(executeEntry.getStdoutStreamName())\n            .setStderrStreamName(executeEntry.getStderrStreamName())\n            .build();\n    Operation operation =\n        Operation.newBuilder()\n            .setName(executeEntry.getOperationName())\n            .setMetadata(Any.pack(metadata))\n            .build();\n    Digest actionDigest = executeEntry.getActionDigest();\n    ActionKey actionKey = DigestUtil.asActionKey(actionDigest);\n\n    Stopwatch stopwatch = Stopwatch.createStarted();\n    ListenableFuture<Boolean> cachedResultFuture;\n    if (executeEntry.getSkipCacheLookup()) {\n      cachedResultFuture = immediateFuture(false);\n    } else {\n      cachedResultFuture =\n          checkCacheFuture(actionKey, operation, executeEntry.getRequestMetadata());\n    }\n    return transformAsync(\n        cachedResultFuture,\n        (cachedResult) -> {\n          if (cachedResult) {\n            poller.pause();\n            long checkCacheUSecs = stopwatch.elapsed(MICROSECONDS);\n            log.log(\n                Level.FINER,\n                format(\n                    \"ServerInstance(%s): checkCache(%s): %sus elapsed\",\n                    getName(), operation.getName(), checkCacheUSecs));\n            return IMMEDIATE_VOID_FUTURE;\n          }\n          return transformAndQueue(executeEntry, poller, operation, stopwatch, timeout);\n        },\n        operationTransformService);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void queueActionFailsQueueEligibility() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "queueActionFailsQueueEligibility", "reference": "  @Test\n  public void queueActionFailsQueueEligibility() throws Exception {\n    Directory inputRoot = Directory.newBuilder().build();\n    ByteString inputRootContent = inputRoot.toByteString();\n    Digest inputRootDigest = DIGEST_UTIL.compute(inputRootContent);\n    provideBlob(inputRootDigest, inputRootContent);\n    Action action = createAction(true, true, inputRootDigest, SIMPLE_COMMAND);\n    Digest actionDigest = DIGEST_UTIL.compute(action);\n\n    ExecuteEntry executeEntry =\n        ExecuteEntry.newBuilder()\n            .setOperationName(\"missing-directory-operation\")\n            .setActionDigest(actionDigest)\n            .setSkipCacheLookup(true)\n            .build();\n\n    when(mockBackplane.propertiesEligibleForQueue(anyList())).thenReturn(false);\n\n    when(mockBackplane.canQueue()).thenReturn(true);\n\n    Poller poller = mock(Poller.class);\n\n    boolean failedPreconditionExceptionCaught = false;\n    try {\n      instance\n          .queue(executeEntry, poller, DEFAULT_TIMEOUT)\n          .get(QUEUE_TEST_TIMEOUT_SECONDS, SECONDS);\n    } catch (ExecutionException e) {\n      com.google.rpc.Status status = StatusProto.fromThrowable(e);\n      if (status.getCode() == Code.FAILED_PRECONDITION.getNumber()) {\n        failedPreconditionExceptionCaught = true;\n      } else {\n        e.getCause().printStackTrace();\n      }\n    }\n    assertThat(failedPreconditionExceptionCaught).isTrue();\n\n    PreconditionFailure preconditionFailure =\n        PreconditionFailure.newBuilder()\n            .addViolations(\n                Violation.newBuilder()\n                    .setType(VIOLATION_TYPE_INVALID)\n                    .setSubject(INVALID_PLATFORM)\n                    .setDescription(\n                        \"properties are not valid for queue eligibility: [].  If you think your\"\n                            + \" queue should still accept these poperties without them being\"\n                            + \" specified in queue configuration, consider configuring the queue\"\n                            + \" with `allow_unmatched: True`\"))\n            .build();\n    ExecuteResponse executeResponse =\n        ExecuteResponse.newBuilder()\n            .setStatus(\n                com.google.rpc.Status.newBuilder()\n                    .setCode(Code.FAILED_PRECONDITION.getNumber())\n                    .setMessage(invalidActionVerboseMessage(actionDigest, preconditionFailure))\n                    .addDetails(Any.pack(preconditionFailure)))\n            .build();\n    assertResponse(executeResponse);\n    verify(poller, atLeastOnce()).pause();\n  }", "completions": ["  ```java\n  @Test\n  public void queueActionFailsQueueEligibility() throws Exception {\n    // arrange\n    ExecuteEntry executeEntry = mock(ExecuteEntry.class);\n    Poller poller = mock(Poller.class);\n    Duration timeout = mock(Duration.class);\n    when(executeEntry.getSkipCacheLookup()).thenReturn(true);\n    when(executeEntry.getActionDigest()).thenReturn(mock(Digest.class));\n    when(executeEntry.getStdoutStreamName()).thenReturn(\"stdout\");\n    when(executeEntry.getStderrStreamName()).thenReturn(\"stderr\");\n    when(executeEntry.getOperationName()).thenReturn(\"operation\");\n    when(executeEntry.getRequestMetadata()).thenReturn(mock(RequestMetadata.class));\n    when(poller.pause()).thenReturn(mock(ListenableFuture.class));\n    when(timeout.getSeconds()).thenReturn(10L);\n    when(timeout.getNano()).thenReturn(1000000000L);\n\n    // act\n    ListenableFuture<Void> result = queue(executeEntry, poller, timeout);\n\n    // assert\n    assertThat(result, is(notNullValue()));\n    assertThat(result.isDone(), is(true));\n    assertThat(result.get(), is(nullValue()));\n    verify(executeEntry, times(1)).getSkipCacheLookup();\n    verify(executeEntry, times(1)).getActionDigest();\n    verify(executeEntry, times(1)).getStdoutStreamName();\n    verify(executeEntry, times(1)).getStderrStreamName();\n    verify(executeEntry, times(1)).getOperationName();\n    verify(executeEntry, times(1)).getRequestMetadata();\n    verify(poller, times(1)).pause();\n    verify(timeout, times(1)).getSeconds();\n    verify(timeout, times(1)).getNano();\n  }\n```"]}
{"id": 15, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_serializable_complex_object_with_serializable_nested_object()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_serializable_complex_object_with_serializable_nested_object", "reference": "    @Test\n    public void should_clone_serializable_complex_object_with_serializable_nested_object() {\n        Map<String, List<SerializableObject>> map = new LinkedHashMap<>();\n        map.put(\"key1\", Lists.newArrayList(new SerializableObject(\"name1\")));\n        map.put(\"key2\", Lists.newArrayList(\n            new SerializableObject(\"name2\"),\n            new SerializableObject(\"name3\")\n        ));\n        Object original = new SerializableComplexObject(map);\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n@Test\npublic void should_clone_serializable_complex_object_with_serializable_nested_object() {\n    // Arrange\n    ComplexObject original = new ComplexObject();\n    original.setName(\"Original\");\n    original.setNestedObject(new SerializableNestedObject(\"Nested\"));\n\n    // Act\n    ComplexObject clone = (ComplexObject) clone(original);\n\n    // Assert\n    assertNotSame(original, clone);\n    assertEquals(original.getName(), clone.getName());\n    assertNotSame(original.getNestedObject(), clone.getNestedObject());\n    assertEquals(original.getNestedObject().getName(), clone.getNestedObject().getName());\n}\n```"]}
{"id": 16, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testFullIndexSearchForSumAgg()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testFullIndexSearchForSumAgg", "reference": "  @Test\n  public void testFullIndexSearchForSumAgg() {\n    Instant time = Instant.ofEpochSecond(1593365471);\n    loadTestData(time);\n\n    SearchResult<LogMessage> allIndexItems =\n        strictLogStore.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"\",\n            0L,\n            MAX_TIME,\n            1000,\n            new SumAggBuilder(\"test\", TEST_SOURCE_LONG_PROPERTY, \"0\", null));\n\n    assertThat(allIndexItems.hits.size()).isEqualTo(4);\n\n    InternalSum internalSum =\n        (InternalSum) Objects.requireNonNull(allIndexItems.internalAggregation);\n\n    // 1, 3, 4, 5\n    assertThat(internalSum.getValue()).isEqualTo(13);\n  }", "completions": ["  ```java\n@Test\npublic void testFullIndexSearchForSumAgg() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any())).thenReturn(query);\n    CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector = mock(CollectorManager.class);\n    when(topFieldCollector.getLeafCollector(any())).thenReturn(mock(TopFieldCollector.class));\n    when(openSearchAdapter.getCollectorManager(any(), any(), any())).thenReturn(topFieldCollector);\n    ScoreDoc[] hits = new ScoreDoc[1];\n    hits[0] = new ScoreDoc(1, 1.0f, 1);\n    TopFieldDocs topFieldDocs = new TopFieldDocs(1, hits, new SortField(\"field\", SortField.Type.LONG));\n    when(searcher.search(any(), any())).thenReturn(topFieldDocs);\n    LogMessage logMessage = mock(LogMessage.class);\n    when(logMessage.getFieldValue(\"field\")).thenReturn(1L);\n    when(searcher.doc(anyInt())).thenReturn(logMessage);\n    InternalAggregation internalAggregation = mock(InternalAggregation.class);\n    when(internalAggregation.getProperty(\"_count\")).thenReturn(1L);\n    when(internalAggregation.getProperty(\"_sum\")).thenReturn(1L);\n    when(internalAggregation.getProperty(\"_avg\")).thenReturn(1.0);\n    when(internalAggregation.getProperty(\"_min\")).thenReturn(1L);\n    when(internalAggregation.getProperty(\"_max\")).thenReturn(1L);\n\n    // Call the method under test\n    LogIndexSearcherImpl logIndexSearcher = new LogIndexSearcherImpl(searcherManager, openSearchAdapter);\n    SearchResult<LogMessage> result = logIndexSearcher.search(\"dataset\", \"query\", 0L, 100L, 10, AggBuilder.sum(\"field\"));\n\n    // Verify the results\n    assertEquals(1, result.getTotalHits());\n    assertEquals(1, result.getTotalAggs());\n    assertEquals(1, result.getAggregations().size());\n    assertEquals(1L, result.getAggregations().get(0).getProperty(\"_count\"));\n    assertEquals(1L, result.getAggregations().get(0).getProperty(\"_sum\"));\n    assertEquals(1.0, result.getAggregations().get(0).getProperty(\"_avg\"));\n    assertEquals(1L, result.getAggregations().get(0).getProperty(\"_min\"));\n    assertEquals(1L, result.getAggregations().get(0).getProperty(\"_max\"));\n}\n```"]}
{"id": 17, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public void process(String base64AuthenticatorData, String signature, String clientDataJson, Fido2RegistrationData registration,\n                        Fido2AuthenticationData authenticationEntity) {\n        log.debug(\"Registration: {}\", registration);\n\n        AuthData authData = authenticatorDataParser.parseAssertionData(base64AuthenticatorData);\n        commonVerifiers.verifyRpIdHash(authData, registration.getDomain());\n\n        log.debug(\"User verification option: {}\", authenticationEntity.getUserVerificationOption());\n        userVerificationVerifier.verifyUserVerificationOption(authenticationEntity.getUserVerificationOption(), authData);\n\n        byte[] clientDataHash = DigestUtils.getSha256Digest().digest(base64Service.urlDecode(clientDataJson));\n\n        try {\n            int counter = authenticatorDataParser.parseCounter(authData.getCounters());\n            commonVerifiers.verifyCounter(registration.getCounter(), counter);\n            registration.setCounter(counter);\n\n            JsonNode uncompressedECPointNode = dataMapperService.cborReadTree(base64Service.urlDecode(registration.getUncompressedECPoint()));\n            PublicKey publicKey = coseService.createUncompressedPointFromCOSEPublicKey(uncompressedECPointNode);\n\n            log.debug(\"Uncompressed ECpoint node: {}\", uncompressedECPointNode);\n            log.debug(\"EC Public key hex: {}\", Hex.encodeHexString(publicKey.getEncoded()));\n            log.debug(\"Registration algorithm: {}, default use: -7\", registration.getSignatureAlgorithm());\n            authenticatorDataVerifier.verifyAssertionSignature(authData, clientDataHash, signature, publicKey, -7);\n\n        } catch (Fido2CompromisedDevice ex) {\n            log.error(\"Error compromised device: {}\", ex.getMessage());\n            throw ex;\n        } catch (Exception ex) {\n            log.error(\"Error to check none assertion: {}\", ex.getMessage());\n            throw new Fido2RuntimeException(\"Failed to check none assertion: {}\", ex.getMessage(), ex);\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    void process_ifCborReadTreeThrowException_fido2RuntimeException() throws Fido2CompromisedDevice, IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "process_ifCborReadTreeThrowException_fido2RuntimeException", "reference": "    @Test\n    void process_ifCborReadTreeThrowException_fido2RuntimeException() throws Fido2CompromisedDevice, IOException {\n        String base64AuthenticatorData = \"base64AuthenticatorData_test\";\n        String signature = \"signature_test\";\n        String clientDataJson = \"clientDataJson_test\";\n        Fido2RegistrationData registration = mock(Fido2RegistrationData.class);\n        Fido2AuthenticationData authenticationEntity = mock(Fido2AuthenticationData.class);\n\n        when(authenticationEntity.getUserVerificationOption()).thenReturn(UserVerification.preferred);\n        when(registration.getDomain()).thenReturn(\"domain_test\");\n        when(registration.getCounter()).thenReturn(100);\n        when(registration.getUncompressedECPoint()).thenReturn(\"uncompressedECPoint_test\");\n\n        when(authenticatorDataParser.parseAssertionData(any())).thenReturn(mock(AuthData.class));\n        when(base64Service.urlDecode(any(String.class))).thenReturn(\"decode_test\".getBytes());\n        when(dataMapperService.cborReadTree(any(byte[].class))).thenThrow(new IOException(\"IOException_test\"));\n\n        Fido2RuntimeException ex = assertThrows(Fido2RuntimeException.class, () -> noneAssertionFormatProcessor.process(base64AuthenticatorData, signature, clientDataJson, registration, authenticationEntity));\n        assertNotNull(ex);\n        assertEquals(ex.getMessage(), \"IOException_test\");\n\n        verify(log).debug(eq(\"Registration: {}\"), any(Fido2RegistrationData.class));\n        verify(log).debug(eq(\"User verification option: {}\"), any(UserVerification.class));\n        verify(commonVerifiers).verifyRpIdHash(any(AuthData.class), any(String.class));\n        verify(authenticatorDataParser).parseCounter(any());\n        verify(log).error(eq(\"Error to check none assertion: {}\"), any(String.class));\n\n        verify(log, never()).error(eq(\"Error compromised device: {}\"), any(String.class));\n        verifyNoInteractions(coseService, authenticatorDataVerifier);\n        verifyNoMoreInteractions(log);\n    }", "completions": ["  ```java\n    @Test\n    void process_ifCborReadTreeThrowException_fido2RuntimeException() throws Fido2CompromisedDevice, IOException {\n        // Setup\n        String base64AuthenticatorData = \"dummyAuthenticatorData\";\n        String signature = \"dummySignature\";\n        String clientDataJson = \"dummyClientDataJson\";\n        Fido2RegistrationData registration = mock(Fido2RegistrationData.class);\n        Fido2AuthenticationData authenticationEntity = mock(Fido2AuthenticationData.class);\n        when(registration.getDomain()).thenReturn(\"dummyDomain\");\n        when(authenticationEntity.getUserVerificationOption()).thenReturn(\"dummyUserVerificationOption\");\n        when(dataMapperService.cborReadTree(any())).thenThrow(new IOException(\"dummyException\"));\n\n        // Execute\n        Fido2AuthenticationService service = new Fido2AuthenticationService(authenticatorDataParser, commonVerifiers, userVerificationVerifier, dataMapperService, coseService);\n        try {\n            service.process(base64AuthenticatorData, signature, clientDataJson, registration, authenticationEntity);\n            fail(\"Expected Fido2RuntimeException\");\n        } catch (Fido2RuntimeException ex) {\n            // Verify\n            assertEquals(\"Failed to check none assertion: dummyException\", ex.getMessage());\n            assertEquals(\"dummyException\", ex.getCause().getMessage());\n        }\n    }\n```"]}
{"id": 18, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n\tpublic void setUserData(String theKey, Object theValue) {\n\t\tValidate.isTrue(isNotBlank(theKey), \"Invalid key; key must be non-empty, non-null.\");\n\t\tif (theValue == null) {\n\t\t\tgetUserData().remove(theKey);\n\t\t} else {\n\t\t\tValidate.isTrue(\n\t\t\t\t\tvalidateValue(theValue),\n\t\t\t\t\tString.format(\n\t\t\t\t\t\t\t\"Invalid data type provided %s\", theValue.getClass().getName()));\n\t\t\tgetUserData().put(theKey, theValue);\n\t\t}\n\t}\n```\n###test function signature:\n```java\n\t@Test\n\tpublic void setUserData_invalidKey_throws()\n```\n### Answer: (use the provided format with backticks)\n", "name": "setUserData_invalidKey_throws", "reference": "\t@Test\n\tpublic void setUserData_invalidKey_throws() {\n\t\t// setup\n\t\tTestParameters parameters = new TestParameters();\n\n\t\t// test\n\t\tfor (String key : new String[] { null, \"\" }) {\n\t\t\ttry {\n\t\t\t\tparameters.setUserData(key, \"test\");\n\t\t\t\tfail();\n\t\t\t} catch (IllegalArgumentException ex) {\n\t\t\t\tassertTrue(ex.getMessage().contains(\"Invalid key; key must be non-empty, non-null\"),\n\t\t\t\t\tex.getMessage());\n\t\t\t}\n\t\t}\n\t}", "completions": ["  ```\n@Test\npublic void setUserData_invalidKey_throws() {\n    String key = \"\";\n    Object value = new Object();\n    try {\n        setUserData(key, value);\n        fail(\"Expected IllegalArgumentException\");\n    } catch (IllegalArgumentException e) {\n        assertEquals(\"Invalid key; key must be non-empty, non-null.\", e.getMessage());\n    }\n}\n```"]}
{"id": 19, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  public ListenableFuture<Void> queue(ExecuteEntry executeEntry, Poller poller, Duration timeout) {\n    ExecuteOperationMetadata metadata =\n        ExecuteOperationMetadata.newBuilder()\n            .setActionDigest(executeEntry.getActionDigest())\n            .setStdoutStreamName(executeEntry.getStdoutStreamName())\n            .setStderrStreamName(executeEntry.getStderrStreamName())\n            .build();\n    Operation operation =\n        Operation.newBuilder()\n            .setName(executeEntry.getOperationName())\n            .setMetadata(Any.pack(metadata))\n            .build();\n    Digest actionDigest = executeEntry.getActionDigest();\n    ActionKey actionKey = DigestUtil.asActionKey(actionDigest);\n\n    Stopwatch stopwatch = Stopwatch.createStarted();\n    ListenableFuture<Boolean> cachedResultFuture;\n    if (executeEntry.getSkipCacheLookup()) {\n      cachedResultFuture = immediateFuture(false);\n    } else {\n      cachedResultFuture =\n          checkCacheFuture(actionKey, operation, executeEntry.getRequestMetadata());\n    }\n    return transformAsync(\n        cachedResultFuture,\n        (cachedResult) -> {\n          if (cachedResult) {\n            poller.pause();\n            long checkCacheUSecs = stopwatch.elapsed(MICROSECONDS);\n            log.log(\n                Level.FINER,\n                format(\n                    \"ServerInstance(%s): checkCache(%s): %sus elapsed\",\n                    getName(), operation.getName(), checkCacheUSecs));\n            return IMMEDIATE_VOID_FUTURE;\n          }\n          return transformAndQueue(executeEntry, poller, operation, stopwatch, timeout);\n        },\n        operationTransformService);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void queueDirectoryMissingErrorsOperation() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "queueDirectoryMissingErrorsOperation", "reference": "  @Test\n  public void queueDirectoryMissingErrorsOperation() throws Exception {\n    ByteString foo = ByteString.copyFromUtf8(\"foo\");\n    Digest subdirDigest = DIGEST_UTIL.compute(foo);\n    Directory inputRoot =\n        Directory.newBuilder()\n            .addDirectories(\n                DirectoryNode.newBuilder().setName(\"missing-subdir\").setDigest(subdirDigest))\n            .build();\n    ByteString inputRootContent = inputRoot.toByteString();\n    Digest inputRootDigest = DIGEST_UTIL.compute(inputRootContent);\n    provideBlob(inputRootDigest, inputRootContent);\n    Action action = createAction(true, true, inputRootDigest, SIMPLE_COMMAND);\n    Digest actionDigest = DIGEST_UTIL.compute(action);\n\n    ExecuteEntry executeEntry =\n        ExecuteEntry.newBuilder()\n            .setOperationName(\"missing-directory-operation\")\n            .setActionDigest(actionDigest)\n            .setSkipCacheLookup(true)\n            .build();\n\n    when(mockBackplane.propertiesEligibleForQueue(anyList())).thenReturn(true);\n\n    when(mockBackplane.canQueue()).thenReturn(true);\n\n    Poller poller = mock(Poller.class);\n\n    boolean failedPreconditionExceptionCaught = false;\n    try {\n      instance\n          .queue(executeEntry, poller, DEFAULT_TIMEOUT)\n          .get(QUEUE_TEST_TIMEOUT_SECONDS, SECONDS);\n    } catch (ExecutionException e) {\n      com.google.rpc.Status status = StatusProto.fromThrowable(e);\n      if (status.getCode() == Code.FAILED_PRECONDITION.getNumber()) {\n        failedPreconditionExceptionCaught = true;\n      } else {\n        e.getCause().printStackTrace();\n      }\n    }\n    assertThat(failedPreconditionExceptionCaught).isTrue();\n\n    PreconditionFailure preconditionFailure =\n        PreconditionFailure.newBuilder()\n            .addViolations(\n                Violation.newBuilder()\n                    .setType(VIOLATION_TYPE_MISSING)\n                    .setSubject(\"blobs/\" + DigestUtil.toString(subdirDigest))\n                    .setDescription(\"The directory `/missing-subdir` was not found in the CAS.\"))\n            .build();\n    ExecuteResponse executeResponse =\n        ExecuteResponse.newBuilder()\n            .setStatus(\n                com.google.rpc.Status.newBuilder()\n                    .setCode(Code.FAILED_PRECONDITION.getNumber())\n                    .setMessage(invalidActionVerboseMessage(actionDigest, preconditionFailure))\n                    .addDetails(Any.pack(preconditionFailure)))\n            .build();\n    assertResponse(executeResponse);\n    verify(poller, atLeastOnce()).pause();\n  }", "completions": ["  ```java\n  @Test\n  public void queueDirectoryMissingErrorsOperation() throws Exception {\n    // arrange\n    ExecuteEntry executeEntry = mock(ExecuteEntry.class);\n    Poller poller = mock(Poller.class);\n    Duration timeout = mock(Duration.class);\n    when(executeEntry.getActionDigest()).thenReturn(mock(Digest.class));\n    when(executeEntry.getStdoutStreamName()).thenReturn(\"stdout\");\n    when(executeEntry.getStderrStreamName()).thenReturn(\"stderr\");\n    when(executeEntry.getOperationName()).thenReturn(\"operation\");\n    when(executeEntry.getRequestMetadata()).thenReturn(mock(RequestMetadata.class));\n    when(executeEntry.getSkipCacheLookup()).thenReturn(false);\n    when(poller.pause()).thenReturn(mock(ListenableFuture.class));\n    when(timeout.getSeconds()).thenReturn(10L);\n    when(timeout.getNano()).thenReturn(0L);\n\n    // act\n    ListenableFuture<Void> result = queue(executeEntry, poller, timeout);\n\n    // assert\n    assertThat(result, is(notNullValue()));\n    verify(executeEntry, times(1)).getActionDigest();\n    verify(executeEntry, times(1)).getStdoutStreamName();\n    verify(executeEntry, times(1)).getStderrStreamName();\n    verify(executeEntry, times(1)).getOperationName();\n    verify(executeEntry, times(1)).getRequestMetadata();\n    verify(executeEntry, times(1)).getSkipCacheLookup();\n    verify(poller, times(1)).pause();\n    verify(timeout, times(1)).getSeconds();\n    verify(timeout, times(1)).getNano();\n  }\n```"]}
{"id": 20, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  boolean handleRecoveryTask(RecoveryTaskMetadata recoveryTaskMetadata) {\n    LOG.info(\"Started handling the recovery task: {}\", recoveryTaskMetadata);\n    long startTime = System.nanoTime();\n    Timer.Sample taskTimer = Timer.start(meterRegistry);\n\n    PartitionOffsets partitionOffsets =\n        validateKafkaOffsets(\n            adminClient,\n            recoveryTaskMetadata,\n            AstraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic());\n    long offsetsValidatedTime = System.nanoTime();\n    long consumerPreparedTime = 0, messagesConsumedTime = 0, rolloversCompletedTime = 0;\n\n    if (partitionOffsets != null) {\n      RecoveryTaskMetadata validatedRecoveryTask =\n          new RecoveryTaskMetadata(\n              recoveryTaskMetadata.name,\n              recoveryTaskMetadata.partitionId,\n              partitionOffsets.startOffset,\n              partitionOffsets.endOffset,\n              recoveryTaskMetadata.createdTimeEpochMs);\n\n      if (partitionOffsets.startOffset != recoveryTaskMetadata.startOffset\n          || recoveryTaskMetadata.endOffset != partitionOffsets.endOffset) {\n        recoveryRecordsNoLongerAvailable.increment(\n            (partitionOffsets.startOffset - recoveryTaskMetadata.startOffset)\n                + (partitionOffsets.endOffset - recoveryTaskMetadata.endOffset));\n      }\n\n      try {\n        RecoveryChunkManager<LogMessage> chunkManager =\n            RecoveryChunkManager.fromConfig(\n                meterRegistry,\n                searchMetadataStore,\n                snapshotMetadataStore,\n                AstraConfig.getIndexerConfig(),\n                blobFs,\n                AstraConfig.getS3Config());\n\n        // Ingest data in parallel\n        LogMessageWriterImpl logMessageWriterImpl = new LogMessageWriterImpl(chunkManager);\n        AstraKafkaConsumer kafkaConsumer =\n            new AstraKafkaConsumer(\n                makeKafkaConfig(\n                    AstraConfig.getRecoveryConfig().getKafkaConfig(),\n                    validatedRecoveryTask.partitionId),\n                logMessageWriterImpl,\n                meterRegistry);\n\n        kafkaConsumer.prepConsumerForConsumption(validatedRecoveryTask.startOffset);\n        consumerPreparedTime = System.nanoTime();\n        kafkaConsumer.consumeMessagesBetweenOffsetsInParallel(\n            AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS,\n            validatedRecoveryTask.startOffset,\n            validatedRecoveryTask.endOffset);\n        messagesConsumedTime = System.nanoTime();\n        // Wait for chunks to upload.\n        boolean success = chunkManager.waitForRollOvers();\n        rolloversCompletedTime = System.nanoTime();\n        // Close the recovery chunk manager and kafka consumer.\n        kafkaConsumer.close();\n        chunkManager.stopAsync();\n        chunkManager.awaitTerminated(DEFAULT_START_STOP_DURATION);\n        LOG.info(\"Finished handling the recovery task: {}\", validatedRecoveryTask);\n        taskTimer.stop(recoveryTaskTimerSuccess);\n        return success;\n      } catch (Exception ex) {\n        LOG.error(\"Exception in recovery task [{}]: {}\", validatedRecoveryTask, ex);\n        taskTimer.stop(recoveryTaskTimerFailure);\n        return false;\n      } finally {\n        long endTime = System.nanoTime();\n        LOG.info(\n            \"Recovery task {} took {}ms, (subtask times offset validation {}, consumer prep {}, msg consumption {}, rollover {})\",\n            recoveryTaskMetadata,\n            nanosToMillis(endTime - startTime),\n            nanosToMillis(offsetsValidatedTime - startTime),\n            nanosToMillis(consumerPreparedTime - offsetsValidatedTime),\n            nanosToMillis(messagesConsumedTime - consumerPreparedTime),\n            nanosToMillis(rolloversCompletedTime - messagesConsumedTime));\n      }\n    } else {\n      LOG.info(\n          \"Recovery task {} data no longer available in Kafka (validation time {}ms)\",\n          recoveryTaskMetadata,\n          nanosToMillis(offsetsValidatedTime - startTime));\n      recoveryRecordsNoLongerAvailable.increment(\n          recoveryTaskMetadata.endOffset - recoveryTaskMetadata.startOffset + 1);\n      return true;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testShouldHandleRecoveryTaskWithPartiallyUnavailableOffsets() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testShouldHandleRecoveryTaskWithPartiallyUnavailableOffsets", "reference": "  @Test\n  public void testShouldHandleRecoveryTaskWithPartiallyUnavailableOffsets() throws Exception {\n    final TopicPartition topicPartition = new TopicPartition(TestKafkaServer.TEST_KAFKA_TOPIC, 0);\n    TestKafkaServer.KafkaComponents components = getKafkaTestServer(S3_MOCK_EXTENSION);\n    AstraConfigs.AstraConfig astraCfg =\n        makeAstraConfig(components.testKafkaServer, TEST_S3_BUCKET, topicPartition.topic());\n    curatorFramework =\n        CuratorBuilder.build(meterRegistry, astraCfg.getMetadataStoreConfig().getZookeeperConfig());\n\n    AstraConfigs.KafkaConfig kafkaConfig =\n        AstraConfigs.KafkaConfig.newBuilder()\n            .setKafkaTopic(topicPartition.topic())\n            .setKafkaTopicPartition(Integer.toString(topicPartition.partition()))\n            .setKafkaBootStrapServers(components.testKafkaServer.getBroker().getBrokerList().get())\n            .setKafkaClientGroup(TEST_KAFKA_CLIENT_GROUP)\n            .setEnableKafkaAutoCommit(\"true\")\n            .setKafkaAutoCommitInterval(\"500\")\n            .setKafkaSessionTimeout(\"500\")\n            .putAllAdditionalProps(Maps.fromProperties(components.consumerOverrideProps))\n            .build();\n\n    final AstraKafkaConsumer localTestConsumer =\n        new AstraKafkaConsumer(kafkaConfig, components.logMessageWriter, components.meterRegistry);\n    final Instant startTime = Instant.now();\n    final long msgsToProduce = 100;\n    TestKafkaServer.produceMessagesToKafka(\n        components.testKafkaServer.getBroker(),\n        startTime,\n        topicPartition.topic(),\n        topicPartition.partition(),\n        (int) msgsToProduce);\n    await().until(() -> localTestConsumer.getEndOffSetForPartition() == msgsToProduce);\n    // we immediately force delete the messages, as this is faster than changing the retention and\n    // waiting for the cleaner to run\n    components\n        .adminClient\n        .deleteRecords(Map.of(topicPartition, RecordsToDelete.beforeOffset(100)))\n        .all()\n        .get();\n    assertThat(getStartOffset(components.adminClient, topicPartition)).isGreaterThan(0);\n\n    // produce some more messages that won't be expired\n    setRetentionTime(components.adminClient, topicPartition.topic(), 25000);\n    TestKafkaServer.produceMessagesToKafka(\n        components.testKafkaServer.getBroker(),\n        startTime,\n        topicPartition.topic(),\n        topicPartition.partition(),\n        (int) msgsToProduce);\n    await()\n        .until(() -> localTestConsumer.getEndOffSetForPartition() == msgsToProduce + msgsToProduce);\n\n    SnapshotMetadataStore snapshotMetadataStore = new SnapshotMetadataStore(curatorFramework);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore).size()).isZero();\n\n    // Start recovery service\n    recoveryService =\n        new RecoveryService(astraCfg, curatorFramework, components.meterRegistry, blobFs);\n    recoveryService.startAsync();\n    recoveryService.awaitRunning(DEFAULT_START_STOP_DURATION);\n\n    // Start recovery with an offset range that is partially unavailable\n    long startOffset = 50;\n    long endOffset = 150;\n    RecoveryTaskMetadata recoveryTask =\n        new RecoveryTaskMetadata(\n            topicPartition.topic(),\n            Integer.toString(topicPartition.partition()),\n            startOffset,\n            endOffset,\n            Instant.now().toEpochMilli());\n    assertThat(recoveryService.handleRecoveryTask(recoveryTask)).isTrue();\n    assertThat(getCount(RECORDS_NO_LONGER_AVAILABLE, components.meterRegistry)).isEqualTo(50);\n    assertThat(getCount(MESSAGES_RECEIVED_COUNTER, components.meterRegistry)).isEqualTo(51);\n    List<SnapshotMetadata> snapshots =\n        AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore);\n    assertThat(snapshots.size()).isEqualTo(1);\n    assertThat(blobFs.listFiles(BlobFsUtils.createURI(TEST_S3_BUCKET, \"/\", \"\"), true)).isNotEmpty();\n    assertThat(blobFs.exists(URI.create(snapshots.get(0).snapshotPath))).isTrue();\n    assertThat(blobFs.listFiles(URI.create(snapshots.get(0).snapshotPath), false).length)\n        .isGreaterThan(1);\n    assertThat(getCount(MESSAGES_FAILED_COUNTER, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_INITIATED, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_COMPLETED, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_FAILED, meterRegistry)).isEqualTo(0);\n  }", "completions": ["  ```java\n@Test\npublic void testShouldHandleRecoveryTaskWithPartiallyUnavailableOffsets() throws Exception {\n    // Set up mocks\n    AdminClient adminClient = mock(AdminClient.class);\n    MeterRegistry meterRegistry = mock(MeterRegistry.class);\n    SearchMetadataStore searchMetadataStore = mock(SearchMetadataStore.class);\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    BlobFs blobFs = mock(BlobFs.class);\n    AstraConfig astraConfig = mock(AstraConfig.class);\n    RecoveryTaskMetadata recoveryTaskMetadata = mock(RecoveryTaskMetadata.class);\n    PartitionOffsets partitionOffsets = mock(PartitionOffsets.class);\n    RecoveryChunkManager<LogMessage> chunkManager = mock(RecoveryChunkManager.class);\n    LogMessageWriterImpl logMessageWriterImpl = mock(LogMessageWriterImpl.class);\n    AstraKafkaConsumer kafkaConsumer = mock(AstraKafkaConsumer.class);\n\n    // Set up expectations\n    when(astraConfig.getRecoveryConfig()).thenReturn(mock(RecoveryConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig()).thenReturn(mock(KafkaConfig.class));\n    when(astraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic()).thenReturn(\"test-topic\");\n    when(recoveryTaskMetadata.name).thenReturn(\"test-task\");\n    when(recoveryTaskMetadata.partitionId).thenReturn(1);\n    when(recoveryTaskMetadata.startOffset).thenReturn(100L);\n    when(recoveryTaskMetadata.endOffset).thenReturn(200L);\n    when(recoveryTaskMetadata.createdTimeEpochMs).thenReturn(1000L);\n    when(partitionOffsets.startOffset).thenReturn(100L);\n    when(partitionOffsets.endOffset).thenReturn(200L);\n    when(chunkManager.waitForRollOvers()).thenReturn(true);\n    when(kafkaConsumer.prepConsumerForConsumption(100L)).thenReturn(null);\n    when(kafkaConsumer.consumeMessagesBetweenOffsetsInParallel(AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS, 100L, 200L)).thenReturn(null);\n\n    // Call the method under test\n    boolean result = handleRecoveryTask(recoveryTaskMetadata);\n\n    // Verify the results\n    assertTrue(result);\n    verify(recoveryTaskMetadata, times(1)).name;\n    verify(recoveryTaskMetadata, times(1)).partitionId;\n    verify(recoveryTaskMetadata, times(1)).startOffset;\n    verify(recoveryTaskMetadata, times(1)).endOffset;\n    verify(recoveryTaskMetadata, times(1)).createdTimeEpochMs;\n    verify(partitionOffsets, times(1)).startOffset;\n    verify(partitionOffsets, times(1)).endOffset;\n    verify(chunkManager, times(1)).waitForRollOvers();\n    verify(kafkaConsumer, times(1)).prepConsumerForConsumption(100L);\n    verify(kafkaConsumer, times(1)).consumeMessagesBetweenOffsetsInParallel(AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS, 100L, 200L);\n}\n```"]}
{"id": 21, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public List<MediaType> selectHeaderAccept(String[] accepts) {\n        if (accepts.length == 0) {\n            return null;\n        }\n        for (String accept : accepts) {\n            MediaType mediaType = MediaType.parseMediaType(accept);\n            if (isJsonMime(mediaType) && !isProblemJsonMime(accept)) {\n                return Collections.singletonList(mediaType);\n            }\n        }\n        return MediaType.parseMediaTypes(StringUtils.arrayToCommaDelimitedString(accepts));\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testSelectHeaderAccept()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSelectHeaderAccept", "reference": "    @Test\n    public void testSelectHeaderAccept() {\n        String[] accepts = {\"application/json\", \"application/xml\"};\n        assertEquals(\"application/json\", apiClient.selectHeaderAccept(accepts));\n\n        accepts = new String[]{\"APPLICATION/XML\", \"APPLICATION/JSON\"};\n        assertEquals(\"APPLICATION/JSON\", apiClient.selectHeaderAccept(accepts));\n\n        accepts = new String[]{\"application/xml\", \"application/json; charset=UTF8\"};\n        assertEquals(\"application/json; charset=UTF8\", apiClient.selectHeaderAccept(accepts));\n\n        accepts = new String[]{\"text/plain\", \"application/xml\"};\n        assertEquals(\"text/plain,application/xml\", apiClient.selectHeaderAccept(accepts));\n\n        accepts = new String[]{};\n        assertNull(apiClient.selectHeaderAccept(accepts));\n    }", "completions": ["  ```\n@Test\npublic void testSelectHeaderAccept() {\n    // Test with empty array\n    String[] accepts = new String[0];\n    List<MediaType> result = selectHeaderAccept(accepts);\n    assertNull(result);\n\n    // Test with single accept header\n    accepts = new String[] {\"application/json\"};\n    result = selectHeaderAccept(accepts);\n    assertEquals(1, result.size());\n    assertEquals(\"application/json\", result.get(0).toString());\n\n    // Test with multiple accept headers\n    accepts = new String[] {\"application/json\", \"text/plain\"};\n    result = selectHeaderAccept(accepts);\n    assertEquals(2, result.size());\n    assertEquals(\"application/json\", result.get(0).toString());\n    assertEquals(\"text/plain\", result.get(1).toString());\n\n    // Test with invalid accept header\n    accepts = new String[] {\"invalid/header\"};\n    result = selectHeaderAccept(accepts);\n    assertNull(result);\n\n    // Test with problem JSON accept header\n    accepts = new String[] {\"application/problem+json\"};\n    result = selectHeaderAccept(accepts);\n    assertNull(result);\n}\n```"]}
{"id": 22, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public ConsumerRecords<K, V> poll(final Duration timeout) {\n        Timer timer = time.timer(timeout);\n\n        acquireAndEnsureOpen();\n        try {\n            kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());\n\n            if (subscriptions.hasNoSubscriptionOrUserAssignment()) {\n                throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n            }\n\n            do {\n\n                // Make sure to let the background thread know that we are still polling.\n                applicationEventHandler.add(new PollEvent(timer.currentTimeMs()));\n\n                // We must not allow wake-ups between polling for fetches and returning the records.\n                // If the polled fetches are not empty the consumed position has already been updated in the polling\n                // of the fetches. A wakeup between returned fetches and returning records would lead to never\n                // returning the records in the fetches. Thus, we trigger a possible wake-up before we poll fetches.\n                wakeupTrigger.maybeTriggerWakeup();\n\n                updateAssignmentMetadataIfNeeded(timer);\n                final Fetch<K, V> fetch = pollForFetches(timer);\n                if (!fetch.isEmpty()) {\n                    if (fetch.records().isEmpty()) {\n                        log.trace(\"Returning empty records from `poll()` \"\n                            + \"since the consumer's position has advanced for at least one topic partition\");\n                    }\n\n                    return interceptors.onConsume(new ConsumerRecords<>(fetch.records()));\n                }\n                // We will wait for retryBackoffMs\n            } while (timer.notExpired());\n\n            return ConsumerRecords.empty();\n        } finally {\n            kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testEnsurePollEventSentOnConsumerPoll()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testEnsurePollEventSentOnConsumerPoll", "reference": "    @Test\n    public void testEnsurePollEventSentOnConsumerPoll() {\n        SubscriptionState subscriptions = new SubscriptionState(new LogContext(), OffsetResetStrategy.NONE);\n        consumer = newConsumer(\n                mock(FetchBuffer.class),\n                new ConsumerInterceptors<>(Collections.emptyList()),\n                mock(ConsumerRebalanceListenerInvoker.class),\n                subscriptions,\n                singletonList(new RoundRobinAssignor()),\n                \"group-id\",\n                \"client-id\");\n        final TopicPartition tp = new TopicPartition(\"topic\", 0);\n        final List<ConsumerRecord<String, String>> records = singletonList(\n                new ConsumerRecord<>(\"topic\", 0, 2, \"key1\", \"value1\"));\n        doAnswer(invocation -> Fetch.forPartition(tp, records, true))\n                .when(fetchCollector)\n                .collectFetch(Mockito.any(FetchBuffer.class));\n\n        consumer.subscribe(singletonList(\"topic1\"));\n        consumer.poll(Duration.ofMillis(100));\n        verify(applicationEventHandler).add(any(PollEvent.class));\n    }", "completions": ["  ```java\n    @Test\n    public void testEnsurePollEventSentOnConsumerPoll() {\n        // Set up the consumer and its dependencies\n        Consumer<String, String> consumer = new Consumer<>(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null"]}
{"id": 23, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public long determineStartingOffset(\n      long currentEndOffsetForPartition,\n      long currentBeginningOffsetForPartition,\n      AstraConfigs.IndexerConfig indexerConfig) {\n    // Filter stale snapshots for partition.\n    if (partitionId == null) {\n      LOG.warn(\"PartitionId can't be null.\");\n    }\n\n    List<SnapshotMetadata> snapshots = snapshotMetadataStore.listSync();\n    List<SnapshotMetadata> snapshotsForPartition =\n        snapshots.stream()\n            .filter(\n                snapshotMetadata -> {\n                  if (snapshotMetadata == null || snapshotMetadata.partitionId == null) {\n                    LOG.warn(\n                        \"snapshot metadata or partition id can't be null: {} \",\n                        Strings.join(snapshots, ','));\n                  }\n                  return snapshotMetadata != null\n                      && snapshotMetadata.partitionId != null\n                      && snapshotMetadata.partitionId.equals(partitionId);\n                })\n            .collect(Collectors.toUnmodifiableList());\n    List<SnapshotMetadata> deletedSnapshots = deleteStaleLiveSnapshots(snapshotsForPartition);\n\n    List<SnapshotMetadata> nonLiveSnapshotsForPartition =\n        snapshotsForPartition.stream()\n            .filter(s -> !deletedSnapshots.contains(s))\n            .collect(Collectors.toUnmodifiableList());\n\n    // Get the highest offset that is indexed in durable store.\n    List<RecoveryTaskMetadata> recoveryTasks = recoveryTaskMetadataStore.listSync();\n    long highestDurableOffsetForPartition =\n        getHighestDurableOffsetForPartition(\n            nonLiveSnapshotsForPartition, recoveryTasks, partitionId);\n    LOG.debug(\n        \"The highest durable offset for partition {} is {}\",\n        partitionId,\n        highestDurableOffsetForPartition);\n\n    if (highestDurableOffsetForPartition <= 0) {\n      LOG.info(\"There is no prior offset for this partition {}.\", partitionId);\n\n      // If the user wants to start at the current offset in Kafka and _does not_ want to create\n      // recovery tasks to backfill, then we can just return the current offset.\n      // If the user wants to start at the current offset in Kafka and _does_ want to create\n      // recovery tasks to backfill, then we create the recovery tasks needed and then return\n      // the current offset for the indexer. And if the user does _not_ want to start at the\n      // current offset in Kafka, then we'll just default to the old behavior of starting from\n      // the very beginning\n      if (!indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set to false and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" NOT spinning up recovery tasks\");\n        return currentEndOffsetForPartition;\n      } else if (indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        // Todo - this appears to be able to create recovery tasks that have a start and end\n        // position of 0, which is invalid. This seems to occur when new clusters are initialized,\n        // and is  especially problematic when indexers are created but never get assigned (ie,\n        // deploy 5, only assign 3).\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" spinning up recovery tasks\");\n        createRecoveryTasks(\n            partitionId,\n            currentBeginningOffsetForPartition,\n            currentEndOffsetForPartition,\n            indexerConfig.getMaxMessagesPerChunk());\n        return currentEndOffsetForPartition;\n\n      } else {\n        return highestDurableOffsetForPartition;\n      }\n    }\n\n    // The current head offset shouldn't be lower than the highest durable offset. If it is it\n    // means that we indexed more data than the current head offset. This is either a bug in the\n    // offset handling mechanism or the kafka partition has rolled over. We throw an exception\n    // for now, so we can investigate.\n    if (currentEndOffsetForPartition < highestDurableOffsetForPartition) {\n      final String message =\n          String.format(\n              \"The current head for the partition %d can't \"\n                  + \"be lower than the highest durable offset for that partition %d\",\n              currentEndOffsetForPartition, highestDurableOffsetForPartition);\n      LOG.error(message);\n      throw new IllegalStateException(message);\n    }\n\n    // The head offset for Kafka partition is the offset of the next message to be indexed. We\n    // assume that offset is passed into this function. The highest durable offset is the partition\n    // offset of the message that is indexed. Hence, the offset is incremented by 1 to get the\n    // next message.\n    long nextOffsetForPartition = highestDurableOffsetForPartition + 1;\n\n    // Create a recovery task if needed.\n    if (currentEndOffsetForPartition - highestDurableOffsetForPartition > maxOffsetDelay) {\n      LOG.info(\n          \"Recovery task needed. The current position {} and head location {} are higher than max\"\n              + \" offset {}\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay);\n      createRecoveryTasks(\n          partitionId,\n          nextOffsetForPartition,\n          currentEndOffsetForPartition - 1,\n          maxMessagesPerRecoveryTask);\n      return currentEndOffsetForPartition;\n    } else {\n      LOG.info(\n          \"The difference between the last indexed position {} and head location {} is lower \"\n              + \"than max offset {}. So, using {} position as the start offset\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay,\n          nextOffsetForPartition);\n      return nextOffsetForPartition;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testDetermineStartingOffsetMultiplePartitionRecoveriesBehind()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDetermineStartingOffsetMultiplePartitionRecoveriesBehind", "reference": "  @Test\n  public void testDetermineStartingOffsetMultiplePartitionRecoveriesBehind() {\n    RecoveryTaskCreator recoveryTaskCreator =\n        new RecoveryTaskCreator(\n            snapshotMetadataStore,\n            recoveryTaskStore,\n            partitionId,\n            100,\n            TEST_MAX_MESSAGES_PER_RECOVERY_TASK,\n            meterRegistry);\n\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore)).isEmpty();\n\n    // When there is no data return -1.\n    assertThat(recoveryTaskCreator.determineStartingOffset(1000, 0, indexerConfig)).isNegative();\n    final String recoveryTaskName = \"BasicRecoveryTask\";\n    final long recoveryStartOffset = 400;\n    final long createdTimeUtc = Instant.now().toEpochMilli();\n\n    final RecoveryTaskMetadata recoveryTask1 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"1\",\n            partitionId,\n            recoveryStartOffset,\n            recoveryStartOffset * 2,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask1);\n    final RecoveryTaskMetadata recoveryTask11 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"11\",\n            partitionId,\n            recoveryStartOffset * 2 + 1,\n            recoveryStartOffset * 3,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask11);\n    final RecoveryTaskMetadata recoveryTask2 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"2\",\n            \"2\",\n            recoveryStartOffset * 3 + 1,\n            recoveryStartOffset * 4,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask2);\n    final RecoveryTaskMetadata recoveryTask21 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"21\", \"2\", recoveryStartOffset * 4 + 1, 50000, createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask21);\n    await()\n        .until(\n            () ->\n                recoveryTaskStore\n                    .listSync()\n                    .containsAll(\n                        List.of(recoveryTask1, recoveryTask11, recoveryTask2, recoveryTask21)));\n\n    final long currentHeadOffset = 4000;\n    assertThat(recoveryTaskCreator.determineStartingOffset(currentHeadOffset, 0, indexerConfig))\n        .isEqualTo(currentHeadOffset);\n    List<RecoveryTaskMetadata> recoveryTasks =\n        AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore);\n    assertThat(recoveryTasks.size()).isEqualTo(5);\n    assertThat(recoveryTasks)\n        .contains(recoveryTask1, recoveryTask11, recoveryTask2, recoveryTask21);\n    Optional<RecoveryTaskMetadata> newRecoveryTask =\n        recoveryTasks.stream().filter(r -> !r.name.contains(recoveryTaskName)).findFirst();\n    assertThat(newRecoveryTask).isNotEmpty();\n    RecoveryTaskMetadata recoveryTask = newRecoveryTask.get();\n    assertThat(recoveryTask.startOffset).isEqualTo((recoveryStartOffset * 3) + 1);\n    assertThat(recoveryTask.endOffset).isEqualTo(currentHeadOffset - 1);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n  }", "completions": ["  ```\n@Test\npublic void testDetermineStartingOffsetMultiplePartitionRecoveriesBehind() {\n    // Set up mocks\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    RecoveryTaskMetadataStore recoveryTaskMetadataStore = mock(RecoveryTaskMetadataStore.class);\n    AstraConfigs.IndexerConfig indexerConfig = mock(AstraConfigs.IndexerConfig.class);\n\n    // Set up test data\n    long currentEndOffsetForPartition = 100;\n    long currentBeginningOffsetForPartition = 50;\n    long maxOffsetDelay = 10;\n    long maxMessagesPerRecoveryTask = 10;\n    List<SnapshotMetadata> snapshots = new ArrayList<>();\n    List<RecoveryTaskMetadata> recoveryTasks = new ArrayList<>();\n\n    // Set up mock behavior\n    when(snapshotMetadataStore.listSync()).thenReturn(snapshots);\n    when(recoveryTaskMetadataStore.listSync()).thenReturn(recoveryTasks);\n    when(indexerConfig.getMaxMessagesPerChunk()).thenReturn(maxMessagesPerRecoveryTask);\n\n    // Call the method under test\n    long startingOffset = determineStartingOffset(currentEndOffsetForPartition, currentBeginningOffsetForPartition, indexerConfig);\n\n    // Verify the results\n    assertEquals(currentEndOffsetForPartition, startingOffset);\n    verify(snapshotMetadataStore, times(1)).listSync();\n    verify(recoveryTaskMetadataStore, times(1)).listSync();\n    verify(indexerConfig, times(1)).getMaxMessagesPerChunk();\n}\n```"]}
{"id": 24, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public CompletableFuture<Void> commitStreamObject(apache.rocketmq.controller.v1.S3StreamObject streamObject,\n        List<Long> compactedObjects) {\n        LOGGER.info(\"commitStreamObject with streamObject: {}, compactedObjects: {}\", TextFormat.shortDebugString(streamObject),\n            compactedObjects);\n\n        CompletableFuture<Void> future = new CompletableFuture<>();\n        try (SqlSession session = sessionFactory.openSession()) {\n            if (streamObject.getObjectId() == S3Constants.NOOP_OBJECT_ID) {\n                LOGGER.error(\"S3StreamObject[object-id={}] is null or objectId is unavailable\", streamObject.getObjectId());\n                String msg = String.format(\"S3StreamObject[object-id=%d] is null or objectId is unavailable\",\n                    streamObject.getObjectId());\n                ControllerException e = new ControllerException(Code.NOT_FOUND_VALUE, msg);\n                future.completeExceptionally(e);\n                return future;\n            }\n\n            long committedTs = System.currentTimeMillis();\n            S3ObjectMapper s3ObjectMapper = session.getMapper(S3ObjectMapper.class);\n            S3StreamObjectMapper s3StreamObjectMapper = session.getMapper(S3StreamObjectMapper.class);\n\n            // commit object\n            if (!commitObject(streamObject.getObjectId(), streamObject.getStreamId(), streamObject.getObjectSize(), session)) {\n                String msg = String.format(\"S3StreamObject[object-id=%d] is not ready for commit\",\n                    streamObject.getObjectId());\n                ControllerException e = new ControllerException(Code.ILLEGAL_STATE_VALUE, msg);\n                future.completeExceptionally(e);\n                return future;\n            }\n            long dataTs = committedTs;\n            if (!Objects.isNull(compactedObjects) && !compactedObjects.isEmpty()) {\n                dataTs = compactedObjects.stream()\n                    .map(id -> {\n                        // mark destroy compacted object\n                        S3Object object = s3ObjectMapper.getById(id);\n                        object.setState(S3ObjectState.BOS_WILL_DELETE);\n                        object.setMarkedForDeletionTimestamp(new Date());\n                        s3ObjectMapper.markToDelete(object.getId(), new Date());\n\n                        // update dataTs to the min compacted object's dataTs\n                        com.automq.rocketmq.metadata.dao.S3StreamObject s3StreamObject =\n                            s3StreamObjectMapper.getByObjectId(id);\n                        return s3StreamObject.getBaseDataTimestamp().getTime();\n                    })\n                    .min(Long::compareTo).get();\n            }\n\n            List<com.automq.rocketmq.metadata.dao.S3StreamObject> toCache = new ArrayList<>();\n\n            // create a new S3StreamObject to replace committed ones\n            if (streamObject.getObjectId() != S3Constants.NOOP_OBJECT_ID) {\n                com.automq.rocketmq.metadata.dao.S3StreamObject newS3StreamObj =\n                    new com.automq.rocketmq.metadata.dao.S3StreamObject();\n                newS3StreamObj.setStreamId(streamObject.getStreamId());\n                newS3StreamObj.setObjectId(streamObject.getObjectId());\n                newS3StreamObj.setObjectSize(streamObject.getObjectSize());\n                newS3StreamObj.setStartOffset(streamObject.getStartOffset());\n                newS3StreamObj.setEndOffset(streamObject.getEndOffset());\n                newS3StreamObj.setBaseDataTimestamp(new Date(dataTs));\n                newS3StreamObj.setCommittedTimestamp(new Date(committedTs));\n                s3StreamObjectMapper.create(newS3StreamObj);\n                toCache.add(newS3StreamObj);\n            }\n\n            // delete the compactedObjects of S3Stream\n            if (!Objects.isNull(compactedObjects) && !compactedObjects.isEmpty()) {\n                compactedObjects.forEach(id -> s3StreamObjectMapper.delete(null, null, id));\n            }\n            session.commit();\n\n            // Update Cache\n            s3StreamObjectCache.cache(streamObject.getStreamId(), toCache);\n            s3StreamObjectCache.onCompact(streamObject.getStreamId(), compactedObjects);\n\n            LOGGER.info(\"S3StreamObject[object-id={}] commit success, compacted objects: {}\",\n                streamObject.getObjectId(), compactedObjects);\n            future.complete(null);\n        } catch (Exception e) {\n            LOGGER.error(\"CommitStream failed\", e);\n            ControllerException ex = new ControllerException(Code.INTERNAL_VALUE, \"CommitStream failed\" + e.getMessage());\n            future.completeExceptionally(ex);\n        }\n        return future;\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testCommitStreamObject() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testCommitStreamObject", "reference": "    @Test\n    public void testCommitStreamObject() throws IOException {\n        long objectId, streamId = 1;\n\n        try (S3MetadataService metadataService = new DefaultS3MetadataService(config, getSessionFactory(), executorService)) {\n            objectId = metadataService.prepareS3Objects(3, 5).get();\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n\n        S3StreamObject news3StreamObject = S3StreamObject.newBuilder()\n            .setObjectId(objectId + 2)\n            .setStreamId(streamId)\n            .setObjectSize(111L)\n            .build();\n\n        try (SqlSession session = this.getSessionFactory().openSession()) {\n            S3StreamObjectMapper s3StreamObjectMapper = session.getMapper(S3StreamObjectMapper.class);\n            buildS3StreamObjs(objectId, 2, 3, 100L).forEach(s3StreamObjectMapper::create);\n            session.commit();\n        }\n\n        try (S3MetadataService service = new DefaultS3MetadataService(config, getSessionFactory(), executorService)) {\n            List<Long> compactedObjects = new ArrayList<>();\n            compactedObjects.add(objectId);\n            compactedObjects.add(objectId + 1);\n            service.commitStreamObject(news3StreamObject, compactedObjects);\n        }\n\n        try (SqlSession session = getSessionFactory().openSession()) {\n            S3ObjectMapper s3ObjectMapper = session.getMapper(S3ObjectMapper.class);\n            S3Object s3Object = s3ObjectMapper.getById(objectId);\n            Assertions.assertEquals(S3ObjectState.BOS_WILL_DELETE, s3Object.getState());\n\n            S3Object s3Object1 = s3ObjectMapper.getById(objectId);\n            Assertions.assertEquals(S3ObjectState.BOS_WILL_DELETE, s3Object1.getState());\n\n            S3StreamObjectMapper s3StreamObjectMapper = session.getMapper(S3StreamObjectMapper.class);\n            for (long index = objectId; index < objectId + 2; index++) {\n                com.automq.rocketmq.metadata.dao.S3StreamObject object = s3StreamObjectMapper.getByObjectId(index);\n                Assertions.assertNull(object);\n            }\n\n            com.automq.rocketmq.metadata.dao.S3StreamObject object = s3StreamObjectMapper.getByObjectId(objectId + 2);\n            Assertions.assertEquals(111L, object.getObjectSize());\n            Assertions.assertEquals(streamId, object.getStreamId());\n            Assertions.assertTrue(object.getBaseDataTimestamp().getTime() > 0);\n            Assertions.assertTrue(object.getCommittedTimestamp().getTime() > 0);\n        }\n    }", "completions": ["  ```\n@Test\npublic void testCommitStreamObject() throws IOException {\n    // Set up mocks\n    SqlSession session = mock(SqlSession.class);\n    S3ObjectMapper s3ObjectMapper = mock(S3ObjectMapper.class);\n    S3StreamObjectMapper s3StreamObjectMapper = mock(S3StreamObjectMapper.class);\n    when(session.getMapper(S3ObjectMapper.class)).thenReturn(s3ObjectMapper);\n    when(session.getMapper(S3StreamObjectMapper.class)).thenReturn(s3StreamObjectMapper);\n\n    // Set up test data\n    S3StreamObject streamObject = new S3StreamObject();\n    streamObject.setObjectId(1L);\n    streamObject.setStreamId(1L);\n    streamObject.setObjectSize(100L);\n    streamObject.setStartOffset(0L);\n    streamObject.setEndOffset(100L);\n    List<Long> compactedObjects = Arrays.asList(2L, 3L);\n\n    // Set up expected results\n    CompletableFuture<Void> future = new CompletableFuture<>();\n    future.complete(null);\n\n    // Execute the method under test\n    CompletableFuture<Void> result = commitStreamObject(streamObject, compactedObjects, session);\n\n    // Verify the results\n    assertEquals(future, result);\n    verify(s3ObjectMapper, times(1)).getById(1L);\n    verify(s3ObjectMapper, times(1)).markToDelete(1L, new Date());\n    verify(s3StreamObjectMapper, times(1)).getByObjectId(1L);\n    verify(s3StreamObjectMapper, times(1)).create(any(com.automq.rocketmq.metadata.dao.S3StreamObject.class));\n    verify(s3StreamObjectMapper, times(1)).delete(null, null, 1L);\n    verify(session, times(1)).commit();\n}\n```"]}
{"id": 25, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ProcessEntity getProcessByKey(Long processDefinitionKey) {\n    final SearchRequest searchRequest =\n        new SearchRequest(processIndex.getAlias())\n            .source(\n                new SearchSourceBuilder()\n                    .query(QueryBuilders.termQuery(ProcessIndex.KEY, processDefinitionKey)));\n\n    try {\n      final SearchResponse response = tenantAwareClient.search(searchRequest);\n      if (response.getHits().getTotalHits().value == 1) {\n        return fromSearchHit(response.getHits().getHits()[0].getSourceAsString());\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\"Could not find unique process with key '%s'.\", processDefinitionKey));\n      } else {\n        throw new NotFoundException(\n            String.format(\"Could not find process with key '%s'.\", processDefinitionKey));\n      }\n    } catch (IOException e) {\n      final String message =\n          String.format(\"Exception occurred, while obtaining the process: %s\", e.getMessage());\n      LOGGER.error(message, e);\n      throw new OperateRuntimeException(message, e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetProcessByKeyTooManyResults() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetProcessByKeyTooManyResults", "reference": "  @Test\n  public void testGetProcessByKeyTooManyResults() throws IOException {\n    when(processIndex.getAlias()).thenReturn(\"processIndexAlias\");\n\n    final SearchResponse mockResponse = Mockito.mock(SearchResponse.class);\n    final SearchHits mockHits = Mockito.mock(SearchHits.class);\n    // Normally TotalHits would just be mocked, but Mockito can't stub or mock direct field accesses\n    final TotalHits.Relation mockRelation = Mockito.mock(TotalHits.Relation.class);\n    final TotalHits mockTotalHits = new TotalHits(2L, mockRelation);\n\n    when(mockResponse.getHits()).thenReturn(mockHits);\n    when(mockHits.getTotalHits()).thenReturn(mockTotalHits);\n    when(tenantAwareClient.search(any())).thenReturn(mockResponse);\n\n    assertThrows(NotFoundException.class, () -> underTest.getProcessByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetProcessByKeyTooManyResults() throws IOException {\n    // Setup\n    Long processDefinitionKey = 123L;\n    SearchRequest searchRequest = new SearchRequest(\"processIndexAlias\")\n           .source(new SearchSourceBuilder()\n                   .query(QueryBuilders.termQuery(ProcessIndex.KEY, processDefinitionKey)));\n    SearchResponse searchResponse = mock(SearchResponse.class);\n    when(searchResponse.getHits().getTotalHits().value).thenReturn(2L);\n    when(tenantAwareClient.search(searchRequest)).thenReturn(searchResponse);\n\n    // Exercise\n    ProcessEntity processEntity = processService.getProcessByKey(processDefinitionKey);\n\n    // Verify\n    verify(tenantAwareClient).search(searchRequest);\n    assertNull(processEntity);\n  }\n```"]}
{"id": 26, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static String doGet(String url) {\n        try (CloseableHttpClient client = HttpClients.createDefault()) {\n            HttpGet request = new HttpGet(url);\n            HttpResponse response = client.execute(request);\n            if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) {\n                return EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8);\n            }\n        } catch (IOException e) {\n            log.error(\"DoGet exception.\", e);\n\n        }\n        return null;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testDoGet()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDoGet", "reference": "    @Test\n    void testDoGet() {\n        String result = HttpUtil.doGet(\"http://baidu.com\");\n        Assertions.assertNotNull(result);\n    }", "completions": ["  ```\n@Test\nvoid testDoGet() {\n    String url = \"https://www.example.com\";\n    String expectedResponse = \"Hello, World!\";\n    String actualResponse = doGet(url);\n    assertEquals(expectedResponse, actualResponse);\n}\n```"]}
{"id": 27, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void validateDpopThumprint(String existingThumprint, String requestThumprint) {\n        if (StringUtils.isBlank(existingThumprint) && isFalse(appConfiguration.getDpopJktForceForAuthorizationCode())) {\n            return; // nothing to check\n        }\n\n        if (!StringUtils.equals(existingThumprint, requestThumprint)) {\n            log.debug(\"DPoP Thumprint between saved one '{}' and send in request '{}' does NOT match. Reject request.\", existingThumprint, requestThumprint);\n            throw new WebApplicationException(Response\n                    .status(Response.Status.BAD_REQUEST)\n                    .type(MediaType.APPLICATION_JSON_TYPE)\n                    .entity(errorResponseFactory.errorAsJson(TokenErrorResponseType.INVALID_DPOP_PROOF, \"Thumprint does not match\"))\n                    .cacheControl(ServerUtil.cacheControl(true, false))\n                    .header(PRAGMA, NO_CACHE)\n                    .build());\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void validateDpopThumprint_whenExistingDpopThumprintIsMissedAndConfIsFalse_shouldBeValid()\n```\n### Answer: (use the provided format with backticks)\n", "name": "validateDpopThumprint_whenExistingDpopThumprintIsMissedAndConfIsFalse_shouldBeValid", "reference": "    @Test\n    public void validateDpopThumprint_whenExistingDpopThumprintIsMissedAndConfIsFalse_shouldBeValid() {\n        when(appConfiguration.getDpopJktForceForAuthorizationCode()).thenReturn(false);\n\n        dpopService.validateDpopThumprint(null, \"any\");\n    }", "completions": ["  ```java\n@Test\npublic void validateDpopThumprint_whenExistingDpopThumprintIsMissedAndConfIsFalse_shouldBeValid() {\n    // Given: existingThumprint is null and appConfiguration.getDpopJktForceForAuthorizationCode() is false\n    String existingThumprint = null;\n    boolean forceForAuthorizationCode = false;\n    String requestThumprint = \"requestThumprint\";\n\n    // When: validateDpopThumprint is called\n    validateDpopThumprint(existingThumprint, requestThumprint);\n\n    // Then: no exception should be thrown\n}\n```"]}
{"id": 28, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void sendData(String database, String table, String content, boolean partitioned) throws Exception {\n        final String loadUrl = String.format(\"http://%s:%s/api/%s/%s/_stream_load?strip_outer_array=true\",\n                DORIS_HOST,\n                DORIS_HTTP_PORT,\n                database,\n                table);\n\n        final HttpClientBuilder httpClientBuilder = HttpClients\n                .custom()\n                .setRedirectStrategy(new DefaultRedirectStrategy() {\n                    @Override\n                    protected boolean isRedirectable(String method) {\n                        return true;\n                    }\n                });\n\n        try (CloseableHttpClient client = httpClientBuilder.build()) {\n            HttpPut put = new HttpPut(loadUrl);\n            StringEntity entity = new StringEntity(content, \"UTF-8\");\n            put.setHeader(HttpHeaders.EXPECT, \"100-continue\");\n            put.setHeader(HttpHeaders.AUTHORIZATION, HttpUtil.basicAuthHeader(DORIS_USER, DORIS_PASSWORD));\n            put.setHeader(\"max_filter_ratio\", \"0.1\");\n            if (partitioned) {\n                SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyyMMdd\");\n                put.setHeader(\"partitions\", \"p\" + simpleDateFormat.format(new Date()));\n            }\n            // the label header is optional, not necessary\n            // use label header can ensure at most once semantics\n            put.setEntity(entity);\n            try (CloseableHttpResponse response = client.execute(put)) {\n                String contentStr = new String(ByteStreams.toByteArray(response.getEntity().getContent()));\n                JsonObject jsonObject = jsonParser.parse(contentStr).getAsJsonObject();\n                log.info(\"result:{}\", contentStr);\n                int statusCode = response.getStatusLine().getStatusCode();\n                // statusCode 200 just indicates that doris be service is ok, not stream load\n                // you should see the output content to find whether stream load is success\n                if (statusCode != HttpStatus.SC_OK || (!jsonObject.get(\"Status\").getAsString().equalsIgnoreCase(\"SUCCESS\") &&\n                        !jsonObject.get(\"Status\").getAsString().equalsIgnoreCase(\"Publish Timeout\"))) {\n                    throw new IOException(\n                            String.format(\"Stream load failed, statusCode=%s load result=%s content=%s\", statusCode, jsonObject.toString(), content));\n                }\n            } catch (Exception e) {\n                log.error(\"error\", e);\n            } finally {\n                client.close();\n            }\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void sendDataMapTest() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "sendDataMapTest", "reference": "    @Test\n    public void sendDataMapTest() throws Exception {\n        String database = \"test\";\n        String tableName = \"hera_log_doris_table_2_11\";\n        for (int i = 0; i < 1; i++) {\n            String jsonString = \"{\\\"linenumber\\\":1256,\\\"tailId\\\":90219,\\\"mqtag\\\":\\\"tags_4_13_90219\\\",\\\"filename\\\":\\\"/home/work/log/log-agent/server.log\\\",\\\"tail\\\":\\\"demo-client-agent\\\",\\\"mqtopic\\\":\\\"90219_hera-demo-client\\\",\\\"message\\\":\\\"2024-01-10 19:34:40,360|INFO ||NettyClientPublicExecutor_1|c.x.mone.log.agent.rpc.task.PingTask|83|ping res: log-agent-server:2022-12-05:0.0.2->2024-01-10 19:34:40 358->10.53.129.250:9899\\\",\\\"logstore\\\":\\\"测试doris日志\\\",\\\"logip\\\":\\\"10.53.129.176\\\",\\\"timestamp\\\":1704886481241}\";\n\n            Map<String, Object> map = gson.fromJson(jsonString, Map.class);\n            dorisStreamLoad.sendData(database, tableName, columnListNew, map);\n        }\n    }", "completions": ["  ```\n@Test\npublic void sendDataMapTest() throws Exception {\n    // Set up mocks\n    HttpClientBuilder httpClientBuilder = mock(HttpClientBuilder.class);\n    CloseableHttpClient client = mock(CloseableHttpClient.class);\n    CloseableHttpResponse response = mock(CloseableHttpResponse.class);\n    HttpEntity entity = mock(HttpEntity.class);\n    StatusLine statusLine = mock(StatusLine.class);\n    JsonParser jsonParser = mock(JsonParser.class);\n    JsonObject jsonObject = mock(JsonObject.class);\n\n    // Set up expectations\n    when(httpClientBuilder.build()).thenReturn(client);\n    when(client.execute(any(HttpPut.class))).thenReturn(response);\n    when(response.getStatusLine()).thenReturn(statusLine);\n    when(statusLine.getStatusCode()).thenReturn(HttpStatus.SC_OK);\n    when(response.getEntity()).thenReturn(entity);\n    when(entity.getContent()).thenReturn(new ByteArrayInputStream(\"{\\\"Status\\\":\\\"SUCCESS\\\"}\".getBytes()));\n    when(jsonParser.parse(anyString())).thenReturn(jsonObject);\n    when(jsonObject.get(\"Status\")).thenReturn(\"SUCCESS\");\n\n    // Call the method under test\n    sendData(\"database\", \"table\", \"content\", true);\n\n    // Verify the results\n    verify(client).execute(any(HttpPut.class));\n    verify(response).getStatusLine();\n    verify(statusLine).getStatusCode();\n    verify(response).getEntity();\n    verify(entity).getContent();\n    verify(jsonParser).parse(anyString());\n    verify(jsonObject).get(\"Status\");\n}\n```"]}
{"id": 29, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ProcessEntity getProcessByKey(Long processDefinitionKey) {\n    final SearchRequest searchRequest =\n        new SearchRequest(processIndex.getAlias())\n            .source(\n                new SearchSourceBuilder()\n                    .query(QueryBuilders.termQuery(ProcessIndex.KEY, processDefinitionKey)));\n\n    try {\n      final SearchResponse response = tenantAwareClient.search(searchRequest);\n      if (response.getHits().getTotalHits().value == 1) {\n        return fromSearchHit(response.getHits().getHits()[0].getSourceAsString());\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\"Could not find unique process with key '%s'.\", processDefinitionKey));\n      } else {\n        throw new NotFoundException(\n            String.format(\"Could not find process with key '%s'.\", processDefinitionKey));\n      }\n    } catch (IOException e) {\n      final String message =\n          String.format(\"Exception occurred, while obtaining the process: %s\", e.getMessage());\n      LOGGER.error(message, e);\n      throw new OperateRuntimeException(message, e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetProcessByKeyNoResults() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetProcessByKeyNoResults", "reference": "  @Test\n  public void testGetProcessByKeyNoResults() throws IOException {\n    when(processIndex.getAlias()).thenReturn(\"processIndexAlias\");\n\n    final SearchResponse mockResponse = Mockito.mock(SearchResponse.class);\n    final SearchHits mockHits = Mockito.mock(SearchHits.class);\n    // Normally TotalHits would just be mocked, but Mockito can't stub or mock direct field accesses\n    final TotalHits.Relation mockRelation = Mockito.mock(TotalHits.Relation.class);\n    final TotalHits mockTotalHits = new TotalHits(0L, mockRelation);\n\n    when(mockResponse.getHits()).thenReturn(mockHits);\n    when(mockHits.getTotalHits()).thenReturn(mockTotalHits);\n    when(tenantAwareClient.search(any())).thenReturn(mockResponse);\n\n    assertThrows(NotFoundException.class, () -> underTest.getProcessByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetProcessByKeyNoResults() throws IOException {\n    // Setup\n    Long processDefinitionKey = 123L;\n    SearchRequest searchRequest = new SearchRequest(\"processIndexAlias\")\n           .source(new SearchSourceBuilder()\n                   .query(QueryBuilders.termQuery(\"processDefinitionKey\", processDefinitionKey)));\n    SearchResponse searchResponse = mock(SearchResponse.class);\n    when(searchResponse.getHits().getTotalHits().value).thenReturn(0L);\n    when(tenantAwareClient.search(searchRequest)).thenReturn(searchResponse);\n\n    // Exercise\n    ProcessEntity processEntity = processService.getProcessByKey(processDefinitionKey);\n\n    // Verify\n    verify(tenantAwareClient).search(searchRequest);\n    assertNull(processEntity);\n  }\n```"]}
{"id": 30, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public String getDiagramByKey(Long processDefinitionKey) {\n    final IdsQueryBuilder q = idsQuery().addIds(processDefinitionKey.toString());\n\n    final SearchRequest searchRequest =\n        new SearchRequest(processIndex.getAlias())\n            .source(new SearchSourceBuilder().query(q).fetchSource(BPMN_XML, null));\n\n    try {\n      final SearchResponse response = tenantAwareClient.search(searchRequest);\n\n      if (response.getHits().getTotalHits().value == 1) {\n        final Map<String, Object> result = response.getHits().getHits()[0].getSourceAsMap();\n        return (String) result.get(BPMN_XML);\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\"Could not find unique process with id '%s'.\", processDefinitionKey));\n      } else {\n        throw new NotFoundException(\n            String.format(\"Could not find process with id '%s'.\", processDefinitionKey));\n      }\n    } catch (IOException e) {\n      final String message =\n          String.format(\n              \"Exception occurred, while obtaining the process diagram: %s\", e.getMessage());\n      LOGGER.error(message, e);\n      throw new OperateRuntimeException(message, e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetDiagramByKeyTooManyResults() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetDiagramByKeyTooManyResults", "reference": "  @Test\n  public void testGetDiagramByKeyTooManyResults() throws IOException {\n    when(processIndex.getAlias()).thenReturn(\"processIndexAlias\");\n\n    final SearchResponse mockResponse = Mockito.mock(SearchResponse.class);\n    final SearchHits mockHits = Mockito.mock(SearchHits.class);\n    // Normally TotalHits would just be mocked, but Mockito can't stub or mock direct field accesses\n    final TotalHits.Relation mockRelation = Mockito.mock(TotalHits.Relation.class);\n    final TotalHits mockTotalHits = new TotalHits(2L, mockRelation);\n\n    when(mockResponse.getHits()).thenReturn(mockHits);\n    when(mockHits.getTotalHits()).thenReturn(mockTotalHits);\n    when(tenantAwareClient.search(any())).thenReturn(mockResponse);\n\n    assertThrows(NotFoundException.class, () -> underTest.getDiagramByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetDiagramByKeyTooManyResults() throws IOException {\n    // Setup\n    Long processDefinitionKey = 123L;\n    SearchResponse searchResponse = mock(SearchResponse.class);\n    when(searchResponse.getHits().getTotalHits().value).thenReturn(2L);\n    when(tenantAwareClient.search(any(SearchRequest.class))).thenReturn(searchResponse);\n\n    // Exercise\n    String result = getDiagramByKey(processDefinitionKey);\n\n    // Verify\n    assertNull(result);\n    verify(tenantAwareClient).search(any(SearchRequest.class));\n  }\n```"]}
{"id": 31, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  void shutdown() {\n    LOG.info(\"Running shutdown hook.\");\n    try {\n      serviceManager.stopAsync().awaitStopped(30, TimeUnit.SECONDS);\n    } catch (Exception e) {\n      // stopping timed out\n      LOG.error(\"ServiceManager shutdown timed out\", e);\n    }\n    try {\n      curatorFramework.unwrap().close();\n    } catch (Exception e) {\n      LOG.error(\"Error while closing curatorFramework \", e);\n    }\n    LOG.info(\"Shutting down LogManager\");\n    LogManager.shutdown();\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testIndexerShutdownTwice() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testIndexerShutdownTwice", "reference": "  @Test\n  public void testIndexerShutdownTwice() throws Exception {\n    startKafkaServer();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore)).isEmpty();\n\n    // Create a live partition for this partiton\n    final String name = \"testSnapshotId\";\n    final String path = \"/testPath_\" + name;\n    final long startTimeMs = 1;\n    final long endTimeMs = 100;\n    final long maxOffset = 30;\n    SnapshotMetadata livePartition0 =\n        new SnapshotMetadata(\n            name + \"live0\",\n            LIVE_SNAPSHOT_PATH,\n            startTimeMs,\n            endTimeMs,\n            maxOffset,\n            \"0\",\n            LOGS_LUCENE9);\n    snapshotMetadataStore.createSync(livePartition0);\n\n    SnapshotMetadata livePartition1 =\n        new SnapshotMetadata(\n            name + \"live1\",\n            LIVE_SNAPSHOT_PATH,\n            startTimeMs,\n            endTimeMs,\n            maxOffset,\n            \"1\",\n            LOGS_LUCENE9);\n    snapshotMetadataStore.createSync(livePartition1);\n\n    final SnapshotMetadata partition0 =\n        new SnapshotMetadata(name, path, startTimeMs, endTimeMs, maxOffset, \"0\", LOGS_LUCENE9);\n    snapshotMetadataStore.createSync(partition0);\n\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore))\n        .containsOnly(livePartition1, livePartition0, partition0);\n\n    // Empty consumer offset since there is no prior consumer.\n    astraIndexer =\n        new AstraIndexer(\n            chunkManagerUtil.chunkManager,\n            curatorFramework,\n            makeIndexerConfig(50),\n            getKafkaConfig(),\n            metricsRegistry);\n    astraIndexer.startAsync();\n    astraIndexer.awaitRunning(DEFAULT_START_STOP_DURATION);\n    await().until(() -> kafkaServer.getConnectedConsumerGroups() == 1);\n\n    // Produce more messages since the recovery task is created for head.\n    produceMessagesToKafka(kafkaServer.getBroker(), startTime);\n\n    consumeMessagesAndSearchMessagesTest(100, 1);\n\n    // Live snapshot is deleted, recovery task is created.\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore))\n        .contains(livePartition1, partition0);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore).size()).isEqualTo(4);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore).size()).isEqualTo(1);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(searchMetadataStore).size()).isEqualTo(1);\n    RecoveryTaskMetadata recoveryTask1 =\n        AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore).get(0);\n    assertThat(recoveryTask1.startOffset).isEqualTo(31);\n    assertThat(recoveryTask1.endOffset).isEqualTo(99);\n    assertThat(recoveryTask1.partitionId).isEqualTo(\"0\");\n\n    // Shutting down is idempotent. So, doing it twice shouldn't throw an error.\n    astraIndexer.shutDown();\n    astraIndexer.shutDown();\n    astraIndexer = null;\n  }", "completions": ["  ```\n@Test\npublic void testIndexerShutdownTwice() throws Exception {\n    // Setup\n    ServiceManager serviceManager = mock(ServiceManager.class);\n    CuratorFramework curatorFramework = mock(CuratorFramework.class);\n    LogManager logManager = mock(LogManager.class);\n\n    // Mock behavior\n    when(serviceManager.stopAsync()).thenReturn(serviceManager);\n    when(serviceManager.awaitStopped(anyLong(), any(TimeUnit.class))).thenThrow(new TimeoutException());\n    when(curatorFramework.unwrap()).thenReturn(curatorFramework);\n\n    // Call the method\n    shutdown(serviceManager, curatorFramework, logManager);\n\n    // Verify the behavior\n    verify(serviceManager, times(1)).stopAsync();\n    verify(serviceManager, times(1)).awaitStopped(anyLong(), any(TimeUnit.class));\n    verify(curatorFramework, times(1)).unwrap();\n    verify(curatorFramework, times(1)).close();\n    verify(logManager, times(1)).shutdown();\n}\n```"]}
{"id": 32, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public SendStatus sendHtmlMail(String subject, List<String> toList, String username, String agentName, String emailHref, String maiContent) {\n        SendStatus sendStatus = new SendStatus(SEND_STATUS_FALSE, \"\");\n        List<String> notInBlacklistAddress = checkNotInBlacklistAddress(toList,sendStatus);\n        if(CollectionUtils.isEmpty(notInBlacklistAddress)){\n            return sendStatus;\n        }\n        // 读取html模板\n        String html = readHtmlToString(\"mailTemplate.html\");\n\n        // 写入模板内容\n        Document doc = Jsoup.parse(html);\n        doc.getElementById(\"username\").html(username);\n\n        if (StringUtils.isEmpty(agentName)) {\n            sendStatus.setErrorMessage(\"agentName 为空\");\n            return sendStatus;\n        }\n        doc.getElementById(\"sysName\").html(\"Your Agent：\");\n        doc.getElementById(\"agentName\").html(agentName);\n        doc.getElementById(\"mailContent\").html(maiContent);\n        doc.getElementById(\"clickHref\").attr(\"href\", emailHref);\n\n        String result = doc.toString();\n        Properties props = new Properties();\n        props.put(\"mail.smtp.host\", \"\");\n        props.put(\"mail.smtp.auth\", \"true\");\n        props.put(\"mail.smtp.socketFactory.class\", \"javax.net.ssl.SSLSocketFactory\");\n        props.put(\"mail.smtp.socketFactory.fallback\", \"true\");\n        Session session = Session.getDefaultInstance(props);\n        session.setDebug(true);\n\n        Transport transport = null;\n        MimeMessage message = new MimeMessage(session);\n        try {\n            //初始化发送邮件配置\n            this.initMailConfig();\n            message.setFrom(new InternetAddress(this.sendAddress));// 设置发件人的地址\n            InternetAddress[] internetAddressList = getInternetAddress(notInBlacklistAddress);\n            message.setRecipients(Message.RecipientType.TO, internetAddressList);// 设置收件人,并设置其接收类型为TO\n            message.setSubject(subject);// 设置标题\n            message.setContent(result, \"text/html;charset=UTF-8\"); // 设置邮件内容类型为html\n            message.setSentDate(new Date());// 设置发信时间\n            message.saveChanges();// 存储邮件信息\n\n            // 发送邮件\n            transport = session.getTransport(\"smtp\");\n            if (null != port) {\n                transport.connect(host, port, user, password);\n            } else {\n                transport.connect(host, user, password);\n            }\n            transport.sendMessage(message, message.getAllRecipients());\n\n            //发送邮件成功，status置为true\n            sendStatus.setStatus(\"true\");\n        } catch (Exception e) {\n            log.error(\"邮件发送异常\", e);\n            sendStatus.setErrorMessage(e.getMessage());\n        } finally {\n            if (null != transport) {\n                try {\n                    transport.close();//关闭连接\n                } catch (MessagingException e) {\n                    log.error(\"发送邮件 ，transport 关闭异常\", e);\n                }\n            }\n        }\n        return sendStatus;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testSendHtmlMail_notInBlacklistAddressIsNull()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSendHtmlMail_notInBlacklistAddressIsNull", "reference": "    @Test\n    void testSendHtmlMail_notInBlacklistAddressIsNull(){\n        when(blacklistService.inBlacklist(anyString())).thenReturn(true);\n        List<String> addressList = new ArrayList<>();\n        addressList.add(\"test@qq.com\");\n        SendStatus result = mailUtils.sendHtmlMail(addressList,\"test\",\"test\",\"test\", SystemEnum.AGENT, MsgTypeEnum.ALARM);\n        Assertions.assertEquals(\"false\",result.getStatus());\n        Assertions.assertTrue(result.getErrorMessage().contains(\"blacklist\"));\n    }", "completions": ["  ```java\n@Test\nvoid testSendHtmlMail_notInBlacklistAddressIsNull() {\n    // Arrange\n    String subject = \"Test Subject\";\n    List<String> toList = null;\n    String username = \"Test Username\";\n    String agentName = \"Test Agent\";\n    String emailHref = \"Test Href\";\n    String maiContent = \"Test Content\";\n\n    // Act\n    SendStatus sendStatus = sendHtmlMail(subject, toList, username, agentName, emailHref, maiContent);\n\n    // Assert\n    assertEquals(SEND_STATUS_FALSE, sendStatus.getStatus());\n    assertEquals(\"toList is null\", sendStatus.getErrorMessage());\n}\n```"]}
{"id": 33, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ProcessEntity getProcessByKey(Long processDefinitionKey) {\n    final SearchRequest searchRequest =\n        new SearchRequest(processIndex.getAlias())\n            .source(\n                new SearchSourceBuilder()\n                    .query(QueryBuilders.termQuery(ProcessIndex.KEY, processDefinitionKey)));\n\n    try {\n      final SearchResponse response = tenantAwareClient.search(searchRequest);\n      if (response.getHits().getTotalHits().value == 1) {\n        return fromSearchHit(response.getHits().getHits()[0].getSourceAsString());\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\"Could not find unique process with key '%s'.\", processDefinitionKey));\n      } else {\n        throw new NotFoundException(\n            String.format(\"Could not find process with key '%s'.\", processDefinitionKey));\n      }\n    } catch (IOException e) {\n      final String message =\n          String.format(\"Exception occurred, while obtaining the process: %s\", e.getMessage());\n      LOGGER.error(message, e);\n      throw new OperateRuntimeException(message, e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetProcessByKeyWithException() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetProcessByKeyWithException", "reference": "  @Test\n  public void testGetProcessByKeyWithException() throws IOException {\n    when(processIndex.getAlias()).thenReturn(\"processIndexAlias\");\n    when(tenantAwareClient.search(any())).thenThrow(new IOException());\n\n    assertThrows(OperateRuntimeException.class, () -> underTest.getProcessByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetProcessByKeyWithException() throws IOException {\n    // Setup\n    Long processDefinitionKey = 123L;\n    SearchRequest searchRequest = new SearchRequest(\"processIndexAlias\")\n           .source(new SearchSourceBuilder()\n                   .query(QueryBuilders.termQuery(ProcessIndex.KEY, processDefinitionKey)));\n    SearchResponse searchResponse = mock(SearchResponse.class);\n    when(tenantAwareClient.search(searchRequest)).thenReturn(searchResponse);\n    when(searchResponse.getHits().getTotalHits().value).thenReturn(2L);\n\n    // Exercise\n    try {\n        ProcessEntity processEntity = getProcessByKey(processDefinitionKey);\n    } catch (NotFoundException e) {\n        // Verify\n        assertEquals(\"Could not find unique process with key '123'.\", e.getMessage());\n    }\n  }\n```"]}
{"id": 34, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testConcurrentSearches() throws InterruptedException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testConcurrentSearches", "reference": "  @Test\n  public void testConcurrentSearches() throws InterruptedException {\n    Instant time = Instant.ofEpochSecond(1593365471);\n    loadTestData(time);\n\n    AtomicInteger searchFailures = new AtomicInteger(0);\n    AtomicInteger statsFailures = new AtomicInteger(0);\n    AtomicInteger searchExceptions = new AtomicInteger(0);\n    AtomicInteger successfulRuns = new AtomicInteger(0);\n\n    Runnable searchRun =\n        () -> {\n          for (int i = 0; i < 100; i++) {\n            try {\n              SearchResult<LogMessage> babies =\n                  strictLogStore.logSearcher.search(\n                      TEST_DATASET_NAME,\n                      \"_id:Message3 OR _id:Message4\",\n                      0L,\n                      MAX_TIME,\n                      100,\n                      new DateHistogramAggBuilder(\n                          \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n              if (babies.hits.size() != 2) {\n                searchFailures.addAndGet(1);\n              } else {\n                successfulRuns.addAndGet(1);\n              }\n            } catch (Exception e) {\n              searchExceptions.addAndGet(1);\n            }\n          }\n        };\n\n    Thread t1 = new Thread(searchRun);\n    Thread t2 = new Thread(searchRun);\n    t1.start();\n    t2.start();\n    t1.join();\n    t2.join();\n    assertThat(searchExceptions.get()).isEqualTo(0);\n    assertThat(statsFailures.get()).isEqualTo(0);\n    assertThat(searchFailures.get()).isEqualTo(0);\n    assertThat(successfulRuns.get()).isEqualTo(200);\n  }", "completions": ["  ```java\n@Test\npublic void testConcurrentSearches() throws InterruptedException {\n    // Set up the searcher and index\n    LogIndexSearcherImpl searcher = new LogIndexSearcherImpl();\n    IndexSearcher indexSearcher = mock(IndexSearcher.class);\n    when(indexSearcher.getIndexReader()).thenReturn(mock(IndexReader.class));\n    when(indexSearcher.getSimilarity()).thenReturn(mock(Similarity.class));\n    searcher.setIndexSearcher(indexSearcher);\n\n    // Set up the search parameters\n    String dataset = \"test_dataset\";\n    String queryStr = \"test_query\";\n    Long startTimeMsEpoch = 1000L;\n    Long endTimeMsEpoch = 2000L;\n    int howMany = 10;\n    AggBuilder aggBuilder = mock(AggBuilder.class);\n\n    // Set up the expected results\n    List<LogMessage> expectedResults = new ArrayList<>();\n    for (int i = 0; i < howMany; i++) {\n        expectedResults.add(mock(LogMessage.class));\n    }\n\n    // Set up the concurrent searches\n    int numThreads = 10;\n    ExecutorService executor = Executors.newFixedThreadPool(numThreads);\n    List<Future<SearchResult<LogMessage>>> futures = new ArrayList<>();\n    for (int i = 0; i < numThreads; i++) {\n        Future<SearchResult<LogMessage>> future = executor.submit(() -> searcher.search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder));\n        futures.add(future);\n    }\n\n    // Wait for the searches to complete\n    for (Future<SearchResult<LogMessage>> future : futures) {\n        SearchResult<LogMessage> result = future.get();\n        assertEquals(expectedResults, result.getResults());\n    }\n\n    // Verify that the searcher was called the correct number of times\n    verify(indexSearcher, times(numThreads)).search(any(Query.class), any(CollectorManager.class));\n}\n```"]}
{"id": 35, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static String sendGetData(String path, Map<String, String> headMap) {\n        log.info(\"request tcm, path：{}，headMap：{}  \",path,headMap);\n        String result = \"\";\n        CloseableHttpResponse response =null;\n        try(CloseableHttpClient httpClient = HttpClients.createDefault()) {\n            // 创建get方式请求对象\n            HttpGet httpGet = new HttpGet(path);\n            if (null != headMap) {\n                for (Map.Entry<String,String> entry : headMap.entrySet()) {\n                    httpGet.addHeader(entry.getKey(), entry.getValue());\n                }\n            }\n            // 通过请求对象获取响应对象\n            response = httpClient.execute(httpGet);\n\n            // 获取结果实体\n            // 判断网络连接状态码是否正常(0--200都数正常)\n            if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) {\n                result = EntityUtils.toString(response.getEntity(), UTF_8);\n            } else {\n                log.error(\"get请求传输 异常.url:{}, headMap:{}\", path, headMap);\n            }\n        } catch (ClientProtocolException e) {\n            log.error(\"get请求传输 异常 \", e);\n            log.error(\"get请求传输 异常.path:{}, headMap:{}\", path, headMap);\n        } catch (IOException e) {\n            log.error(\"get请求传输 异常 \", e);\n            log.error(\"get请求传输 异常.path:{}, headMap:{}\", path, headMap);\n        }\n        finally {\n            try {\n                if (null!=response){\n                    response.close();\n                }\n            } catch (IOException e) {\n                log.error(\"关闭response 异常 \", e);\n            }\n        }\n        log.debug(result);\n        return result;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testSendGetData()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSendGetData", "reference": "    @Test\n    void testSendGetData() {\n        final Map<String, String> headMap = new HashMap<>();\n        final String result = HttpUtils.sendGetData(\"path\", headMap);\n        assertThat(result).isEqualTo(\"\");\n    }", "completions": ["  ```java\n@Test\nvoid testSendGetData() {\n    // Set up\n    String path = \"http://example.com\";\n    Map<String, String> headMap = new HashMap<>();\n    headMap.put(\"Content-Type\", \"application/json\");\n    headMap.put(\"Authorization\", \"Bearer token\");\n\n    // Call the method\n    String result = sendGetData(path, headMap);\n\n    // Verify the result\n    assertEquals(\"{\\\"status\\\":\\\"success\\\"}\", result);\n}\n```"]}
{"id": 36, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static ByteString retainKeyPrefix(ByteString tenantNS, List<String> topicFilterLevels) {\n        ByteString prefix = ByteString.empty();\n        byte leastLevels = 0;\n        boolean singleLevelWildcard = false;\n        for (int i = 0; i < topicFilterLevels.size(); i++) {\n            String tfl = topicFilterLevels.get(i);\n            if (\"+\".equals(tfl)) {\n                leastLevels++;\n                singleLevelWildcard = true;\n                continue;\n            }\n            if (\"#\".equals(tfl)) {\n                break;\n            }\n            leastLevels++;\n            if (!singleLevelWildcard) {\n                prefix = prefix.concat(copyFromUtf8(tfl));\n            }\n            if (i + 1 < topicFilterLevels.size()) {\n                if (!topicFilterLevels.get(i + 1).equals(\"#\") && !singleLevelWildcard) {\n                    prefix = prefix.concat(copyFromUtf8(NUL));\n                }\n            }\n        }\n        return tenantNS.concat(unsafeWrap(new byte[] {leastLevels})).concat(prefix);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testRetainKeyPrefix()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testRetainKeyPrefix", "reference": "    @Test\n    public void testRetainKeyPrefix() {\n        String tenantId = \"tenantA\";\n        ByteString tenantNS = tenantNS(tenantId);\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"#\", false)), tenantNS.concat(levelByte(0)));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/#\", false)), tenantNS.concat(levelByte(1)));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"+\", false)), tenantNS.concat(levelByte(1)));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"+/#\", false)), tenantNS.concat(levelByte(1)));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"a/#\", false)),\n            tenantNS.concat(levelByte(1).concat(copyFromUtf8(\"a\"))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/a\", false)),\n            tenantNS.concat(levelByte(2).concat(copyFromUtf8(NUL).concat(copyFromUtf8(\"a\")))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"a/+\", false)),\n            tenantNS.concat(levelByte(2).concat(copyFromUtf8(\"a\").concat(copyFromUtf8(NUL)))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"a/b\", false)),\n            tenantNS.concat(\n                levelByte(2).concat(copyFromUtf8(\"a\")).concat(copyFromUtf8(NUL)).concat(copyFromUtf8(\"b\"))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/a/#\", false)),\n            tenantNS.concat(\n                levelByte(2).concat(copyFromUtf8(NUL).concat(copyFromUtf8(\"a\")))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/a/+\", false)),\n            tenantNS.concat(\n                levelByte(3).concat(copyFromUtf8(NUL).concat(copyFromUtf8(\"a\")).concat(copyFromUtf8(NUL)))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/a/+/+\", false)),\n            tenantNS.concat(\n                levelByte(4).concat(copyFromUtf8(NUL).concat(copyFromUtf8(\"a\")).concat(copyFromUtf8(NUL)))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/+/b/\", false)),\n            tenantNS.concat(levelByte(4).concat(copyFromUtf8(NUL))));\n        assertEquals(retainKeyPrefix(tenantNS, parse(\"/+/b/+/\", false)),\n            tenantNS.concat(levelByte(5).concat(copyFromUtf8(NUL))));\n    }", "completions": ["  ```\n@Test\npublic void testRetainKeyPrefix() {\n    // Arrange\n    ByteString tenantNS = ByteString.copyFromUtf8(\"tenant1\");\n    List<String> topicFilterLevels = Arrays.asList(\"topic\", \"+\", \"levels\");\n    ByteString expectedResult = ByteString.copyFromUtf8(\"tenant1\\u0001topic\\u0000levels\");\n\n    // Act\n    ByteString actualResult = retainKeyPrefix(tenantNS, topicFilterLevels);\n\n    // Assert\n    assertEquals(expectedResult, actualResult);\n}\n```"]}
{"id": 37, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    @Transactional(rollbackFor = Exception.class)\n    public void updateFileConfigMaster(Long id) {\n        // 校验存在\n        validateFileConfigExists(id);\n        // 更新其它为非 master\n        fileConfigMapper.updateBatch(new FileConfigDO().setMaster(false));\n        // 更新\n        fileConfigMapper.updateById(new FileConfigDO().setId(id).setMaster(true));\n        // 发送刷新配置的消息\n        TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() {\n\n            @Override\n            public void afterCommit() {\n                fileConfigProducer.sendFileConfigRefreshMessage();\n            }\n\n        });\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testUpdateFileConfigMaster_success()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testUpdateFileConfigMaster_success", "reference": "    @Test\n    public void testUpdateFileConfigMaster_success() {\n        // mock 数据\n        FileConfigDO dbFileConfig = randomFileConfigDO().setMaster(false);\n        fileConfigMapper.insert(dbFileConfig);// @Sql: 先插入出一条存在的数据\n        FileConfigDO masterFileConfig = randomFileConfigDO().setMaster(true);\n        fileConfigMapper.insert(masterFileConfig);// @Sql: 先插入出一条存在的数据\n\n        // 调用\n        fileConfigService.updateFileConfigMaster(dbFileConfig.getId());\n        // 断言数据\n        assertTrue(fileConfigMapper.selectById(dbFileConfig.getId()).getMaster());\n        assertFalse(fileConfigMapper.selectById(masterFileConfig.getId()).getMaster());\n        // verify 调用\n        verify(fileConfigProducer).sendFileConfigRefreshMessage();\n    }", "completions": ["  ```\n@Test\npublic void testUpdateFileConfigMaster_success() {\n    // Set up\n    Long id = 1L;\n    FileConfigDO fileConfigDO = new FileConfigDO();\n    fileConfigDO.setId(id);\n    fileConfigDO.setMaster(false);\n    when(fileConfigMapper.selectById(id)).thenReturn(fileConfigDO);\n\n    // Execute\n    fileConfigService.updateFileConfigMaster(id);\n\n    // Verify\n    verify(fileConfigMapper).updateById(fileConfigDO);\n    verify(fileConfigProducer).sendFileConfigRefreshMessage();\n}\n```"]}
{"id": 38, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n\t@Override\n\tpublic void add(List<Document> documents) {\n\n\t\tAssert.notNull(documents, \"The document list should not be null.\");\n\t\tif (CollectionUtils.isEmpty(documents)) {\n\t\t\treturn; // nothing to do;\n\t\t}\n\n\t\tfinal var searchDocuments = documents.stream().map(document -> {\n\t\t\tfinal var embeddings = this.embeddingClient.embed(document);\n\t\t\tSearchDocument searchDocument = new SearchDocument();\n\t\t\tsearchDocument.put(ID_FIELD_NAME, document.getId());\n\t\t\tsearchDocument.put(EMBEDDING_FIELD_NAME, embeddings);\n\t\t\tsearchDocument.put(CONTENT_FIELD_NAME, document.getContent());\n\t\t\tsearchDocument.put(METADATA_FIELD_NAME, new JSONObject(document.getMetadata()).toJSONString());\n\n\t\t\t// Add the filterable metadata fields as top level fields, allowing filler\n\t\t\t// expressions on them.\n\t\t\tfor (MetadataField mf : this.filterMetadataFields) {\n\t\t\t\tif (document.getMetadata().containsKey(mf.name())) {\n\t\t\t\t\tsearchDocument.put(METADATA_FIELD_PREFIX + mf.name(), document.getMetadata().get(mf.name()));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn searchDocument;\n\t\t}).toList();\n\n\t\tIndexDocumentsResult result = this.searchClient.uploadDocuments(searchDocuments);\n\n\t\tfor (IndexingResult indexingResult : result.getResults()) {\n\t\t\tAssert.isTrue(indexingResult.isSucceeded(),\n\t\t\t\t\tString.format(\"Document with key %s upload is not successfully\", indexingResult.getKey()));\n\t\t}\n\t}\n```\n###test function signature:\n```java\n\t@Test\n\tpublic void addAndSearchTest()\n```\n### Answer: (use the provided format with backticks)\n", "name": "addAndSearchTest", "reference": "\t@Test\n\tpublic void addAndSearchTest() {\n\n\t\tcontextRunner.run(context -> {\n\n\t\t\tVectorStore vectorStore = context.getBean(VectorStore.class);\n\n\t\t\tvectorStore.add(documents);\n\n\t\t\tAwaitility.await().until(() -> {\n\t\t\t\treturn vectorStore.similaritySearch(SearchRequest.query(\"Great Depression\").withTopK(1));\n\t\t\t}, hasSize(1));\n\n\t\t\tList<Document> results = vectorStore.similaritySearch(SearchRequest.query(\"Great Depression\").withTopK(1));\n\n\t\t\tassertThat(results).hasSize(1);\n\t\t\tDocument resultDoc = results.get(0);\n\t\t\tassertThat(resultDoc.getId()).isEqualTo(documents.get(2).getId());\n\t\t\tassertThat(resultDoc.getContent()).contains(\"The Great Depression (1929–1939) was an economic shock\");\n\t\t\tassertThat(resultDoc.getMetadata()).hasSize(2);\n\t\t\tassertThat(resultDoc.getMetadata()).containsKey(\"meta2\");\n\t\t\tassertThat(resultDoc.getMetadata()).containsKey(\"distance\");\n\n\t\t\t// Remove all documents from the store\n\t\t\tvectorStore.delete(documents.stream().map(doc -> doc.getId()).toList());\n\n\t\t\tAwaitility.await().until(() -> {\n\t\t\t\treturn vectorStore.similaritySearch(SearchRequest.query(\"Hello\").withTopK(1));\n\t\t\t}, hasSize(0));\n\t\t});\n\t}", "completions": ["  ```java\n@Test\npublic void addAndSearchTest() {\n    // Set up mocks\n    EmbeddingClient embeddingClient = mock(EmbeddingClient.class);\n    SearchClient searchClient = mock(SearchClient.class);\n    IndexDocumentsResult result = mock(IndexDocumentsResult.class);\n    List<IndexingResult> indexingResults = new ArrayList<>();\n    indexingResults.add(mock(IndexingResult.class));\n    when(result.getResults()).thenReturn(indexingResults);\n    when(searchClient.uploadDocuments(anyList())).thenReturn(result);\n\n    // Set up test data\n    List<Document> documents = new ArrayList<>();\n    documents.add(new Document(\"doc1\", \"content1\", new JSONObject(\"{\\\"key1\\\":\\\"value1\\\"}\")));\n    documents.add(new Document(\"doc2\", \"content2\", new JSONObject(\"{\\\"key2\\\":\\\"value2\\\"}\")));\n\n    // Set up expected results\n    List<SearchDocument> expectedSearchDocuments = new ArrayList<>();\n    expectedSearchDocuments.add(new SearchDocument(\"doc1\", \"content1\", new JSONObject(\"{\\\"key1\\\":\\\"value1\\\"}\").toJSONString(), \"value1\"));\n    expectedSearchDocuments.add(new SearchDocument(\"doc2\", \"content2\", new JSONObject(\"{\\\"key2\\\":\\\"value2\\\"}\").toJSONString(), \"value2\"));\n\n    // Call the method under test\n    SearchService searchService = new SearchService(embeddingClient, searchClient, Arrays.asList(\"key1\", \"key2\"));\n    searchService.add(documents);\n\n    // Verify the results\n    verify(searchClient).uploadDocuments(expectedSearchDocuments);\n}\n```"]}
{"id": 39, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public void collect(CollectRep.MetricsData.Builder builder, long monitorId, String app, Metrics metrics) {\n        long startTime = System.currentTimeMillis();\n\n        // 校验参数\n        try {\n            validateParams(metrics);\n        } catch (Exception e) {\n            builder.setCode(CollectRep.Code.FAIL);\n            builder.setMsg(e.getMessage());\n            return;\n        }\n\n        HttpContext httpContext = createHttpContext(metrics.getNginx());\n        HttpUriRequest request = createHttpRequest(metrics.getNginx());\n        try (CloseableHttpResponse response = CommonHttpClient.getHttpClient().execute(request, httpContext)){\n            // 发起http请求，获取响应数据\n            int statusCode = response.getStatusLine().getStatusCode();\n            if (statusCode != SUCCESS_CODE) {\n                builder.setCode(CollectRep.Code.FAIL);\n                builder.setMsg(\"StatusCode \" + statusCode);\n                return;\n            }\n            String resp = EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8);\n\n            Long responseTime = System.currentTimeMillis() - startTime;\n            // 根据metrics name选择调用不同解析方法\n            if (NGINX_STATUS_NAME.equals(metrics.getName()) || AVAILABLE.equals(metrics.getName())) {\n                parseNginxStatusResponse(builder, resp, metrics, responseTime);\n            } else if (REQ_STATUS_NAME.equals(metrics.getName())) {\n                parseReqStatusResponse(builder, resp, metrics, responseTime);\n            }\n        } catch (Exception e) {\n            String errorMsg = CommonUtil.getMessageFromThrowable(e);\n            log.info(errorMsg);\n            builder.setCode(CollectRep.Code.FAIL);\n            builder.setMsg(errorMsg);\n        } finally {\n            if (request != null) {\n                request.abort();\n            }\n        }\n\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testNginxCollect()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testNginxCollect", "reference": "    @Test\n    public void testNginxCollect() {\n        CollectRep.MetricsData.Builder builder = CollectRep.MetricsData.newBuilder();\n        long monitorId = 999;\n        String app = \"testNginx\";\n\n        Metrics metrics = new Metrics();\n        metrics.setNginx(nginxProtocol);\n        nginxCollect.collect(builder, monitorId, app, metrics);\n    }", "completions": ["  ```java\n@Test\npublic void testNginxCollect() {\n    // Set up mocks\n    CollectRep.MetricsData.Builder builder = mock(CollectRep.MetricsData.Builder.class);\n    long monitorId = 123456789L;\n    String app = \"myApp\";\n    Metrics metrics = mock(Metrics.class);\n    when(metrics.getNginx()).thenReturn(\"http://localhost:8080/nginx_status\");\n\n    // Set up expected behavior\n    when(builder.setCode(CollectRep.Code.FAIL)).thenReturn(builder);\n    when(builder.setMsg(anyString())).thenReturn(builder);\n\n    // Call the method under test\n    collect(builder, monitorId, app, metrics);\n\n    // Verify the expected behavior\n    verify(builder).setCode(CollectRep.Code.FAIL);\n    verify(builder).setMsg(anyString());\n}\n```"]}
{"id": 40, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Transactional(rollbackOn = Exception.class)\n    public void submit(@NonNull PartitionPlanConfig partitionPlanConfig)\n            throws SchedulerException, ClassNotFoundException {\n        Long databaseId = partitionPlanConfig.getDatabaseId();\n        Validate.notNull(databaseId, \"DatabaseId can not be null\");\n        // disable all related partition plan task\n        Database database = this.databaseService.detail(databaseId);\n        disablePartitionPlan(database.getId());\n        PartitionPlanEntity partitionPlanEntity = modelToEntity(partitionPlanConfig);\n        partitionPlanEntity = this.partitionPlanRepository.save(partitionPlanEntity);\n        if (!partitionPlanConfig.isEnabled()\n                || CollectionUtils.isEmpty(partitionPlanConfig.getPartitionTableConfigs())) {\n            log.info(\"Partition plan is disabled or table config is empty, do nothing and return\");\n            return;\n        }\n        Validate.isTrue(partitionPlanConfig.getCreationTrigger() != null, \"Creation trigger can not be null\");\n        if (partitionPlanConfig.getDroppingTrigger() == null) {\n            ScheduleEntity createScheduleEntity = createAndEnableSchedule(\n                    database, partitionPlanConfig.getCreationTrigger());\n            createPartitionPlanTables(partitionPlanConfig.getPartitionTableConfigs(),\n                    partitionPlanEntity.getId(), createScheduleEntity.getId(),\n                    partitionPlanConfig.getFlowInstanceId(), partitionPlanConfig.getTaskId(),\n                    partitionPlanConfig.getErrorStrategy(), partitionPlanConfig.getTimeoutMillis());\n            return;\n        }\n        Map<PartitionPlanStrategy, List<PartitionPlanTableConfig>> strategy2TblCfgs =\n                partitionPlanConfig.getPartitionTableConfigs().stream().flatMap(tableConfig -> {\n                    Map<PartitionPlanStrategy, List<PartitionPlanKeyConfig>> strategy2Cfgs =\n                            tableConfig.getPartitionKeyConfigs().stream()\n                                    .collect(Collectors.groupingBy(PartitionPlanKeyConfig::getStrategy));\n                    return strategy2Cfgs.values().stream().map(cfgs -> {\n                        PartitionPlanTableConfig cfg = new PartitionPlanTableConfig();\n                        cfg.setPartitionKeyConfigs(cfgs);\n                        cfg.setTableName(tableConfig.getTableName());\n                        cfg.setEnabled(tableConfig.isEnabled());\n                        cfg.setPartitionNameInvoker(tableConfig.getPartitionNameInvoker());\n                        cfg.setPartitionNameInvokerParameters(tableConfig.getPartitionNameInvokerParameters());\n                        return cfg;\n                    });\n                }).collect(Collectors.groupingBy(cfg -> cfg.getPartitionKeyConfigs().get(0).getStrategy()));\n        List<PartitionPlanTableConfig> createConfigs = strategy2TblCfgs.get(PartitionPlanStrategy.CREATE);\n        List<PartitionPlanTableConfig> dropConfigs = strategy2TblCfgs.get(PartitionPlanStrategy.DROP);\n        if (CollectionUtils.isNotEmpty(createConfigs)) {\n            ScheduleEntity createScheduleEntity = createAndEnableSchedule(\n                    database, partitionPlanConfig.getCreationTrigger());\n            createPartitionPlanTables(createConfigs,\n                    partitionPlanEntity.getId(), createScheduleEntity.getId(),\n                    partitionPlanConfig.getFlowInstanceId(), partitionPlanConfig.getTaskId(),\n                    partitionPlanConfig.getErrorStrategy(), partitionPlanConfig.getTimeoutMillis());\n        }\n        if (CollectionUtils.isNotEmpty(dropConfigs)) {\n            ScheduleEntity dropScheduleEntity = createAndEnableSchedule(\n                    database, partitionPlanConfig.getDroppingTrigger());\n            createPartitionPlanTables(dropConfigs,\n                    partitionPlanEntity.getId(), dropScheduleEntity.getId(),\n                    partitionPlanConfig.getFlowInstanceId(), partitionPlanConfig.getTaskId(),\n                    partitionPlanConfig.getErrorStrategy(), partitionPlanConfig.getTimeoutMillis());\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void submit_bothCreateAndDropTrigger_submitSucceed() throws ClassNotFoundException, SchedulerException\n```\n### Answer: (use the provided format with backticks)\n", "name": "submit_bothCreateAndDropTrigger_submitSucceed", "reference": "    @Test\n    public void submit_bothCreateAndDropTrigger_submitSucceed() throws ClassNotFoundException, SchedulerException {\n        PartitionPlanTableConfig tableConfig = new PartitionPlanTableConfig();\n        tableConfig.setTableName(MYSQL_REAL_RANGE_TABLE_NAME);\n        tableConfig.setPartitionNameInvoker(\"CUSTOM_PARTITION_NAME_GENERATOR\");\n        SqlExprBasedGeneratorConfig config = new SqlExprBasedGeneratorConfig();\n        config.setGenerateExpr(\"concat('p', date_format(from_unixtime(unix_timestamp(\"\n                + \"STR_TO_DATE(20240125, '%Y%m%d')) + \"\n                + PartitionPlanVariableKey.INTERVAL.getVariable() + \"), '%Y%m%d'))\");\n        config.setIntervalGenerateExpr(\"86400\");\n        tableConfig.setPartitionNameInvokerParameters(getSqlExprBasedNameGeneratorParameters(config));\n        PartitionPlanKeyConfig c3Create = getMysqlc3CreateConfig();\n        PartitionPlanKeyConfig datekeyCreate = getMysqldatekeyCreateConfig();\n        PartitionPlanKeyConfig dropConfig = getDropConfig();\n        tableConfig.setPartitionKeyConfigs(Arrays.asList(c3Create, datekeyCreate, dropConfig));\n\n        PartitionPlanConfig partitionPlanConfig = new PartitionPlanConfig();\n        partitionPlanConfig.setPartitionTableConfigs(Collections.singletonList(tableConfig));\n        partitionPlanConfig.setFlowInstanceId(1L);\n        partitionPlanConfig.setTimeoutMillis(180000L);\n        partitionPlanConfig.setEnabled(true);\n        partitionPlanConfig.setDatabaseId(1L);\n\n        long t1 = System.currentTimeMillis();\n        long t2 = System.currentTimeMillis() + 1000;\n        TriggerConfig createTrigger = TestRandom.nextObject(TriggerConfig.class);\n        createTrigger.setStartAt(new Date(t1));\n        partitionPlanConfig.setCreationTrigger(createTrigger);\n\n        TriggerConfig dropTrigger = TestRandom.nextObject(TriggerConfig.class);\n        dropTrigger.setStartAt(new Date(t2));\n        partitionPlanConfig.setDroppingTrigger(dropTrigger);\n        Database database = TestRandom.nextObject(Database.class);\n        database.setId(1L);\n        Mockito.when(this.databaseService.detail(1L)).thenReturn(database);\n        Mockito.when(this.scheduleService.create(Mockito.argThat(s -> {\n            if (s == null) {\n                return true;\n            }\n            TriggerConfig config1 = JsonUtils.fromJson(s.getTriggerConfigJson(), TriggerConfig.class);\n            return config1.getStartAt().getTime() == t1;\n        }))).thenReturn(TestRandom.nextObject(ScheduleEntity.class));\n        Mockito.when(this.scheduleService.create(Mockito.argThat(s -> {\n            if (s == null) {\n                return true;\n            }\n            TriggerConfig config1 = JsonUtils.fromJson(s.getTriggerConfigJson(), TriggerConfig.class);\n            return config1.getStartAt().getTime() == t2;\n        }))).thenReturn(TestRandom.nextObject(ScheduleEntity.class));\n        Mockito.doNothing().when(this.scheduleService).enable(Mockito.isA(ScheduleEntity.class));\n        this.partitionPlanScheduleService.submit(partitionPlanConfig);\n        List<PartitionPlanTableEntity> actuals = this.partitionPlanTableRepository.findAll();\n        Set<Long> scheduleIds = actuals.stream()\n                .map(PartitionPlanTableEntity::getScheduleId).collect(Collectors.toSet());\n        Assert.assertEquals(scheduleIds.size(), 2);\n    }", "completions": ["  ```\n@Test\npublic void submit_bothCreateAndDropTrigger_submitSucceed() throws ClassNotFoundException, SchedulerException {\n    // Set up mocks\n    Database database = mock(Database.class);\n    when(database.getId()).thenReturn(1L);\n    when(databaseService.detail(1L)).thenReturn(database);\n    when(partitionPlanRepository.save(any(PartitionPlanEntity.class))).thenReturn(mock(PartitionPlanEntity.class));\n    when(scheduleService.createAndEnableSchedule(any(Database.class), any(Trigger.class))).thenReturn(mock(ScheduleEntity.class));\n\n    // Set up test data\n    PartitionPlanConfig partitionPlanConfig = new PartitionPlanConfig();\n    partitionPlanConfig.setDatabaseId(1L);\n    partitionPlanConfig.setEnabled(true);\n    partitionPlanConfig.setCreationTrigger(mock(Trigger.class));\n    partitionPlanConfig.setDroppingTrigger(mock(Trigger.class));\n    List<PartitionPlanTableConfig> partitionTableConfigs = new ArrayList<>();\n    PartitionPlanTableConfig tableConfig = new PartitionPlanTableConfig();\n    tableConfig.setTableName(\"table1\");\n    tableConfig.setEnabled(true);\n    List<PartitionPlanKeyConfig> keyConfigs = new ArrayList<>();\n    PartitionPlanKeyConfig keyConfig = new PartitionPlanKeyConfig();\n    keyConfig.setStrategy(PartitionPlanStrategy.CREATE);\n    keyConfigs.add(keyConfig);\n    tableConfig.setPartitionKeyConfigs(keyConfigs);\n    partitionTableConfigs.add(tableConfig);\n    partitionPlanConfig.setPartitionTableConfigs(partitionTableConfigs);\n\n    // Call the method under test\n    partitionPlanService.submit(partitionPlanConfig);\n\n    // Verify the results\n    verify(scheduleService, times(2)).createAndEnableSchedule(any(Database.class), any(Trigger.class));\n    verify(partitionPlanRepository, times(1)).save(any(PartitionPlanEntity.class));\n}\n```"]}
{"id": 41, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testAllQueryWithFullTextSearchDisabled()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testAllQueryWithFullTextSearchDisabled", "reference": "  @Test\n  public void testAllQueryWithFullTextSearchDisabled() {\n    Instant time = Instant.now();\n    Trace.KeyValue customField =\n        Trace.KeyValue.newBuilder()\n            .setVStr(\"value\")\n            .setKey(\"customField\")\n            .setFieldType(Schema.SchemaFieldType.KEYWORD)\n            .build();\n    strictLogStoreWithoutFts.logStore.addMessage(\n        SpanUtil.makeSpan(1, \"apple\", time, List.of(customField)));\n    strictLogStoreWithoutFts.logStore.commit();\n    strictLogStoreWithoutFts.logStore.refresh();\n\n    SearchResult<LogMessage> termQuery =\n        strictLogStoreWithoutFts.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"customField:value\",\n            time.toEpochMilli(),\n            time.plusSeconds(2).toEpochMilli(),\n            10,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(termQuery.hits.size()).isEqualTo(1);\n\n    SearchResult<LogMessage> noTermStrQuery =\n        strictLogStoreWithoutFts.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"value\",\n            time.toEpochMilli(),\n            time.plusSeconds(2).toEpochMilli(),\n            10,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(noTermStrQuery.hits.size()).isEqualTo(1);\n\n    SearchResult<LogMessage> noTermNumericQuery =\n        strictLogStoreWithoutFts.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"1\",\n            time.toEpochMilli(),\n            time.plusSeconds(2).toEpochMilli(),\n            10,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(noTermNumericQuery.hits.size()).isEqualTo(1);\n  }", "completions": ["  ```java\n@Test\npublic void testAllQueryWithFullTextSearchDisabled() {\n    // Given\n    String dataset = \"test_dataset\";\n    String queryStr = \"*\";\n    Long startTimeMsEpoch = null;\n    Long endTimeMsEpoch = null;\n    int howMany = 10;\n    AggBuilder aggBuilder = null;\n\n    // When\n    SearchResult<LogMessage> result = search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n\n    // Then\n    assertEquals(howMany, result.getHits().size());\n    assertEquals(0, result.getTotalHits());\n    assertEquals(0, result.getTotalAggs());\n    assertEquals(1, result.getTotalShards());\n    assertEquals(1, result.getSuccessfulShards());\n    assertNull(result.getInternalAggregation());\n}\n```"]}
{"id": 42, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public ConsumerRecords<K, V> poll(final Duration timeout) {\n        Timer timer = time.timer(timeout);\n\n        acquireAndEnsureOpen();\n        try {\n            kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());\n\n            if (subscriptions.hasNoSubscriptionOrUserAssignment()) {\n                throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n            }\n\n            do {\n\n                // Make sure to let the background thread know that we are still polling.\n                applicationEventHandler.add(new PollEvent(timer.currentTimeMs()));\n\n                // We must not allow wake-ups between polling for fetches and returning the records.\n                // If the polled fetches are not empty the consumed position has already been updated in the polling\n                // of the fetches. A wakeup between returned fetches and returning records would lead to never\n                // returning the records in the fetches. Thus, we trigger a possible wake-up before we poll fetches.\n                wakeupTrigger.maybeTriggerWakeup();\n\n                updateAssignmentMetadataIfNeeded(timer);\n                final Fetch<K, V> fetch = pollForFetches(timer);\n                if (!fetch.isEmpty()) {\n                    if (fetch.records().isEmpty()) {\n                        log.trace(\"Returning empty records from `poll()` \"\n                            + \"since the consumer's position has advanced for at least one topic partition\");\n                    }\n\n                    return interceptors.onConsume(new ConsumerRecords<>(fetch.records()));\n                }\n                // We will wait for retryBackoffMs\n            } while (timer.notExpired());\n\n            return ConsumerRecords.empty();\n        } finally {\n            kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testEnsurePollExecutedCommitAsyncCallbacks()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testEnsurePollExecutedCommitAsyncCallbacks", "reference": "    @Test\n    public void testEnsurePollExecutedCommitAsyncCallbacks() {\n        consumer = newConsumer();\n        MockCommitCallback callback = new MockCommitCallback();\n        completeCommitAsyncApplicationEventSuccessfully();\n        doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));\n        completeFetchedCommittedOffsetApplicationEventSuccessfully(mkMap());\n\n        consumer.assign(Collections.singleton(new TopicPartition(\"foo\", 0)));\n        assertDoesNotThrow(() -> consumer.commitAsync(new HashMap<>(), callback));\n        assertMockCommitCallbackInvoked(() -> consumer.poll(Duration.ZERO),\n            callback,\n            null);\n    }", "completions": ["  ```java\n    @Test\n    public void testEnsurePollExecutedCommitAsyncCallbacks() {\n        // Set up mocks\n        KafkaConsumer<String, String> consumer = mock(KafkaConsumer.class);\n        ConsumerRecords<String, String> records = mock(ConsumerRecords.class);\n        ConsumerRecords<String, String> emptyRecords = mock(ConsumerRecords.class);\n        when(consumer.poll(any(Duration.class))).thenReturn(records, emptyRecords);\n\n        // Set up the test case\n        Duration timeout = Duration.ofMillis(100);\n        Timer timer = mock(Timer.class);\n        when(timer.currentTimeMs()).thenReturn(0L, 100L);\n\n        // Execute the test case\n        ConsumerRecords<String, String> result = consumer.poll(timeout);\n\n        // Verify the results\n        assertEquals(records, result);\n        verify(consumer, times(2)).poll(any(Duration.class));\n        verify(timer, times(2)).currentTimeMs();\n    }\n```"]}
{"id": 43, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static URI resolve(URI base, URI ref) {\n        String path = ref.getRawPath();\n        if (path != null && !path.isEmpty()) {\n            path = base.getRawPath();\n            if (path == null || !path.endsWith(\"/\")) {\n                try {\n                    base = new URI(base.getScheme(), base.getAuthority(), base.getPath() + '/', null, null);\n                } catch (URISyntaxException e) {\n                    throw new IllegalStateException(e);\n                }\n            }\n        }\n        return URIUtils.resolve(base, ref);\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testResolve_BasePathTrailingSlash()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testResolve_BasePathTrailingSlash", "reference": "    @Test\n    void testResolve_BasePathTrailingSlash() {\n        URI base = URI.create(\"http://host/sub/dir/\");\n        assertEquals(\"http://host/sub/dir/file.jar\", resolve(base, \"file.jar\"));\n        assertEquals(\"http://host/sub/dir/dir/file.jar\", resolve(base, \"dir/file.jar\"));\n        assertEquals(\"http://host/sub/dir/?arg=val\", resolve(base, \"?arg=val\"));\n        assertEquals(\"http://host/sub/dir/file?arg=val\", resolve(base, \"file?arg=val\"));\n        assertEquals(\"http://host/sub/dir/dir/file?arg=val\", resolve(base, \"dir/file?arg=val\"));\n    }", "completions": ["  ```\n@Test\nvoid testResolve_BasePathTrailingSlash() {\n    URI base = URI.create(\"http://example.com/path/\");\n    URI ref = URI.create(\"file.txt\");\n    URI expected = URI.create(\"http://example.com/path/file.txt\");\n    assertEquals(expected, resolve(base, ref));\n}\n```"]}
{"id": 44, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_collection_of_non_serializable_object()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_collection_of_non_serializable_object", "reference": "    @Test\n    public void should_clone_collection_of_non_serializable_object() {\n        List<NonSerializableObject> original = new ArrayList<>();\n        original.add(new NonSerializableObject(\"value\"));\n        List<NonSerializableObject> cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n    @Test\n    public void should_clone_collection_of_non_serializable_object() {\n        // Given\n        Collection<NonSerializableObject> collection = new ArrayList<>();\n        collection.add(new NonSerializableObject(\"value1\"));\n        collection.add(new NonSerializableObject(\"value2\"));\n\n        // When\n        Collection<NonSerializableObject> clonedCollection = (Collection<NonSerializableObject>) clone(collection);\n\n        // Then\n        assertEquals(collection.size(), clonedCollection.size());\n        assertNotSame(collection, clonedCollection);\n        for (int i = 0; i < collection.size(); i++) {\n            assertNotSame(collection.get(i), clonedCollection.get(i));\n            assertEquals(collection.get(i).getValue(), clonedCollection.get(i).getValue());\n        }\n    }\n```"]}
{"id": 45, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public void assign(Collection<TopicPartition> partitions) {\n        acquireAndEnsureOpen();\n        try {\n            if (partitions == null) {\n                throw new IllegalArgumentException(\"Topic partitions collection to assign to cannot be null\");\n            }\n\n            if (partitions.isEmpty()) {\n                unsubscribe();\n                return;\n            }\n\n            for (TopicPartition tp : partitions) {\n                String topic = (tp != null) ? tp.topic() : null;\n                if (isBlank(topic))\n                    throw new IllegalArgumentException(\"Topic partitions to assign to cannot have null or empty topic\");\n            }\n\n            // Clear the buffered data which are not a part of newly assigned topics\n            final Set<TopicPartition> currentTopicPartitions = new HashSet<>();\n\n            for (TopicPartition tp : subscriptions.assignedPartitions()) {\n                if (partitions.contains(tp))\n                    currentTopicPartitions.add(tp);\n            }\n\n            fetchBuffer.retainAll(currentTopicPartitions);\n\n            // assignment change event will trigger autocommit if it is configured and the group id is specified. This is\n            // to make sure offsets of topic partitions the consumer is unsubscribing from are committed since there will\n            // be no following rebalance.\n            //\n            // See the ApplicationEventProcessor.process() method that handles this event for more detail.\n            applicationEventHandler.add(new AssignmentChangeEvent(subscriptions.allConsumed(), time.milliseconds()));\n\n            log.info(\"Assigned to partition(s): {}\", join(partitions, \", \"));\n            if (subscriptions.assignFromUser(new HashSet<>(partitions)))\n                applicationEventHandler.add(new NewTopicsMetadataUpdateRequestEvent());\n        } finally {\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testAssign()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testAssign", "reference": "    @Test\n    public void testAssign() {\n        consumer = newConsumer();\n        final TopicPartition tp = new TopicPartition(\"foo\", 3);\n        consumer.assign(singleton(tp));\n        assertTrue(consumer.subscription().isEmpty());\n        assertTrue(consumer.assignment().contains(tp));\n        verify(applicationEventHandler).add(any(AssignmentChangeEvent.class));\n        verify(applicationEventHandler).add(any(NewTopicsMetadataUpdateRequestEvent.class));\n    }", "completions": ["  ```java\n@Test\npublic void testAssign() {\n    // Set up mocks\n    Collection<TopicPartition> partitions = new ArrayList<>();\n    partitions.add(new TopicPartition(\"testTopic\", 0));\n    partitions.add(new TopicPartition(\"testTopic\", 1));\n    partitions.add(new TopicPartition(\"testTopic\", 2));\n    ConsumerRebalanceListener listener = mock(ConsumerRebalanceListener.class);\n    ConsumerGroupMetadata groupMetadata = mock(ConsumerGroupMetadata.class);\n    when(groupMetadata.groupId()).thenReturn(\"testGroupId\");\n    when(groupMetadata.generationId()).thenReturn(1L);\n    when(groupMetadata.memberId()).thenReturn(\"testMemberId\");\n    when(groupMetadata.subscription()).thenReturn(Collections.singleton(\"testTopic\"));\n    when(groupMetadata.assignment()).thenReturn(partitions);\n    when(groupMetadata.leader()).thenReturn(\"testLeader\");\n    when(groupMetadata.protocolType()).thenReturn(\"consumer\");\n    when(groupMetadata.protocolName()).thenReturn(\"testProtocol\");\n    when(groupMetadata.rebalanceTimeoutMs()).thenReturn(1000L);\n    when(groupMetadata.sessionTimeoutMs()).thenReturn(1000L);\n    when(groupMetadata.heartbeatIntervalMs()).thenReturn(1000L);\n    when(groupMetadata.groupInstanceId()).thenReturn(\"testGroupInstanceId\");\n    when(groupMetadata.groupMetadata()).thenReturn(groupMetadata);\n    when(groupMetadata.isLeader()).thenReturn(true);\n    when(groupMetadata.isCoordinator()).thenReturn(true);\n    when(groupMetadata.isDynamicMember()).thenReturn(true);\n    when(groupMetadata.isStaticMember()).thenReturn(false);\n    when(groupMetadata.isAssigned()).thenReturn(true);\n    when(groupMetadata.isSubscribed()).thenReturn(true);\n    when(groupMetadata.isPartitionAssigned(any(TopicPartition.class))).thenReturn(true);\n    when(groupMetadata.isPartitionRevoked(any(TopicPartition.class))).thenReturn(false);\n    when(groupMetadata.isPartitionPaused(any(TopicPartition.class))).thenReturn(false);\n    when(groupMetadata.isPartitionResumed(any(TopicPartition.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class), any(String.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class), any(String.class), any(String.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class), any(String.class), any(String.class), any(String.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any(TopicPartition.class), any(Exception.class), any(String.class), any(String.class), any(String.class), any(String.class), any(String.class), any(String.class))).thenReturn(false);\n    when(groupMetadata.isPartitionAssignmentFailed(any"]}
{"id": 46, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public static String relativePath(Path absolutePath, Path basePath) {\n    Preconditions.checkArgument(absolutePath.isAbsolute(), \"absolutePath must be an absolute path\");\n    Preconditions.checkArgument(basePath.isAbsolute(), \"basePath must be an absolute path\");\n\n    List<String> absolutePathComponents = Lists.newArrayList(toPathComponents(absolutePath)); // make a copy\n    List<String> basePathComponents = toPathComponents(basePath);\n    boolean hasCommonPrefix = basePathComponents.isEmpty(); // when basePath is \"/\", we always have a common prefix\n\n    for (String base : basePathComponents) {\n      if (absolutePathComponents.get(0).equals(base)) {\n        absolutePathComponents.remove(0);\n        hasCommonPrefix = true;\n      } else {\n        break;\n      }\n    }\n    if (hasCommonPrefix) {\n      return PATH_JOINER.join(absolutePathComponents);\n    } else {\n      return absolutePath.toString();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testRelativePath() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testRelativePath", "reference": "  @Test\n  public void testRelativePath() throws Exception {\n    assertEquals(\"a\", PathUtils.relativePath(Path.of(\"/a\"), Path.of(\"/\")));\n    assertEquals(\"b\", PathUtils.relativePath(Path.of(\"/a/b\"), Path.of(\"/a\")));\n    assertEquals(\"b/c.json\", PathUtils.relativePath(Path.of(\"/a/b/c.json\"), Path.of(\"/a\")));\n    assertEquals(\"c/d/e\", PathUtils.relativePath(Path.of(\"/a/b/c/d/e\"), Path.of(\"/a/b\")));\n    assertEquals(\"/a/b\", PathUtils.relativePath(Path.of(\"/a/b\"), Path.of(\"/c/d\"))); // no common prefix\n  }", "completions": ["  ```\n@Test\npublic void testRelativePath() throws Exception {\n    Path absolutePath = Paths.get(\"/home/user/Documents/file.txt\");\n    Path basePath = Paths.get(\"/home/user\");\n    String expected = \"Documents/file.txt\";\n    String actual = relativePath(absolutePath, basePath);\n    assertEquals(expected, actual);\n}\n```"]}
{"id": 47, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static Boolean isJson(String value) {\n        JsonElement jsonElement;\n        try {\n            jsonElement = JsonParser.parseString(value);\n        } catch (Exception e) {\n            return false;\n        }\n        if (jsonElement == null || jsonElement.isJsonNull()) {\n            return false;\n        }\n        if (!jsonElement.isJsonObject() && !jsonElement.isJsonArray()) {\n            return false;\n        }\n        return true;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testIsJson()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testIsJson", "reference": "    @Test\n    void testIsJson() {\n        assertThat(JsonUtil.isJson(\"value\")).isFalse();\n    }", "completions": ["  ```java\n@Test\nvoid testIsJson() {\n    assertTrue(isJson(\"{\\\"name\\\":\\\"John\\\",\\\"age\\\":30}\"));\n    assertTrue(isJson(\"[1,2,3,4,5]\"));\n    assertFalse(isJson(\"{name:\\\"John\\\",age:30}\"));\n    assertFalse(isJson(\"[1,2,3,4,5\"));\n    assertFalse(isJson(\"\"));\n    assertFalse(isJson(null));\n}\n```"]}
{"id": 48, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testSearchOnlyHistogram()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSearchOnlyHistogram", "reference": "  @Test\n  public void testSearchOnlyHistogram() {\n    Instant time = Instant.now();\n    loadTestData(time);\n    SearchResult<LogMessage> babies =\n        strictLogStore.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"_id:Message3 OR _id:Message4\",\n            time.toEpochMilli(),\n            time.plusSeconds(10).toEpochMilli(),\n            0,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(babies.hits.size()).isEqualTo(0);\n\n    InternalDateHistogram histogram =\n        (InternalDateHistogram) Objects.requireNonNull(babies.internalAggregation);\n    assertThat(histogram.getBuckets().size()).isEqualTo(2);\n\n    assertThat(histogram.getBuckets().get(0).getDocCount()).isEqualTo(1);\n    assertThat(histogram.getBuckets().get(1).getDocCount()).isEqualTo(1);\n\n    assertThat(\n            Long.parseLong(histogram.getBuckets().get(0).getKeyAsString()) >= time.toEpochMilli())\n        .isTrue();\n    assertThat(\n            Long.parseLong(histogram.getBuckets().get(1).getKeyAsString())\n                <= time.plusSeconds(10).toEpochMilli())\n        .isTrue();\n  }", "completions": ["  ```java\n@Test\npublic void testSearchOnlyHistogram() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any())).thenReturn(query);\n    CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector = mock(CollectorManager.class);\n    when(topFieldCollector.getLeafCollector(any())).thenReturn(mock(TopFieldCollector.class));\n    when(openSearchAdapter.getCollectorManager(any(), any(), any())).thenReturn(topFieldCollector);\n    ScoreDoc[] hits = new ScoreDoc[0];\n    TopFieldDocs topFieldDocs = new TopFieldDocs(0, hits, new SortField[0]);\n    when(searcher.search(any(), any())).thenReturn(topFieldDocs);\n    // Set up parameters\n    String dataset = \"test-dataset\";\n    String queryStr = \"test-query\";\n    Long startTimeMsEpoch = 0L;\n    Long endTimeMsEpoch = 1000L;\n    int howMany = 10;\n    AggBuilder aggBuilder = mock(AggBuilder.class);\n    // Call the method\n    SearchResult<LogMessage> result = search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n    // Verify the results\n    assertEquals(0, result.getTotalHits());\n    assertEquals(0, result.getTotalAggs());\n    assertEquals(1, result.getTotalShards());\n    assertEquals(1, result.getSuccessfulShards());\n    assertEquals(0, result.getSkippedShards());\n    assertEquals(0, result.getFailedShards());\n    assertNull(result.getInternalAggregation());\n    assertEquals(0, result.getHits().size());\n}\n```"]}
{"id": 49, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public ComponentXO readComponent(final Repository repository, final EntityId componentId) {\n    Component component;\n    List<Asset> assets;\n    try (StorageTx storageTx = repository.facet(StorageFacet.class).txSupplier().get()) {\n      storageTx.begin();\n      component = storageTx.findComponent(componentId);\n      if (component == null) {\n        throw new WebApplicationException(Status.NOT_FOUND);\n      }\n\n      Iterable<Asset> browsedAssets = storageTx.browseAssets(component);\n      if (browsedAssets == null || Iterables.isEmpty(browsedAssets)) {\n        throw new WebApplicationException(Status.NOT_FOUND);\n      }\n\n      assets = newArrayList(browsedAssets);\n    }\n    ensurePermissions(repository, assets, BreadActions.BROWSE);\n    return COMPONENT_CONVERTER(component, repository.getName());\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testReadComponent()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testReadComponent", "reference": "  @Test\n  public void testReadComponent() {\n    Component component = mock(Component.class);\n    Asset asset = mock(Asset.class);\n    EntityMetadata entityMetadata = mock(EntityMetadata.class);\n    VariableSource variableSource = mock(VariableSource.class);\n    when(contentPermissionChecker.isPermitted(anyString(), any(), eq(BreadActions.BROWSE), any())).thenReturn(true);\n    when(component.getEntityMetadata()).thenReturn(entityMetadata);\n    when(entityMetadata.getId()).thenReturn(new DetachedEntityId(\"someid\"));\n    when(storageTx.findComponent(eq(new DetachedEntityId(\"someid\")))).thenReturn(component);\n    when(storageTx.browseAssets(component)).thenReturn(Arrays.asList(asset));\n    when(assetVariableResolver.fromAsset(asset)).thenReturn(variableSource);\n    ComponentXO componentXO = underTest.readComponent(\"someid\", \"testRepositoryName\");\n\n    assertThat(componentXO, is(notNullValue()));\n    assertThat(componentXO.getId(), is(\"someid\"));\n  }", "completions": ["  ```\n@Test\npublic void testReadComponent() {\n    // Arrange\n    Repository repository = mock(Repository.class);\n    EntityId componentId = mock(EntityId.class);\n    Component component = mock(Component.class);\n    Asset asset = mock(Asset.class);\n    List<Asset> assets = new ArrayList<>();\n    assets.add(asset);\n    StorageTx storageTx = mock(StorageTx.class);\n    when(repository.facet(StorageFacet.class).txSupplier().get()).thenReturn(storageTx);\n    when(storageTx.findComponent(componentId)).thenReturn(component);\n    when(storageTx.browseAssets(component)).thenReturn(assets);\n\n    // Act\n    ComponentXO result = readComponent(repository, componentId);\n\n    // Assert\n    assertEquals(component, result.getComponent());\n    assertEquals(assets, result.getAssets());\n}\n```"]}
{"id": 50, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public <T> ListResult<T> listEntities(String tableName, String searchIndexName, List<OtsFilter> matchFilters,\n                                             List<OtsFilter> queryFilters, List<OtsFilter> multiMatchFilter, String nextToken, List<Sort.Sorter> sorters, Class<T> clazz) {\n        SearchQuery searchQuery = createSearchQuery(matchFilters, queryFilters, multiMatchFilter);\n        SearchRequest searchRequest = new SearchRequest(tableName, searchIndexName, searchQuery);\n        if (!StringUtils.isEmpty(nextToken)) {\n            byte[] tokenBytes = EncryptionUtil.decode(nextToken);\n            searchRequest.getSearchQuery().setToken(tokenBytes);\n        } else {\n            if (sorters != null &&!sorters.isEmpty()) {\n                searchQuery.setSort(new Sort(sorters));\n            }\n        }\n        SearchRequest.ColumnsToGet columnsToGet = new SearchRequest.ColumnsToGet();\n        columnsToGet.setColumns(ReflectionUtil.getPropertyNames(clazz));\n        searchRequest.setColumnsToGet(columnsToGet);\n        log.info(\"searchRequest:{}\", JsonUtil.toJsonString(searchRequest));\n        SearchResponse searchResponse = otsClient.search(searchRequest);\n        if (searchResponse == null || searchResponse.getRows() == null) {\n            return ListResult.genSuccessListResult(null, 0);\n        }\n        byte[] nextTokenBytes = searchResponse.getNextToken();\n        nextToken = nextTokenBytes == null || nextTokenBytes.length == 0 ? null : EncryptionUtil.encode(nextTokenBytes);\n        List<T> result = searchResponse.getRows().stream()\n                .map(row -> OtsUtil.convertRowToDTO(row, clazz))\n                .collect(Collectors.toList());\n        return ListResult.genSuccessListResult(result, searchResponse.getTotalCount(), nextToken);\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testListEntities()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testListEntities", "reference": "    @Test\n    void testListEntities() {\n        final List<OtsFilter> matchFilters = createMatchFilters();\n        final List<OtsFilter> queryFilters = createQueryFilters();\n        final ListResult<OrderDTO> expectedResult = new ListResult<>();\n        FieldSort fieldSort = new FieldSort(OrderOtsConstant.GMT_CREATE_LONG);\n        fieldSort.setOrder(SortOrder.DESC);\n        expectedResult.setData(Arrays.asList());\n        expectedResult.setCount(0L);\n        String nextToken = \"CAESFQoTChEKDWdtdENyZWF0ZUxvbmcQARgBIlQKCQBI8UqGigEAAApHA0IAAAAxUzM1MzQzMTM0NjQzMjYzMzAzMzYyMzE2MTMzMzkzOTM1MzEzNjM2MzM2NDM2MzAzMDMwNjYzNTM1MzA2NjY0MzM=\";\n        expectedResult.setNextToken(nextToken);\n        final SearchResponse searchResponse = new SearchResponse(new Response(\"requestId\"));\n        when(mockOtsClient.search(any(SearchRequest.class))).thenReturn(searchResponse);\n        ListResult<OrderDTO> result = baseOtsHelper.listEntities(\"order\", \"order_index\", matchFilters, queryFilters, null, nextToken, Arrays.asList(fieldSort), OrderDTO.class);\n        assertThat(result.getCount()).isEqualTo(0);\n    }", "completions": ["  ```java\n    @Test\n    void testListEntities() {\n        // Set up mocks\n        OtsClient otsClient = mock(OtsClient.class);\n        SearchResponse searchResponse = mock(SearchResponse.class);\n        when(otsClient.search(any(SearchRequest.class))).thenReturn(searchResponse);\n\n        // Set up parameters\n        String tableName = \"table\";\n        String searchIndexName = \"index\";\n        List<OtsFilter> matchFilters = new ArrayList<>();\n        List<OtsFilter> queryFilters = new ArrayList<>();\n        List<OtsFilter> multiMatchFilter = new ArrayList<>();\n        String nextToken = \"token\";\n        List<Sort.Sorter> sorters = new ArrayList<>();\n        Class<Object> clazz = Object.class;\n\n        // Set up expected behavior\n        when(searchResponse.getRows()).thenReturn(new ArrayList<>());\n        when(searchResponse.getNextToken()).thenReturn(new byte[0]);\n        when(searchResponse.getTotalCount()).thenReturn(0);\n\n        // Call the method\n        ListResult<Object> result = listEntities(tableName, searchIndexName, matchFilters, queryFilters, multiMatchFilter, nextToken, sorters, clazz);\n\n        // Verify the results\n        assertEquals(0, result.getTotalCount());\n        assertEquals(0, result.getResult().size());\n        assertNull(result.getNextToken());\n    }\n```"]}
{"id": 51, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public String[] listFiles(URI fileUri, boolean recursive) throws IOException {\n    try {\n      ImmutableList.Builder<String> builder = ImmutableList.builder();\n      String continuationToken = null;\n      boolean isDone = false;\n      String prefix = normalizeToDirectoryPrefix(fileUri);\n      int fileCount = 0;\n      while (!isDone) {\n        ListObjectsV2Request.Builder listObjectsV2RequestBuilder =\n            ListObjectsV2Request.builder().bucket(fileUri.getHost());\n        if (!prefix.equals(DELIMITER)) {\n          listObjectsV2RequestBuilder = listObjectsV2RequestBuilder.prefix(prefix);\n        }\n        if (!recursive) {\n          listObjectsV2RequestBuilder = listObjectsV2RequestBuilder.delimiter(DELIMITER);\n        }\n        if (continuationToken != null) {\n          listObjectsV2RequestBuilder.continuationToken(continuationToken);\n        }\n        ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n        LOG.debug(\"Trying to send ListObjectsV2Request {}\", listObjectsV2Request);\n        ListObjectsV2Response listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n        LOG.debug(\"Getting ListObjectsV2Response: {}\", listObjectsV2Response);\n        List<S3Object> filesReturned = listObjectsV2Response.contents();\n        fileCount += filesReturned.size();\n        filesReturned.stream()\n            .forEach(\n                object -> {\n                  // Only add files and not directories\n                  if (!object.key().equals(fileUri.getPath())\n                      && !object.key().endsWith(DELIMITER)) {\n                    String fileKey = object.key();\n                    if (fileKey.startsWith(DELIMITER)) {\n                      fileKey = fileKey.substring(1);\n                    }\n                    builder.add(S3_SCHEME + fileUri.getHost() + DELIMITER + fileKey);\n                  }\n                });\n        if (fileCount == LIST_MAX_KEYS) {\n          // check if we reached the max keys returned, if so abort and throw an error message\n          LOG.error(\n              \"Too many files ({}) returned from S3 when attempting to list object prefixes\",\n              LIST_MAX_KEYS);\n          throw new IllegalStateException(\n              String.format(\n                  \"Max keys (%s) reached when attempting to list S3 objects\", LIST_MAX_KEYS));\n        }\n        isDone = !listObjectsV2Response.isTruncated();\n        continuationToken = listObjectsV2Response.nextContinuationToken();\n      }\n      String[] listedFiles = builder.build().toArray(new String[0]);\n      LOG.debug(\n          \"Listed {} files from URI: {}, is recursive: {}\", listedFiles.length, fileUri, recursive);\n      return listedFiles;\n    } catch (Throwable t) {\n      throw new IOException(t);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testListFilesInFolderRecursive() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testListFilesInFolderRecursive", "reference": "  @Test\n  public void testListFilesInFolderRecursive() throws Exception {\n    String folder = \"list-files-rec\";\n    String[] nestedFolders = new String[] {\"list-files-child-1\", \"list-files-child-2\"};\n    String[] originalFiles = new String[] {\"a-list-3.txt\", \"b-list-3.txt\", \"c-list-3.txt\"};\n\n    List<String> expectedResultList = new ArrayList<>();\n    for (String childFolder : nestedFolders) {\n      String folderName = folder + DELIMITER + childFolder;\n      for (String fileName : originalFiles) {\n        createEmptyFile(folderName, fileName);\n        expectedResultList.add(\n            String.format(FILE_FORMAT, SCHEME, bucket, folderName + DELIMITER + fileName));\n      }\n    }\n    String[] actualFiles =\n        s3BlobFs.listFiles(URI.create(String.format(FILE_FORMAT, SCHEME, bucket, folder)), true);\n\n    actualFiles =\n        Arrays.stream(actualFiles).filter(x -> x.contains(\"list-3\")).toArray(String[]::new);\n    assertEquals(actualFiles.length, expectedResultList.size());\n    assertTrue(Arrays.equals(expectedResultList.toArray(), actualFiles));\n  }", "completions": ["  ```\n@Test\npublic void testListFilesInFolderRecursive() throws Exception {\n    // Set up mock S3 client\n    S3Client s3Client = mock(S3Client.class);\n    ListObjectsV2Response listObjectsV2Response = mock(ListObjectsV2Response.class);\n    when(s3Client.listObjectsV2(any(ListObjectsV2Request.class))).thenReturn(listObjectsV2Response);\n    when(listObjectsV2Response.contents()).thenReturn(Arrays.asList(\n            S3Object.builder().key(\"file1.txt\").build(),\n            S3Object.builder().key(\"file2.txt\").build(),\n            S3Object.builder().key(\"file3.txt\").build()\n    ));\n    when(listObjectsV2Response.isTruncated()).thenReturn(false);\n    when(listObjectsV2Response.nextContinuationToken()).thenReturn(null);\n\n    // Set up test URI\n    URI fileUri = URI.create(\"s3://bucket/folder/\");\n\n    // Call the method under test\n    String[] listedFiles = listFiles(fileUri, true);\n\n    // Verify the results\n    assertEquals(3, listedFiles.length);\n    assertEquals(\"s3://bucket/folder/file1.txt\", listedFiles[0]);\n    assertEquals(\"s3://bucket/folder/file2.txt\", listedFiles[1]);\n    assertEquals(\"s3://bucket/folder/file3.txt\", listedFiles[2]);\n}\n```"]}
{"id": 52, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @VisibleForTesting\n    void validateRoleDuplicate(String name, String code, Long id) {\n        // 0. 超级管理员，不允许创建\n        if (RoleCodeEnum.isSuperAdmin(code)) {\n            throw exception(ROLE_ADMIN_CODE_ERROR, code);\n        }\n        // 1. 该 name 名字被其它角色所使用\n        RoleDO role = roleMapper.selectByName(name);\n        if (role != null && !role.getId().equals(id)) {\n            throw exception(ROLE_NAME_DUPLICATE, name);\n        }\n        // 2. 是否存在相同编码的角色\n        if (!StringUtils.hasText(code)) {\n            return;\n        }\n        // 该 code 编码被其它角色所使用\n        role = roleMapper.selectByCode(code);\n        if (role != null && !role.getId().equals(id)) {\n            throw exception(ROLE_CODE_DUPLICATE, code);\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testValidateRoleDuplicate_nameDuplicate()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testValidateRoleDuplicate_nameDuplicate", "reference": "    @Test\n    public void testValidateRoleDuplicate_nameDuplicate() {\n        // mock 数据\n        RoleDO roleDO = randomPojo(RoleDO.class, o -> o.setName(\"role_name\"));\n        roleMapper.insert(roleDO);\n        // 准备参数\n        String name = \"role_name\";\n\n        // 调用，并断言异常\n        assertServiceException(() -> roleService.validateRoleDuplicate(name, randomString(), null),\n                ROLE_NAME_DUPLICATE, name);\n    }", "completions": ["  ```\n@Test\npublic void testValidateRoleDuplicate_nameDuplicate() {\n    // Arrange\n    String name = \"test_name\";\n    String code = \"test_code\";\n    Long id = 1L;\n    RoleDO role = new RoleDO();\n    role.setId(id);\n    role.setName(name);\n    role.setCode(code);\n    when(roleMapper.selectByName(name)).thenReturn(role);\n    when(roleMapper.selectByCode(code)).thenReturn(null);\n\n    // Act\n    try {\n        validateRoleDuplicate(name, code, id);\n    } catch (Exception e) {\n        // Assert\n        assertEquals(ROLE_NAME_DUPLICATE, e.getMessage());\n    }\n}\n```"]}
{"id": 53, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public String sign(Map<String, Object> map) {\n        try {\n            Date date = new Date(System.currentTimeMillis() + jwtProperties.getExpireTimeMills());\n            Algorithm algorithm = Algorithm.HMAC256(jwtProperties.getTokenSecret());\n            Map<String, Object> header = new HashMap<>(2);\n            header.put(\"typ\", \"jwt\");\n            JWTCreator.Builder builder = JWT.create()\n                    .withHeader(header)\n                    .withIssuedAt(new Date())\n                    .withExpiresAt(date);\n            map.entrySet().forEach(entry -> {\n                if (entry.getValue() instanceof Integer) {\n                    builder.withClaim(entry.getKey(), (Integer) entry.getValue());\n                } else if (entry.getValue() instanceof Long) {\n                    builder.withClaim(entry.getKey(), (Long) entry.getValue());\n                } else if (entry.getValue() instanceof Boolean) {\n                    builder.withClaim(entry.getKey(), (Boolean) entry.getValue());\n                } else if (entry.getValue() instanceof String) {\n                    builder.withClaim(entry.getKey(), String.valueOf(entry.getValue()));\n                } else if (entry.getValue() instanceof Double) {\n                    builder.withClaim(entry.getKey(), (Double) entry.getValue());\n                } else if (entry.getValue() instanceof Date) {\n                    builder.withClaim(entry.getKey(), (Date) entry.getValue());\n                }\n            });\n            return builder.sign(algorithm);\n        } catch (Exception e) {\n            return null;\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void sign_generateJwtToken_succeed()\n```\n### Answer: (use the provided format with backticks)\n", "name": "sign_generateJwtToken_succeed", "reference": "    @Test\n    public void sign_generateJwtToken_succeed() {\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"userId\", 123);\n        map.put(\"username\", \"testUser\");\n        String token = jwtService.sign(map);\n        Assert.assertNotNull(token);\n    }", "completions": ["  ```java\n@Test\npublic void sign_generateJwtToken_succeed() {\n    // Arrange\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"username\", \"johndoe\");\n    map.put(\"role\", \"admin\");\n    map.put(\"exp\", 1234567890);\n    map.put(\"iat\", 1234567890);\n    map.put(\"jti\", \"abcdefg\");\n    JwtProperties jwtProperties = new JwtProperties();\n    jwtProperties.setTokenSecret(\"my-secret-key\");\n    jwtProperties.setExpireTimeMills(3600000);\n\n    // Act\n    String token = sign(map, jwtProperties);\n\n    // Assert\n    assertNotNull(token);\n    assertTrue(token.startsWith(\"eyJhbGciOiJIUzI1NiJ9\"));\n    assertTrue(token.contains(\"username\"));\n    assertTrue(token.contains(\"role\"));\n    assertTrue(token.contains(\"exp\"));\n    assertTrue(token.contains(\"iat\"));\n    assertTrue(token.contains(\"jti\"));\n}\n```"]}
{"id": 54, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_map_of_non_serializable_value_with_null_value()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_map_of_non_serializable_value_with_null_value", "reference": "    @Test\n    public void should_clone_map_of_non_serializable_value_with_null_value() {\n        Map<String, NonSerializableObject> original = new LinkedHashMap<>();\n        original.put(\"null\", null);\n        original.put(\"key\", new NonSerializableObject(\"value\"));\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n    @Test\n    public void should_clone_map_of_non_serializable_value_with_null_value() {\n        Map<String, NonSerializableObject> map = new HashMap<>();\n        map.put(\"key1\", new NonSerializableObject(\"value1\"));\n        map.put(\"key2\", null);\n        Map<String, NonSerializableObject> clonedMap = (Map<String, NonSerializableObject>) clone(map);\n        assertEquals(map.size(), clonedMap.size());\n        assertEquals(map.get(\"key1\"), clonedMap.get(\"key1\"));\n        assertNull(clonedMap.get(\"key2\"));\n    }\n```"]}
{"id": 55, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public void init(final DiscoveryConfig config) {\n        if (this.namingService != null) {\n            LOGGER.info(\"Nacos naming service already registered\");\n            return;\n        }\n        Properties properties = config.getProps();\n        Properties nacosProperties = new Properties();\n        this.groupName = properties.getProperty(\"groupName\", \"SHENYU_GROUP\");\n        String serverAddr = config.getServerList();\n        nacosProperties.put(PropertyKeyConst.SERVER_ADDR, serverAddr);\n        nacosProperties.put(PropertyKeyConst.NAMESPACE, properties.getProperty(NAMESPACE, \"\"));\n        nacosProperties.put(PropertyKeyConst.USERNAME, properties.getProperty(PropertyKeyConst.USERNAME, \"\"));\n        nacosProperties.put(PropertyKeyConst.PASSWORD, properties.getProperty(PropertyKeyConst.PASSWORD, \"\"));\n        nacosProperties.put(PropertyKeyConst.ACCESS_KEY, properties.getProperty(PropertyKeyConst.ACCESS_KEY, \"\"));\n        nacosProperties.put(PropertyKeyConst.SECRET_KEY, properties.getProperty(PropertyKeyConst.SECRET_KEY, \"\"));\n        try {\n            this.namingService = NamingFactory.createNamingService(nacosProperties);\n            LOGGER.info(\"Nacos naming service initialized success\");\n        } catch (NacosException e) {\n            LOGGER.error(\"Error initializing Nacos naming service\", e);\n            throw new ShenyuException(e);\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testInit() throws NoSuchFieldException, IllegalAccessException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testInit", "reference": "    @Test\n    void testInit() throws NoSuchFieldException, IllegalAccessException {\n        // Set the discovery config\n        setField(nacosDiscoveryServiceUnderTest.getClass(), \"namingService\", null);\n        DiscoveryConfig config = new DiscoveryConfig();\n        Properties properties = new Properties();\n        config.setServerList(\"127.0.0.1:8848\");\n        properties.setProperty(\"groupName\", \"SHENYU_GROUP\");\n        config.setProps(properties);\n\n        try (MockedStatic<NamingFactory> mockedNamingFactory = mockStatic(NamingFactory.class)) {\n            // Mock the successful creation of NamingService\n            mockedNamingFactory.when(() -> NamingFactory.createNamingService(any(Properties.class)))\n                    .thenReturn(namingService);\n            nacosDiscoveryServiceUnderTest.init(config);\n            mockedNamingFactory.verify(() -> NamingFactory.createNamingService(any(Properties.class)));\n            assertEquals(namingService, getField(nacosDiscoveryServiceUnderTest, \"namingService\"));\n            // Mock the situation where NamingService fails to be created and throws an exception\n            mockedNamingFactory.when(() -> NamingFactory.createNamingService(any(Properties.class)))\n                    .thenThrow(new NacosException());\n            assertDoesNotThrow(() -> nacosDiscoveryServiceUnderTest.init(config));\n        }\n    }", "completions": ["  ```java\n@Test\nvoid testInit() throws NoSuchFieldException, IllegalAccessException {\n    // Setup\n    DiscoveryConfig config = mock(DiscoveryConfig.class);\n    Properties properties = new Properties();\n    properties.setProperty(\"groupName\", \"SHENYU_GROUP\");\n    properties.setProperty(\"serverList\", \"localhost:8848\");\n    properties.setProperty(\"namespace\", \"shenyu\");\n    properties.setProperty(\"username\", \"shenyu\");\n    properties.setProperty(\"password\", \"shenyu\");\n    properties.setProperty(\"accessKey\", \"shenyu\");\n    properties.setProperty(\"secretKey\", \"shenyu\");\n    when(config.getProps()).thenReturn(properties);\n\n    // Execute\n    NacosDiscoveryClient client = new NacosDiscoveryClient();\n    client.init(config);\n\n    // Verify\n    NamingService namingService = client.getNamingService();\n    assertNotNull(namingService);\n    assertEquals(\"localhost:8848\", namingService.getServerList());\n    assertEquals(\"shenyu\", namingService.getNamespace());\n    assertEquals(\"shenyu\", namingService.getUsername());\n    assertEquals(\"shenyu\", namingService.getPassword());\n    assertEquals(\"shenyu\", namingService.getAccessKey());\n    assertEquals(\"shenyu\", namingService.getSecretKey());\n}\n```"]}
{"id": 56, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public long determineStartingOffset(\n      long currentEndOffsetForPartition,\n      long currentBeginningOffsetForPartition,\n      AstraConfigs.IndexerConfig indexerConfig) {\n    // Filter stale snapshots for partition.\n    if (partitionId == null) {\n      LOG.warn(\"PartitionId can't be null.\");\n    }\n\n    List<SnapshotMetadata> snapshots = snapshotMetadataStore.listSync();\n    List<SnapshotMetadata> snapshotsForPartition =\n        snapshots.stream()\n            .filter(\n                snapshotMetadata -> {\n                  if (snapshotMetadata == null || snapshotMetadata.partitionId == null) {\n                    LOG.warn(\n                        \"snapshot metadata or partition id can't be null: {} \",\n                        Strings.join(snapshots, ','));\n                  }\n                  return snapshotMetadata != null\n                      && snapshotMetadata.partitionId != null\n                      && snapshotMetadata.partitionId.equals(partitionId);\n                })\n            .collect(Collectors.toUnmodifiableList());\n    List<SnapshotMetadata> deletedSnapshots = deleteStaleLiveSnapshots(snapshotsForPartition);\n\n    List<SnapshotMetadata> nonLiveSnapshotsForPartition =\n        snapshotsForPartition.stream()\n            .filter(s -> !deletedSnapshots.contains(s))\n            .collect(Collectors.toUnmodifiableList());\n\n    // Get the highest offset that is indexed in durable store.\n    List<RecoveryTaskMetadata> recoveryTasks = recoveryTaskMetadataStore.listSync();\n    long highestDurableOffsetForPartition =\n        getHighestDurableOffsetForPartition(\n            nonLiveSnapshotsForPartition, recoveryTasks, partitionId);\n    LOG.debug(\n        \"The highest durable offset for partition {} is {}\",\n        partitionId,\n        highestDurableOffsetForPartition);\n\n    if (highestDurableOffsetForPartition <= 0) {\n      LOG.info(\"There is no prior offset for this partition {}.\", partitionId);\n\n      // If the user wants to start at the current offset in Kafka and _does not_ want to create\n      // recovery tasks to backfill, then we can just return the current offset.\n      // If the user wants to start at the current offset in Kafka and _does_ want to create\n      // recovery tasks to backfill, then we create the recovery tasks needed and then return\n      // the current offset for the indexer. And if the user does _not_ want to start at the\n      // current offset in Kafka, then we'll just default to the old behavior of starting from\n      // the very beginning\n      if (!indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set to false and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" NOT spinning up recovery tasks\");\n        return currentEndOffsetForPartition;\n      } else if (indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        // Todo - this appears to be able to create recovery tasks that have a start and end\n        // position of 0, which is invalid. This seems to occur when new clusters are initialized,\n        // and is  especially problematic when indexers are created but never get assigned (ie,\n        // deploy 5, only assign 3).\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" spinning up recovery tasks\");\n        createRecoveryTasks(\n            partitionId,\n            currentBeginningOffsetForPartition,\n            currentEndOffsetForPartition,\n            indexerConfig.getMaxMessagesPerChunk());\n        return currentEndOffsetForPartition;\n\n      } else {\n        return highestDurableOffsetForPartition;\n      }\n    }\n\n    // The current head offset shouldn't be lower than the highest durable offset. If it is it\n    // means that we indexed more data than the current head offset. This is either a bug in the\n    // offset handling mechanism or the kafka partition has rolled over. We throw an exception\n    // for now, so we can investigate.\n    if (currentEndOffsetForPartition < highestDurableOffsetForPartition) {\n      final String message =\n          String.format(\n              \"The current head for the partition %d can't \"\n                  + \"be lower than the highest durable offset for that partition %d\",\n              currentEndOffsetForPartition, highestDurableOffsetForPartition);\n      LOG.error(message);\n      throw new IllegalStateException(message);\n    }\n\n    // The head offset for Kafka partition is the offset of the next message to be indexed. We\n    // assume that offset is passed into this function. The highest durable offset is the partition\n    // offset of the message that is indexed. Hence, the offset is incremented by 1 to get the\n    // next message.\n    long nextOffsetForPartition = highestDurableOffsetForPartition + 1;\n\n    // Create a recovery task if needed.\n    if (currentEndOffsetForPartition - highestDurableOffsetForPartition > maxOffsetDelay) {\n      LOG.info(\n          \"Recovery task needed. The current position {} and head location {} are higher than max\"\n              + \" offset {}\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay);\n      createRecoveryTasks(\n          partitionId,\n          nextOffsetForPartition,\n          currentEndOffsetForPartition - 1,\n          maxMessagesPerRecoveryTask);\n      return currentEndOffsetForPartition;\n    } else {\n      LOG.info(\n          \"The difference between the last indexed position {} and head location {} is lower \"\n              + \"than max offset {}. So, using {} position as the start offset\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay,\n          nextOffsetForPartition);\n      return nextOffsetForPartition;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testDetermineStartingOffsetOnlyRecoveryNotBehind()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDetermineStartingOffsetOnlyRecoveryNotBehind", "reference": "  @Test\n  public void testDetermineStartingOffsetOnlyRecoveryNotBehind() {\n    RecoveryTaskCreator recoveryTaskCreator =\n        new RecoveryTaskCreator(\n            snapshotMetadataStore,\n            recoveryTaskStore,\n            partitionId,\n            100,\n            TEST_MAX_MESSAGES_PER_RECOVERY_TASK,\n            meterRegistry);\n\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore)).isEmpty();\n\n    // When there is no data return -1.\n    assertThat(recoveryTaskCreator.determineStartingOffset(1000, 0, indexerConfig)).isNegative();\n    final String recoveryTaskName = \"recoveryTask\";\n    final long recoveryStartOffset = 400;\n    final long createdTimeUtc = Instant.now().toEpochMilli();\n\n    final RecoveryTaskMetadata recoveryTask1 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"1\",\n            partitionId,\n            recoveryStartOffset,\n            recoveryStartOffset * 2,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask1);\n    await().until(() -> recoveryTaskStore.listSync().contains(recoveryTask1));\n    assertThat(recoveryTaskCreator.determineStartingOffset(850, 0, indexerConfig))\n        .isEqualTo((recoveryStartOffset * 2) + 1);\n    assertThatIllegalStateException()\n        .isThrownBy(() -> recoveryTaskCreator.determineStartingOffset(750, 0, indexerConfig));\n\n    final RecoveryTaskMetadata recoveryTask11 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"11\",\n            partitionId,\n            recoveryStartOffset * 2 + 1,\n            recoveryStartOffset * 3,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask11);\n    await()\n        .until(\n            () -> recoveryTaskStore.listSync().containsAll(List.of(recoveryTask1, recoveryTask11)));\n    assertThat(recoveryTaskCreator.determineStartingOffset(1201, 0, indexerConfig))\n        .isEqualTo((recoveryStartOffset * 3) + 1);\n    assertThat(recoveryTaskCreator.determineStartingOffset(1200, 0, indexerConfig))\n        .isEqualTo((recoveryStartOffset * 3) + 1);\n    assertThatIllegalStateException()\n        .isThrownBy(() -> recoveryTaskCreator.determineStartingOffset(1150, 0, indexerConfig));\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore))\n        .contains(recoveryTask1, recoveryTask11);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n  }", "completions": ["  ```\n@Test\npublic void testDetermineStartingOffsetOnlyRecoveryNotBehind() {\n    // Set up mocks\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    RecoveryTaskMetadataStore recoveryTaskMetadataStore = mock(RecoveryTaskMetadataStore.class);\n    AstraConfigs.IndexerConfig indexerConfig = mock(AstraConfigs.IndexerConfig.class);\n\n    // Set up test data\n    long currentEndOffsetForPartition = 100L;\n    long currentBeginningOffsetForPartition = 50L;\n    long highestDurableOffsetForPartition = 90L;\n    long maxOffsetDelay = 10L;\n    long maxMessagesPerRecoveryTask = 10L;\n    List<SnapshotMetadata> snapshots = new ArrayList<>();\n    List<SnapshotMetadata> deletedSnapshots = new ArrayList<>();\n    List<RecoveryTaskMetadata> recoveryTasks = new ArrayList<>();\n\n    // Set up mock behavior\n    when(snapshotMetadataStore.listSync()).thenReturn(snapshots);\n    when(recoveryTaskMetadataStore.listSync()).thenReturn(recoveryTasks);\n    when(indexerConfig.getCreateRecoveryTasksOnStart()).thenReturn(true);\n    when(indexerConfig.getReadFromLocationOnStart()).thenReturn(AstraConfigs.KafkaOffsetLocation.LATEST);\n\n    // Call the method under test\n    long actualStartingOffset = determineStartingOffset(currentEndOffsetForPartition, currentBeginningOffsetForPartition, indexerConfig);\n\n    // Verify the results\n    assertEquals(highestDurableOffsetForPartition + 1, actualStartingOffset);\n    verify(snapshotMetadataStore, times(1)).listSync();\n    verify(recoveryTaskMetadataStore, times(1)).listSync();\n    verify(indexerConfig, times(1)).getCreateRecoveryTasksOnStart();\n    verify(indexerConfig, times(1)).getReadFromLocationOnStart();\n}\n```"]}
{"id": 57, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public boolean isJsonMime(String mediaType) {\n        // \"* / *\" is default to JSON\n        if (\"*/*\".equals(mediaType)) {\n            return true;\n        }\n\n        try {\n            return isJsonMime(MediaType.parseMediaType(mediaType));\n        } catch (InvalidMediaTypeException e) {\n        }\n        return false;\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testIsJsonMime()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testIsJsonMime", "reference": "    @Test\n    public void testIsJsonMime() {\n        assertFalse(apiClient.isJsonMime(null));\n        assertFalse(apiClient.isJsonMime(\"\"));\n        assertFalse(apiClient.isJsonMime(\"text/plain\"));\n        assertFalse(apiClient.isJsonMime(\"application/xml\"));\n        assertFalse(apiClient.isJsonMime(\"application/jsonp\"));\n        assertFalse(apiClient.isJsonMime(\"example/json\"));\n        assertFalse(apiClient.isJsonMime(\"example/foo+bar+jsonx\"));\n        assertFalse(apiClient.isJsonMime(\"example/foo+bar+xjson\"));\n\n        assertTrue(apiClient.isJsonMime(\"application/json\"));\n        assertTrue(apiClient.isJsonMime(\"application/json; charset=UTF8\"));\n        assertTrue(apiClient.isJsonMime(\"APPLICATION/JSON\"));\n\n        assertTrue(apiClient.isJsonMime(\"application/problem+json\"));\n        assertTrue(apiClient.isJsonMime(\"APPLICATION/PROBLEM+JSON\"));\n        assertTrue(apiClient.isJsonMime(\"application/json\\t\"));\n        assertTrue(apiClient.isJsonMime(\"example/foo+bar+json\"));\n        assertTrue(apiClient.isJsonMime(\"example/foo+json;x;y\"));\n        assertTrue(apiClient.isJsonMime(\"example/foo+json\\t;\"));\n        assertTrue(apiClient.isJsonMime(\"Example/fOO+JSON\"));\n    }", "completions": ["  ```\n@Test\npublic void testIsJsonMime() {\n    assertTrue(isJsonMime(\"application/json\"));\n    assertTrue(isJsonMime(\"application/json; charset=UTF-8\"));\n    assertFalse(isJsonMime(\"text/plain\"));\n    assertFalse(isJsonMime(\"*/*\"));\n    assertTrue(isJsonMime(\"*/*; charset=UTF-8\"));\n}\n```"]}
{"id": 58, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public void validateDpopThumprint(String existingThumprint, String requestThumprint) {\n        if (StringUtils.isBlank(existingThumprint) && isFalse(appConfiguration.getDpopJktForceForAuthorizationCode())) {\n            return; // nothing to check\n        }\n\n        if (!StringUtils.equals(existingThumprint, requestThumprint)) {\n            log.debug(\"DPoP Thumprint between saved one '{}' and send in request '{}' does NOT match. Reject request.\", existingThumprint, requestThumprint);\n            throw new WebApplicationException(Response\n                    .status(Response.Status.BAD_REQUEST)\n                    .type(MediaType.APPLICATION_JSON_TYPE)\n                    .entity(errorResponseFactory.errorAsJson(TokenErrorResponseType.INVALID_DPOP_PROOF, \"Thumprint does not match\"))\n                    .cacheControl(ServerUtil.cacheControl(true, false))\n                    .header(PRAGMA, NO_CACHE)\n                    .build());\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void validateDpopThumprint_whenExistingDpopThumprintMatchToActual_shouldPass()\n```\n### Answer: (use the provided format with backticks)\n", "name": "validateDpopThumprint_whenExistingDpopThumprintMatchToActual_shouldPass", "reference": "    @Test\n    public void validateDpopThumprint_whenExistingDpopThumprintMatchToActual_shouldPass() {\n        dpopService.validateDpopThumprint(\"test\", \"test\");\n    }", "completions": ["  ```\n@Test\npublic void validateDpopThumprint_whenExistingDpopThumprintMatchToActual_shouldPass() {\n    String existingThumprint = \"existingThumprint\";\n    String requestThumprint = \"existingThumprint\";\n    validateDpopThumprint(existingThumprint, requestThumprint);\n}\n```"]}
{"id": 59, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public static String getExpandUrl(String url, Object paramObj) {\n        UriComponentsBuilder builder = UriComponentsBuilder.fromHttpUrl(url);\n        if (paramObj instanceof Map) {\n            for (Map.Entry<String, Object> param : ((Map<String, Object>) paramObj).entrySet()) {\n                if (null != param.getValue()) {\n                    builder.queryParam(param.getKey(), param.getValue());\n                }\n            }\n        } else {\n            for (Field param : paramObj.getClass().getDeclaredFields()) {\n                param.setAccessible(true);\n\n                try {\n                    Object value = param.get(paramObj);\n                    if (null != value) {\n                        if (value instanceof List) {\n                            builder.queryParam(param.getName(), (List) value);\n                        } else {\n                            builder.queryParam(param.getName(), value);\n                        }\n                    }\n                } catch (IllegalAccessException e) {\n                    log.warn(\"Field: {} value retrieval failed, exception: {}\", param.getName(), e);\n                }\n            }\n        }\n\n        return builder.build().encode().toUri().toString();\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testGetExpandUrl()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetExpandUrl", "reference": "    @Test\n    void testGetExpandUrl() {\n        String result = HttpUtil.getExpandUrl(\"http://baidu.com\", \"paramObj\");\n        Assertions.assertNotNull(result);\n    }", "completions": ["  ```\n@Test\nvoid testGetExpandUrl() {\n    // Test with a Map parameter\n    Map<String, Object> paramMap = new HashMap<>();\n    paramMap.put(\"key1\", \"value1\");\n    paramMap.put(\"key2\", \"value2\");\n    String url = \"http://example.com\";\n    String expectedUrl = \"http://example.com?key1=value1&key2=value2\";\n    assertEquals(expectedUrl, getExpandUrl(url, paramMap));\n\n    // Test with a non-Map parameter\n    TestObject testObject = new TestObject();\n    testObject.setField1(\"value1\");\n    testObject.setField2(\"value2\");\n    url = \"http://example.com\";\n    expectedUrl = \"http://example.com?field1=value1&field2=value2\";\n    assertEquals(expectedUrl, getExpandUrl(url, testObject));\n\n    // Test with a List parameter\n    List<String> list = new ArrayList<>();\n    list.add(\"value1\");\n    list.add(\"value2\");\n    url = \"http://example.com\";\n    expectedUrl = \"http://example.com?list=value1&list=value2\";\n    assertEquals(expectedUrl, getExpandUrl(url, list));\n}\n```"]}
{"id": 60, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public static CacheControlHeader fromExpirationTime(String expirationTime) {\n    String maxAge = DEFAULT_MAX_AGE;\n\n    if (expirationTime != null) {\n      if (expirationTimeIsValid(expirationTime)) {\n        Duration totalTime = Duration.ZERO;\n        for (String timeString : Splitter.on(\" \").split(expirationTime)) {\n          String timeUnitShort = Ascii.toLowerCase(timeString.substring(timeString.length() - 1));\n          TemporalUnit timeUnit = EXPIRATION_TIME_UNITS.get(timeUnitShort);\n          String timeValue = timeString.substring(0, timeString.length() - 1);\n          totalTime = totalTime.plus(Long.parseLong(timeValue), timeUnit);\n        }\n        maxAge = String.valueOf(totalTime.getSeconds());\n      } else {\n          logger.atWarning().log(\n            \"Failed to parse expiration time: \\\"%s\\\". Using default value instead.\",\n            expirationTime\n        );\n      }\n    }\n\n    String output = DEFAULT_BASE_VALUE + maxAge;\n    return new CacheControlHeader(output);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForInvalidExpirationTime() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "fromExpirationTime_usesDefaultMaxAgeForInvalidExpirationTime", "reference": "  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForInvalidExpirationTime() throws Exception {\n    CacheControlHeader cacheControlHeader = CacheControlHeader.fromExpirationTime(\"asdf\");\n    assertThat(cacheControlHeader.getValue()).isEqualTo(\"public, max-age=600\");\n  }", "completions": ["  ```java\n  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForInvalidExpirationTime() throws Exception {\n    String invalidExpirationTime = \"10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}
{"id": 61, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Get\n  @Path(\"/:indexName/_mapping\")\n  public HttpResponse mapping(\n      @Param(\"indexName\") Optional<String> indexName,\n      @Param(\"startTimeEpochMs\") Optional<Long> startTimeEpochMs,\n      @Param(\"endTimeEpochMs\") Optional<Long> endTimeEpochMs)\n      throws IOException {\n    // Use a tree map so the results are naturally sorted\n    Map<String, Map<String, String>> propertiesMap = new TreeMap<>();\n\n    // we default the schema search to the last hour if params are not provided\n    AstraSearch.SchemaResult schemaResult =\n        searcher.getSchema(\n            AstraSearch.SchemaRequest.newBuilder()\n                .setDataset(indexName.orElse(\"*\"))\n                .setStartTimeEpochMs(\n                    startTimeEpochMs.orElse(\n                        Instant.now().minus(1, ChronoUnit.HOURS).toEpochMilli()))\n                .setEndTimeEpochMs(endTimeEpochMs.orElse(Instant.now().toEpochMilli()))\n                .build());\n\n    Map<String, FieldType> schema = SearchResultUtils.fromSchemaResultProto(schemaResult);\n    schema.forEach((key, value) -> propertiesMap.put(key, Map.of(\"type\", value.getName())));\n\n    // todo - remove this after we add support for a \"date\" type\n    // override the timestamp as a date field for proper autocomplete\n    propertiesMap.put(LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, Map.of(\"type\", \"date\"));\n\n    return HttpResponse.of(\n        HttpStatus.OK,\n        MediaType.JSON,\n        JsonUtil.writeAsString(\n            ImmutableMap.of(\n                indexName.orElseThrow(),\n                ImmutableMap.of(\"mappings\", ImmutableMap.of(\"properties\", propertiesMap)))));\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testIndexMapping() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testIndexMapping", "reference": "  @Test\n  public void testIndexMapping() throws IOException {\n    AstraQueryServiceBase searcher = mock(AstraQueryServiceBase.class);\n    ElasticsearchApiService serviceUnderTest = new ElasticsearchApiService(searcher);\n\n    Instant start = Instant.now();\n    Instant end = start.minusSeconds(60);\n\n    when(searcher.getSchema(\n            eq(\n                AstraSearch.SchemaRequest.newBuilder()\n                    .setDataset(\"foo\")\n                    .setStartTimeEpochMs(start.toEpochMilli())\n                    .setEndTimeEpochMs(end.toEpochMilli())\n                    .build())))\n        .thenReturn(AstraSearch.SchemaResult.newBuilder().build());\n\n    HttpResponse response =\n        serviceUnderTest.mapping(\n            Optional.of(\"foo\"), Optional.of(start.toEpochMilli()), Optional.of(end.toEpochMilli()));\n    verify(searcher)\n        .getSchema(\n            eq(\n                AstraSearch.SchemaRequest.newBuilder()\n                    .setDataset(\"foo\")\n                    .setStartTimeEpochMs(start.toEpochMilli())\n                    .setEndTimeEpochMs(end.toEpochMilli())\n                    .build()));\n\n    // handle response\n    AggregatedHttpResponse aggregatedRes = response.aggregate().join();\n    String body = aggregatedRes.content(StandardCharsets.UTF_8);\n    JsonNode jsonNode = new ObjectMapper().readTree(body);\n\n    assertThat(aggregatedRes.status().code()).isEqualTo(200);\n\n    assertThat(jsonNode.findValue(\"foo\")).isNotNull();\n    assertThat(\n            jsonNode.findValue(\"foo\").findValue(LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName))\n        .isNotNull();\n\n    when(searcher.getSchema(any()))\n        .thenAnswer(\n            invocationOnMock -> {\n              AstraSearch.SchemaRequest request =\n                  ((AstraSearch.SchemaRequest) invocationOnMock.getArguments()[0]);\n              assertThat(request.getDataset()).isEqualTo(\"bar\");\n              assertThat(request.getStartTimeEpochMs())\n                  .isCloseTo(\n                      Instant.now().minus(1, ChronoUnit.HOURS).toEpochMilli(),\n                      Offset.offset(1000L));\n              assertThat(request.getEndTimeEpochMs())\n                  .isCloseTo(Instant.now().toEpochMilli(), Offset.offset(1000L));\n              return AstraSearch.SchemaResult.newBuilder().build();\n            });\n    serviceUnderTest.mapping(Optional.of(\"bar\"), Optional.empty(), Optional.empty());\n  }", "completions": ["  ```java\n  @Test\n  public void testIndexMapping() throws IOException {\n    // Set up mocks\n    Searcher searcher = mock(Searcher.class);\n    AstraSearch.SchemaResult schemaResult = mock(AstraSearch.SchemaResult.class);\n    Map<String, FieldType> schema = mock(Map.class);\n    JsonUtil jsonUtil = mock(JsonUtil.class);\n\n    // Set up expectations\n    when(searcher.getSchema(any(AstraSearch.SchemaRequest.class))).thenReturn(schemaResult);\n    when(schemaResult.getSchema()).thenReturn(schema);\n    when(jsonUtil.writeAsString(any(Map.class))).thenReturn(\"{\\\"mappings\\\":{\\\"properties\\\":{}}}\");\n\n    // Call the method under test\n    HttpResponse response = mapping(Optional.of(\"my-index\"), Optional.of(123456789L), Optional.of(987654321L));\n\n    // Verify the results\n    assertEquals(HttpStatus.OK, response.getStatus());\n    assertEquals(MediaType.JSON, response.getContentType());\n    assertEquals(\"{\\\"my-index\\\":{\\\"mappings\\\":{\\\"properties\\\":{}}}}\", response.getBody());\n  }\n```"]}
{"id": 62, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public ConsumerRecords<K, V> poll(final Duration timeout) {\n        Timer timer = time.timer(timeout);\n\n        acquireAndEnsureOpen();\n        try {\n            kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());\n\n            if (subscriptions.hasNoSubscriptionOrUserAssignment()) {\n                throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n            }\n\n            do {\n\n                // Make sure to let the background thread know that we are still polling.\n                applicationEventHandler.add(new PollEvent(timer.currentTimeMs()));\n\n                // We must not allow wake-ups between polling for fetches and returning the records.\n                // If the polled fetches are not empty the consumed position has already been updated in the polling\n                // of the fetches. A wakeup between returned fetches and returning records would lead to never\n                // returning the records in the fetches. Thus, we trigger a possible wake-up before we poll fetches.\n                wakeupTrigger.maybeTriggerWakeup();\n\n                updateAssignmentMetadataIfNeeded(timer);\n                final Fetch<K, V> fetch = pollForFetches(timer);\n                if (!fetch.isEmpty()) {\n                    if (fetch.records().isEmpty()) {\n                        log.trace(\"Returning empty records from `poll()` \"\n                            + \"since the consumer's position has advanced for at least one topic partition\");\n                    }\n\n                    return interceptors.onConsume(new ConsumerRecords<>(fetch.records()));\n                }\n                // We will wait for retryBackoffMs\n            } while (timer.notExpired());\n\n            return ConsumerRecords.empty();\n        } finally {\n            kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    @SuppressWarnings(\"deprecation\")\n    public void testPollLongThrowsException()\n```\n### Answer: (use the provided format with backticks)\n", "name": "@SuppressWarnings", "reference": "    @Test\n    @SuppressWarnings(\"deprecation\")\n    public void testPollLongThrowsException() {\n        consumer = newConsumer();\n        Exception e = assertThrows(UnsupportedOperationException.class, () -> consumer.poll(0L));\n        assertEquals(\"Consumer.poll(long) is not supported when \\\"group.protocol\\\" is \\\"consumer\\\". \" +\n            \"This method is deprecated and will be removed in the next major release.\", e.getMessage());\n    }", "completions": ["  ```java\n    @Test\n    @SuppressWarnings(\"deprecation\")\n    public void testPollLongThrowsException() {\n        // Set up the consumer with a mocked KafkaConsumer\n        KafkaConsumer<String, String> consumer = mock(KafkaConsumer.class);\n        when(consumer.poll(any(Duration.class))).thenThrow(new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\"));\n\n        // Set up the subscriptions with a mocked SubscriptionState\n        SubscriptionState subscriptions = mock(SubscriptionState.class);\n        when(subscriptions.hasNoSubscriptionOrUserAssignment()).thenReturn(true);\n\n        // Set up the application event handler with a mocked ApplicationEventHandler\n        ApplicationEventHandler applicationEventHandler = mock(ApplicationEventHandler.class);\n\n        // Set up the wakeup trigger with a mocked WakeupTrigger\n        WakeupTrigger wakeupTrigger = mock(WakeupTrigger.class);\n\n        // Set up the timer with a mocked Timer\n        Timer timer = mock(Timer.class);\n        when(timer.currentTimeMs()).thenReturn(0L);\n\n        // Set up the kafka consumer metrics with a mocked KafkaConsumerMetrics\n        KafkaConsumerMetrics kafkaConsumerMetrics = mock(KafkaConsumerMetrics.class);\n\n        // Set up the interceptors with a mocked ConsumerInterceptors\n        ConsumerInterceptors interceptors = mock(ConsumerInterceptors.class);\n\n        // Set up the poll method with a mocked Fetch\n        Fetch<String, String> fetch = mock(Fetch.class);\n        when(fetch.isEmpty()).thenReturn(true);\n\n        // Call the poll method with a long timeout\n        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n\n        // Verify that the poll method throws an IllegalStateException\n        verify(consumer).poll(any(Duration.class));\n        assertThat(records, is(ConsumerRecords.empty()));\n    }\n```"]}
{"id": 63, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testNullSearchString()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testNullSearchString", "reference": "  @Test\n  public void testNullSearchString() {\n    Instant time = Instant.ofEpochSecond(1593365471);\n    loadTestData(time);\n\n    assertThatExceptionOfType(IllegalArgumentException.class)\n        .isThrownBy(\n            () ->\n                strictLogStore.logSearcher.search(\n                    TEST_DATASET_NAME + \"miss\",\n                    null,\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\")));\n  }", "completions": ["  ```java\n@Test\npublic void testNullSearchString() {\n    // Given\n    String dataset = \"testDataset\";\n    String queryStr = null;\n    Long startTimeMsEpoch = 1000L;\n    Long endTimeMsEpoch = 2000L;\n    int howMany = 10;\n    AggBuilder aggBuilder = null;\n\n    // When\n    SearchResult<LogMessage> result = search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n\n    // Then\n    assertEquals(0, result.getTotalHits());\n    assertEquals(0, result.getTotalAggs());\n    assertEquals(0, result.getElapsedTime());\n    assertEquals(0, result.getTotalShards());\n    assertEquals(0, result.getSuccessfulShards());\n    assertNull(result.getInternalAggregation());\n}\n```"]}
{"id": 64, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public CompletableFuture<RemotingCommand> sendMessageBack(ProxyContext ctx, ReceiptHandle handle, String messageId,\n        ConsumerSendMsgBackRequestHeader requestHeader, long timeoutMillis) {\n        // Build the response.\n        final RemotingCommand response = RemotingCommand.createResponseCommand(ResponseCode.SUCCESS, null, null);\n\n        Integer delayLevel = requestHeader.getDelayLevel();\n        if (Objects.isNull(delayLevel)) {\n            response.setCode(ResponseCode.ILLEGAL_OPERATION);\n            response.setRemark(\"argument delay level is null\");\n            return CompletableFuture.completedFuture(response);\n        }\n\n        Long offset = requestHeader.getOffset();\n        if (Objects.isNull(offset)) {\n            response.setCode(ResponseCode.ILLEGAL_OPERATION);\n            response.setRemark(\"argument offset is null\");\n            return CompletableFuture.completedFuture(response);\n        }\n\n        VirtualQueue virtualQueue = new VirtualQueue(requestHeader.getBname());\n\n        CompletableFuture<Topic> topicFuture = topicOf(requestHeader.getOriginTopic());\n        CompletableFuture<ConsumerGroup> groupFuture = consumerGroupOf(requestHeader.getGroup());\n        return topicFuture.thenCombine(groupFuture, (topic, group) -> {\n            if (topic.getTopicId() != virtualQueue.topicId()) {\n                LOGGER.error(\"Topic id in request header {} does not match topic id in message queue {}, maybe the topic is recreated.\",\n                    topic.getTopicId(), virtualQueue.topicId());\n                throw new ProxyException(apache.rocketmq.v2.Code.TOPIC_NOT_FOUND, \"Topic resource does not exist.\");\n            }\n            return Pair.of(topic, group);\n        }).thenCompose(pair -> {\n            Topic topic = pair.getLeft();\n            ConsumerGroup group = pair.getRight();\n\n            return store.pull(StoreContext.EMPTY, group.getGroupId(), topic.getTopicId(), virtualQueue.physicalQueueId(),\n                    Filter.DEFAULT_FILTER, requestHeader.getOffset(), 1, false)\n                .thenApply(pullResult -> {\n                    if (pullResult.status() == com.automq.rocketmq.store.model.message.PullResult.Status.FOUND) {\n                        return pullResult.messageList().get(0);\n                    }\n                    throw new ProxyException(apache.rocketmq.v2.Code.MESSAGE_NOT_FOUND, \"Message not found from server.\");\n                }).thenCompose(messageExt -> {\n                    if (messageExt.deliveryAttempts() > group.getMaxDeliveryAttempt()) {\n                        return deadLetterService.send((ProxyContextExt) ctx, group.getGroupId(), messageExt.message());\n                    }\n\n                    // Message consume retry strategy\n                    // <0: no retry,put into DLQ directly\n                    // =0: broker control retry frequency\n                    // >0: client control retry frequency\n                    return switch (Integer.compare(delayLevel, 0)) {\n                        case -1 ->\n                            deadLetterService.send((ProxyContextExt) ctx, group.getGroupId(), messageExt.message());\n                        case 0 -> topicOf(MixAll.RETRY_GROUP_TOPIC_PREFIX + requestHeader.getGroup())\n                            .thenCompose(retryTopic -> {\n                                // Keep the same logic as apache RocketMQ.\n                                int serverDelayLevel = messageExt.deliveryAttempts() + 1;\n                                messageExt.setDeliveryAttempts(serverDelayLevel);\n                                messageExt.setOriginalQueueOffset(messageExt.originalOffset());\n\n                                FlatMessage message = messageExt.message();\n                                message.mutateTopicId(retryTopic.getTopicId());\n\n                                message.systemProperties().mutateDeliveryTimestamp(FlatMessageUtil.calculateDeliveryTimestamp(serverDelayLevel));\n                                return store.put(StoreContext.EMPTY, message)\n                                    .exceptionally(ex -> {\n                                        LOGGER.error(\"Put messageExt to retry topic failed\", ex);\n                                        return null;\n                                    })\n                                    .thenApply(ignore -> null);\n                            });\n                        case 1 -> topicOf(MixAll.RETRY_GROUP_TOPIC_PREFIX + requestHeader.getGroup())\n                            .thenCompose(retryTopic -> {\n                                messageExt.setDeliveryAttempts(messageExt.deliveryAttempts() + 1);\n                                messageExt.setOriginalQueueOffset(messageExt.originalOffset());\n\n                                FlatMessage message = messageExt.message();\n                                message.mutateTopicId(retryTopic.getTopicId());\n\n                                message.systemProperties().mutateDeliveryTimestamp(FlatMessageUtil.calculateDeliveryTimestamp(delayLevel));\n                                return store.put(StoreContext.EMPTY, message)\n                                    .exceptionally(ex -> {\n                                        LOGGER.error(\"Put message to retry topic failed\", ex);\n                                        return null;\n                                    })\n                                    .thenApply(ignore -> null);\n                            });\n                        default -> throw new IllegalStateException(\"Never reach here\");\n                    };\n                });\n        }).whenComplete((nil, throwable) -> {\n            if (throwable != null) {\n                response.setCode(ResponseCode.SYSTEM_ERROR);\n                response.setRemark(throwable.getMessage());\n            }\n        }).thenApply(nil -> response);\n    }\n```\n###test function signature:\n```java\n    @Test\n    void sendMessageBack()\n```\n### Answer: (use the provided format with backticks)\n", "name": "sendMessageBack", "reference": "    @Test\n    void sendMessageBack() {\n        String topicName = \"topic\";\n        VirtualQueue virtualQueue = new VirtualQueue(2, 0);\n        ConsumerSendMsgBackRequestHeader header = new ConsumerSendMsgBackRequestHeader();\n        header.setBname(virtualQueue.brokerName());\n        header.setGroup(\"group\");\n        header.setOriginTopic(topicName);\n        header.setOffset(0L);\n        header.setDelayLevel(0);\n\n        CompletionException exception = assertThrowsExactly(CompletionException.class, () -> messageService.sendMessageBack(ProxyContextExt.create(), null, null, header, 0L).join());\n        assertInstanceOf(ProxyException.class, ExceptionUtils.getRealException(exception));\n        ProxyException realException = (ProxyException) ExceptionUtils.getRealException(exception);\n        assertEquals(realException.getErrorCode(), Code.MESSAGE_NOT_FOUND);\n        assertEquals(realException.getMessage(), \"Message not found from server.\");\n\n        long topicId = metadataService.topicOf(topicName).join().getTopicId();\n        messageStore.put(StoreContext.EMPTY, FlatMessageUtil.convertTo(ProxyContextExt.create(), topicId, 0, \"\", new Message(topicName, \"\", new byte[] {})));\n\n        // Broker controlled delay level.\n        header.setDelayLevel(0);\n        RemotingCommand response = messageService.sendMessageBack(ProxyContextExt.create(), null, null, header, 0L).join();\n        assertEquals(ResponseCode.SUCCESS, response.getCode());\n        Mockito.verify(deadLetterSender, Mockito.never()).send(Mockito.any(), Mockito.anyLong(), Mockito.any());\n\n        // Client controlled delay level.\n        header.setDelayLevel(16);\n        response = messageService.sendMessageBack(ProxyContextExt.create(), null, null, header, 0L).join();\n        assertEquals(ResponseCode.SUCCESS, response.getCode());\n        Mockito.verify(deadLetterSender, Mockito.never()).send(Mockito.any(), Mockito.anyLong(), Mockito.any());\n\n        // Forward message into dead letter topic.\n        header.setDelayLevel(-1);\n        response = messageService.sendMessageBack(ProxyContextExt.create(), null, null, header, 0L).join();\n        assertEquals(ResponseCode.SUCCESS, response.getCode());\n        Mockito.verify(deadLetterSender, Mockito.times(1)).send(Mockito.any(), Mockito.anyLong(), Mockito.any());\n    }", "completions": ["  ```\n@Test\nvoid sendMessageBack() {\n    // Set up the context, handle, and message ID\n    ProxyContext ctx = mock(ProxyContext.class);\n    ReceiptHandle handle = mock(ReceiptHandle.class);\n    String messageId = \"test-message-id\";\n\n    // Set up the request header\n    ConsumerSendMsgBackRequestHeader requestHeader = mock(ConsumerSendMsgBackRequestHeader.class);\n    when(requestHeader.getDelayLevel()).thenReturn(1);\n    when(requestHeader.getOffset()).thenReturn(100L);\n    when(requestHeader.getOriginTopic()).thenReturn(\"test-topic\");\n    when(requestHeader.getGroup()).thenReturn(\"test-group\");\n\n    // Set up the topic and consumer group\n    Topic topic = mock(Topic.class);\n    when(topic.getTopicId()).thenReturn(\"test-topic-id\");\n    ConsumerGroup group = mock(ConsumerGroup.class);\n    when(group.getGroupId()).thenReturn(\"test-group-id\");\n    when(group.getMaxDeliveryAttempt()).thenReturn(3);\n\n    // Set up the store and dead letter service\n    Store store = mock(Store.class);\n    DeadLetterService deadLetterService = mock(DeadLetterService.class);\n\n    // Set up the virtual queue\n    VirtualQueue virtualQueue = new VirtualQueue(\"test-bname\");\n\n    // Call the method\n    CompletableFuture<RemotingCommand> responseFuture = sendMessageBack(ctx, handle, messageId, requestHeader, 1000L);\n\n    // Verify the response\n    RemotingCommand response = responseFuture.get();\n    assertEquals(ResponseCode.SUCCESS, response.getCode());\n    assertNull(response.getRemark());\n\n    // Verify the interactions with the store and dead letter service\n    verify(store).pull(any(StoreContext.class), eq(\"test-group-id\"), eq(\"test-topic-id\"), eq(virtualQueue.physicalQueueId()),\n            eq(Filter.DEFAULT_FILTER), eq(100L), eq(1), eq(false));\n    verify(deadLetterService, never()).send(any(ProxyContextExt.class), anyString(), any(FlatMessage.class));\n}\n```"]}
{"id": 65, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public ApolloAuditTracer tracer() {\n    RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n    if (requestAttributes != null) {\n      Object tracer = requestAttributes.getAttribute(ApolloAuditConstants.TRACER,\n          RequestAttributes.SCOPE_REQUEST);\n      if (tracer != null) {\n        return ((ApolloAuditTracer) tracer);\n      } else {\n        ApolloAuditTracer newTracer = new ApolloAuditTracer(new ApolloAuditScopeManager(), operatorSupplier);\n        setTracer(newTracer);\n        return newTracer;\n      }\n    }\n    return null;\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetTracerInRequestThreads()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetTracerInRequestThreads", "reference": "  @Test\n  public void testGetTracerInRequestThreads() {\n    ApolloAuditTracer mockTracer = new ApolloAuditTracer(Mockito.mock(ApolloAuditScopeManager.class), supplier);\n    RequestAttributes mockRequestAttributes = Mockito.mock(RequestAttributes.class);\n    RequestContextHolder.setRequestAttributes(mockRequestAttributes);\n    Mockito.when(mockRequestAttributes.getAttribute(Mockito.eq(ApolloAuditConstants.TRACER), Mockito.eq(RequestAttributes.SCOPE_REQUEST)))\n            .thenReturn(mockTracer);\n    ApolloAuditTracer get = traceContext.tracer();\n    assertNotNull(get);\n    Mockito.verify(traceContext, Mockito.times(0))\n        .setTracer(Mockito.any(ApolloAuditTracer.class));\n  }", "completions": ["  ```\n@Test\npublic void testGetTracerInRequestThreads() {\n    // Set up mock request attributes\n    RequestAttributes requestAttributes = mock(RequestAttributes.class);\n    when(requestAttributes.getAttribute(ApolloAuditConstants.TRACER, RequestAttributes.SCOPE_REQUEST)).thenReturn(null);\n    RequestContextHolder.setRequestAttributes(requestAttributes);\n\n    // Set up mock operator supplier\n    Supplier<Operator> operatorSupplier = mock(Supplier.class);\n    when(operatorSupplier.get()).thenReturn(mock(Operator.class));\n\n    // Call the method under test\n    ApolloAuditTracer tracer = tracer();\n\n    // Verify that the tracer was created with the correct scope manager and operator supplier\n    assertNotNull(tracer);\n    assertEquals(new ApolloAuditScopeManager(), tracer.getScopeManager());\n    assertEquals(operatorSupplier, tracer.getOperatorSupplier());\n\n    // Verify that the tracer was set as a request attribute\n    verify(requestAttributes).setAttribute(ApolloAuditConstants.TRACER, tracer, RequestAttributes.SCOPE_REQUEST);\n}\n```"]}
{"id": 66, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public Map<String, String> generate(String modelName) {\n        Map<String, String> kv = new HashMap<>();\n        if (modelName != null) {\n            final Schema schema = this.globalContext.getSchemaMap().get(modelName);\n            if (schema != null) {\n                String example = Json.pretty(this.resolveModelToExample(modelName, schema));\n\n                if (example != null) {\n                    kv.put(EXAMPLE, example);\n                    return Map.copyOf(kv);\n                }\n            }\n        }\n        return Collections.emptyMap();\n    }\n```\n###test function signature:\n```java\n    @Test\n    void shouldGenerateOneOfWhenOneOfInRoot() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "shouldGenerateOneOfWhenOneOfInRoot", "reference": "    @Test\n    void shouldGenerateOneOfWhenOneOfInRoot() throws Exception {\n        OpenAPIModelGenerator generator = setupPayloadGenerator();\n\n        Map<String, String> example = generator.generate(\"PetType\");\n        String exampleJson = example.get(\"example\");\n\n        Assertions.assertThat(exampleJson)\n                .contains(\"PetTypeONE_OF#/components/schemas/Husky\")\n                .contains(\"PetTypeONE_OF#/components/schemas/Labrador\");\n    }", "completions": ["  ```java\n    @Test\n    void shouldGenerateOneOfWhenOneOfInRoot() throws Exception {\n        // Arrange\n        String modelName = \"oneOfInRoot\";\n        Map<String, String> expected = new HashMap<>();\n        expected.put(EXAMPLE, \"{\\\"oneOf\\\":[{\\\"type\\\":\\\"string\\\"},{\\\"type\\\":\\\"integer\\\"}]}\");\n\n        // Act\n        Map<String, String> actual = generate(modelName);\n\n        // Assert\n        assertEquals(expected, actual);\n    }\n```"]}
{"id": 67, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public ApolloAuditTracer tracer() {\n    RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n    if (requestAttributes != null) {\n      Object tracer = requestAttributes.getAttribute(ApolloAuditConstants.TRACER,\n          RequestAttributes.SCOPE_REQUEST);\n      if (tracer != null) {\n        return ((ApolloAuditTracer) tracer);\n      } else {\n        ApolloAuditTracer newTracer = new ApolloAuditTracer(new ApolloAuditScopeManager(), operatorSupplier);\n        setTracer(newTracer);\n        return newTracer;\n      }\n    }\n    return null;\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetTracerInAnotherThreadButSameRequest()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetTracerInAnotherThreadButSameRequest", "reference": "  @Test\n  public void testGetTracerInAnotherThreadButSameRequest() {\n    ApolloAuditTracer mockTracer = Mockito.mock(ApolloAuditTracer.class);\n    {\n      Mockito.when(traceContext.tracer()).thenReturn(mockTracer);\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    Executors.newSingleThreadExecutor().submit(() -> {\n      ApolloAuditTracer tracer = traceContext.tracer();\n\n      assertEquals(mockTracer, tracer);\n\n      latch.countDown();\n    });\n  }", "completions": ["  ```java\n@Test\npublic void testGetTracerInAnotherThreadButSameRequest() {\n    // Set up a mock request attributes object\n    RequestAttributes requestAttributes = mock(RequestAttributes.class);\n    when(requestAttributes.getAttribute(ApolloAuditConstants.TRACER, RequestAttributes.SCOPE_REQUEST)).thenReturn(null);\n    RequestContextHolder.setRequestAttributes(requestAttributes);\n\n    // Set up a mock operator supplier\n    Supplier<Operator> operatorSupplier = mock(Supplier.class);\n    when(operatorSupplier.get()).thenReturn(mock(Operator.class));\n\n    // Create a new thread and set up the request attributes and operator supplier\n    Thread thread = new Thread(() -> {\n        RequestAttributes threadRequestAttributes = RequestContextHolder.getRequestAttributes();\n        assertNotNull(threadRequestAttributes);\n        assertEquals(requestAttributes, threadRequestAttributes);\n\n        ApolloAuditTracer tracer = tracer();\n        assertNotNull(tracer);\n        assertEquals(new ApolloAuditTracer(new ApolloAuditScopeManager(), operatorSupplier), tracer);\n    });\n\n    // Start the thread and wait for it to finish\n    thread.start();\n    thread.join();\n}\n```"]}
{"id": 68, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testSearchMultipleItemsAndIndices()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSearchMultipleItemsAndIndices", "reference": "  @Test\n  public void testSearchMultipleItemsAndIndices() {\n    Instant time = Instant.now();\n    loadTestData(time);\n    SearchResult<LogMessage> babies =\n        strictLogStore.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"Message1\",\n            time.toEpochMilli(),\n            time.plusSeconds(2).toEpochMilli(),\n            10,\n            new DateHistogramAggBuilder(\n                \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"));\n    assertThat(babies.hits.size()).isEqualTo(1);\n\n    InternalDateHistogram histogram =\n        (InternalDateHistogram) Objects.requireNonNull(babies.internalAggregation);\n    assertThat(histogram.getBuckets().size()).isEqualTo(1);\n    assertThat(histogram.getBuckets().get(0).getDocCount()).isEqualTo(1);\n  }", "completions": ["  ```java\n@Test\npublic void testSearchMultipleItemsAndIndices() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any())).thenReturn(query);\n    CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector = mock(CollectorManager.class);\n    when(topFieldCollector.getLeafCollector(any())).thenReturn(mock(TopFieldCollector.class));\n    when(openSearchAdapter.getCollectorManager(any(), any(), any())).thenReturn(topFieldCollector);\n    ScoreDoc[] hits = new ScoreDoc[2];\n    hits[0] = new ScoreDoc(1, 1.0f);\n    hits[1] = new ScoreDoc(2, 2.0f);\n    TopFieldDocs topFieldDocs = new TopFieldDocs(1, hits, new SortField(\"field\", SortField.Type.STRING));\n    when(searcher.search(any(), any())).thenReturn(topFieldDocs);\n    LogMessage logMessage1 = mock(LogMessage.class);\n    LogMessage logMessage2 = mock(LogMessage.class);\n    when(buildLogMessage(searcher, hits[0])).thenReturn(logMessage1);\n    when(buildLogMessage(searcher, hits[1])).thenReturn(logMessage2);\n    InternalAggregation internalAggregation = mock(InternalAggregation.class);\n    when(searcher.search(any(), any())).thenReturn(internalAggregation);\n\n    // Call the method under test\n    SearchResult<LogMessage> result = search(searcherManager, openSearchAdapter, \"dataset\", \"query\", 10L, 20L, 10, null);\n\n    // Verify the results\n    assertEquals(2, result.getHits().size());\n    assertEquals(logMessage1, result.getHits().get(0));\n    assertEquals(logMessage2, result.getHits().get(1));\n    assertEquals(10, result.getElapsedTime());\n    assertEquals(0, result.getTotalHits());\n    assertEquals(1, result.getTotalIndices());\n    assertEquals(1, result.getTotalShards());\n    assertEquals(internalAggregation, result.getInternalAggregation());\n}\n```"]}
{"id": 69, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  static Map<String, Set<Pair<TableRebalanceContext, Long>>> getCandidateJobs(String tableNameWithType,\n      Map<String, Map<String, String>> allJobMetadata)\n      throws Exception {\n    long nowMs = System.currentTimeMillis();\n    Map<String, Set<Pair<TableRebalanceContext, Long>>> candidates = new HashMap<>();\n    // If the job started most recently has already completed, then skip retry for the table.\n    Pair<String, Long> latestStartedJob = null;\n    Pair<String, Long> latestCompletedJob = null;\n    // The processing order of job metadata from the given Map is not deterministic. Track the completed original\n    // jobs so that we can simply skip the retry jobs belonging to the completed original jobs.\n    Map<String, String> completedOriginalJobs = new HashMap<>();\n    Set<String> cancelledOriginalJobs = new HashSet<>();\n    for (Map.Entry<String, Map<String, String>> entry : allJobMetadata.entrySet()) {\n      String jobId = entry.getKey();\n      Map<String, String> jobMetadata = entry.getValue();\n      long statsUpdatedAt = Long.parseLong(jobMetadata.get(CommonConstants.ControllerJob.SUBMISSION_TIME_MS));\n      String jobStatsInStr = jobMetadata.get(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_PROGRESS_STATS);\n      if (StringUtils.isEmpty(jobStatsInStr)) {\n        LOGGER.info(\"Skip rebalance job: {} as it has no job progress stats\", jobId);\n        continue;\n      }\n      String jobCtxInStr = jobMetadata.get(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_CONTEXT);\n      if (StringUtils.isEmpty(jobCtxInStr)) {\n        LOGGER.info(\"Skip rebalance job: {} as it has no job context\", jobId);\n        continue;\n      }\n      TableRebalanceProgressStats jobStats = JsonUtils.stringToObject(jobStatsInStr, TableRebalanceProgressStats.class);\n      TableRebalanceContext jobCtx = JsonUtils.stringToObject(jobCtxInStr, TableRebalanceContext.class);\n      long jobStartTimeMs = jobStats.getStartTimeMs();\n      if (latestStartedJob == null || latestStartedJob.getRight() < jobStartTimeMs) {\n        latestStartedJob = Pair.of(jobId, jobStartTimeMs);\n      }\n      String originalJobId = jobCtx.getOriginalJobId();\n      RebalanceResult.Status jobStatus = jobStats.getStatus();\n      if (jobStatus == RebalanceResult.Status.DONE || jobStatus == RebalanceResult.Status.NO_OP) {\n        LOGGER.info(\"Skip rebalance job: {} as it has completed with status: {}\", jobId, jobStatus);\n        completedOriginalJobs.put(originalJobId, jobId);\n        if (latestCompletedJob == null || latestCompletedJob.getRight() < jobStartTimeMs) {\n          latestCompletedJob = Pair.of(jobId, jobStartTimeMs);\n        }\n        continue;\n      }\n      if (jobStatus == RebalanceResult.Status.FAILED || jobStatus == RebalanceResult.Status.ABORTED) {\n        LOGGER.info(\"Found rebalance job: {} for original job: {} has been stopped with status: {}\", jobId,\n            originalJobId, jobStatus);\n        candidates.computeIfAbsent(originalJobId, (k) -> new HashSet<>()).add(Pair.of(jobCtx, jobStartTimeMs));\n        continue;\n      }\n      if (jobStatus == RebalanceResult.Status.CANCELLED) {\n        LOGGER.info(\"Found cancelled rebalance job: {} for original job: {}\", jobId, originalJobId);\n        cancelledOriginalJobs.add(originalJobId);\n        continue;\n      }\n      // Check if an IN_PROGRESS job is still actively running.\n      long heartbeatTimeoutMs = jobCtx.getConfig().getHeartbeatTimeoutInMs();\n      if (nowMs - statsUpdatedAt < heartbeatTimeoutMs) {\n        LOGGER.info(\"Rebalance job: {} is actively running with status updated at: {} within timeout: {}. Skip \"\n            + \"retry for table: {}\", jobId, statsUpdatedAt, heartbeatTimeoutMs, tableNameWithType);\n        return Collections.emptyMap();\n      }\n      // The job is considered failed, but it's possible it is still running, then we might end up with more than one\n      // rebalance jobs running in parallel for a table. The rebalance algorithm is idempotent, so this should be fine\n      // for the correctness.\n      LOGGER.info(\"Found stuck rebalance job: {} for original job: {}\", jobId, originalJobId);\n      candidates.computeIfAbsent(originalJobId, (k) -> new HashSet<>()).add(Pair.of(jobCtx, jobStartTimeMs));\n    }\n    if (latestCompletedJob != null && latestCompletedJob.getLeft().equals(latestStartedJob.getLeft())) {\n      LOGGER.info(\"Rebalance job: {} started most recently has already done. Skip retry for table: {}\",\n          latestCompletedJob.getLeft(), tableNameWithType);\n      return Collections.emptyMap();\n    }\n    for (String jobId : cancelledOriginalJobs) {\n      LOGGER.info(\"Skip original job: {} as it's cancelled\", jobId);\n      candidates.remove(jobId);\n    }\n    for (Map.Entry<String, String> entry : completedOriginalJobs.entrySet()) {\n      LOGGER.info(\"Skip original job: {} as it's completed by attempt: {}\", entry.getKey(), entry.getValue());\n      candidates.remove(entry.getKey());\n    }\n    return candidates;\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetCandidateJobs()\n      throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetCandidateJobs", "reference": "  @Test\n  public void testGetCandidateJobs()\n      throws Exception {\n    String tableName = \"table01\";\n    Map<String, Map<String, String>> allJobMetadata = new HashMap<>();\n\n    // Original job run as job1, and all its retry jobs failed too.\n    RebalanceConfig jobCfg = new RebalanceConfig();\n    jobCfg.setMaxAttempts(4);\n    TableRebalanceProgressStats stats = new TableRebalanceProgressStats();\n    stats.setStatus(RebalanceResult.Status.FAILED);\n    stats.setStartTimeMs(1000);\n    TableRebalanceContext jobCtx = TableRebalanceContext.forInitialAttempt(\"job1\", jobCfg);\n    Map<String, String> jobMetadata = ZkBasedTableRebalanceObserver.createJobMetadata(tableName, \"job1\", stats, jobCtx);\n    allJobMetadata.put(\"job1\", jobMetadata);\n    // 3 failed retry runs for job1\n    jobMetadata = createDummyJobMetadata(tableName, \"job1\", 2, 1100, RebalanceResult.Status.FAILED);\n    allJobMetadata.put(\"job1_2\", jobMetadata);\n    jobMetadata = createDummyJobMetadata(tableName, \"job1\", 3, 1200, RebalanceResult.Status.ABORTED);\n    allJobMetadata.put(\"job1_3\", jobMetadata);\n    jobMetadata = createDummyJobMetadata(tableName, \"job1\", 4, 1300, RebalanceResult.Status.FAILED);\n    allJobMetadata.put(\"job1_4\", jobMetadata);\n\n    // Original job run as job2, and its retry job job2_1 completed.\n    jobCfg = new RebalanceConfig();\n    jobCfg.setMaxAttempts(4);\n    stats = new TableRebalanceProgressStats();\n    stats.setStatus(RebalanceResult.Status.FAILED);\n    stats.setStartTimeMs(2000);\n    jobCtx = TableRebalanceContext.forInitialAttempt(\"job2\", jobCfg);\n    jobMetadata = ZkBasedTableRebalanceObserver.createJobMetadata(tableName, \"job2\", stats, jobCtx);\n    allJobMetadata.put(\"job2\", jobMetadata);\n    jobMetadata = createDummyJobMetadata(tableName, \"job2\", 2, 2100, RebalanceResult.Status.DONE);\n    allJobMetadata.put(\"job2_2\", jobMetadata);\n\n    // Original job run as job3, and failed to send out heartbeat in time.\n    jobCfg = new RebalanceConfig();\n    jobCfg.setMaxAttempts(4);\n    stats = new TableRebalanceProgressStats();\n    stats.setStatus(RebalanceResult.Status.IN_PROGRESS);\n    stats.setStartTimeMs(3000);\n    jobCtx = TableRebalanceContext.forInitialAttempt(\"job3\", jobCfg);\n    jobMetadata = ZkBasedTableRebalanceObserver.createJobMetadata(tableName, \"job3\", stats, jobCtx);\n    jobMetadata.put(CommonConstants.ControllerJob.SUBMISSION_TIME_MS, \"3000\");\n    allJobMetadata.put(\"job3\", jobMetadata);\n\n    // Original job run as job4, which didn't have retryJobCfg as from old version of the code.\n    stats = new TableRebalanceProgressStats();\n    stats.setStatus(RebalanceResult.Status.FAILED);\n    stats.setStartTimeMs(4000);\n    jobMetadata = ZkBasedTableRebalanceObserver.createJobMetadata(tableName, \"job4\", stats, null);\n    jobMetadata.remove(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_CONTEXT);\n    allJobMetadata.put(\"job4\", jobMetadata);\n\n    // Only need to retry job1 and job3, as job2 is completed and job4 is from old version of code.\n    Map<String, Set<Pair<TableRebalanceContext, Long>>> jobs =\n        RebalanceChecker.getCandidateJobs(tableName, allJobMetadata);\n    assertEquals(jobs.size(), 2);\n    assertTrue(jobs.containsKey(\"job1\"));\n    assertTrue(jobs.containsKey(\"job3\"));\n    assertEquals(jobs.get(\"job1\").size(), 4); // four runs including job1,job1_1,job1_2,job1_3\n    assertEquals(jobs.get(\"job3\").size(), 1); // just a single run job3\n\n    // Abort job1 and cancel its retries, then only job3 is retry candidate.\n    jobMetadata = allJobMetadata.get(\"job1_4\");\n    cancelRebalanceJob(jobMetadata);\n    jobs = RebalanceChecker.getCandidateJobs(tableName, allJobMetadata);\n    assertEquals(jobs.size(), 1);\n    assertTrue(jobs.containsKey(\"job3\"));\n    assertEquals(jobs.get(\"job3\").size(), 1); // just a single run job3\n\n    // Add latest job5 that's already done, thus no need to retry for table.\n    jobCfg = new RebalanceConfig();\n    jobCfg.setMaxAttempts(4);\n    stats = new TableRebalanceProgressStats();\n    stats.setStatus(RebalanceResult.Status.DONE);\n    stats.setStartTimeMs(5000);\n    jobCtx = TableRebalanceContext.forInitialAttempt(\"job5\", jobCfg);\n    jobMetadata = ZkBasedTableRebalanceObserver.createJobMetadata(tableName, \"job5\", stats, jobCtx);\n    allJobMetadata.put(\"job5\", jobMetadata);\n    jobs = RebalanceChecker.getCandidateJobs(tableName, allJobMetadata);\n    assertEquals(jobs.size(), 0);\n  }", "completions": ["  ```\n@Test\npublic void testGetCandidateJobs() throws Exception {\n    // Set up mock data\n    Map<String, Map<String, String>> allJobMetadata = new HashMap<>();\n    Map<String, String> jobMetadata1 = new HashMap<>();\n    jobMetadata1.put(CommonConstants.ControllerJob.SUBMISSION_TIME_MS, \"1000\");\n    jobMetadata1.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_PROGRESS_STATS, \"{\\\"status\\\":\\\"DONE\\\"}\");\n    jobMetadata1.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_CONTEXT, \"{\\\"originalJobId\\\":\\\"job1\\\"}\");\n    Map<String, String> jobMetadata2 = new HashMap<>();\n    jobMetadata2.put(CommonConstants.ControllerJob.SUBMISSION_TIME_MS, \"2000\");\n    jobMetadata2.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_PROGRESS_STATS, \"{\\\"status\\\":\\\"FAILED\\\"}\");\n    jobMetadata2.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_CONTEXT, \"{\\\"originalJobId\\\":\\\"job2\\\"}\");\n    Map<String, String> jobMetadata3 = new HashMap<>();\n    jobMetadata3.put(CommonConstants.ControllerJob.SUBMISSION_TIME_MS, \"3000\");\n    jobMetadata3.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_PROGRESS_STATS, \"{\\\"status\\\":\\\"CANCELLED\\\"}\");\n    jobMetadata3.put(RebalanceJobConstants.JOB_METADATA_KEY_REBALANCE_CONTEXT, \"{\\\"originalJobId\\\":\\\"job3\\\"}\");\n    allJobMetadata.put(\"job1\", jobMetadata1);\n    allJobMetadata.put(\"job2\", jobMetadata2);\n    allJobMetadata.put(\"job3\", jobMetadata3);\n\n    // Call the method under test\n    Map<String, Set<Pair<TableRebalanceContext, Long>>> candidates = getCandidateJobs(\"table1\", allJobMetadata);\n\n    // Verify the results\n    assertEquals(2, candidates.size());\n    assertTrue(candidates.containsKey(\"job2\"));\n    assertTrue(candidates.containsKey(\"job3\"));\n    assertEquals(1, candidates.get(\"job2\").size());\n    assertEquals(1, candidates.get(\"job3\").size());\n    Pair<TableRebalanceContext, Long> candidate1 = candidates.get(\"job2\").iterator().next();\n    assertEquals(\"job2\", candidate1.getLeft().getOriginalJobId());\n    assertEquals(2000L, candidate1.getRight().longValue());\n    Pair<TableRebalanceContext, Long> candidate2 = candidates.get(\"job3\").iterator().next();\n    assertEquals(\"job3\", candidate2.getLeft().getOriginalJobId());\n    assertEquals(3000L, candidate2.getRight().longValue());\n}\n```"]}
{"id": 70, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public CompletableFuture<DeliveryReply> dist(DeliveryRequest request) {\n        DeliveryReply.Builder replyBuilder = DeliveryReply.newBuilder();\n        DeliveryResults.Builder resultsBuilder = DeliveryResults.newBuilder();\n        for (Map.Entry<String, DeliveryPackage> entry : request.getPackageMap().entrySet()) {\n            String tenantId = entry.getKey();\n            ITenantMeter tenantMeter = ITenantMeter.get(tenantId);\n            boolean isFanOutThrottled = !resourceThrottler.hasResource(tenantId, TotalTransientFanOutBytesPerSeconds);\n            boolean hasFanOutDone = false;\n            Set<MatchInfo> ok = new HashSet<>();\n            Set<MatchInfo> skip = new HashSet<>();\n            Set<MatchInfo> noSub = new HashSet<>();\n            for (DeliveryPack writePack : entry.getValue().getPackList()) {\n                TopicMessagePack topicMsgPack = writePack.getMessagePack();\n                int msgPackSize = SizeUtil.estSizeOf(topicMsgPack);\n                int fanout = 1;\n                for (MatchInfo matchInfo : writePack.getMatchInfoList()) {\n                    if (!noSub.contains(matchInfo) && !skip.contains(matchInfo)) {\n                        if (ILocalDistService.isGlobal(matchInfo.getReceiverId())) {\n                            IMQTTTransientSession session =\n                                sessionMap.get(ILocalDistService.parseReceiverId(matchInfo.getReceiverId()));\n                            if (session != null) {\n                                boolean success = session.publish(matchInfo, singletonList(topicMsgPack));\n                                if (success) {\n                                    ok.add(matchInfo);\n                                } else {\n                                    noSub.add(matchInfo);\n                                }\n                            } else {\n                                // no session found for shared subscription\n                                noSub.add(matchInfo);\n                            }\n                        } else {\n                            if (isFanOutThrottled && hasFanOutDone) {\n                                continue;\n                            }\n                            int bucketId = LocalRoutes.parseBucketId(matchInfo.getReceiverId());\n                            CompletableFuture<LocalRoutes> routesFuture =\n                                routeMap.get(new TopicFilter(tenantId, matchInfo.getTopicFilter(),\n                                    bucketId));\n                            if (routesFuture == null) {\n                                noSub.add(matchInfo);\n                                continue;\n                            }\n                            if (!routesFuture.isDone() || routesFuture.isCompletedExceptionally()) {\n                                skip.add(matchInfo);\n                            }\n                            try {\n                                LocalRoutes localRoutes = routesFuture.join();\n                                if (!localRoutes.localizedReceiverId().equals(matchInfo.getReceiverId())) {\n                                    noSub.add(matchInfo);\n                                    continue;\n                                }\n                                boolean published = false;\n                                if (!isFanOutThrottled) {\n                                    fanout *= localRoutes.routeList.size();\n                                    for (IMQTTTransientSession session : localRoutes.routeList.values()) {\n                                        // at least one session should publish the message\n                                        if (session.publish(matchInfo, singletonList(topicMsgPack))) {\n                                            published = true;\n                                        }\n                                    }\n                                } else {\n                                    // send to one subscriber to make sure matchinfo not lost\n                                    for (IMQTTTransientSession session : localRoutes.routeList.values()) {\n                                        // at least one session should publish the message\n                                        if (session.publish(matchInfo, singletonList(topicMsgPack))) {\n                                            published = true;\n                                            hasFanOutDone = true;\n                                            break;\n                                        }\n                                    }\n                                }\n                                if (published) {\n                                    ok.add(matchInfo);\n                                } else {\n                                    noSub.add(matchInfo);\n                                }\n                            } catch (Throwable e) {\n                                skip.add(matchInfo);\n                            }\n                        }\n                    }\n                }\n                tenantMeter.recordSummary(MqttTransientFanOutBytes, msgPackSize * Math.max(fanout, 1));\n            }\n            Sets.union(ok, skip).forEach(matchInfo -> resultsBuilder.addResult(DeliveryResult.newBuilder()\n                .setMatchInfo(matchInfo)\n                .setCode(DeliveryResult.Code.OK)\n                .build()));\n            noSub.forEach(matchInfo -> resultsBuilder.addResult(DeliveryResult.newBuilder()\n                .setMatchInfo(matchInfo)\n                .setCode(DeliveryResult.Code.NO_SUB)\n                .build()));\n            replyBuilder.putResult(tenantId, resultsBuilder.build());\n        }\n        return CompletableFuture.completedFuture(replyBuilder.build());\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void distClientMatchError()\n```\n### Answer: (use the provided format with backticks)\n", "name": "distClientMatchError", "reference": "    @Test\n    public void distClientMatchError() {\n        String topicFilter = \"topicFilter\";\n        LocalDistService localDistService =\n            new LocalDistService(serverId, distClient, resourceThrottler, eventCollector);\n\n        CompletableFuture<MatchResult> matchFuture = new CompletableFuture<>();\n        when(distClient.match(anyLong(), anyString(), anyString(), anyString(), anyString(), anyInt()))\n            .thenReturn(matchFuture);\n        String tenantId = \"tenantId\";\n        ClientInfo clientInfo = ClientInfo.newBuilder().setTenantId(tenantId).build();\n        List<IMQTTTransientSession> sessions = new ArrayList<>();\n        List<CompletableFuture<MatchResult>> matchFutures = new ArrayList<>();\n        for (int i = 0; i < 10 * TOPIC_FILTER_BUCKET_NUM; i++) {\n            IMQTTTransientSession session = mock(IMQTTTransientSession.class);\n            sessions.add(session);\n            String channelId = \"channelId\" + i;\n            when(session.clientInfo()).thenReturn(clientInfo);\n            when(session.channelId()).thenReturn(channelId);\n            long reqId = System.nanoTime();\n            matchFutures.add(localDistService.match(reqId, topicFilter, session));\n        }\n        matchFuture.complete(MatchResult.ERROR);\n        for (CompletableFuture<MatchResult> future : matchFutures) {\n            assertEquals(future.join(), MatchResult.ERROR);\n        }\n        ArgumentCaptor<String> receiverIdCaptor = ArgumentCaptor.forClass(String.class);\n        verify(distClient, atMost(TOPIC_FILTER_BUCKET_NUM)).match(\n            anyLong(),\n            eq(tenantId),\n            eq(topicFilter),\n            receiverIdCaptor.capture(),\n            anyString(),\n            eq(0));\n        List<MatchInfo> matchInfos = receiverIdCaptor.getAllValues().stream()\n            .map(receiverId -> MatchInfo.newBuilder()\n                .setReceiverId(receiverId)\n                .setTopicFilter(topicFilter).build())\n            .toList();\n        DeliveryReply reply = localDistService.dist(DeliveryRequest.newBuilder()\n            .putPackage(tenantId, DeliveryPackage.newBuilder()\n                .addPack(DeliveryPack.newBuilder()\n                    .addAllMatchInfo(matchInfos)\n                    .build())\n                .build())\n            .build()).join();\n        assertEquals(matchInfos.size(), reply.getResultMap().get(tenantId).getResultCount());\n        assertTrue(reply.getResultMap().get(tenantId).getResultList().stream()\n            .allMatch(result -> result.getCode() == DeliveryResult.Code.NO_SUB));\n        for (IMQTTTransientSession session : sessions) {\n            verify(session, never()).publish(any(), anyList());\n        }\n    }", "completions": ["  ```\n@Test\npublic void distClientMatchError() {\n    // Set up the request\n    DeliveryRequest request = DeliveryRequest.newBuilder()\n           .setClientId(\"client1\")\n           .setTopic(\"topic1\")\n           .setMessage(\"message1\")\n           .build();\n\n    // Set up the expected result\n    DeliveryReply expectedReply = DeliveryReply.newBuilder()\n           .setCode(DeliveryReply.Code.CLIENT_MATCH_ERROR)\n           .build();\n\n    // Call the dist method with the request\n    CompletableFuture<DeliveryReply> actualReply = dist(request);\n\n    // Assert that the actual reply is equal to the expected reply\n    assertEquals(expectedReply, actualReply);\n}\n```"]}
{"id": 71, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public CompletableFuture<DeliveryReply> dist(DeliveryRequest request) {\n        DeliveryReply.Builder replyBuilder = DeliveryReply.newBuilder();\n        DeliveryResults.Builder resultsBuilder = DeliveryResults.newBuilder();\n        for (Map.Entry<String, DeliveryPackage> entry : request.getPackageMap().entrySet()) {\n            String tenantId = entry.getKey();\n            ITenantMeter tenantMeter = ITenantMeter.get(tenantId);\n            boolean isFanOutThrottled = !resourceThrottler.hasResource(tenantId, TotalTransientFanOutBytesPerSeconds);\n            boolean hasFanOutDone = false;\n            Set<MatchInfo> ok = new HashSet<>();\n            Set<MatchInfo> skip = new HashSet<>();\n            Set<MatchInfo> noSub = new HashSet<>();\n            for (DeliveryPack writePack : entry.getValue().getPackList()) {\n                TopicMessagePack topicMsgPack = writePack.getMessagePack();\n                int msgPackSize = SizeUtil.estSizeOf(topicMsgPack);\n                int fanout = 1;\n                for (MatchInfo matchInfo : writePack.getMatchInfoList()) {\n                    if (!noSub.contains(matchInfo) && !skip.contains(matchInfo)) {\n                        if (ILocalDistService.isGlobal(matchInfo.getReceiverId())) {\n                            IMQTTTransientSession session =\n                                sessionMap.get(ILocalDistService.parseReceiverId(matchInfo.getReceiverId()));\n                            if (session != null) {\n                                boolean success = session.publish(matchInfo, singletonList(topicMsgPack));\n                                if (success) {\n                                    ok.add(matchInfo);\n                                } else {\n                                    noSub.add(matchInfo);\n                                }\n                            } else {\n                                // no session found for shared subscription\n                                noSub.add(matchInfo);\n                            }\n                        } else {\n                            if (isFanOutThrottled && hasFanOutDone) {\n                                continue;\n                            }\n                            int bucketId = LocalRoutes.parseBucketId(matchInfo.getReceiverId());\n                            CompletableFuture<LocalRoutes> routesFuture =\n                                routeMap.get(new TopicFilter(tenantId, matchInfo.getTopicFilter(),\n                                    bucketId));\n                            if (routesFuture == null) {\n                                noSub.add(matchInfo);\n                                continue;\n                            }\n                            if (!routesFuture.isDone() || routesFuture.isCompletedExceptionally()) {\n                                skip.add(matchInfo);\n                            }\n                            try {\n                                LocalRoutes localRoutes = routesFuture.join();\n                                if (!localRoutes.localizedReceiverId().equals(matchInfo.getReceiverId())) {\n                                    noSub.add(matchInfo);\n                                    continue;\n                                }\n                                boolean published = false;\n                                if (!isFanOutThrottled) {\n                                    fanout *= localRoutes.routeList.size();\n                                    for (IMQTTTransientSession session : localRoutes.routeList.values()) {\n                                        // at least one session should publish the message\n                                        if (session.publish(matchInfo, singletonList(topicMsgPack))) {\n                                            published = true;\n                                        }\n                                    }\n                                } else {\n                                    // send to one subscriber to make sure matchinfo not lost\n                                    for (IMQTTTransientSession session : localRoutes.routeList.values()) {\n                                        // at least one session should publish the message\n                                        if (session.publish(matchInfo, singletonList(topicMsgPack))) {\n                                            published = true;\n                                            hasFanOutDone = true;\n                                            break;\n                                        }\n                                    }\n                                }\n                                if (published) {\n                                    ok.add(matchInfo);\n                                } else {\n                                    noSub.add(matchInfo);\n                                }\n                            } catch (Throwable e) {\n                                skip.add(matchInfo);\n                            }\n                        }\n                    }\n                }\n                tenantMeter.recordSummary(MqttTransientFanOutBytes, msgPackSize * Math.max(fanout, 1));\n            }\n            Sets.union(ok, skip).forEach(matchInfo -> resultsBuilder.addResult(DeliveryResult.newBuilder()\n                .setMatchInfo(matchInfo)\n                .setCode(DeliveryResult.Code.OK)\n                .build()));\n            noSub.forEach(matchInfo -> resultsBuilder.addResult(DeliveryResult.newBuilder()\n                .setMatchInfo(matchInfo)\n                .setCode(DeliveryResult.Code.NO_SUB)\n                .build()));\n            replyBuilder.putResult(tenantId, resultsBuilder.build());\n        }\n        return CompletableFuture.completedFuture(replyBuilder.build());\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void distClientMatchOK()\n```\n### Answer: (use the provided format with backticks)\n", "name": "distClientMatchOK", "reference": "    @Test\n    public void distClientMatchOK() {\n        String topicFilter = \"topicFilter\";\n        LocalDistService localDistService =\n            new LocalDistService(serverId, distClient, resourceThrottler, eventCollector);\n\n        CompletableFuture<MatchResult> matchFuture = new CompletableFuture<>();\n        when(distClient.match(anyLong(), anyString(), anyString(), anyString(), anyString(), anyInt()))\n            .thenReturn(matchFuture);\n        String tenantId = \"tenantId\";\n        ClientInfo clientInfo = ClientInfo.newBuilder().setTenantId(tenantId).build();\n        List<IMQTTTransientSession> sessions = new ArrayList<>();\n        List<CompletableFuture<MatchResult>> matchFutures = new ArrayList<>();\n        for (int i = 0; i < 10 * TOPIC_FILTER_BUCKET_NUM; i++) {\n            IMQTTTransientSession session = mock(IMQTTTransientSession.class);\n            sessions.add(session);\n            String channelId = \"channelId\" + i;\n            when(session.clientInfo()).thenReturn(clientInfo);\n            when(session.channelId()).thenReturn(channelId);\n            when(session.publish(any(), anyList())).thenReturn(true);\n            long reqId = System.nanoTime();\n            matchFutures.add(localDistService.match(reqId, topicFilter, session));\n        }\n        matchFuture.complete(MatchResult.OK);\n        for (CompletableFuture<MatchResult> future : matchFutures) {\n            assertEquals(future.join(), MatchResult.OK);\n        }\n        ArgumentCaptor<String> receiverIdCaptor = ArgumentCaptor.forClass(String.class);\n        verify(distClient, atMost(TOPIC_FILTER_BUCKET_NUM)).match(\n            anyLong(),\n            eq(tenantId),\n            eq(topicFilter),\n            receiverIdCaptor.capture(),\n            anyString(),\n            eq(0));\n        List<MatchInfo> matchInfos = receiverIdCaptor.getAllValues().stream()\n            .map(receiverId -> MatchInfo.newBuilder()\n                .setReceiverId(receiverId)\n                .setTopicFilter(topicFilter).build())\n            .toList();\n        DeliveryReply reply = localDistService.dist(DeliveryRequest.newBuilder()\n            .putPackage(tenantId, DeliveryPackage.newBuilder()\n                .addPack(DeliveryPack.newBuilder()\n                    .addAllMatchInfo(matchInfos)\n                    .build())\n                .build())\n            .build()).join();\n        assertEquals(matchInfos.size(), reply.getResultMap().get(tenantId).getResultCount());\n        assertTrue(reply.getResultMap().get(tenantId).getResultList().stream()\n            .allMatch(result -> result.getCode() == DeliveryResult.Code.OK));\n        for (IMQTTTransientSession session : sessions) {\n            verify(session, times(1)).publish(any(), anyList());\n        }\n    }", "completions": ["  ```\n@Test\npublic void distClientMatchOK() {\n    // Set up the test case\n    DeliveryRequest request = new DeliveryRequest();\n    request.setPackageMap(new HashMap<>());\n    request.getPackageMap().put(\"tenant1\", new DeliveryPackage());\n    request.getPackageMap().get(\"tenant1\").setPackList(new ArrayList<>());\n    request.getPackageMap().get(\"tenant1\").getPackList().add(new DeliveryPack());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).setMessagePack(new TopicMessagePack());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMessagePack().setTopic(\"test/topic\");\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMessagePack().setPayload(\"test payload\".getBytes());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).setMatchInfoList(new ArrayList<>());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().add(new MatchInfo());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setReceiverId(\"client1\");\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setTopicFilter(\"test/topic\");\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setQos(1);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setRetain(false);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setDup(false);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setMessageId(1);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setTimestamp(System.currentTimeMillis());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setPayload(\"test payload\".getBytes());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setMatched(true);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionId(\"sub1\");\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionType(SubscriptionType.SHARED);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionName(\"subscription1\");\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionQos(1);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionTimestamp(System.currentTimeMillis());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionPayload(\"test payload\".getBytes());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionMatched(true);\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionMatchedTimestamp(System.currentTimeMillis());\n    request.getPackageMap().get(\"tenant1\").getPackList().get(0).getMatchInfoList().get(0).setSubscriptionMatchedPayload(\"test payload\".getBytes());\n    request"]}
{"id": 72, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public Range<BigDecimal> calcInterquartileRangeApproximation(List<BigDecimal> sortedValues) {\n        Range<BigDecimal> iqr = null;\n\n        if (sortedValues.size() > 0) {\n            BigDecimal q1 = valueCloseToQ1(sortedValues);\n            BigDecimal q3 = valueCloseToQ3(sortedValues);\n            BigDecimal max = sortedValues.get(sortedValues.size() - 1);\n\n            // if iqr == 0 AND max == q3 then recursively try finding a non-zero iqr approximation.\n            if (q1.compareTo(q3) == 0 && max.compareTo(q3) == 0) {\n                // filter out max and try again\n                iqr = this.calcInterquartileRangeApproximation(\n                    sortedValues.stream().filter(d -> d.compareTo(max) < 0).collect(Collectors.toList()));\n            }\n\n            // if range is still empty use the original q1 and q3 values\n            if (iqr == null || iqr.isEmpty()) {\n                iqr = Range.closedOpen(q1, q3);\n            }\n        }\n\n        return iqr;\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testCalcInterquartileRangeApproximation()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testCalcInterquartileRangeApproximation", "reference": "    @Test\n    public void testCalcInterquartileRangeApproximation() {\n        List<BigDecimal> values = decList(1, 2, 3, 4, 5, 6, 7, 8);\n        assertEquals(new BigDecimal(\"3\"), dataBinHelper.calcInterquartileRangeApproximation(values).lowerEndpoint());\n        assertEquals(new BigDecimal(\"7\"), dataBinHelper.calcInterquartileRangeApproximation(values).upperEndpoint());\n    }", "completions": ["  ```\n@Test\npublic void testCalcInterquartileRangeApproximation() {\n    List<BigDecimal> sortedValues = Arrays.asList(BigDecimal.valueOf(1), BigDecimal.valueOf(2), BigDecimal.valueOf(3), BigDecimal.valueOf(4), BigDecimal.valueOf(5));\n    Range<BigDecimal> iqr = calcInterquartileRangeApproximation(sortedValues);\n    assertEquals(Range.closedOpen(BigDecimal.valueOf(2), BigDecimal.valueOf(4)), iqr);\n}\n```"]}
{"id": 73, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_serializable_complex_object_with_non_serializable_nested_object()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_serializable_complex_object_with_non_serializable_nested_object", "reference": "    @Test\n    public void should_clone_serializable_complex_object_with_non_serializable_nested_object() {\n        Map<String, List<NonSerializableObject>> map = new LinkedHashMap<>();\n        map.put(\"key1\", Lists.newArrayList(new NonSerializableObject(\"name1\")));\n        map.put(\"key2\", Lists.newArrayList(\n                new NonSerializableObject(\"name2\"),\n                new NonSerializableObject(\"name3\")\n        ));\n        Object original = new SerializableComplexObjectWithNonSerializableNestedObject(map);\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n@Test\npublic void should_clone_serializable_complex_object_with_non_serializable_nested_object() {\n    // Arrange\n    ComplexObject original = new ComplexObject();\n    original.setSerializableField(\"serializable\");\n    original.setNonSerializableField(new NonSerializableObject());\n\n    // Act\n    ComplexObject clone = (ComplexObject) clone(original);\n\n    // Assert\n    assertEquals(original.getSerializableField(), clone.getSerializableField());\n    assertNotSame(original.getNonSerializableField(), clone.getNonSerializableField());\n    assertEquals(original.getNonSerializableField().toString(), clone.getNonSerializableField().toString());\n}\n```"]}
{"id": 74, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public SignedJWT token2Jwt(String token) {\n        if (token == null) {\n            log.error(\"Token is null.\");\n            throw new BizException(ErrorInfo.VERIFY_FAILED.getStatusCode(), ErrorInfo.VERIFY_FAILED.getCode(), ErrorInfo.VERIFY_FAILED.getMessage());\n        }\n        try {\n            return SignedJWT.parse(token);\n        } catch (ParseException e) {\n            log.error(\"Token to JWT Error,message = {}\", e.getMessage());\n            throw new BizException(ErrorInfo.VERIFY_FAILED.getStatusCode(), ErrorInfo.VERIFY_FAILED.getCode(), ErrorInfo.VERIFY_FAILED.getMessage());\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testToken2Jwt()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testToken2Jwt", "reference": "    @Test\n    public void testToken2Jwt() {\n        Assertions.assertThrows(BizException.class, () -> tokenParseHelper.token2Jwt(null));\n    }", "completions": ["  ```\n@Test\npublic void testToken2Jwt() {\n    // Setup\n    String token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c\";\n\n    // Execute\n    SignedJWT jwt = token2Jwt(token);\n\n    // Verify\n    assertNotNull(jwt);\n    assertEquals(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\", jwt.getHeader().toString());\n    assertEquals(\"eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ\", jwt.getPayload().toString());\n    assertEquals(\"SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c\", jwt.getSignature().toString());\n}\n```"]}
{"id": 75, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public ConsumerRecords<K, V> poll(final Duration timeout) {\n        Timer timer = time.timer(timeout);\n\n        acquireAndEnsureOpen();\n        try {\n            kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());\n\n            if (subscriptions.hasNoSubscriptionOrUserAssignment()) {\n                throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n            }\n\n            do {\n\n                // Make sure to let the background thread know that we are still polling.\n                applicationEventHandler.add(new PollEvent(timer.currentTimeMs()));\n\n                // We must not allow wake-ups between polling for fetches and returning the records.\n                // If the polled fetches are not empty the consumed position has already been updated in the polling\n                // of the fetches. A wakeup between returned fetches and returning records would lead to never\n                // returning the records in the fetches. Thus, we trigger a possible wake-up before we poll fetches.\n                wakeupTrigger.maybeTriggerWakeup();\n\n                updateAssignmentMetadataIfNeeded(timer);\n                final Fetch<K, V> fetch = pollForFetches(timer);\n                if (!fetch.isEmpty()) {\n                    if (fetch.records().isEmpty()) {\n                        log.trace(\"Returning empty records from `poll()` \"\n                            + \"since the consumer's position has advanced for at least one topic partition\");\n                    }\n\n                    return interceptors.onConsume(new ConsumerRecords<>(fetch.records()));\n                }\n                // We will wait for retryBackoffMs\n            } while (timer.notExpired());\n\n            return ConsumerRecords.empty();\n        } finally {\n            kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testLongPollWaitIsLimited()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testLongPollWaitIsLimited", "reference": "    @Test\n    public void testLongPollWaitIsLimited() {\n        consumer = newConsumer();\n        String topicName = \"topic1\";\n        consumer.subscribe(singletonList(topicName));\n\n        assertEquals(singleton(topicName), consumer.subscription());\n        assertTrue(consumer.assignment().isEmpty());\n\n        final int partition = 3;\n        final TopicPartition tp = new TopicPartition(topicName, partition);\n        final List<ConsumerRecord<String, String>> records = asList(\n            new ConsumerRecord<>(topicName, partition, 2, \"key1\", \"value1\"),\n            new ConsumerRecord<>(topicName, partition, 3, \"key2\", \"value2\")\n        );\n\n        // On the first iteration, return no data; on the second, return two records\n        doAnswer(invocation -> {\n            // Mock the subscription being assigned as the first fetch is collected\n            consumer.subscriptions().assignFromSubscribed(Collections.singleton(tp));\n            return Fetch.empty();\n        }).doAnswer(invocation -> {\n            return Fetch.forPartition(tp, records, true);\n        }).when(fetchCollector).collectFetch(any(FetchBuffer.class));\n\n        // And then poll for up to 10000ms, which should return 2 records without timing out\n        ConsumerRecords<?, ?> returnedRecords = consumer.poll(Duration.ofMillis(10000));\n        assertEquals(2, returnedRecords.count());\n\n        assertEquals(singleton(topicName), consumer.subscription());\n        assertEquals(singleton(tp), consumer.assignment());\n    }", "completions": ["  ```java\n    @Test\n    public void testLongPollWaitIsLimited() {\n        // Set up the consumer with a short retryBackoffMs\n        Consumer<String, String> consumer = new KafkaConsumer<>(consumerConfig);\n        consumer.subscribe(Collections.singletonList(\"test\"));\n        consumer.pause(consumer.assignment());\n\n        // Set up the mocks\n        Timer timer = mock(Timer.class);\n        when(timer.currentTimeMs()).thenReturn(0L);\n        when(timer.notExpired()).thenReturn(true);\n\n        // Set up the consumer with the mocks\n        consumer.time = timer;\n        consumer.wakeupTrigger = new WakeupTrigger();\n        consumer.applicationEventHandler = new ApplicationEventHandler();\n\n        // Call the method and verify the behavior\n        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));\n        assertEquals(0, records.count());\n        verify(timer, times(1)).notExpired();\n    }\n```"]}
{"id": 76, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testFullIndexSearchForMinAgg()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testFullIndexSearchForMinAgg", "reference": "  @Test\n  public void testFullIndexSearchForMinAgg() {\n    Instant time = Instant.now();\n    loadTestData(time);\n\n    SearchResult<LogMessage> allIndexItems =\n        strictLogStore.logSearcher.search(\n            TEST_DATASET_NAME,\n            \"\",\n            0L,\n            MAX_TIME,\n            1000,\n            new MinAggBuilder(\n                \"test\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"0\", null));\n\n    assertThat(allIndexItems.hits.size()).isEqualTo(4);\n\n    InternalMin internalMin =\n        (InternalMin) Objects.requireNonNull(allIndexItems.internalAggregation);\n\n    assertThat(Double.valueOf(internalMin.getValue()).longValue()).isEqualTo(time.toEpochMilli());\n  }", "completions": ["  ```java\n@Test\npublic void testFullIndexSearchForMinAgg() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any())).thenReturn(query);\n    CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector = mock(CollectorManager.class);\n    when(topFieldCollector.getLeafCollector(any())).thenReturn(mock(TopFieldCollector.class));\n    when(openSearchAdapter.getCollectorManager(any(), any(), any())).thenReturn(topFieldCollector);\n    ScoreDoc[] hits = new ScoreDoc[1];\n    hits[0] = new ScoreDoc(1, 1.0f, 1);\n    TopFieldDocs topFieldDocs = new TopFieldDocs(1, hits, new SortField(\"field\", SortField.Type.LONG));\n    when(searcher.search(any(), any())).thenReturn(topFieldDocs);\n    LogMessage logMessage = mock(LogMessage.class);\n    when(logMessage.getFieldValue(\"field\")).thenReturn(1L);\n    when(searcher.doc(anyInt())).thenReturn(logMessage);\n    // Set up parameters\n    String dataset = \"dataset\";\n    String queryStr = \"query\";\n    Long startTimeMsEpoch = 0L;\n    Long endTimeMsEpoch = 1000L;\n    int howMany = 10;\n    AggBuilder aggBuilder = mock(AggBuilder.class);\n    when(aggBuilder.getType()).thenReturn(AggType.MIN);\n    when(aggBuilder.getField()).thenReturn(\"field\");\n    // Call method\n    SearchResult<LogMessage> result = searcherManager.search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n    // Verify results\n    assertEquals(1, result.getTotalHits());\n    assertEquals(1, result.getHits().size());\n    assertEquals(1L, result.getHits().get(0).getFieldValue(\"field\"));\n    assertEquals(1, result.getAggregation().getCount());\n    assertEquals(1L, result.getAggregation().getMin());\n}\n```"]}
{"id": 77, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  LazyBlockList tryFetch(BlockListType blockListType) {\n    try {\n      URL dataUrl = new URL(blockListUrls.get(blockListType.name()));\n      logger.atInfo().log(\"Downloading from  %s\", dataUrl);\n      HttpsURLConnection connection =\n          (HttpsURLConnection) urlConnectionService.createConnection(dataUrl);\n      connection.setRequestMethod(HttpMethods.GET);\n      connection.setRequestProperty(\"Authorization\", \"Bearer \" + credential.getAuthToken());\n      int code = connection.getResponseCode();\n      if (code != SC_OK) {\n        String errorDetails = \"\";\n        try (InputStream errorStream = connection.getErrorStream()) {\n          errorDetails = new String(ByteStreams.toByteArray(errorStream), UTF_8);\n        } catch (NullPointerException e) {\n          // No error message.\n        } catch (Exception e) {\n          errorDetails = \"Failed to retrieve error message: \" + e.getMessage();\n        }\n        throw new BsaException(\n            String.format(\n                \"Status code: [%s], error: [%s], details: [%s]\",\n                code, connection.getResponseMessage(), errorDetails),\n            /* retriable= */ true);\n      }\n      return new LazyBlockList(blockListType, connection);\n    } catch (IOException e) {\n      throw new BsaException(e, /* retriable= */ true);\n    } catch (GeneralSecurityException e) {\n      throw new BsaException(e, /* retriable= */ false);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  void tryFetch_bsaChecksumFetched() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "tryFetch_bsaChecksumFetched", "reference": "  @Test\n  void tryFetch_bsaChecksumFetched() throws Exception {\n    setupMocks();\n    when(connection.getResponseCode()).thenReturn(SC_OK);\n    when(connection.getInputStream())\n        .thenReturn(new ByteArrayInputStream(\"bsa-checksum\\ndata\".getBytes(UTF_8)));\n    LazyBlockList download = fetcher.tryFetch(BlockListType.BLOCK);\n    assertThat(download.getName()).isEqualTo(BlockListType.BLOCK);\n    assertThat(download.checksum()).isEqualTo(\"bsa-checksum\");\n    verify(connection, times(1)).setRequestMethod(\"GET\");\n    verify(connection, times(1)).setRequestProperty(\"Authorization\", \"Bearer authToken\");\n  }", "completions": ["  ```java\n  @Test\n  void tryFetch_bsaChecksumFetched() throws Exception {\n    // Set up mocks\n    URL dataUrl = mock(URL.class);\n    HttpsURLConnection connection = mock(HttpsURLConnection.class);\n    when(urlConnectionService.createConnection(dataUrl)).thenReturn(connection);\n    when(connection.getResponseCode()).thenReturn(SC_OK);\n    when(connection.getResponseMessage()).thenReturn(\"OK\");\n    when(connection.getErrorStream()).thenReturn(null);\n\n    // Set up test data\n    BlockListType blockListType = BlockListType.BSA_CHECKSUM;\n    String expectedChecksum = \"expectedChecksum\";\n    when(blockListUrls.get(blockListType.name())).thenReturn(\"https://example.com/checksum\");\n    when(connection.getInputStream()).thenReturn(new ByteArrayInputStream(expectedChecksum.getBytes()));\n\n    // Call the method\n    LazyBlockList result = tryFetch(blockListType);\n\n    // Verify the result\n    assertThat(result.getChecksum(), is(expectedChecksum));\n  }\n```"]}
{"id": 78, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testDisabledFullTextSearch()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDisabledFullTextSearch", "reference": "  @Test\n  public void testDisabledFullTextSearch() {\n    Instant time = Instant.ofEpochSecond(1593365471);\n    Trace.KeyValue field1Tag =\n        Trace.KeyValue.newBuilder()\n            .setVInt32(1234)\n            .setKey(\"field1\")\n            .setFieldType(Schema.SchemaFieldType.INTEGER)\n            .build();\n\n    strictLogStoreWithoutFts.logStore.addMessage(\n        SpanUtil.makeSpan(1, \"apple\", time.plusSeconds(4), List.of(field1Tag)));\n\n    strictLogStoreWithoutFts.logStore.addMessage(\n        SpanUtil.makeSpan(2, \"apple baby\", time.plusSeconds(4), List.of(field1Tag)));\n\n    strictLogStoreWithoutFts.logStore.addMessage(\n        SpanUtil.makeSpan(3, \"baby car 1234\", time.plusSeconds(4)));\n    strictLogStoreWithoutFts.logStore.commit();\n    strictLogStoreWithoutFts.logStore.refresh();\n\n    assertThat(\n            strictLogStoreWithoutFts\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"_all:baby\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    assertThat(\n            strictLogStoreWithoutFts\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"_all:1234\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    // Without the _all field as default.\n    assertThat(\n            strictLogStoreWithoutFts\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"baby\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(2);\n\n    assertThat(\n            strictLogStoreWithoutFts\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"1234\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(3);\n\n    // empty string\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"app*\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    // Returns baby or car, 2 messages.\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"baby car\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    // Test numbers\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"apple 1234\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"123\",\n                    0L,\n                    MAX_TIME,\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isZero();\n  }", "completions": ["  ```java\n@Test\npublic void testDisabledFullTextSearch() {\n    // Given\n    String dataset = \"test_dataset\";\n    String queryStr = \"test_query\";\n    Long startTimeMsEpoch = null;\n    Long endTimeMsEpoch = null;\n    int howMany = 0;\n    AggBuilder aggBuilder = null;\n\n    // When\n    SearchResult<LogMessage> result = search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n\n    // Then\n    assertEquals(0, result.getTotalHits());\n    assertEquals(0, result.getTotalAggs());\n    assertEquals(0, result.getElapsedTime());\n    assertEquals(0, result.getTotalShards());\n    assertEquals(0, result.getSuccessfulShards());\n    assertNull(result.getInternalAggregation());\n}\n```"]}
{"id": 79, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ProcessInstanceForListViewEntity getProcessInstanceListViewByKey(Long processInstanceKey) {\n    try {\n      final QueryBuilder query =\n          joinWithAnd(\n              idsQuery().addIds(String.valueOf(processInstanceKey)),\n              termQuery(ListViewTemplate.PROCESS_INSTANCE_KEY, processInstanceKey));\n\n      final SearchRequest request =\n          ElasticsearchUtil.createSearchRequest(listViewTemplate, ALL)\n              .source(new SearchSourceBuilder().query(constantScoreQuery(query)));\n\n      final SearchResponse response;\n\n      response = tenantAwareClient.search(request);\n      final SearchHits searchHits = response.getHits();\n      if (searchHits.getTotalHits().value == 1 && searchHits.getHits().length == 1) {\n        return ElasticsearchUtil.fromSearchHit(\n            searchHits.getAt(0).getSourceAsString(),\n            objectMapper,\n            ProcessInstanceForListViewEntity.class);\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\n                \"Could not find unique process instance with id '%s'.\", processInstanceKey));\n      } else {\n        throw new NotFoundException(\n            (String.format(\"Could not find process instance with id '%s'.\", processInstanceKey)));\n      }\n    } catch (IOException e) {\n      throw new OperateRuntimeException(e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetProcessInstanceListViewByKeyWithException() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetProcessInstanceListViewByKeyWithException", "reference": "  @Test\n  public void testGetProcessInstanceListViewByKeyWithException() throws IOException {\n    when(listViewTemplate.getAlias()).thenReturn(\"listViewIndexAlias\");\n    when(tenantAwareClient.search(any())).thenThrow(new IOException());\n\n    assertThrows(\n        OperateRuntimeException.class, () -> underTest.getProcessInstanceListViewByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetProcessInstanceListViewByKeyWithException() throws IOException {\n    // given\n    Long processInstanceKey = 123L;\n    QueryBuilder query = mock(QueryBuilder.class);\n    SearchRequest request = mock(SearchRequest.class);\n    SearchResponse response = mock(SearchResponse.class);\n    SearchHits searchHits = mock(SearchHits.class);\n    when(query.idsQuery().addIds(String.valueOf(processInstanceKey))).thenReturn(query);\n    when(query.termQuery(ListViewTemplate.PROCESS_INSTANCE_KEY, processInstanceKey)).thenReturn(query);\n    when(ElasticsearchUtil.createSearchRequest(listViewTemplate, ALL)).thenReturn(request);\n    when(request.source(new SearchSourceBuilder().query(constantScoreQuery(query)))).thenReturn(request);\n    when(tenantAwareClient.search(request)).thenReturn(response);\n    when(response.getHits()).thenReturn(searchHits);\n    when(searchHits.getTotalHits().value).thenReturn(2L);\n    when(searchHits.getHits().length).thenReturn(2);\n\n    // when\n    try {\n      getProcessInstanceListViewByKey(processInstanceKey);\n      fail(\"Expected NotFoundException\");\n    } catch (NotFoundException e) {\n      // then\n      assertEquals(\"Could not find unique process instance with id '123'.\", e.getMessage());\n    }\n  }\n```"]}
{"id": 80, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  LazyBlockList tryFetch(BlockListType blockListType) {\n    try {\n      URL dataUrl = new URL(blockListUrls.get(blockListType.name()));\n      logger.atInfo().log(\"Downloading from  %s\", dataUrl);\n      HttpsURLConnection connection =\n          (HttpsURLConnection) urlConnectionService.createConnection(dataUrl);\n      connection.setRequestMethod(HttpMethods.GET);\n      connection.setRequestProperty(\"Authorization\", \"Bearer \" + credential.getAuthToken());\n      int code = connection.getResponseCode();\n      if (code != SC_OK) {\n        String errorDetails = \"\";\n        try (InputStream errorStream = connection.getErrorStream()) {\n          errorDetails = new String(ByteStreams.toByteArray(errorStream), UTF_8);\n        } catch (NullPointerException e) {\n          // No error message.\n        } catch (Exception e) {\n          errorDetails = \"Failed to retrieve error message: \" + e.getMessage();\n        }\n        throw new BsaException(\n            String.format(\n                \"Status code: [%s], error: [%s], details: [%s]\",\n                code, connection.getResponseMessage(), errorDetails),\n            /* retriable= */ true);\n      }\n      return new LazyBlockList(blockListType, connection);\n    } catch (IOException e) {\n      throw new BsaException(e, /* retriable= */ true);\n    } catch (GeneralSecurityException e) {\n      throw new BsaException(e, /* retriable= */ false);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  void tryFetch_SecurityException_notRetriable() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "tryFetch_SecurityException_notRetriable", "reference": "  @Test\n  void tryFetch_SecurityException_notRetriable() throws Exception {\n    when(connectionService.createConnection(any(URL.class)))\n        .thenThrow(new GeneralSecurityException());\n    assertThat(\n            assertThrows(BsaException.class, () -> fetcher.tryFetch(BlockListType.BLOCK))\n                .isRetriable())\n        .isFalse();\n  }", "completions": ["  ```java\n  @Test\n  void tryFetch_SecurityException_notRetriable() throws Exception {\n    // Arrange\n    BlockListType blockListType = BlockListType.BLACK;\n    URL dataUrl = new URL(\"https://example.com/blacklist\");\n    HttpsURLConnection connection = mock(HttpsURLConnection.class);\n    when(connection.getResponseCode()).thenThrow(new GeneralSecurityException(\"Security exception\"));\n    when(urlConnectionService.createConnection(dataUrl)).thenReturn(connection);\n\n    // Act\n    try {\n      LazyBlockList lazyBlockList = tryFetch(blockListType);\n      fail(\"Expected BsaException\");\n    } catch (BsaException e) {\n      // Assert\n      assertThat(e.isRetriable(), is(false));\n      assertThat(e.getMessage(), containsString(\"Security exception\"));\n    }\n  }\n```"]}
{"id": 81, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public void assign(Collection<TopicPartition> partitions) {\n        acquireAndEnsureOpen();\n        try {\n            if (partitions == null) {\n                throw new IllegalArgumentException(\"Topic partitions collection to assign to cannot be null\");\n            }\n\n            if (partitions.isEmpty()) {\n                unsubscribe();\n                return;\n            }\n\n            for (TopicPartition tp : partitions) {\n                String topic = (tp != null) ? tp.topic() : null;\n                if (isBlank(topic))\n                    throw new IllegalArgumentException(\"Topic partitions to assign to cannot have null or empty topic\");\n            }\n\n            // Clear the buffered data which are not a part of newly assigned topics\n            final Set<TopicPartition> currentTopicPartitions = new HashSet<>();\n\n            for (TopicPartition tp : subscriptions.assignedPartitions()) {\n                if (partitions.contains(tp))\n                    currentTopicPartitions.add(tp);\n            }\n\n            fetchBuffer.retainAll(currentTopicPartitions);\n\n            // assignment change event will trigger autocommit if it is configured and the group id is specified. This is\n            // to make sure offsets of topic partitions the consumer is unsubscribing from are committed since there will\n            // be no following rebalance.\n            //\n            // See the ApplicationEventProcessor.process() method that handles this event for more detail.\n            applicationEventHandler.add(new AssignmentChangeEvent(subscriptions.allConsumed(), time.milliseconds()));\n\n            log.info(\"Assigned to partition(s): {}\", join(partitions, \", \"));\n            if (subscriptions.assignFromUser(new HashSet<>(partitions)))\n                applicationEventHandler.add(new NewTopicsMetadataUpdateRequestEvent());\n        } finally {\n            release();\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testAssignOnEmptyTopicPartition()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testAssignOnEmptyTopicPartition", "reference": "    @Test\n    public void testAssignOnEmptyTopicPartition() {\n        consumer = newConsumer();\n        completeUnsubscribeApplicationEventSuccessfully();\n\n        consumer.assign(Collections.emptyList());\n        assertTrue(consumer.subscription().isEmpty());\n        assertTrue(consumer.assignment().isEmpty());\n    }", "completions": ["  ```java\n    @Test\n    public void testAssignOnEmptyTopicPartition() {\n        // Set up mocks\n        Collection<TopicPartition> partitions = new ArrayList<>();\n        ConsumerRebalanceListener listener = mock(ConsumerRebalanceListener.class);\n        Consumer<String, String> consumer = mock(Consumer.class);\n        ConsumerGroupMetadata groupMetadata = mock(ConsumerGroupMetadata.class);\n        when(consumer.groupMetadata()).thenReturn(groupMetadata);\n        when(groupMetadata.groupId()).thenReturn(\"test-group\");\n\n        // Call the method with empty topic partition\n        consumer.assign(partitions);\n\n        // Verify that the method throws an IllegalArgumentException\n        verify(consumer, times(1)).assign(partitions);\n        verify(listener, times(1)).onPartitionsAssigned(partitions);\n        verify(listener, times(1)).onPartitionsRevoked(partitions);\n    }\n```"]}
{"id": 82, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public static ImmutableList<UnblockableDomain> applyLabelDiff(\n      ImmutableList<BlockLabel> labels,\n      IdnChecker idnChecker,\n      DownloadSchedule schedule,\n      DateTime now) {\n    ImmutableList.Builder<UnblockableDomain> nonBlockedDomains = new ImmutableList.Builder<>();\n    ImmutableMap<LabelType, ImmutableList<BlockLabel>> labelsByType =\n        ImmutableMap.copyOf(\n            labels.stream().collect(groupingBy(BlockLabel::labelType, toImmutableList())));\n\n    tm().transact(\n            () -> {\n              for (Map.Entry<LabelType, ImmutableList<BlockLabel>> entry :\n                  labelsByType.entrySet()) {\n                switch (entry.getKey()) {\n                  case CREATE:\n                    // With current Cloud SQL, label upsert throughput is about 200/second. If\n                    // better performance is needed, consider bulk insert in native SQL.\n                    tm().putAll(\n                            entry.getValue().stream()\n                                .filter(label -> isValidInAtLeastOneTld(label, idnChecker))\n                                .map(\n                                    label ->\n                                        new BsaLabel(label.label(), schedule.jobCreationTime()))\n                                .collect(toImmutableList()));\n                    // May not find all unblockables due to race condition: DomainCreateFlow uses\n                    // cached BsaLabels. Eventually will be consistent.\n                    nonBlockedDomains.addAll(\n                        tallyUnblockableDomainsForNewLabels(entry.getValue(), idnChecker, now));\n                    break;\n                  case DELETE:\n                    ImmutableSet<String> deletedLabels =\n                        entry.getValue().stream()\n                            .filter(label -> isValidInAtLeastOneTld(label, idnChecker))\n                            .map(BlockLabel::label)\n                            .collect(toImmutableSet());\n                    // Delete labels in DB. Also cascade-delete BsaUnblockableDomain.\n                    int nDeleted = Queries.deleteBsaLabelByLabels(deletedLabels);\n                    if (nDeleted != deletedLabels.size()) {\n                      logger.atSevere().log(\n                          \"Only found %s entities among the %s labels: [%s]\",\n                          nDeleted, deletedLabels.size(), deletedLabels);\n                    }\n                    break;\n                  case NEW_ORDER_ASSOCIATION:\n                    ImmutableSet<String> affectedLabels =\n                        entry.getValue().stream()\n                            .filter(label -> isValidInAtLeastOneTld(label, idnChecker))\n                            .map(BlockLabel::label)\n                            .collect(toImmutableSet());\n                    ImmutableSet<String> labelsInDb =\n                        Queries.queryBsaLabelByLabels(affectedLabels)\n                            .map(BsaLabel::getLabel)\n                            .collect(toImmutableSet());\n                    verify(\n                        labelsInDb.size() == affectedLabels.size(),\n                        \"Missing labels in DB: %s\",\n                        LazyArgs.lazy(() -> difference(affectedLabels, labelsInDb)));\n\n                    // Reuse registered and reserved names that are already computed.\n                    Queries.queryBsaUnblockableDomainByLabels(affectedLabels)\n                        .map(BsaUnblockableDomain::toUnblockableDomain)\n                        .forEach(nonBlockedDomains::add);\n\n                    for (BlockLabel label : entry.getValue()) {\n                      getInvalidTldsForLabel(label, idnChecker)\n                          .map(tld -> UnblockableDomain.of(label.label(), tld, Reason.INVALID))\n                          .forEach(nonBlockedDomains::add);\n                    }\n                    break;\n                }\n              }\n            },\n            TRANSACTION_REPEATABLE_READ);\n    logger.atInfo().log(\"Processed %s of labels.\", labels.size());\n    return nonBlockedDomains.build();\n  }\n```\n###test function signature:\n```java\n  @Test\n  void applyLabelDiffs_newAssociationOfLabelToOrder()\n```\n### Answer: (use the provided format with backticks)\n", "name": "applyLabelDiffs_newAssociationOfLabelToOrder", "reference": "  @Test\n  void applyLabelDiffs_newAssociationOfLabelToOrder() {\n    tm().transact(\n            () -> {\n              tm().insert(new BsaLabel(\"label\", fakeClock.nowUtc()));\n              tm().insert(new BsaUnblockableDomain(\"label\", \"app\", Reason.REGISTERED));\n            });\n    when(idnChecker.getSupportingTlds(any())).thenReturn(ImmutableSet.of(app));\n    when(idnChecker.getForbiddingTlds(any()))\n        .thenReturn(Sets.difference(ImmutableSet.of(dev), ImmutableSet.of()).immutableCopy());\n\n    ImmutableList<UnblockableDomain> unblockableDomains =\n        applyLabelDiff(\n            ImmutableList.of(\n                BlockLabel.of(\"label\", LabelType.NEW_ORDER_ASSOCIATION, ImmutableSet.of())),\n            idnChecker,\n            schedule,\n            fakeClock.nowUtc());\n    assertThat(unblockableDomains)\n        .containsExactly(\n            UnblockableDomain.of(\"label.app\", UnblockableDomain.Reason.REGISTERED),\n            UnblockableDomain.of(\"label.dev\", UnblockableDomain.Reason.INVALID));\n    assertThat(tm().transact(() -> tm().loadByKeyIfPresent(BsaLabel.vKey(\"label\")))).isPresent();\n    assertThat(\n            tm().transact(() -> tm().loadByKeyIfPresent(BsaUnblockableDomain.vKey(\"label\", \"app\"))))\n        .isPresent();\n  }", "completions": ["  ```java\n  @Test\n  void applyLabelDiffs_newAssociationOfLabelToOrder() {\n    // Set up test data\n    ImmutableList<BlockLabel> labels = ImmutableList.of(\n        BlockLabel.create(\"example\", \"label1\", LabelType.CREATE),\n        BlockLabel.create(\"example\", \"label2\", LabelType.CREATE),\n        BlockLabel.create(\"example\", \"label3\", LabelType.CREATE)\n    );\n    IdnChecker idnChecker = mock(IdnChecker.class);\n    DownloadSchedule schedule = mock(DownloadSchedule.class);\n    DateTime now = mock(DateTime.class);\n\n    // Set up mock behavior\n    when(idnChecker.isValidInAtLeastOneTld(any())).thenReturn(true);\n    when(schedule.jobCreationTime()).thenReturn(DateTime.now());\n    when(now.getMillis()).thenReturn(123456789L);\n\n    // Call the method under test\n    ImmutableList<UnblockableDomain> nonBlockedDomains = applyLabelDiff(labels, idnChecker, schedule, now);\n\n    // Verify the results\n    assertThat(nonBlockedDomains).hasSize(3);\n    assertThat(nonBlockedDomains.get(0).getLabel()).isEqualTo(\"label1\");\n    assertThat(nonBlockedDomains.get(1).getLabel()).isEqualTo(\"label2\");\n    assertThat(nonBlockedDomains.get(2).getLabel()).isEqualTo(\"label3\");\n    assertThat(nonBlockedDomains.get(0).getTld()).isEqualTo(\"example\");\n    assertThat(nonBlockedDomains.get(1).getTld()).isEqualTo(\"example\");\n    assertThat(nonBlockedDomains.get(2).getTld()).isEqualTo(\"example\");\n    assertThat(nonBlockedDomains.get(0).getReason()).isEqualTo(Reason.INVALID);\n    assertThat(nonBlockedDomains.get(1).getReason()).isEqualTo(Reason.INVALID);\n    assertThat(nonBlockedDomains.get(2).getReason()).isEqualTo(Reason.INVALID);\n  }\n```"]}
{"id": 83, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public CompletableFuture<Long> createTopic(CreateTopicRequest request) {\n        CompletableFuture<Long> future = new CompletableFuture<>();\n        for (; ; ) {\n            if (metadataStore.isLeader()) {\n                try (SqlSession session = metadataStore.openSession()) {\n                    if (!metadataStore.maintainLeadershipWithSharedLock(session)) {\n                        continue;\n                    }\n                    TopicMapper topicMapper = session.getMapper(TopicMapper.class);\n                    if (null != topicMapper.get(null, request.getTopic())) {\n                        ControllerException e = new ControllerException(Code.DUPLICATED_VALUE,\n                            String.format(\"Topic %s was taken\", request.getTopic()));\n                        future.completeExceptionally(e);\n                        return future;\n                    }\n\n                    Topic topic = new Topic();\n                    topic.setName(request.getTopic());\n                    topic.setQueueNum(request.getCount());\n                    topic.setStatus(TopicStatus.TOPIC_STATUS_ACTIVE);\n                    topic.setAcceptMessageTypes(JsonFormat.printer().print(request.getAcceptTypes()));\n                    topic.setRetentionHours(request.getRetentionHours());\n                    topicMapper.create(topic);\n                    long topicId = topic.getId();\n                    List<QueueAssignment> assignments = createQueues(IntStream.range(0, request.getCount()),\n                        topicId, session);\n                    // Commit transaction\n                    session.commit();\n\n                    // Cache new topic and queue assignments immediately\n                    topicCache.apply(List.of(topic));\n                    assignmentCache.apply(assignments);\n                    future.complete(topicId);\n                } catch (ControllerException | InvalidProtocolBufferException e) {\n                    future.completeExceptionally(e);\n                }\n                return future;\n            } else {\n                Optional<String> leaderAddress = metadataStore.electionService().leaderAddress();\n                if (leaderAddress.isEmpty()) {\n                    return CompletableFuture.failedFuture(new ControllerException(Code.NO_LEADER_VALUE, \"No leader is elected yet\"));\n                }\n                metadataStore.controllerClient().createTopic(leaderAddress.get(), request).whenComplete((res, e) -> {\n                    if (null != e) {\n                        future.completeExceptionally(e);\n                    } else {\n                        future.complete(res);\n                    }\n                });\n            }\n            break;\n        }\n        return future;\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testCreateTopic()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testCreateTopic", "reference": "    @Test\n    public void testCreateTopic() {\n        MetadataStore metadataStore = Mockito.mock(MetadataStore.class);\n        ControllerClient controllerClient = Mockito.mock(ControllerClient.class);\n        Mockito.when(controllerClient.createTopic(ArgumentMatchers.anyString(), ArgumentMatchers.any())).thenReturn(\n            CompletableFuture.failedFuture(new CompletionException(new RuntimeException()))\n        );\n        Mockito.when(metadataStore.controllerClient()).thenReturn(controllerClient);\n        Mockito.when(metadataStore.isLeader()).thenReturn(false);\n\n        ElectionService electionService = Mockito.mock(ElectionService.class);\n        Mockito.when(metadataStore.electionService()).thenReturn(electionService);\n\n        Mockito.when(electionService.leaderAddress()).thenReturn(Optional.of(\"localhost:1234\"));\n\n        TopicManager topicManager = new TopicManager(metadataStore);\n        topicManager.createTopic(CreateTopicRequest.newBuilder().build());\n    }", "completions": ["  ```\n@Test\npublic void testCreateTopic() {\n    // Set up mocks\n    MetadataStore metadataStore = mock(MetadataStore.class);\n    SqlSession session = mock(SqlSession.class);\n    TopicMapper topicMapper = mock(TopicMapper.class);\n    when(metadataStore.openSession()).thenReturn(session);\n    when(session.getMapper(TopicMapper.class)).thenReturn(topicMapper);\n    when(topicMapper.get(null, \"test-topic\")).thenReturn(null);\n    when(metadataStore.maintainLeadershipWithSharedLock(session)).thenReturn(true);\n    when(metadataStore.electionService().leaderAddress()).thenReturn(Optional.of(\"localhost:8080\"));\n    ControllerClient controllerClient = mock(ControllerClient.class);\n    when(metadataStore.controllerClient()).thenReturn(controllerClient);\n    when(controllerClient.createTopic(\"localhost:8080\", new CreateTopicRequest(\"test-topic\", 1, 1, 1, 1))).thenReturn(CompletableFuture.completedFuture(1L));\n\n    // Set up topic cache and assignment cache\n    TopicCache topicCache = mock(TopicCache.class);\n    AssignmentCache assignmentCache = mock(AssignmentCache.class);\n\n    // Call createTopic method\n    CompletableFuture<Long> future = metadataStore.createTopic(new CreateTopicRequest(\"test-topic\", 1, 1, 1, 1));\n\n    // Verify results\n    assertTrue(future.isDone());\n    assertEquals(1L, future.get());\n    verify(topicCache).apply(List.of(new Topic(\"test-topic\", 1, TopicStatus.TOPIC_STATUS_ACTIVE, \"[]\", 1, 1L)));\n    verify(assignmentCache).apply(List.of(new QueueAssignment(1L, 1, 1)));\n}\n```"]}
{"id": 84, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    public SendStatus sendHtmlMail(String subject, List<String> toList, String username, String agentName, String emailHref, String maiContent) {\n        SendStatus sendStatus = new SendStatus(SEND_STATUS_FALSE, \"\");\n        List<String> notInBlacklistAddress = checkNotInBlacklistAddress(toList,sendStatus);\n        if(CollectionUtils.isEmpty(notInBlacklistAddress)){\n            return sendStatus;\n        }\n        // 读取html模板\n        String html = readHtmlToString(\"mailTemplate.html\");\n\n        // 写入模板内容\n        Document doc = Jsoup.parse(html);\n        doc.getElementById(\"username\").html(username);\n\n        if (StringUtils.isEmpty(agentName)) {\n            sendStatus.setErrorMessage(\"agentName 为空\");\n            return sendStatus;\n        }\n        doc.getElementById(\"sysName\").html(\"Your Agent：\");\n        doc.getElementById(\"agentName\").html(agentName);\n        doc.getElementById(\"mailContent\").html(maiContent);\n        doc.getElementById(\"clickHref\").attr(\"href\", emailHref);\n\n        String result = doc.toString();\n        Properties props = new Properties();\n        props.put(\"mail.smtp.host\", \"\");\n        props.put(\"mail.smtp.auth\", \"true\");\n        props.put(\"mail.smtp.socketFactory.class\", \"javax.net.ssl.SSLSocketFactory\");\n        props.put(\"mail.smtp.socketFactory.fallback\", \"true\");\n        Session session = Session.getDefaultInstance(props);\n        session.setDebug(true);\n\n        Transport transport = null;\n        MimeMessage message = new MimeMessage(session);\n        try {\n            //初始化发送邮件配置\n            this.initMailConfig();\n            message.setFrom(new InternetAddress(this.sendAddress));// 设置发件人的地址\n            InternetAddress[] internetAddressList = getInternetAddress(notInBlacklistAddress);\n            message.setRecipients(Message.RecipientType.TO, internetAddressList);// 设置收件人,并设置其接收类型为TO\n            message.setSubject(subject);// 设置标题\n            message.setContent(result, \"text/html;charset=UTF-8\"); // 设置邮件内容类型为html\n            message.setSentDate(new Date());// 设置发信时间\n            message.saveChanges();// 存储邮件信息\n\n            // 发送邮件\n            transport = session.getTransport(\"smtp\");\n            if (null != port) {\n                transport.connect(host, port, user, password);\n            } else {\n                transport.connect(host, user, password);\n            }\n            transport.sendMessage(message, message.getAllRecipients());\n\n            //发送邮件成功，status置为true\n            sendStatus.setStatus(\"true\");\n        } catch (Exception e) {\n            log.error(\"邮件发送异常\", e);\n            sendStatus.setErrorMessage(e.getMessage());\n        } finally {\n            if (null != transport) {\n                try {\n                    transport.close();//关闭连接\n                } catch (MessagingException e) {\n                    log.error(\"发送邮件 ，transport 关闭异常\", e);\n                }\n            }\n        }\n        return sendStatus;\n    }\n```\n###test function signature:\n```java\n    @Test\n    void testSendHtmlMail_subjectNotNull()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSendHtmlMail_subjectNotNull", "reference": "    @Test\n    void testSendHtmlMail_subjectNotNull(){\n        try(MockedStatic<Session> sessionMockedStatic = Mockito.mockStatic(Session.class)){\n            Session mockSession = mock(Session.class);\n            Transport transport = mock(Transport.class);\n            sessionMockedStatic.when(()->Session.getDefaultInstance(any(Properties.class))).thenReturn(mockSession);\n            when(blacklistService.inBlacklist(anyString())).thenReturn(false);\n            List<String> addressList = new ArrayList<>();\n            addressList.add(\"test@qq.com\");\n            when(settingsService.getByCategoryAndKey(anyString(),anyString())).thenReturn(\"test\").thenReturn(5678).thenReturn(\"test\").thenReturn(\"test\").thenReturn(\"123456\");\n            when(mockSession.getTransport(anyString())).thenReturn(transport);\n            doNothing().when(transport).connect(anyString(),anyInt(),anyString(),anyString());\n            doAnswer(invocationOnMock -> {\n                InternetAddress[] internetAddressList = invocationOnMock.getArgument(1);\n                Assertions.assertEquals(addressList.get(0),internetAddressList[0].getAddress());\n                return null;\n            }).when(transport).sendMessage(any(MimeMessage.class),any());\n            mailUtils.sendHtmlMail(\"\",addressList,\"test\",\"test\",\"test\",\"test\");\n        } catch (MessagingException e) {\n            throw new RuntimeException(e);\n        }\n    }", "completions": ["  ```java\n@Test\nvoid testSendHtmlMail_subjectNotNull() {\n    // Arrange\n    String subject = \"Test Subject\";\n    List<String> toList = Arrays.asList(\"test@example.com\");\n    String username = \"Test User\";\n    String agentName = \"Test Agent\";\n    String emailHref = \"https://www.example.com\";\n    String mailContent = \"Test Content\";\n\n    // Act\n    SendStatus sendStatus = sendHtmlMail(subject, toList, username, agentName, emailHref, mailContent);\n\n    // Assert\n    assertEquals(\"true\", sendStatus.getStatus());\n    assertEquals(\"\", sendStatus.getErrorMessage());\n}\n```"]}
{"id": 85, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public long determineStartingOffset(\n      long currentEndOffsetForPartition,\n      long currentBeginningOffsetForPartition,\n      AstraConfigs.IndexerConfig indexerConfig) {\n    // Filter stale snapshots for partition.\n    if (partitionId == null) {\n      LOG.warn(\"PartitionId can't be null.\");\n    }\n\n    List<SnapshotMetadata> snapshots = snapshotMetadataStore.listSync();\n    List<SnapshotMetadata> snapshotsForPartition =\n        snapshots.stream()\n            .filter(\n                snapshotMetadata -> {\n                  if (snapshotMetadata == null || snapshotMetadata.partitionId == null) {\n                    LOG.warn(\n                        \"snapshot metadata or partition id can't be null: {} \",\n                        Strings.join(snapshots, ','));\n                  }\n                  return snapshotMetadata != null\n                      && snapshotMetadata.partitionId != null\n                      && snapshotMetadata.partitionId.equals(partitionId);\n                })\n            .collect(Collectors.toUnmodifiableList());\n    List<SnapshotMetadata> deletedSnapshots = deleteStaleLiveSnapshots(snapshotsForPartition);\n\n    List<SnapshotMetadata> nonLiveSnapshotsForPartition =\n        snapshotsForPartition.stream()\n            .filter(s -> !deletedSnapshots.contains(s))\n            .collect(Collectors.toUnmodifiableList());\n\n    // Get the highest offset that is indexed in durable store.\n    List<RecoveryTaskMetadata> recoveryTasks = recoveryTaskMetadataStore.listSync();\n    long highestDurableOffsetForPartition =\n        getHighestDurableOffsetForPartition(\n            nonLiveSnapshotsForPartition, recoveryTasks, partitionId);\n    LOG.debug(\n        \"The highest durable offset for partition {} is {}\",\n        partitionId,\n        highestDurableOffsetForPartition);\n\n    if (highestDurableOffsetForPartition <= 0) {\n      LOG.info(\"There is no prior offset for this partition {}.\", partitionId);\n\n      // If the user wants to start at the current offset in Kafka and _does not_ want to create\n      // recovery tasks to backfill, then we can just return the current offset.\n      // If the user wants to start at the current offset in Kafka and _does_ want to create\n      // recovery tasks to backfill, then we create the recovery tasks needed and then return\n      // the current offset for the indexer. And if the user does _not_ want to start at the\n      // current offset in Kafka, then we'll just default to the old behavior of starting from\n      // the very beginning\n      if (!indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set to false and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" NOT spinning up recovery tasks\");\n        return currentEndOffsetForPartition;\n      } else if (indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        // Todo - this appears to be able to create recovery tasks that have a start and end\n        // position of 0, which is invalid. This seems to occur when new clusters are initialized,\n        // and is  especially problematic when indexers are created but never get assigned (ie,\n        // deploy 5, only assign 3).\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" spinning up recovery tasks\");\n        createRecoveryTasks(\n            partitionId,\n            currentBeginningOffsetForPartition,\n            currentEndOffsetForPartition,\n            indexerConfig.getMaxMessagesPerChunk());\n        return currentEndOffsetForPartition;\n\n      } else {\n        return highestDurableOffsetForPartition;\n      }\n    }\n\n    // The current head offset shouldn't be lower than the highest durable offset. If it is it\n    // means that we indexed more data than the current head offset. This is either a bug in the\n    // offset handling mechanism or the kafka partition has rolled over. We throw an exception\n    // for now, so we can investigate.\n    if (currentEndOffsetForPartition < highestDurableOffsetForPartition) {\n      final String message =\n          String.format(\n              \"The current head for the partition %d can't \"\n                  + \"be lower than the highest durable offset for that partition %d\",\n              currentEndOffsetForPartition, highestDurableOffsetForPartition);\n      LOG.error(message);\n      throw new IllegalStateException(message);\n    }\n\n    // The head offset for Kafka partition is the offset of the next message to be indexed. We\n    // assume that offset is passed into this function. The highest durable offset is the partition\n    // offset of the message that is indexed. Hence, the offset is incremented by 1 to get the\n    // next message.\n    long nextOffsetForPartition = highestDurableOffsetForPartition + 1;\n\n    // Create a recovery task if needed.\n    if (currentEndOffsetForPartition - highestDurableOffsetForPartition > maxOffsetDelay) {\n      LOG.info(\n          \"Recovery task needed. The current position {} and head location {} are higher than max\"\n              + \" offset {}\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay);\n      createRecoveryTasks(\n          partitionId,\n          nextOffsetForPartition,\n          currentEndOffsetForPartition - 1,\n          maxMessagesPerRecoveryTask);\n      return currentEndOffsetForPartition;\n    } else {\n      LOG.info(\n          \"The difference between the last indexed position {} and head location {} is lower \"\n              + \"than max offset {}. So, using {} position as the start offset\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay,\n          nextOffsetForPartition);\n      return nextOffsetForPartition;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void\n      testDetermineStartingOffsetReturnsHeadWhenCreateTasksIsFalseAndOffsetLocationIsHead()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDetermineStartingOffsetReturnsHeadWhenCreateTasksIsFalseAndOffsetLocationIsHead", "reference": "  @Test\n  public void\n      testDetermineStartingOffsetReturnsHeadWhenCreateTasksIsFalseAndOffsetLocationIsHead() {\n    RecoveryTaskCreator recoveryTaskCreator =\n        new RecoveryTaskCreator(\n            snapshotMetadataStore,\n            recoveryTaskStore,\n            partitionId,\n            1,\n            TEST_MAX_MESSAGES_PER_RECOVERY_TASK,\n            meterRegistry);\n\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore)).isEmpty();\n\n    AstraConfigs.IndexerConfig headLocationAndNoRecoveryConfig =\n        AstraConfigs.IndexerConfig.newBuilder()\n            .setCreateRecoveryTasksOnStart(false)\n            .setReadFromLocationOnStart(AstraConfigs.KafkaOffsetLocation.LATEST)\n            .build();\n\n    // When there is no data and ReadFromLocationOnStart is set to LATEST, return the current head\n    assertThat(\n            recoveryTaskCreator.determineStartingOffset(1000, 0, headLocationAndNoRecoveryConfig))\n        .isEqualTo(1000);\n\n    // Data exists for not for this partition.\n    final String name = \"testSnapshotId\";\n    final String path = \"/testPath_\" + name;\n    final long startTime = 1;\n    final long endTime = 100;\n    final long maxOffset = 100;\n\n    final SnapshotMetadata partition1 =\n        new SnapshotMetadata(name, path, startTime, endTime, maxOffset, \"2\", LOGS_LUCENE9);\n    snapshotMetadataStore.createSync(partition1);\n    await().until(() -> snapshotMetadataStore.listSync().contains(partition1));\n\n    assertThat(recoveryTaskCreator.determineStartingOffset(1, -1, headLocationAndNoRecoveryConfig))\n        .isEqualTo(1);\n\n    final SnapshotMetadata partition11 =\n        new SnapshotMetadata(\n            name + \"1\", path, endTime + 1, endTime * 2, maxOffset * 2, \"2\", LOGS_LUCENE9);\n    snapshotMetadataStore.createSync(partition11);\n    await().until(() -> snapshotMetadataStore.listSync().contains(partition11));\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore))\n        .contains(partition1, partition11);\n    assertThat(recoveryTaskCreator.determineStartingOffset(0, 0, indexerConfig)).isNegative();\n\n    final String recoveryTaskName = \"recoveryTask\";\n    final long recoveryStartOffset = 400;\n    final long createdTimeUtc = Instant.now().toEpochMilli();\n\n    final RecoveryTaskMetadata recoveryTask1 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"1\",\n            \"2\",\n            recoveryStartOffset,\n            recoveryStartOffset * 2,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask1);\n    await().until(() -> recoveryTaskStore.listSync().contains(recoveryTask1));\n    assertThat(recoveryTaskCreator.determineStartingOffset(1, -1, headLocationAndNoRecoveryConfig))\n        .isEqualTo(1);\n  }", "completions": ["  ```\n@Test\npublic void testDetermineStartingOffsetReturnsHeadWhenCreateTasksIsFalseAndOffsetLocationIsHead() {\n    // Set up test data\n    long currentEndOffsetForPartition = 100L;\n    long currentBeginningOffsetForPartition = 50L;\n    AstraConfigs.IndexerConfig indexerConfig = new AstraConfigs.IndexerConfig();\n    indexerConfig.setCreateRecoveryTasksOnStart(false);\n    indexerConfig.setReadFromLocationOnStart(AstraConfigs.KafkaOffsetLocation.LATEST);\n\n    // Call the method under test\n    long startingOffset = determineStartingOffset(currentEndOffsetForPartition, currentBeginningOffsetForPartition, indexerConfig);\n\n    // Assert the result\n    assertEquals(currentEndOffsetForPartition, startingOffset);\n}\n```"]}
{"id": 86, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @VisibleForTesting\n  boolean handleRecoveryTask(RecoveryTaskMetadata recoveryTaskMetadata) {\n    LOG.info(\"Started handling the recovery task: {}\", recoveryTaskMetadata);\n    long startTime = System.nanoTime();\n    Timer.Sample taskTimer = Timer.start(meterRegistry);\n\n    PartitionOffsets partitionOffsets =\n        validateKafkaOffsets(\n            adminClient,\n            recoveryTaskMetadata,\n            AstraConfig.getRecoveryConfig().getKafkaConfig().getKafkaTopic());\n    long offsetsValidatedTime = System.nanoTime();\n    long consumerPreparedTime = 0, messagesConsumedTime = 0, rolloversCompletedTime = 0;\n\n    if (partitionOffsets != null) {\n      RecoveryTaskMetadata validatedRecoveryTask =\n          new RecoveryTaskMetadata(\n              recoveryTaskMetadata.name,\n              recoveryTaskMetadata.partitionId,\n              partitionOffsets.startOffset,\n              partitionOffsets.endOffset,\n              recoveryTaskMetadata.createdTimeEpochMs);\n\n      if (partitionOffsets.startOffset != recoveryTaskMetadata.startOffset\n          || recoveryTaskMetadata.endOffset != partitionOffsets.endOffset) {\n        recoveryRecordsNoLongerAvailable.increment(\n            (partitionOffsets.startOffset - recoveryTaskMetadata.startOffset)\n                + (partitionOffsets.endOffset - recoveryTaskMetadata.endOffset));\n      }\n\n      try {\n        RecoveryChunkManager<LogMessage> chunkManager =\n            RecoveryChunkManager.fromConfig(\n                meterRegistry,\n                searchMetadataStore,\n                snapshotMetadataStore,\n                AstraConfig.getIndexerConfig(),\n                blobFs,\n                AstraConfig.getS3Config());\n\n        // Ingest data in parallel\n        LogMessageWriterImpl logMessageWriterImpl = new LogMessageWriterImpl(chunkManager);\n        AstraKafkaConsumer kafkaConsumer =\n            new AstraKafkaConsumer(\n                makeKafkaConfig(\n                    AstraConfig.getRecoveryConfig().getKafkaConfig(),\n                    validatedRecoveryTask.partitionId),\n                logMessageWriterImpl,\n                meterRegistry);\n\n        kafkaConsumer.prepConsumerForConsumption(validatedRecoveryTask.startOffset);\n        consumerPreparedTime = System.nanoTime();\n        kafkaConsumer.consumeMessagesBetweenOffsetsInParallel(\n            AstraKafkaConsumer.KAFKA_POLL_TIMEOUT_MS,\n            validatedRecoveryTask.startOffset,\n            validatedRecoveryTask.endOffset);\n        messagesConsumedTime = System.nanoTime();\n        // Wait for chunks to upload.\n        boolean success = chunkManager.waitForRollOvers();\n        rolloversCompletedTime = System.nanoTime();\n        // Close the recovery chunk manager and kafka consumer.\n        kafkaConsumer.close();\n        chunkManager.stopAsync();\n        chunkManager.awaitTerminated(DEFAULT_START_STOP_DURATION);\n        LOG.info(\"Finished handling the recovery task: {}\", validatedRecoveryTask);\n        taskTimer.stop(recoveryTaskTimerSuccess);\n        return success;\n      } catch (Exception ex) {\n        LOG.error(\"Exception in recovery task [{}]: {}\", validatedRecoveryTask, ex);\n        taskTimer.stop(recoveryTaskTimerFailure);\n        return false;\n      } finally {\n        long endTime = System.nanoTime();\n        LOG.info(\n            \"Recovery task {} took {}ms, (subtask times offset validation {}, consumer prep {}, msg consumption {}, rollover {})\",\n            recoveryTaskMetadata,\n            nanosToMillis(endTime - startTime),\n            nanosToMillis(offsetsValidatedTime - startTime),\n            nanosToMillis(consumerPreparedTime - offsetsValidatedTime),\n            nanosToMillis(messagesConsumedTime - consumerPreparedTime),\n            nanosToMillis(rolloversCompletedTime - messagesConsumedTime));\n      }\n    } else {\n      LOG.info(\n          \"Recovery task {} data no longer available in Kafka (validation time {}ms)\",\n          recoveryTaskMetadata,\n          nanosToMillis(offsetsValidatedTime - startTime));\n      recoveryRecordsNoLongerAvailable.increment(\n          recoveryTaskMetadata.endOffset - recoveryTaskMetadata.startOffset + 1);\n      return true;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testShouldHandleRecoveryTaskWithCompletelyUnavailableOffsets() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "testShouldHandleRecoveryTaskWithCompletelyUnavailableOffsets", "reference": "  @Test\n  public void testShouldHandleRecoveryTaskWithCompletelyUnavailableOffsets() throws Exception {\n    final TopicPartition topicPartition = new TopicPartition(TestKafkaServer.TEST_KAFKA_TOPIC, 0);\n    TestKafkaServer.KafkaComponents components = getKafkaTestServer(S3_MOCK_EXTENSION);\n    AstraConfigs.AstraConfig astraCfg =\n        makeAstraConfig(components.testKafkaServer, TEST_S3_BUCKET, topicPartition.topic());\n    curatorFramework =\n        CuratorBuilder.build(meterRegistry, astraCfg.getMetadataStoreConfig().getZookeeperConfig());\n\n    AstraConfigs.KafkaConfig kafkaConfig =\n        AstraConfigs.KafkaConfig.newBuilder()\n            .setKafkaTopic(topicPartition.topic())\n            .setKafkaTopicPartition(Integer.toString(topicPartition.partition()))\n            .setKafkaBootStrapServers(components.testKafkaServer.getBroker().getBrokerList().get())\n            .setKafkaClientGroup(TEST_KAFKA_CLIENT_GROUP)\n            .setEnableKafkaAutoCommit(\"true\")\n            .setKafkaAutoCommitInterval(\"500\")\n            .setKafkaSessionTimeout(\"500\")\n            .putAllAdditionalProps(Maps.fromProperties(components.consumerOverrideProps))\n            .build();\n\n    final AstraKafkaConsumer localTestConsumer =\n        new AstraKafkaConsumer(kafkaConfig, components.logMessageWriter, components.meterRegistry);\n    final Instant startTime =\n        LocalDateTime.of(2020, 10, 1, 10, 10, 0).atZone(ZoneOffset.UTC).toInstant();\n    final long msgsToProduce = 100;\n    TestKafkaServer.produceMessagesToKafka(\n        components.testKafkaServer.getBroker(),\n        startTime,\n        topicPartition.topic(),\n        topicPartition.partition(),\n        (int) msgsToProduce);\n    await().until(() -> localTestConsumer.getEndOffSetForPartition() == msgsToProduce);\n    // we immediately force delete the messages, as this is faster than changing the retention and\n    // waiting for the cleaner to run\n    components\n        .adminClient\n        .deleteRecords(Map.of(topicPartition, RecordsToDelete.beforeOffset(100)))\n        .all()\n        .get();\n    assertThat(getStartOffset(components.adminClient, topicPartition)).isGreaterThan(0);\n\n    // produce some more messages that won't be expired\n    setRetentionTime(components.adminClient, topicPartition.topic(), 25000);\n    TestKafkaServer.produceMessagesToKafka(\n        components.testKafkaServer.getBroker(),\n        startTime,\n        topicPartition.topic(),\n        topicPartition.partition(),\n        (int) msgsToProduce);\n    await()\n        .until(() -> localTestConsumer.getEndOffSetForPartition() == msgsToProduce + msgsToProduce);\n\n    SnapshotMetadataStore snapshotMetadataStore = new SnapshotMetadataStore(curatorFramework);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore).size()).isZero();\n\n    // Start recovery service\n    recoveryService =\n        new RecoveryService(astraCfg, curatorFramework, components.meterRegistry, blobFs);\n    recoveryService.startAsync();\n    recoveryService.awaitRunning(DEFAULT_START_STOP_DURATION);\n    long startOffset = 1;\n    long endOffset = msgsToProduce - 1;\n    RecoveryTaskMetadata recoveryTask =\n        new RecoveryTaskMetadata(\n            topicPartition.topic(),\n            Integer.toString(topicPartition.partition()),\n            startOffset,\n            endOffset,\n            Instant.now().toEpochMilli());\n    assertThat(recoveryService.handleRecoveryTask(recoveryTask)).isTrue();\n    assertThat(getCount(RECORDS_NO_LONGER_AVAILABLE, components.meterRegistry))\n        .isEqualTo(endOffset - startOffset + 1);\n    assertThat(getCount(MESSAGES_RECEIVED_COUNTER, components.meterRegistry)).isEqualTo(0);\n    List<SnapshotMetadata> snapshots =\n        AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore);\n    assertThat(snapshots.size()).isEqualTo(0);\n    assertThat(blobFs.listFiles(BlobFsUtils.createURI(TEST_S3_BUCKET, \"/\", \"\"), true)).isEmpty();\n    assertThat(getCount(MESSAGES_FAILED_COUNTER, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_INITIATED, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_COMPLETED, meterRegistry)).isEqualTo(0);\n    assertThat(getCount(ROLLOVERS_FAILED, meterRegistry)).isEqualTo(0);\n  }", "completions": ["  ```java\n  @Test\n  public void testShouldHandleRecoveryTaskWithCompletelyUnavailableOffsets() throws Exception {\n    // Set up the necessary mocks and stubs\n    AdminClient adminClient = mock(AdminClient.class);\n    RecoveryTaskMetadata recoveryTaskMetadata = mock(RecoveryTaskMetadata.class);\n    MeterRegistry meterRegistry = mock(MeterRegistry.class);\n    SearchMetadataStore searchMetadataStore = mock(SearchMetadataStore.class);\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    AstraConfig astraConfig = mock(AstraConfig.class);\n    BlobFs blobFs = mock(BlobFs.class);\n\n    // Set up the expected behavior of the mocks and stubs\n    when(adminClient.validateKafkaOffsets(any(), any(), any())).thenReturn(null);\n    when(recoveryTaskMetadata.getStartOffset()).thenReturn(100L);\n    when(recoveryTaskMetadata.getEndOffset()).thenReturn(200L);\n\n    // Call the method under test\n    boolean result = handleRecoveryTask(recoveryTaskMetadata);\n\n    // Verify the expected behavior\n    verify(adminClient).validateKafkaOffsets(any(), any(), any());\n    verify(recoveryTaskMetadata).getStartOffset();\n    verify(recoveryTaskMetadata).getEndOffset();\n    assertFalse(result);\n  }\n```"]}
{"id": 87, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public static CacheControlHeader fromExpirationTime(String expirationTime) {\n    String maxAge = DEFAULT_MAX_AGE;\n\n    if (expirationTime != null) {\n      if (expirationTimeIsValid(expirationTime)) {\n        Duration totalTime = Duration.ZERO;\n        for (String timeString : Splitter.on(\" \").split(expirationTime)) {\n          String timeUnitShort = Ascii.toLowerCase(timeString.substring(timeString.length() - 1));\n          TemporalUnit timeUnit = EXPIRATION_TIME_UNITS.get(timeUnitShort);\n          String timeValue = timeString.substring(0, timeString.length() - 1);\n          totalTime = totalTime.plus(Long.parseLong(timeValue), timeUnit);\n        }\n        maxAge = String.valueOf(totalTime.getSeconds());\n      } else {\n          logger.atWarning().log(\n            \"Failed to parse expiration time: \\\"%s\\\". Using default value instead.\",\n            expirationTime\n        );\n      }\n    }\n\n    String output = DEFAULT_BASE_VALUE + maxAge;\n    return new CacheControlHeader(output);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForIncorrectTimeUnits() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "fromExpirationTime_usesDefaultMaxAgeForIncorrectTimeUnits", "reference": "  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForIncorrectTimeUnits() throws Exception {\n    CacheControlHeader cacheControlHeader = CacheControlHeader.fromExpirationTime(\"3g\");\n    assertThat(cacheControlHeader.getValue()).isEqualTo(\"public, max-age=600\");\n  }", "completions": ["  ```java\n  @Test\n  public void fromExpirationTime_usesDefaultMaxAgeForIncorrectTimeUnits() throws Exception {\n    String expirationTime = \"10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}
{"id": 88, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public <T> T clone(T object) {\n        if (object instanceof String) {\n            return object;\n        } else if (object instanceof Collection) {\n            Object firstElement = findFirstNonNullElement((Collection) object);\n            if (firstElement != null && !(firstElement instanceof Serializable)) {\n                JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), firstElement.getClass());\n                return objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n            }\n        } else if (object instanceof Map) {\n            Map.Entry firstEntry = this.findFirstNonNullEntry((Map) object);\n            if (firstEntry != null) {\n                Object key = firstEntry.getKey();\n                Object value = firstEntry.getValue();\n                if (!(key instanceof Serializable) || !(value instanceof Serializable)) {\n                    JavaType type = TypeFactory.defaultInstance().constructParametricType(object.getClass(), key.getClass(), value.getClass());\n                    return (T) objectMapperWrapper.fromBytes(objectMapperWrapper.toBytes(object), type);\n                }\n            }\n        } else if (object instanceof JsonNode) {\n            return (T) ((JsonNode) object).deepCopy();\n        }\n\n        if (object instanceof Serializable) {\n            try {\n                return (T) SerializationHelper.clone((Serializable) object);\n            } catch (SerializationException e) {\n                //it is possible that object itself implements java.io.Serializable, but underlying structure does not\n                //in this case we switch to the other JSON marshaling strategy which doesn't use the Java serialization\n            }\n        }\n\n        return jsonClone(object);\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void should_clone_empty_collection()\n```\n### Answer: (use the provided format with backticks)\n", "name": "should_clone_empty_collection", "reference": "    @Test\n    public void should_clone_empty_collection() {\n        List<?> original = new ArrayList<>();\n        Object cloned = serializer.clone(original);\n        assertEquals(original, cloned);\n        assertNotSame(original, cloned);\n    }", "completions": ["  ```java\n    @Test\n    public void should_clone_empty_collection() {\n        Collection<String> collection = new ArrayList<>();\n        Collection<String> clonedCollection = (Collection<String>) clone(collection);\n        assertEquals(collection, clonedCollection);\n    }\n```"]}
{"id": 89, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public SearchResult<LogMessage> search(\n      String dataset,\n      String queryStr,\n      Long startTimeMsEpoch,\n      Long endTimeMsEpoch,\n      int howMany,\n      AggBuilder aggBuilder) {\n\n    ensureNonEmptyString(dataset, \"dataset should be a non-empty string\");\n    ensureNonNullString(queryStr, \"query should be a non-empty string\");\n    if (startTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch >= 0, \"start time should be non-negative value\");\n    }\n    if (startTimeMsEpoch != null && endTimeMsEpoch != null) {\n      ensureTrue(startTimeMsEpoch < endTimeMsEpoch, \"end time should be greater than start time\");\n    }\n    ensureTrue(howMany >= 0, \"hits requested should not be negative.\");\n    ensureTrue(howMany > 0 || aggBuilder != null, \"Hits or aggregation should be requested.\");\n\n    ScopedSpan span = Tracing.currentTracer().startScopedSpan(\"LogIndexSearcherImpl.search\");\n    span.tag(\"dataset\", dataset);\n    span.tag(\"startTimeMsEpoch\", String.valueOf(startTimeMsEpoch));\n    span.tag(\"endTimeMsEpoch\", String.valueOf(endTimeMsEpoch));\n    span.tag(\"howMany\", String.valueOf(howMany));\n\n    Stopwatch elapsedTime = Stopwatch.createStarted();\n    try {\n      // Acquire an index searcher from searcher manager.\n      // This is a useful optimization for indexes that are static.\n      IndexSearcher searcher = searcherManager.acquire();\n\n      Query query =\n          openSearchAdapter.buildQuery(\n              dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n      try {\n        List<LogMessage> results;\n        InternalAggregation internalAggregation = null;\n\n        if (howMany > 0) {\n          CollectorManager<TopFieldCollector, TopFieldDocs> topFieldCollector =\n              buildTopFieldCollector(howMany, aggBuilder != null ? Integer.MAX_VALUE : howMany);\n          MultiCollectorManager collectorManager;\n          if (aggBuilder != null) {\n            collectorManager =\n                new MultiCollectorManager(\n                    topFieldCollector,\n                    openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n          } else {\n            collectorManager = new MultiCollectorManager(topFieldCollector);\n          }\n          Object[] collector = searcher.search(query, collectorManager);\n\n          ScoreDoc[] hits = ((TopFieldDocs) collector[0]).scoreDocs;\n          results = new ArrayList<>(hits.length);\n          for (ScoreDoc hit : hits) {\n            results.add(buildLogMessage(searcher, hit));\n          }\n          if (aggBuilder != null) {\n            internalAggregation = (InternalAggregation) collector[1];\n          }\n        } else {\n          results = Collections.emptyList();\n          internalAggregation =\n              searcher.search(\n                  query, openSearchAdapter.getCollectorManager(aggBuilder, searcher, query));\n        }\n\n        elapsedTime.stop();\n        return new SearchResult<>(\n            results, elapsedTime.elapsed(TimeUnit.MICROSECONDS), 0, 0, 1, 1, internalAggregation);\n      } finally {\n        searcherManager.release(searcher);\n      }\n    } catch (IOException e) {\n      span.error(e);\n      throw new IllegalArgumentException(\"Failed to acquire an index searcher.\", e);\n    } finally {\n      span.finish();\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testTimeBoundSearch()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testTimeBoundSearch", "reference": "  @Test\n  public void testTimeBoundSearch() {\n    Instant time = Instant.now();\n    strictLogStore.logStore.addMessage(SpanUtil.makeSpan(1, time));\n    strictLogStore.logStore.addMessage(SpanUtil.makeSpan(2, time.plusSeconds(100)));\n    strictLogStore.logStore.commit();\n    strictLogStore.logStore.refresh();\n\n    assertThat(getCount(MESSAGES_RECEIVED_COUNTER, strictLogStore.metricsRegistry)).isEqualTo(2);\n    assertThat(getCount(MESSAGES_FAILED_COUNTER, strictLogStore.metricsRegistry)).isEqualTo(0);\n    assertThat(getTimerCount(REFRESHES_TIMER, strictLogStore.metricsRegistry)).isEqualTo(1);\n\n    // Start inclusive.\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"Message1\",\n                    time.toEpochMilli(),\n                    time.plusSeconds(10).toEpochMilli(),\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(1);\n\n    // Extended range still only picking one element.\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"Message1\",\n                    time.minusSeconds(1).toEpochMilli(),\n                    time.plusSeconds(90).toEpochMilli(),\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(1);\n\n    // Both ranges are inclusive.\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"_id:Message1 OR Message2\",\n                    time.toEpochMilli(),\n                    time.plusSeconds(100).toEpochMilli(),\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(2);\n\n    // Extended range to pick up both events\n    assertThat(\n            strictLogStore\n                .logSearcher\n                .search(\n                    TEST_DATASET_NAME,\n                    \"_id:Message1 OR Message2\",\n                    time.minusSeconds(1).toEpochMilli(),\n                    time.plusSeconds(1000).toEpochMilli(),\n                    1000,\n                    new DateHistogramAggBuilder(\n                        \"1\", LogMessage.SystemField.TIME_SINCE_EPOCH.fieldName, \"1s\"))\n                .hits\n                .size())\n        .isEqualTo(2);\n  }", "completions": ["  ```java\n@Test\npublic void testTimeBoundSearch() {\n    // Set up mocks\n    SearcherManager searcherManager = mock(SearcherManager.class);\n    IndexSearcher searcher = mock(IndexSearcher.class);\n    when(searcherManager.acquire()).thenReturn(searcher);\n    when(searcherManager.release(searcher)).thenReturn(null);\n    OpenSearchAdapter openSearchAdapter = mock(OpenSearchAdapter.class);\n    Query query = mock(Query.class);\n    when(openSearchAdapter.buildQuery(anyString(), anyString(), anyLong(), anyLong(), any())).thenReturn(query);\n    TopFieldCollector topFieldCollector = mock(TopFieldCollector.class);\n    when(topFieldCollector.getTotalHits()).thenReturn(10L);\n    when(topFieldCollector.topDocs()).thenReturn(new TopFieldDocs(0, new ScoreDoc[0], new SortField[0]));\n    CollectorManager<TopFieldCollector, TopFieldDocs> collectorManager = mock(CollectorManager.class);\n    when(collectorManager.newCollector()).thenReturn(topFieldCollector);\n    when(collectorManager.reduce(any())).thenReturn(topFieldCollector);\n    when(openSearchAdapter.getCollectorManager(any(), any(), any())).thenReturn(collectorManager);\n\n    // Set up parameters\n    String dataset = \"test-dataset\";\n    String queryStr = \"test-query\";\n    Long startTimeMsEpoch = 1000L;\n    Long endTimeMsEpoch = 2000L;\n    int howMany = 10;\n    AggBuilder aggBuilder = mock(AggBuilder.class);\n\n    // Call the method under test\n    SearchResult<LogMessage> result = search(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, howMany, aggBuilder);\n\n    // Verify the results\n    assertEquals(10, result.getTotalHits());\n    assertEquals(10, result.getHits().size());\n    assertEquals(0, result.getAggregations().size());\n    verify(searcherManager).acquire();\n    verify(searcherManager).release(searcher);\n    verify(openSearchAdapter).buildQuery(dataset, queryStr, startTimeMsEpoch, endTimeMsEpoch, searcher);\n    verify(openSearchAdapter).getCollectorManager(aggBuilder, searcher, query);\n    verify(collectorManager).newCollector();\n    verify(collectorManager).reduce(any());\n}\n```"]}
{"id": 90, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n\tpublic void setUserData(String theKey, Object theValue) {\n\t\tValidate.isTrue(isNotBlank(theKey), \"Invalid key; key must be non-empty, non-null.\");\n\t\tif (theValue == null) {\n\t\t\tgetUserData().remove(theKey);\n\t\t} else {\n\t\t\tValidate.isTrue(\n\t\t\t\t\tvalidateValue(theValue),\n\t\t\t\t\tString.format(\n\t\t\t\t\t\t\t\"Invalid data type provided %s\", theValue.getClass().getName()));\n\t\t\tgetUserData().put(theKey, theValue);\n\t\t}\n\t}\n```\n###test function signature:\n```java\n\t@ParameterizedTest\n\t@MethodSource(\"parameters\")\n\tpublic void setUserData_acceptsStringNumberAndBooleansOnly(TestParam theParams)\n```\n### Answer: (use the provided format with backticks)\n", "name": "\t@ParameterizedTest\n\t@MethodSource", "reference": "\t@ParameterizedTest\n\t@MethodSource(\"parameters\")\n\tpublic void setUserData_acceptsStringNumberAndBooleansOnly(TestParam theParams) {\n\t\t// setup\n\t\tString key = \"key\";\n\t\tTestParameters parameters = new TestParameters();\n\t\tObject testValue = theParams.getTestValue();\n\n\t\t// test\n\t\tif (theParams.isExpectedToWork()) {\n\t\t\tparameters.setUserData(key, testValue);\n\t\t\tassertFalse(parameters.getUserData().isEmpty());\n\t\t\tassertEquals(testValue, parameters.getUserData().get(key));\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tparameters.setUserData(key, testValue);\n\t\t\t\tfail();\n\t\t\t} catch (IllegalArgumentException ex) {\n\t\t\t\tString dataType = testValue.getClass().getName();\n\t\t\t\tassertTrue(ex.getMessage().contains(\"Invalid data type provided \" + dataType),\n\t\t\t\t\tex.getMessage());\n\t\t\t\tassertTrue(parameters.getUserData().isEmpty());\n\t\t\t}\n\t\t}\n\t}", "completions": ["  ```\n@ParameterizedTest\n@MethodSource(\"parameters\")\npublic void setUserData_acceptsStringNumberAndBooleansOnly(TestParam theParams) {\n    // Arrange\n    String key = theParams.getKey();\n    Object value = theParams.getValue();\n    Map<String, Object> userData = new HashMap<>();\n\n    // Act\n    setUserData(key, value);\n\n    // Assert\n    assertEquals(value, userData.get(key));\n}\n```"]}
{"id": 91, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n\tpublic Embedding embedText(String text) {\n\t\tAssert.hasText(text, \"The text can not be null or empty.\");\n\n\t\t@JsonInclude(Include.NON_NULL)\n\t\trecord EmbeddingResponse(Embedding embedding) {\n\t\t}\n\n\t\tEmbeddingResponse response = this.restClient.post()\n\t\t\t\t.uri(\"/models/{model}:embedText?key={apiKey}\", this.embeddingModel, this.apiKey)\n\t\t\t\t.body(Map.of(\"text\", text))\n\t\t\t\t.retrieve()\n\t\t\t\t.body(EmbeddingResponse.class);\n\n\t\treturn response != null ? response.embedding() : null;\n\t}\n```\n###test function signature:\n```java\n\t@Test\n\tpublic void embedText() throws JsonProcessingException\n```\n### Answer: (use the provided format with backticks)\n", "name": "embedText", "reference": "\t@Test\n\tpublic void embedText() throws JsonProcessingException {\n\n\t\tString text = \"Hello, how are you?\";\n\n\t\tEmbedding expectedEmbedding = new Embedding(List.of(0.1, 0.2, 0.3));\n\n\t\tserver\n\t\t\t.expect(requestToUriTemplate(\"/models/{generative}:embedText?key={apiKey}\",\n\t\t\t\t\tVertexAiPaLm2Api.DEFAULT_EMBEDDING_MODEL, TEST_API_KEY))\n\t\t\t.andExpect(method(HttpMethod.POST))\n\t\t\t.andExpect(content().json(objectMapper.writeValueAsString(Map.of(\"text\", text))))\n\t\t\t.andRespond(withSuccess(objectMapper.writeValueAsString(Map.of(\"embedding\", expectedEmbedding)),\n\t\t\t\t\tMediaType.APPLICATION_JSON));\n\n\t\tEmbedding embedding = client.embedText(text);\n\n\t\tassertThat(embedding).isEqualTo(expectedEmbedding);\n\n\t\tserver.verify();\n\t}", "completions": ["  ```java\n@Test\npublic void embedText() throws JsonProcessingException {\n    // Set up\n    String text = \"Hello, world!\";\n    Embedding expectedEmbedding = new Embedding(new double[] {1.0, 2.0, 3.0});\n    when(this.restClient.post()).thenReturn(this.restClient);\n    when(this.restClient.uri(anyString(), anyString(), anyString())).thenReturn(this.restClient);\n    when(this.restClient.body(anyMap())).thenReturn(this.restClient);\n    when(this.restClient.retrieve()).thenReturn(this.restClient);\n    when(this.restClient.body(EmbeddingResponse.class)).thenReturn(new EmbeddingResponse(expectedEmbedding));\n\n    // Call method\n    Embedding actualEmbedding = this.embedText(text);\n\n    // Verify\n    assertEquals(expectedEmbedding, actualEmbedding);\n}\n```"]}
{"id": 92, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public Mono<Void> syncAclWithAclCsv(KafkaCluster cluster, String csv) {\n    return adminClientService.get(cluster)\n        .flatMap(ac -> ac.listAcls(ResourcePatternFilter.ANY).flatMap(existingAclList -> {\n          var existingSet = Set.copyOf(existingAclList);\n          var newAcls = Set.copyOf(AclCsv.parseCsv(csv));\n          var toDelete = Sets.difference(existingSet, newAcls);\n          var toAdd = Sets.difference(newAcls, existingSet);\n          logAclSyncPlan(cluster, toAdd, toDelete);\n          if (toAdd.isEmpty() && toDelete.isEmpty()) {\n            return Mono.empty();\n          }\n          log.info(\"Starting new ACLs creation\");\n          return ac.createAcls(toAdd)\n              .doOnSuccess(v -> {\n                log.info(\"{} new ACLs created\", toAdd.size());\n                log.info(\"Starting ACLs deletion\");\n              })\n              .then(ac.deleteAcls(toDelete)\n                  .doOnSuccess(v -> log.info(\"{} ACLs deleted\", toDelete.size())));\n        }));\n  }\n```\n###test function signature:\n```java\n  @Test\n  void testSyncAclWithAclCsv()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testSyncAclWithAclCsv", "reference": "  @Test\n  void testSyncAclWithAclCsv() {\n    var existingBinding1 = new AclBinding(\n        new ResourcePattern(ResourceType.TOPIC, \"*\", PatternType.LITERAL),\n        new AccessControlEntry(\"User:test1\", \"*\", AclOperation.READ, AclPermissionType.ALLOW));\n\n    var existingBinding2 = new AclBinding(\n        new ResourcePattern(ResourceType.GROUP, \"group1\", PatternType.PREFIXED),\n        new AccessControlEntry(\"User:test2\", \"localhost\", AclOperation.DESCRIBE, AclPermissionType.DENY));\n\n    var newBindingToBeAdded = new AclBinding(\n        new ResourcePattern(ResourceType.GROUP, \"groupNew\", PatternType.PREFIXED),\n        new AccessControlEntry(\"User:test3\", \"localhost\", AclOperation.DESCRIBE, AclPermissionType.DENY));\n\n    when(adminClientMock.listAcls(ResourcePatternFilter.ANY))\n        .thenReturn(Mono.just(List.of(existingBinding1, existingBinding2)));\n\n    ArgumentCaptor<Collection<AclBinding>> createdCaptor = ArgumentCaptor.forClass(Collection.class);\n    when(adminClientMock.createAcls(createdCaptor.capture()))\n        .thenReturn(Mono.empty());\n\n    ArgumentCaptor<Collection<AclBinding>> deletedCaptor = ArgumentCaptor.forClass(Collection.class);\n    when(adminClientMock.deleteAcls(deletedCaptor.capture()))\n        .thenReturn(Mono.empty());\n\n    aclsService.syncAclWithAclCsv(\n        CLUSTER,\n        \"Principal,ResourceType, PatternType, ResourceName,Operation,PermissionType,Host\\n\"\n            + \"User:test1,TOPIC,LITERAL,*,READ,ALLOW,*\\n\"\n            + \"User:test3,GROUP,PREFIXED,groupNew,DESCRIBE,DENY,localhost\"\n    ).block();\n\n    Collection<AclBinding> createdBindings = createdCaptor.getValue();\n    assertThat(createdBindings)\n        .hasSize(1)\n        .contains(newBindingToBeAdded);\n\n    Collection<AclBinding> deletedBindings = deletedCaptor.getValue();\n    assertThat(deletedBindings)\n        .hasSize(1)\n        .contains(existingBinding2);\n  }", "completions": ["  ```\n@Test\nvoid testSyncAclWithAclCsv() {\n    // Arrange\n    KafkaCluster cluster = mock(KafkaCluster.class);\n    String csv = \"user,topic,read,write\\n\" +\n            \"user1,topic1,true,false\\n\" +\n            \"user2,topic2,false,true\\n\" +\n            \"user3,topic3,true,true\";\n    AdminClientService adminClientService = mock(AdminClientService.class);\n    AdminClient adminClient = mock(AdminClient.class);\n    when(adminClientService.get(cluster)).thenReturn(Mono.just(adminClient));\n    when(adminClient.listAcls(ResourcePatternFilter.ANY)).thenReturn(Mono.just(List.of(\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic1\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user1\", \"*\", AclOperation.READ, AclPermissionType.ALLOW)),\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic2\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user2\", \"*\", AclOperation.WRITE, AclPermissionType.ALLOW))\n    )));\n    when(adminClient.createAcls(anyList())).thenReturn(Mono.empty());\n    when(adminClient.deleteAcls(anyList())).thenReturn(Mono.empty());\n\n    // Act\n    Mono<Void> result = syncAclWithAclCsv(cluster, csv);\n\n    // Assert\n    StepVerifier.create(result)\n           .expectComplete()\n           .verify();\n    verify(adminClient, times(1)).createAcls(List.of(\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic3\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user3\", \"*\", AclOperation.READ, AclPermissionType.ALLOW)),\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic3\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user3\", \"*\", AclOperation.WRITE, AclPermissionType.ALLOW))\n    ));\n    verify(adminClient, times(1)).deleteAcls(List.of(\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic1\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user1\", \"*\", AclOperation.READ, AclPermissionType.ALLOW)),\n            new Acl(new ResourcePattern(ResourceType.TOPIC, \"topic2\", PatternType.LITERAL),\n                    new AccessControlEntry(\"user2\", \"*\", AclOperation.WRITE, AclPermissionType.ALLOW))\n    ));\n}\n```"]}
{"id": 93, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ProcessInstanceForListViewEntity getProcessInstanceListViewByKey(Long processInstanceKey) {\n    try {\n      final QueryBuilder query =\n          joinWithAnd(\n              idsQuery().addIds(String.valueOf(processInstanceKey)),\n              termQuery(ListViewTemplate.PROCESS_INSTANCE_KEY, processInstanceKey));\n\n      final SearchRequest request =\n          ElasticsearchUtil.createSearchRequest(listViewTemplate, ALL)\n              .source(new SearchSourceBuilder().query(constantScoreQuery(query)));\n\n      final SearchResponse response;\n\n      response = tenantAwareClient.search(request);\n      final SearchHits searchHits = response.getHits();\n      if (searchHits.getTotalHits().value == 1 && searchHits.getHits().length == 1) {\n        return ElasticsearchUtil.fromSearchHit(\n            searchHits.getAt(0).getSourceAsString(),\n            objectMapper,\n            ProcessInstanceForListViewEntity.class);\n      } else if (response.getHits().getTotalHits().value > 1) {\n        throw new NotFoundException(\n            String.format(\n                \"Could not find unique process instance with id '%s'.\", processInstanceKey));\n      } else {\n        throw new NotFoundException(\n            (String.format(\"Could not find process instance with id '%s'.\", processInstanceKey)));\n      }\n    } catch (IOException e) {\n      throw new OperateRuntimeException(e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testGetProcessInstanceListViewByKeyNoResults() throws IOException\n```\n### Answer: (use the provided format with backticks)\n", "name": "testGetProcessInstanceListViewByKeyNoResults", "reference": "  @Test\n  public void testGetProcessInstanceListViewByKeyNoResults() throws IOException {\n    when(listViewTemplate.getAlias()).thenReturn(\"listViewIndexAlias\");\n\n    final SearchResponse mockResponse = Mockito.mock(SearchResponse.class);\n    final SearchHits mockHits = Mockito.mock(SearchHits.class);\n    // Normally TotalHits would just be mocked, but Mockito can't stub or mock direct field accesses\n    final TotalHits.Relation mockRelation = Mockito.mock(TotalHits.Relation.class);\n    final TotalHits mockTotalHits = new TotalHits(0L, mockRelation);\n\n    when(mockResponse.getHits()).thenReturn(mockHits);\n    when(mockHits.getTotalHits()).thenReturn(mockTotalHits);\n    when(tenantAwareClient.search(any())).thenReturn(mockResponse);\n\n    assertThrows(NotFoundException.class, () -> underTest.getProcessInstanceListViewByKey(123L));\n  }", "completions": ["  ```java\n  @Test\n  public void testGetProcessInstanceListViewByKeyNoResults() throws IOException {\n    // given\n    Long processInstanceKey = 123L;\n    SearchResponse response = mock(SearchResponse.class);\n    when(response.getHits().getTotalHits().value).thenReturn(0L);\n    when(tenantAwareClient.search(any(SearchRequest.class))).thenReturn(response);\n\n    // when\n    ProcessInstanceForListViewEntity result =\n        getProcessInstanceListViewByKey(processInstanceKey);\n\n    // then\n    assertNull(result);\n  }\n```"]}
{"id": 94, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public long determineStartingOffset(\n      long currentEndOffsetForPartition,\n      long currentBeginningOffsetForPartition,\n      AstraConfigs.IndexerConfig indexerConfig) {\n    // Filter stale snapshots for partition.\n    if (partitionId == null) {\n      LOG.warn(\"PartitionId can't be null.\");\n    }\n\n    List<SnapshotMetadata> snapshots = snapshotMetadataStore.listSync();\n    List<SnapshotMetadata> snapshotsForPartition =\n        snapshots.stream()\n            .filter(\n                snapshotMetadata -> {\n                  if (snapshotMetadata == null || snapshotMetadata.partitionId == null) {\n                    LOG.warn(\n                        \"snapshot metadata or partition id can't be null: {} \",\n                        Strings.join(snapshots, ','));\n                  }\n                  return snapshotMetadata != null\n                      && snapshotMetadata.partitionId != null\n                      && snapshotMetadata.partitionId.equals(partitionId);\n                })\n            .collect(Collectors.toUnmodifiableList());\n    List<SnapshotMetadata> deletedSnapshots = deleteStaleLiveSnapshots(snapshotsForPartition);\n\n    List<SnapshotMetadata> nonLiveSnapshotsForPartition =\n        snapshotsForPartition.stream()\n            .filter(s -> !deletedSnapshots.contains(s))\n            .collect(Collectors.toUnmodifiableList());\n\n    // Get the highest offset that is indexed in durable store.\n    List<RecoveryTaskMetadata> recoveryTasks = recoveryTaskMetadataStore.listSync();\n    long highestDurableOffsetForPartition =\n        getHighestDurableOffsetForPartition(\n            nonLiveSnapshotsForPartition, recoveryTasks, partitionId);\n    LOG.debug(\n        \"The highest durable offset for partition {} is {}\",\n        partitionId,\n        highestDurableOffsetForPartition);\n\n    if (highestDurableOffsetForPartition <= 0) {\n      LOG.info(\"There is no prior offset for this partition {}.\", partitionId);\n\n      // If the user wants to start at the current offset in Kafka and _does not_ want to create\n      // recovery tasks to backfill, then we can just return the current offset.\n      // If the user wants to start at the current offset in Kafka and _does_ want to create\n      // recovery tasks to backfill, then we create the recovery tasks needed and then return\n      // the current offset for the indexer. And if the user does _not_ want to start at the\n      // current offset in Kafka, then we'll just default to the old behavior of starting from\n      // the very beginning\n      if (!indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set to false and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" NOT spinning up recovery tasks\");\n        return currentEndOffsetForPartition;\n      } else if (indexerConfig.getCreateRecoveryTasksOnStart()\n          && indexerConfig.getReadFromLocationOnStart()\n              == AstraConfigs.KafkaOffsetLocation.LATEST) {\n        // Todo - this appears to be able to create recovery tasks that have a start and end\n        // position of 0, which is invalid. This seems to occur when new clusters are initialized,\n        // and is  especially problematic when indexers are created but never get assigned (ie,\n        // deploy 5, only assign 3).\n        LOG.info(\n            \"CreateRecoveryTasksOnStart is set and ReadLocationOnStart is set to current. Reading from current and\"\n                + \" spinning up recovery tasks\");\n        createRecoveryTasks(\n            partitionId,\n            currentBeginningOffsetForPartition,\n            currentEndOffsetForPartition,\n            indexerConfig.getMaxMessagesPerChunk());\n        return currentEndOffsetForPartition;\n\n      } else {\n        return highestDurableOffsetForPartition;\n      }\n    }\n\n    // The current head offset shouldn't be lower than the highest durable offset. If it is it\n    // means that we indexed more data than the current head offset. This is either a bug in the\n    // offset handling mechanism or the kafka partition has rolled over. We throw an exception\n    // for now, so we can investigate.\n    if (currentEndOffsetForPartition < highestDurableOffsetForPartition) {\n      final String message =\n          String.format(\n              \"The current head for the partition %d can't \"\n                  + \"be lower than the highest durable offset for that partition %d\",\n              currentEndOffsetForPartition, highestDurableOffsetForPartition);\n      LOG.error(message);\n      throw new IllegalStateException(message);\n    }\n\n    // The head offset for Kafka partition is the offset of the next message to be indexed. We\n    // assume that offset is passed into this function. The highest durable offset is the partition\n    // offset of the message that is indexed. Hence, the offset is incremented by 1 to get the\n    // next message.\n    long nextOffsetForPartition = highestDurableOffsetForPartition + 1;\n\n    // Create a recovery task if needed.\n    if (currentEndOffsetForPartition - highestDurableOffsetForPartition > maxOffsetDelay) {\n      LOG.info(\n          \"Recovery task needed. The current position {} and head location {} are higher than max\"\n              + \" offset {}\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay);\n      createRecoveryTasks(\n          partitionId,\n          nextOffsetForPartition,\n          currentEndOffsetForPartition - 1,\n          maxMessagesPerRecoveryTask);\n      return currentEndOffsetForPartition;\n    } else {\n      LOG.info(\n          \"The difference between the last indexed position {} and head location {} is lower \"\n              + \"than max offset {}. So, using {} position as the start offset\",\n          highestDurableOffsetForPartition,\n          currentEndOffsetForPartition,\n          maxOffsetDelay,\n          nextOffsetForPartition);\n      return nextOffsetForPartition;\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testDetermineStartingOffsetOnlyMultipleRecoveryBehind()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testDetermineStartingOffsetOnlyMultipleRecoveryBehind", "reference": "  @Test\n  public void testDetermineStartingOffsetOnlyMultipleRecoveryBehind() {\n    RecoveryTaskCreator recoveryTaskCreator =\n        new RecoveryTaskCreator(\n            snapshotMetadataStore,\n            recoveryTaskStore,\n            partitionId,\n            100,\n            TEST_MAX_MESSAGES_PER_RECOVERY_TASK,\n            meterRegistry);\n\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n    assertThat(AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore)).isEmpty();\n\n    // When there is no data return -1.\n    assertThat(recoveryTaskCreator.determineStartingOffset(1000, 0, indexerConfig)).isNegative();\n    final String recoveryTaskName = \"BasicRecoveryTask\";\n    final long recoveryStartOffset = 400;\n    final long createdTimeUtc = Instant.now().toEpochMilli();\n\n    final RecoveryTaskMetadata recoveryTask1 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"1\",\n            partitionId,\n            recoveryStartOffset,\n            recoveryStartOffset * 2,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask1);\n    final RecoveryTaskMetadata recoveryTask11 =\n        new RecoveryTaskMetadata(\n            recoveryTaskName + \"11\",\n            partitionId,\n            recoveryStartOffset * 2 + 1,\n            recoveryStartOffset * 3,\n            createdTimeUtc);\n    recoveryTaskStore.createSync(recoveryTask11);\n    await()\n        .until(\n            () -> recoveryTaskStore.listSync().containsAll(List.of(recoveryTask1, recoveryTask11)));\n\n    final long currentHeadOffset = 4000;\n    assertThat(recoveryTaskCreator.determineStartingOffset(currentHeadOffset, 0, indexerConfig))\n        .isEqualTo(currentHeadOffset);\n    List<RecoveryTaskMetadata> recoveryTasks =\n        AstraMetadataTestUtils.listSyncUncached(recoveryTaskStore);\n    assertThat(recoveryTasks.size()).isEqualTo(3);\n    assertThat(recoveryTasks).contains(recoveryTask1, recoveryTask11);\n    Optional<RecoveryTaskMetadata> newRecoveryTask =\n        recoveryTasks.stream().filter(r -> !r.name.contains(recoveryTaskName)).findFirst();\n    assertThat(newRecoveryTask).isNotEmpty();\n    RecoveryTaskMetadata recoveryTask = newRecoveryTask.get();\n    assertThat(recoveryTask.startOffset).isEqualTo(recoveryStartOffset * 3 + 1);\n    assertThat(recoveryTask.endOffset).isEqualTo(currentHeadOffset - 1);\n    assertThat(AstraMetadataTestUtils.listSyncUncached(snapshotMetadataStore)).isEmpty();\n  }", "completions": ["  ```\n@Test\npublic void testDetermineStartingOffsetOnlyMultipleRecoveryBehind() {\n    // Set up mocks\n    SnapshotMetadataStore snapshotMetadataStore = mock(SnapshotMetadataStore.class);\n    RecoveryTaskMetadataStore recoveryTaskMetadataStore = mock(RecoveryTaskMetadataStore.class);\n    AstraConfigs.IndexerConfig indexerConfig = mock(AstraConfigs.IndexerConfig.class);\n\n    // Set up test data\n    long currentEndOffsetForPartition = 1000;\n    long currentBeginningOffsetForPartition = 500;\n    long highestDurableOffsetForPartition = 800;\n    long maxOffsetDelay = 100;\n    long maxMessagesPerRecoveryTask = 100;\n    List<SnapshotMetadata> snapshots = new ArrayList<>();\n    List<SnapshotMetadata> deletedSnapshots = new ArrayList<>();\n    List<RecoveryTaskMetadata> recoveryTasks = new ArrayList<>();\n\n    // Set up mock behavior\n    when(snapshotMetadataStore.listSync()).thenReturn(snapshots);\n    when(recoveryTaskMetadataStore.listSync()).thenReturn(recoveryTasks);\n    when(indexerConfig.getCreateRecoveryTasksOnStart()).thenReturn(true);\n    when(indexerConfig.getReadFromLocationOnStart()).thenReturn(AstraConfigs.KafkaOffsetLocation.LATEST);\n\n    // Call the method under test\n    long actualStartingOffset = determineStartingOffset(currentEndOffsetForPartition, currentBeginningOffsetForPartition, indexerConfig);\n\n    // Verify the results\n    assertEquals(highestDurableOffsetForPartition + 1, actualStartingOffset);\n    verify(snapshotMetadataStore).listSync();\n    verify(recoveryTaskMetadataStore).listSync();\n    verify(indexerConfig).getCreateRecoveryTasksOnStart();\n    verify(indexerConfig).getReadFromLocationOnStart();\n}\n```"]}
{"id": 95, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  private String saveAndChecksumBlockList(String jobName, LazyBlockList blockList) {\n    BlobId blobId = getBlobId(jobName, getBlockListFileName(blockList.getName()));\n    try (BufferedOutputStream gcsWriter =\n        new BufferedOutputStream(gcsUtils.openOutputStream(blobId))) {\n      MessageDigest messageDigest = MessageDigest.getInstance(checksumAlgorithm);\n      blockList.consumeAll(\n          (byteArray, length) -> {\n            try {\n              gcsWriter.write(byteArray, 0, length);\n            } catch (IOException e) {\n              throw new RuntimeException(e);\n            }\n            messageDigest.update(byteArray, 0, length);\n          });\n      return base16().lowerCase().encode(messageDigest.digest());\n    } catch (IOException | NoSuchAlgorithmException e) {\n      throw new RuntimeException(e);\n    }\n  }\n```\n###test function signature:\n```java\n  @Test\n  void saveAndChecksumBlockList_success() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "saveAndChecksumBlockList_success", "reference": "  @Test\n  void saveAndChecksumBlockList_success() throws Exception {\n    String payload = \"somedata\\n\";\n    String payloadChecksum = \"0737c8e591c68b93feccde50829aca86a80137547d8cfbe96bab6b20f8580c63\";\n\n    when(connection.getInputStream())\n        .thenReturn(new ByteArrayInputStream((\"bsa-checksum\\n\" + payload).getBytes(UTF_8)));\n    lazyBlockList = new LazyBlockList(BlockListType.BLOCK, connection);\n\n    ImmutableMap<BlockListType, String> checksums =\n        gcsClient.saveAndChecksumBlockList(\"some-name\", ImmutableList.of(lazyBlockList));\n    assertThat(gcsUtils.existsAndNotEmpty(BlobId.of(\"my-bucket\", \"some-name/BLOCK.csv\"))).isTrue();\n    assertThat(checksums).containsExactly(BlockListType.BLOCK, payloadChecksum);\n    assertThat(gcsClient.readBlockList(\"some-name\", BlockListType.BLOCK))\n        .containsExactly(\"somedata\");\n  }", "completions": ["  ```\n@Test\nvoid saveAndChecksumBlockList_success() throws Exception {\n    // Arrange\n    String jobName = \"testJob\";\n    LazyBlockList blockList = mock(LazyBlockList.class);\n    BlobId blobId = mock(BlobId.class);\n    BufferedOutputStream gcsWriter = mock(BufferedOutputStream.class);\n    MessageDigest messageDigest = mock(MessageDigest.class);\n    when(gcsUtils.openOutputStream(blobId)).thenReturn(gcsWriter);\n    when(blockList.getName()).thenReturn(\"testBlockList\");\n    when(messageDigest.digest()).thenReturn(new byte[0]);\n\n    // Act\n    String result = saveAndChecksumBlockList(jobName, blockList);\n\n    // Assert\n    verify(gcsWriter).write(any(byte[].class), anyInt(), anyInt());\n    verify(messageDigest).update(any(byte[].class), anyInt(), anyInt());\n    assertEquals(\"\", result);\n}\n```"]}
{"id": 96, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  @Override\n  public ListenableFuture<Iterable<Digest>> findMissingBlobs(\n      Iterable<Digest> blobDigests, RequestMetadata requestMetadata) {\n    // Some requests have been blocked, and we should tell the client we refuse to perform a lookup.\n    try {\n      if (inDenyList(requestMetadata)) {\n        return immediateFailedFuture(\n            Status.UNAVAILABLE\n                .withDescription(\"The action associated with this request is forbidden\")\n                .asException());\n      }\n    } catch (IOException e) {\n      return immediateFailedFuture(Status.fromThrowable(e).asException());\n    }\n\n    // Empty blobs are an exceptional case. Filter them out.\n    // If the user only requested empty blobs we can immediately tell them we already have it.\n    Iterable<Digest> nonEmptyDigests =\n        Iterables.filter(blobDigests, (digest) -> digest.getSizeBytes() != 0);\n    if (Iterables.isEmpty(nonEmptyDigests)) {\n      return immediateFuture(ImmutableList.of());\n    }\n\n    if (configs.getServer().isFindMissingBlobsViaBackplane()) {\n      return findMissingBlobsViaBackplane(nonEmptyDigests, requestMetadata);\n    }\n\n    return findMissingBlobsQueryingEachWorker(nonEmptyDigests, requestMetadata);\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void findMissingBlobsTest_ViaBackPlane() throws Exception\n```\n### Answer: (use the provided format with backticks)\n", "name": "findMissingBlobsTest_ViaBackPlane", "reference": "  @Test\n  public void findMissingBlobsTest_ViaBackPlane() throws Exception {\n    Set<String> activeWorkers = ImmutableSet.of(\"worker1\", \"worker2\", \"worker3\");\n    Set<String> expiredWorkers = ImmutableSet.of(\"workerX\", \"workerY\", \"workerZ\");\n    Set<String> imposterWorkers = ImmutableSet.of(\"imposter1\", \"imposter2\", \"imposter3\");\n\n    Set<Digest> availableDigests =\n        ImmutableSet.of(\n            Digest.newBuilder().setHash(\"toBeFound1\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"toBeFound2\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"toBeFound3\").setSizeBytes(1).build(),\n            // a copy is added in final digest list\n            Digest.newBuilder().setHash(\"toBeFoundDuplicate\").setSizeBytes(1).build());\n\n    Set<Digest> missingDigests =\n        ImmutableSet.of(\n            Digest.newBuilder().setHash(\"missing1\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"missing2\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"missing3\").setSizeBytes(1).build(),\n            // a copy is added in final digest list\n            Digest.newBuilder().setHash(\"missingDuplicate\").setSizeBytes(1).build());\n\n    Set<Digest> digestAvailableOnImposters =\n        ImmutableSet.of(\n            Digest.newBuilder().setHash(\"toBeFoundOnImposter1\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"toBeFoundOnImposter2\").setSizeBytes(1).build(),\n            Digest.newBuilder().setHash(\"toBeFoundOnImposter3\").setSizeBytes(1).build());\n\n    Set<Digest> emptyDigests =\n        new HashSet<>(\n            Arrays.asList(\n                Digest.newBuilder().setHash(\"empty1\").build(),\n                Digest.newBuilder().setHash(\"empty2\").build()));\n\n    Iterable<Digest> allDigests =\n        Iterables.concat(\n            availableDigests,\n            missingDigests,\n            emptyDigests,\n            digestAvailableOnImposters,\n            Arrays.asList(\n                Digest.newBuilder().setHash(\"toBeFoundDuplicate\").setSizeBytes(1).build(),\n                Digest.newBuilder().setHash(\"missingDuplicate\").setSizeBytes(1).build()));\n\n    Map<Digest, Set<String>> digestAndWorkersMap = new HashMap<>();\n\n    for (Digest digest : availableDigests) {\n      digestAndWorkersMap.put(digest, getRandomSubset(activeWorkers));\n    }\n    for (Digest digest : missingDigests) {\n      digestAndWorkersMap.put(digest, getRandomSubset(expiredWorkers));\n    }\n    for (Digest digest : digestAvailableOnImposters) {\n      digestAndWorkersMap.put(digest, getRandomSubset(imposterWorkers));\n    }\n\n    BuildfarmConfigs buildfarmConfigs = instance.getBuildFarmConfigs();\n    buildfarmConfigs.getServer().setFindMissingBlobsViaBackplane(true);\n    Set<String> activeAndImposterWorkers =\n        Sets.newHashSet(Iterables.concat(activeWorkers, imposterWorkers));\n\n    when(mockBackplane.getStorageWorkers()).thenReturn(activeAndImposterWorkers);\n    when(mockBackplane.getBlobDigestsWorkers(any(Iterable.class))).thenReturn(digestAndWorkersMap);\n    when(mockInstanceLoader.load(anyString())).thenReturn(mockWorkerInstance);\n    when(mockWorkerInstance.findMissingBlobs(anyIterable(), any(RequestMetadata.class)))\n        .thenReturn(Futures.immediateFuture(new ArrayList<>()));\n\n    long serverStartTime = 1686951033L; // june 15th, 2023\n    Map<String, Long> workersStartTime = new HashMap<>();\n    for (String worker : activeAndImposterWorkers) {\n      workersStartTime.put(worker, serverStartTime);\n    }\n    when(mockBackplane.getWorkersStartTimeInEpochSecs(activeAndImposterWorkers))\n        .thenReturn(workersStartTime);\n    long oneDay = 86400L;\n    for (Digest digest : availableDigests) {\n      when(mockBackplane.getDigestInsertTime(digest)).thenReturn(serverStartTime + oneDay);\n    }\n    for (Digest digest : digestAvailableOnImposters) {\n      when(mockBackplane.getDigestInsertTime(digest)).thenReturn(serverStartTime - oneDay);\n    }\n\n    Iterable<Digest> actualMissingDigests =\n        instance.findMissingBlobs(allDigests, RequestMetadata.getDefaultInstance()).get();\n    Iterable<Digest> expectedMissingDigests =\n        Iterables.concat(missingDigests, digestAvailableOnImposters);\n\n    assertThat(actualMissingDigests).containsExactlyElementsIn(expectedMissingDigests);\n    verify(mockWorkerInstance, atMost(3))\n        .findMissingBlobs(anyIterable(), any(RequestMetadata.class));\n    verify(mockWorkerInstance, atLeast(1))\n        .findMissingBlobs(anyIterable(), any(RequestMetadata.class));\n\n    for (Digest digest : actualMissingDigests) {\n      assertThat(digest).isNotIn(availableDigests);\n      assertThat(digest).isNotIn(emptyDigests);\n      assertThat(digest).isIn(expectedMissingDigests);\n    }\n\n    // reset BuildfarmConfigs\n    buildfarmConfigs.getServer().setFindMissingBlobsViaBackplane(false);\n  }", "completions": ["  ```java\n  @Test\n  public void findMissingBlobsTest_ViaBackPlane() throws Exception {\n    // Mock the configs to return true for findMissingBlobsViaBackplane\n    Configs configs = mock(Configs.class);\n    when(configs.getServer().isFindMissingBlobsViaBackplane()).thenReturn(true);\n\n    // Mock the requestMetadata to return false for inDenyList\n    RequestMetadata requestMetadata = mock(RequestMetadata.class);\n    when(requestMetadata.inDenyList()).thenReturn(false);\n\n    // Create a list of digests to pass to the method\n    List<Digest> digests = new ArrayList<>();\n    digests.add(new Digest(\"digest1\", 10));\n    digests.add(new Digest(\"digest2\", 20));\n\n    // Create a mock ListenableFuture to return from the method\n    ListenableFuture<Iterable<Digest>> future = mock(ListenableFuture.class);\n    when(future.get()).thenReturn(digests);\n\n    // Call the method with the mocked configs, requestMetadata, and digests\n    ListenableFuture<Iterable<Digest>> result = findMissingBlobs(digests, requestMetadata);\n\n    // Verify that the method returned the expected result\n    assertEquals(future, result);\n  }\n```"]}
{"id": 97, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n  public ComponentXO readComponent(final Repository repository, final EntityId componentId) {\n    Component component;\n    List<Asset> assets;\n    try (StorageTx storageTx = repository.facet(StorageFacet.class).txSupplier().get()) {\n      storageTx.begin();\n      component = storageTx.findComponent(componentId);\n      if (component == null) {\n        throw new WebApplicationException(Status.NOT_FOUND);\n      }\n\n      Iterable<Asset> browsedAssets = storageTx.browseAssets(component);\n      if (browsedAssets == null || Iterables.isEmpty(browsedAssets)) {\n        throw new WebApplicationException(Status.NOT_FOUND);\n      }\n\n      assets = newArrayList(browsedAssets);\n    }\n    ensurePermissions(repository, assets, BreadActions.BROWSE);\n    return COMPONENT_CONVERTER(component, repository.getName());\n  }\n```\n###test function signature:\n```java\n  @Test\n  public void testReadComponent_notFound()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testReadComponent_notFound", "reference": "  @Test\n  public void testReadComponent_notFound() {\n    Component component = mock(Component.class);\n    when(storageTx.findComponent(eq(new DetachedEntityId(\"someid\")))).thenReturn(component);\n    when(storageTx.browseAssets(component)).thenReturn(null);\n    try {\n      underTest.readComponent(\"someid\", \"testRepositoryName\");\n      fail(\"Exception should have been thrown\");\n    }\n    catch (WebApplicationException e) {\n      assertThat(e.getResponse(), is(notNullValue()));\n      assertThat(e.getResponse().getStatus(), is(404));\n    }\n  }", "completions": ["  ```java\n  @Test\n  public void testReadComponent_notFound() {\n    // Arrange\n    Repository repository = mock(Repository.class);\n    EntityId componentId = mock(EntityId.class);\n    StorageFacet storageFacet = mock(StorageFacet.class);\n    StorageTx storageTx = mock(StorageTx.class);\n    when(repository.facet(StorageFacet.class)).thenReturn(storageFacet);\n    when(storageFacet.txSupplier()).thenReturn(Suppliers.ofInstance(storageTx));\n    when(storageTx.findComponent(componentId)).thenReturn(null);\n\n    // Act\n    ComponentXO result = readComponent(repository, componentId);\n\n    // Assert\n    assertNull(result);\n    verify(storageTx).begin();\n    verify(storageTx).findComponent(componentId);\n    verify(storageTx, never()).browseAssets(componentId);\n    verify(storageTx).close();\n  }\n```"]}
{"id": 98, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @Override\n    public CompletableFuture<MQTT3AuthResult> auth(MQTT3AuthData authData) {\n        try {\n            HttpRequest request = HttpRequest.newBuilder()\n                .uri(URI.create(webhookURI + \"/auth\"))\n                .header(\"Content-Type\", \"application/json\")\n                .POST(HttpRequest.BodyPublishers.ofString(JsonFormat.printer().print(authData)))\n                .timeout(Duration.ofSeconds(5))\n                .build();\n            return httpClient.sendAsync(request, HttpResponse.BodyHandlers.ofString())\n                .thenApply(response -> {\n                    if (response.statusCode() == 200) {\n                        try {\n                            MQTT3AuthResult.Builder resultBuilder = MQTT3AuthResult.newBuilder();\n                            JsonFormat.parser()\n                                .ignoringUnknownFields()\n                                .merge(response.body(), resultBuilder);\n                            return resultBuilder.build();\n                        } catch (Throwable e) {\n                            return MQTT3AuthResult.newBuilder()\n                                .setReject(Reject.newBuilder()\n                                    .setCode(Reject.Code.Error)\n                                    .setReason(e.getMessage())\n                                    .build())\n                                .build();\n                        }\n                    } else {\n                        return MQTT3AuthResult.newBuilder()\n                            .setReject(Reject.newBuilder()\n                                .setCode(Reject.Code.Error)\n                                .setReason(\"Authenticate failed\")\n                                .build())\n                            .build();\n                    }\n                })\n                .exceptionally(e -> {\n                    System.out.println(\"Failed to call webhook: \" + e.getMessage());\n                    return null;\n                });\n        } catch (Throwable e) {\n            return CompletableFuture.completedFuture(MQTT3AuthResult.newBuilder()\n                .setReject(Reject.newBuilder()\n                    .setCode(Reject.Code.Error)\n                    .setReason(e.getMessage())\n                    .build())\n                .build());\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testAuth()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testAuth", "reference": "    @Test\n    public void testAuth() {\n        MQTT3AuthData authedUser = MQTT3AuthData.newBuilder()\n            .setUsername(\"authUser\")\n            .build();\n\n        MQTT3AuthData unauthUser = MQTT3AuthData.newBuilder()\n            .setUsername(\"unauthUser\")\n            .build();\n        testServer.addAuthedUser(authedUser.getUsername());\n        WebHookBasedAuthProvider provider = new WebHookBasedAuthProvider(testServer.getURI());\n        MQTT3AuthResult authResult = provider.auth(authedUser).join();\n        assertTrue(authResult.hasOk());\n\n        authResult = provider.auth(unauthUser).join();\n        assertFalse(authResult.hasOk());\n    }", "completions": ["  ```java\n    @Test\n    public void testAuth() {\n        // Set up mock webhook server\n        MockWebServer server = new MockWebServer();\n        server.start();\n        String webhookURI = server.url(\"/auth\").toString();\n\n        // Set up mock MQTT3AuthData\n        MQTT3AuthData authData = MQTT3AuthData.newBuilder()\n               .setClientId(\"testClient\")\n               .setUsername(\"testUser\")\n               .setPassword(\"testPassword\")\n               .build();\n\n        // Set up mock MQTT3AuthResult\n        MQTT3AuthResult expectedResult = MQTT3AuthResult.newBuilder()\n               .setSuccess(Success.newBuilder()\n                       .setCode(Success.Code.Success)\n                       .setReason(\"Authenticate success\")\n                       .build())\n               .build();\n\n        // Set up mock HTTP response\n        MockResponse response = new MockResponse()\n               .setResponseCode(200)\n               .setBody(JsonFormat.printer().print(expectedResult));\n        server.enqueue(response);\n\n        // Call the auth method with the mock MQTT3AuthData\n        CompletableFuture<MQTT3AuthResult> resultFuture = auth(authData);\n\n        // Verify the result\n        MQTT3AuthResult actualResult = resultFuture.get();\n        assertEquals(expectedResult, actualResult);\n\n        // Verify the HTTP request\n        RecordedRequest recordedRequest = server.takeRequest();\n        assertEquals(\"POST\", recordedRequest.getMethod());\n        assertEquals(webhookURI, recordedRequest.getPath());\n        assertEquals(\"application/json\", recordedRequest.getHeader(\"Content-Type\"));\n        assertEquals(JsonFormat.printer().print(authData), recordedRequest.getBody().readUtf8());\n\n        // Clean up\n        server.shutdown();\n    }\n```"]}
{"id": 99, "prompt": "\nYou are an expert Java programmer. You will be given some information and will generate a correct test case for the given function.\nYour response will only be java test function and without anything else.\n\n### focal method:\n```java\n    @VisibleForTesting\n    void validateRoleDuplicate(String name, String code, Long id) {\n        // 0. 超级管理员，不允许创建\n        if (RoleCodeEnum.isSuperAdmin(code)) {\n            throw exception(ROLE_ADMIN_CODE_ERROR, code);\n        }\n        // 1. 该 name 名字被其它角色所使用\n        RoleDO role = roleMapper.selectByName(name);\n        if (role != null && !role.getId().equals(id)) {\n            throw exception(ROLE_NAME_DUPLICATE, name);\n        }\n        // 2. 是否存在相同编码的角色\n        if (!StringUtils.hasText(code)) {\n            return;\n        }\n        // 该 code 编码被其它角色所使用\n        role = roleMapper.selectByCode(code);\n        if (role != null && !role.getId().equals(id)) {\n            throw exception(ROLE_CODE_DUPLICATE, code);\n        }\n    }\n```\n###test function signature:\n```java\n    @Test\n    public void testValidateRoleDuplicate_success()\n```\n### Answer: (use the provided format with backticks)\n", "name": "testValidateRoleDuplicate_success", "reference": "    @Test\n    public void testValidateRoleDuplicate_success() {\n        // 调用，不会抛异常\n        roleService.validateRoleDuplicate(randomString(), randomString(), null);\n    }", "completions": ["  ```\n@Test\npublic void testValidateRoleDuplicate_success() {\n    // Arrange\n    String name = \"test_name\";\n    String code = \"test_code\";\n    Long id = 1L;\n\n    // Act\n    validateRoleDuplicate(name, code, id);\n\n    // Assert\n    // No exception should be thrown\n}\n```"]}
