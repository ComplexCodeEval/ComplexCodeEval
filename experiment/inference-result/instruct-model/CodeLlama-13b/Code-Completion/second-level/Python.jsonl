{"id": 0, "name": "load_image_from_string", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport base64\nimport os\nfrom typing import Generator, List, Optional, Tuple, Union\n\nimport aiohttp\nimport cv2\nimport numpy as np\nimport requests\nimport supervision as sv\nfrom PIL import Image\n\nfrom inference_sdk.http.entities import ImagesReference\nfrom inference_sdk.http.errors import EncodingError, InvalidInputFormatError\nfrom inference_sdk.http.utils.encoding import (\n    bytes_to_opencv_image,\n    encode_base_64,\n    numpy_array_to_base64_jpeg,\n    pillow_image_to_base64_jpeg,\n)\nfrom inference_sdk.http.utils.pre_processing import (\n    resize_opencv_image,\n    resize_pillow_image,\n)\n\n\ndef load_stream_inference_input(\n    input_uri: str,\n    image_extensions: Optional[List[str]],\n) -> Generator[Tuple[Union[str, int], np.ndarray], None, None]:\n    if os.path.isdir(input_uri):\n        yield from load_directory_inference_input(\n            directory_path=input_uri, image_extensions=image_extensions\n        )\n    else:\n        yield from enumerate(sv.get_video_frames_generator(source_path=input_uri))\n\n\ndef load_directory_inference_input(\n    directory_path: str,\n    image_extensions: Optional[List[str]],\n) -> Generator[Tuple[Union[str, int], np.ndarray], None, None]:\n    for path in sv.list_files_with_extensions(\n        directory=directory_path,\n        extensions=image_extensions,\n    ):\n        yield path, cv2.imread(path.as_posix())\n\n\ndef load_static_inference_input(\n    inference_input: Union[ImagesReference, List[ImagesReference]],\n    max_height: Optional[int] = None,\n    max_width: Optional[int] = None,\n) -> List[Tuple[str, Optional[float]]]:\n    if issubclass(type(inference_input), list):\n        results = []\n        for element in inference_input:\n            results.extend(\n                load_static_inference_input(\n                    inference_input=element,\n                    max_height=max_height,\n                    max_width=max_width,\n                )\n            )\n        return results\n    if issubclass(type(inference_input), str):\n        return [\n            load_image_from_string(\n                reference=inference_input, max_height=max_height, max_width=max_width\n            )\n        ]\n    if issubclass(type(inference_input), np.ndarray):\n        image, scaling_factor = resize_opencv_image(\n            image=inference_input,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return [(numpy_array_to_base64_jpeg(image=image), scaling_factor)]\n    if issubclass(type(inference_input), Image.Image):\n        image, scaling_factor = resize_pillow_image(\n            image=inference_input,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return [(pillow_image_to_base64_jpeg(image=image), scaling_factor)]\n    raise InvalidInputFormatError(\n        f\"Unknown type of input ({inference_input.__class__.__name__}) submitted.\"\n    )\n\n\nasync def load_static_inference_input_async(\n    inference_input: Union[ImagesReference, List[ImagesReference]],\n    max_height: Optional[int] = None,\n    max_width: Optional[int] = None,\n) -> List[Tuple[str, Optional[float]]]:\n    if issubclass(type(inference_input), list):\n        results = []\n        for element in inference_input:\n            results.extend(\n                await load_static_inference_input_async(\n                    inference_input=element,\n                    max_height=max_height,\n                    max_width=max_width,\n                )\n            )\n        return results\n    if issubclass(type(inference_input), str):\n        return [\n            await load_image_from_string_async(\n                reference=inference_input, max_height=max_height, max_width=max_width\n            )\n        ]\n    if issubclass(type(inference_input), np.ndarray):\n        image, scaling_factor = resize_opencv_image(\n            image=inference_input,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return [(numpy_array_to_base64_jpeg(image=image), scaling_factor)]\n    if issubclass(type(inference_input), Image.Image):\n        image, scaling_factor = resize_pillow_image(\n            image=inference_input,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return [(pillow_image_to_base64_jpeg(image=image), scaling_factor)]\n    raise InvalidInputFormatError(\n        f\"Unknown type of input ({inference_input.__class__.__name__}) submitted.\"\n    )\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function loads an image from a given reference, which can be a URL, a local file path, or a base64 encoded string.\n\nArgs:\n    reference (str): The reference to the image. It can be a URL, a local file path, or a base64 encoded string.\n    max_height (Optional[int]): The maximum height to which the image should be resized. If None, the image will not be resized in height.\n    max_width (Optional[int]): The maximum width to which the image should be resized. If None, the image will not be resized in width.\n\nReturns:\n    Tuple[str, Optional[float]]: A tuple containing the base64 encoded string of the image and the scaling factor used to resize the image. If the image was not resized, the scaling factor will be None.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef load_image_from_string(\n    reference: str,\n    max_height: Optional[int] = None,\n    max_width: Optional[int] = None,\n) -> Tuple[str, Optional[float]]:\n    if uri_is_http_link(uri=reference):\n        return load_image_from_url(\n            url=reference, max_height=max_height, max_width=max_width\n        )\n    if os.path.exists(reference):\n        if max_height is None or max_width is None:\n            with open(reference, \"rb\") as f:\n                img_bytes = f.read()\n            img_base64_str = encode_base_64(payload=img_bytes)\n            return img_base64_str, None\n        local_image = cv2.imread(reference)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        if local_image is None:\n            raise EncodingError(f\"Could not load image from {reference}\")\n        local_image, scaling_factor = resize_opencv_image(\n            image=local_image,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return numpy_array_to_base64_jpeg(image=local_image), scaling_factor\n    if max_height is not None and max_width is not None:\n        image_bytes = base64.b64decode(reference)\n        image = bytes_to_opencv_image(payload=image_bytes)\n        image, scaling_factor = resize_opencv_image(\n            image=image,\n            max_height=max_height,\n            max_width=max_width,\n        )\n        return numpy_array_to_base64_jpeg(image=image), scaling_factor\n    return reference, None", "completions": ["  \n[PYTHON]\ndef load_image_from_string(\n    reference: str,\n    max_height: Optional[int] = None,\n    max_width: Optional[int] = None,\n) -> Tuple[str, Optional[float]]:\n    if uri_is_http_link(uri=reference):\n        return load_image_from_url(\n            url=reference, max_height=max_height, max_width=max_width\n        )\n    if os.path.exists(reference):\n        if max_height is None or max_width is None:\n            with open(reference, \"rb\") as f:\n                img_bytes = f.read()\n            img_base64_str = encode_base_64(payload=img_bytes)\n            return img_base64_str, None\n        local_image = cv2.imread(reference)\n        resized_image, scaling_factor = resize_opencv_image(\n            image=local_image, max_height=max_height, max_width=max_width\n        )\n        resized_image_base64_str = numpy_array_to_base64_jpeg(image=resized_image)\n        return resized_image_base64_str, scaling_factor\n[/PYTHON]\n"]}
{"id": 1, "name": "open_lm_config_to_gpt2_config", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport math\nimport re\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn.functional as F\nfrom transformers import AutoConfig, GPT2Config\n\n\ndef remap_state_dict_hf_open_lm(state_dict, config):\n    def key_mapping_layers(key):\n        return re.sub(r\"^model.\", \"\", key)\n\n    state_dict = OrderedDict((key_mapping_layers(k), v) for k, v in state_dict.items())\n\n    # Word embedding\n    def key_mapping_emb(key):\n        return re.sub(r\"^tok_embeddings.\", \"embeddings.\", key)\n\n    state_dict = OrderedDict((key_mapping_emb(k), v) for k, v in state_dict.items())\n\n    def key_mapping_lm_head(key):\n        return re.sub(r\"^output.\", \"lm_head.\", key)\n\n    state_dict = OrderedDict((key_mapping_lm_head(k), v) for k, v in state_dict.items())\n\n    word_embeddings = state_dict.pop(\"embeddings.weight\")\n    # It's possible that vocab_size is padded to be a multiple of 8, for example.\n    pad_vocab_size_multiple = getattr(config, \"pad_vocab_size_multiple\", 1)\n    vocab_size = math.ceil(config.vocab_size / pad_vocab_size_multiple) * pad_vocab_size_multiple\n    state_dict[\"embeddings.weight\"] = F.pad(word_embeddings, (0, 0, 0, vocab_size - word_embeddings.shape[0]))\n    if getattr(config, \"tie_word_embeddings\"):\n        state_dict[\"lm_head.weight\"] = state_dict[\"embeddings.weight\"]\n    else:\n        output_embeddings = state_dict.pop(\"lm_head.weight\")\n        # It's possible that vocab_size is padded to be a multiple of 8, for example.\n        state_dict[\"lm_head.weight\"] = F.pad(output_embeddings, (0, 0, 0, vocab_size - output_embeddings.shape[0]))\n\n    # LayerNorm\n    def key_mapping_ln(key):\n        key = re.sub(r\"^norm.\", r\"ln_f.\", key)\n        key = re.sub(r\"^layers.(\\d+).attention_norm.\", r\"layers.\\1.norm1.\", key)\n        key = re.sub(\n            r\"^layers.(\\d+).ffn_norm.\",\n            r\"layers.\\1.norm2.\",\n            key,\n        )\n        return key\n\n    state_dict = OrderedDict((key_mapping_ln(k), v) for k, v in state_dict.items())\n\n    # MLP\n    def key_mapping_mlp(key):\n        key = re.sub(r\"^layers.(\\d+).feed_forward.w12.\", r\"layers.\\1.mlp.fc1.\", key)\n        key = re.sub(r\"^layers.(\\d+).feed_forward.w3.\", r\"layers.\\1.mlp.fc2.\", key)\n        return key\n\n    state_dict = OrderedDict((key_mapping_mlp(k), v) for k, v in state_dict.items())\n\n    # ordering of weight makes difference for gatedmlp\n    for layer in range(config.n_layer):\n        fc1 = state_dict.pop(f\"layers.{layer}.mlp.fc1.weight\")\n        w1, w2 = fc1.chunk(2, dim=0)\n        fc1 = torch.cat([w2, w1], dim=0)\n        state_dict[f\"layers.{layer}.mlp.fc1.weight\"] = fc1\n\n    state_dict = {k: v for k, v in state_dict.items() if \"inv_freq\" not in k}\n\n    def key_mapping_attn(key):\n        key = re.sub(\n            r\"^layers.(\\d+).attention.dense.\",\n            r\"layers.\\1.attn.out_proj.\",\n            key,\n        )\n        key = re.sub(\n            r\"^layers.(\\d+).attention.rotary_emb.\",\n            r\"layers.\\1.attn.rotary_emb.\",\n            key,\n        )\n        key = re.sub(\n            r\"^layers.(\\d+).attention.in_proj.\",\n            r\"layers.\\1.attn.Wqkv.\",\n            key,\n        )\n        key = re.sub(\n            r\"^layers.(\\d+).attention.out_proj.\",\n            r\"layers.\\1.attn.out_proj.\",\n            key,\n        )\n        return key\n\n    state_dict.pop(\"lm_head.weight\")\n\n    state_dict = OrderedDict((key_mapping_attn(k), v) for k, v in state_dict.items())\n\n    return state_dict\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function converts an OpenLM configuration to a GPT2 configuration.\n\nArgs:\n    open_lm_config (AutoConfig): The configuration of the OpenLM model.\n\nReturns:\n    GPT2Config: The configuration of the GPT2 model.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef open_lm_config_to_gpt2_config(open_lm_config: AutoConfig) -> GPT2Config:\n    # NOTE: rotary is applied to the head dimension instead of the sequence dimension (accident by open_lm team)\n    return GPT2Config(\n        vocab_size=open_lm_config.vocab_size,\n        n_positions=0,  # No absolute position embedding\n        n_embd=open_lm_config.hidden_dim,\n        n_layer=open_lm_config.n_layers,\n        n_head=open_lm_config.n_heads,\n        n_inner=256 * ((int(2 * 4 * open_lm_config.hidden_dim / 3) + 256 - 1) // 256),\n        activation_function=\"swiglu\",\n        resid_pdrop=0.0,  # No dropout\n        embd_pdrop=0.0,\n        attn_pdrop=0.0,\n        layer_norm_epsilon=1e-5,\n        # NOTE: this isn't correct, should look at code as it's scaled by depth according to: https://arxiv.org/abs/1908.11365\n        initializer_range=0.02,\n        bos_token_id=0,\n        eos_token_id=0,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        # These are new arguments not in the original GPT2Config\n        prenorm=True,\n        parallel_block=False,\n        parallel_block_tied_norm=False,\n        rotary_emb_fraction=1,\n        tie_word_embeddings=open_lm_config.weight_tying,\n        fused_dropout_add_ln=True,\n        fused_bias_fc=True,\n        use_flash_attn=True,\n        qkv_proj_bias=getattr(open_lm_config, \"qkv_proj_bias\", False),\n        rotary_emb_base=10000,\n        rotary_emb_scale_base=getattr(open_lm_config, \"rotary_emb_scale_base\", None),\n        rotary_emb_interleaved=getattr(open_lm_config, \"rotary_emb_interleaved\", False),\n        rotary_head_dim=getattr(open_lm_config, \"rotary_old\", False),\n        mlp_fc1_bias=getattr(open_lm_config, \"mlp_fc1_bias\", False),\n        mlp_fc2_bias=getattr(open_lm_config, \"mlp_fc2_bias\", False),\n        use_rms_norm=False,\n        causal=True,\n    )", "completions": ["  \n[PYTHON]\ndef open_lm_config_to_gpt2_config(open_lm_config: AutoConfig) -> GPT2Config:\n    # NOTE: rotary is applied to the head dimension instead of the sequence dimension (accident by open_lm team)\n    return GPT2Config(\n        vocab_size=open_lm_config.vocab_size,\n        n_positions=0,  # No absolute position embedding\n        n_embd=open_lm_config.hidden_dim,\n        n_layer=open_lm_config.n_layers,\n        n_head=open_lm_config.n_heads,\n        n_inner=256 * ((int(2 * 4 * open_lm_config.hidden_dim / 3) + 256 - 1) // 256),\n        activation_function=\"swiglu\",\n        resid_pdrop=0.0,  # No dropout\n        embd_pdrop=0.0,\n        attn_pdrop=0.0,\n        layer_norm_epsilon=1e-5,\n        # NOTE: this isn't correct, should look at code as it's scaled by depth according to: https://arxiv.org/abs/1908.11365\n        initializer_range=0.02,\n        bos_token_id=0,\n        eos_token_id=0,\n    )\n[/PYTHON]\n"]}
{"id": 3, "name": "get_enemy_pos", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport math\nimport os\nimport time\nfrom functools import lru_cache\nfrom typing import Set, Optional, List\n\nimport cv2\nimport numpy as np\nfrom cv2.typing import MatLike\n\nfrom basic import Point, os_utils, cal_utils\nfrom basic.img import cv2_utils, MatchResultList, MatchResult\nfrom basic.log_utils import log\nfrom sr import const\nfrom sr.config.game_config import MiniMapPos\nfrom sr.image import ImageMatcher, TemplateImage\nfrom sr.image.sceenshot import MiniMapInfo, mini_map_angle_alas\nfrom sr.performance_recorder import record_performance\n\n\ndef cal_little_map_pos(screen: MatLike) -> MiniMapPos:\n    \"\"\"\n    计算小地图的坐标\n    通过截取屏幕左上方部分 找出最大的圆圈 就是小地图。\n    部分场景无法准确识别 所以使用一次校准后续读取配置使用。\n    最容易匹配地点在【空间站黑塔】【基座舱段】【接待中心】传送点\n    :param screen: 屏幕截图\n    \"\"\"\n    # 左上角部分\n    x, y = 0, 0\n    x2, y2 = 340, 380\n    image = screen[y:y2, x:x2]\n\n    # 对图像进行预处理\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.2, 100, minRadius=80, maxRadius=100)  # 小地图大概的圆半径\n\n    # 如果找到了圆\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        tx, ty, tr = 0, 0, 0\n\n        # 保留半径最大的圆\n        for circle in circles[0, :]:\n            if circle[2] > tr:\n                tx, ty, tr = circle[0], circle[1], circle[2]\n\n        mm_pos = MiniMapPos(tx, ty, tr)\n        log.debug('计算小地图所在坐标为 %s', mm_pos)\n        return mm_pos\n    else:\n        log.error('无法找到小地图的圆')\n\n\ndef cut_mini_map(screen: MatLike, mm_pos: MiniMapPos) -> MatLike:\n    \"\"\"\n    从整个游戏窗口截图中 裁剪出小地图部分\n    :param screen: 屏幕截图\n    :param mm_pos: 小地图位置的配置\n    :return:\n    \"\"\"\n    return screen[mm_pos.ly:mm_pos.ry, mm_pos.lx:mm_pos.rx]\n\n\ndef preheat():\n    \"\"\"\n    预热缓存\n    :return:\n    \"\"\"\n    for i in range(93, 100):  # 不同时期截图大小可能不一致\n        mini_map_angle_alas.RotationRemapData(i * 2)\n\n    for i in range(int(360 // 1.875)):\n        get_radio_to_del(i * 1.875)\n\n\ndef extract_arrow(mini_map: MatLike):\n    \"\"\"\n    提取小箭头部分 范围越小越精准\n    :param mini_map: 小地图\n    :return: 小箭头\n    \"\"\"\n    return cv2_utils.color_similarity_2d(mini_map, const.COLOR_ARROW_BGR)\n\n\ndef get_arrow_mask(mm: MatLike):\n    \"\"\"\n    获取小地图的小箭头掩码\n    :param mm: 小地图\n    :return: 中心区域的掩码 和 整张图的掩码\n    \"\"\"\n    w, h = mm.shape[1], mm.shape[0]\n    cx, cy = w // 2, h // 2\n    d = const.TEMPLATE_ARROW_LEN\n    r = const.TEMPLATE_ARROW_R\n    center = mm[cy - r:cy + r, cx - r:cx + r]\n    arrow = extract_arrow(center)\n    _, mask = cv2.threshold(arrow, 180, 255, cv2.THRESH_BINARY)\n    # 做一个连通性检测 小于50个连通的认为是噪点\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n    large_components = []\n    for label in range(1, num_labels):\n        if stats[label, cv2.CC_STAT_AREA] < 50:\n            large_components.append(label)\n    for label in large_components:\n        mask[labels == label] = 0\n\n    whole_mask = np.zeros((h,w), dtype=np.uint8)\n    whole_mask[cy-r:cy+r, cx-r:cx+r] = mask\n    # 黑色边缘线条采集不到 稍微膨胀一下\n    kernel = np.ones((5, 5), np.uint8)\n    cv2.dilate(src=whole_mask, dst=whole_mask, kernel=kernel, iterations=1)\n    arrow_mask, _ = cv2_utils.convert_to_standard(mask, mask, width=d, height=d)\n    return arrow_mask, whole_mask\n\n\ndef get_angle_from_arrow(arrow: MatLike,\n                         im: ImageMatcher,\n                         show: bool = False) -> int:\n    \"\"\"\n    用小地图上的箭头 计算当前方向 正右方向为0度 逆时针旋转为正度数\n    先匹配1度的图 再匹配0.1度的图\n    实验结果误差较大\n    :param arrow: 已经提取好的白色的箭头\n    :param im: 图片匹配器\n    :param show: 显示结果\n    :return: 角度 正右方向为0度 顺时针旋转为正度数\n    \"\"\"\n    rough_template = im.get_template('arrow_rough').mask\n    result = im.match_image(rough_template, arrow, threshold=0.85)\n    if len(result) == 0:\n        return None\n\n    if show:\n        cv2_utils.show_image(arrow, win_name=\"arrow\")\n        cv2_utils.show_image(rough_template, result.max, win_name=\"rough_template_match\")\n\n    d = const.TEMPLATE_ARROW_LEN_PLUS\n\n    row = result.max.center.y // d\n    col = result.max.center.x // d\n    rough_angle = (row * 11 + col) * 3\n\n    rough_arrow = cv2_utils.image_rotate(arrow, -rough_angle)\n    precise_template = im.get_template('arrow_precise').mask\n    result2 = im.match_image(precise_template, rough_arrow, threshold=0.85)\n\n    if show:\n        cv2_utils.show_image(precise_template, result2.max, win_name=\"precise_template_match\")\n\n    if len(result2) == 0:\n        precise_angle = rough_angle\n    else:\n        row = result2.max.center.y // d\n        col = result2.max.center.x // d\n        precise_delta_angle = (row * 11 + col - 60) / 10.0\n        precise_angle = rough_angle + precise_delta_angle\n\n    if precise_angle is not None and precise_angle <= 0:\n        precise_angle += 360\n    if precise_angle is not None and precise_angle > 360:\n        precise_angle -= 360\n    return 360 - precise_angle\n\n\ndef analyse_arrow_and_angle(mini_map: MatLike):\n    \"\"\"\n    在小地图上获取小箭头掩码和角度\n    没有性能问题\n    :param mini_map: 小地图图片\n    :return:\n    \"\"\"\n    center_arrow_mask, arrow_mask = get_arrow_mask(mini_map)\n    angle = mini_map_angle_alas.calculate(mini_map)\n    return center_arrow_mask, arrow_mask, angle\n\n\ndef analyse_angle(mini_map: MatLike) -> float:\n    return mini_map_angle_alas.calculate(mini_map)\n\n\n@record_performance\ndef init_sp_mask_by_feature_match(mm_info: MiniMapInfo, im: ImageMatcher,\n                                  sp_types: Set = None,\n                                  show: bool = False):\n    \"\"\"\n    在小地图上找到特殊点 使用特征匹配 每个模板最多只能找到一个\n    特征点提取匹配、画掩码耗时都很少 主要花费在读模板 真实运行有缓存就没问题\n    :param mm_info: 小地图信息\n    :param im: 图片匹配器\n    :param sp_types: 限定种类的特殊点\n    :param show: 是否展示结果\n    :return:\n    \"\"\"\n    if mm_info.sp_mask is not None:\n        return\n\n    sp_mask = np.zeros_like(mm_info.circle_mask)\n    sp_match_result = {}\n\n    if sp_types is None or len(sp_types) == 0:  # 没有特殊点\n        mm_info.sp_mask = sp_mask\n        mm_info.sp_result = sp_match_result\n        return\n\n    source = mm_info.origin_del_radio\n    source_mask = mm_info.circle_mask\n    source_kps, source_desc = cv2_utils.feature_detect_and_compute(source, mask=source_mask)\n    for prefix in ['mm_tp', 'mm_sp', 'mm_boss', 'mm_sub']:\n        for i in range(100):\n            if i == 0:\n                continue\n\n            template_id = '%s_%02d' % (prefix, i)\n            t: TemplateImage = im.get_template(template_id)\n            if t is None:\n                break\n            if sp_types is not None and template_id not in sp_types:\n                continue\n\n            match_result_list = MatchResultList()\n            template = t.origin\n            template_mask = t.mask\n\n            template_kps, template_desc = t.kps, t.desc\n\n            good_matches, offset_x, offset_y, scale = cv2_utils.feature_match(\n                source_kps, source_desc,\n                template_kps, template_desc,\n                source_mask=source_mask)\n\n            if offset_x is not None:\n                mr = MatchResult(1, offset_x, offset_y, template.shape[1], template.shape[0], template_scale=scale)  #\n                match_result_list.append(mr, auto_merge=False)\n                sp_match_result[template_id] = match_result_list\n\n                # 缩放后的宽度和高度\n                sw = int(template.shape[1] * scale)\n                sh = int(template.shape[0] * scale)\n                # one_sp_mask = cv2.resize(template_mask, (sh, sw))\n                one_sp_mask = np.zeros((sh, sw))\n\n                rect1, rect2 = cv2_utils.get_overlap_rect(sp_mask, one_sp_mask, mr.x, mr.y)\n                sx_start, sy_start, sx_end, sy_end = rect1\n                tx_start, ty_start, tx_end, ty_end = rect2\n                # sp_mask[sy_start:sy_end, sx_start:sx_end] = cv2.bitwise_or(\n                #     sp_mask[sy_start:sy_end, sx_start:sx_end],\n                #     one_sp_mask[ty_start:ty_end, tx_start:tx_end]\n                # )\n                sp_mask[sy_start:sy_end, sx_start:sx_end] = 255\n\n            if show:\n                cv2_utils.show_image(source, win_name='source')\n                cv2_utils.show_image(source_mask, win_name='source_mask')\n                source_with_keypoints = cv2.drawKeypoints(source, source_kps, None)\n                cv2_utils.show_image(source_with_keypoints, win_name='source_with_keypoints_%s' % template_id)\n                template_with_keypoints = cv2.drawKeypoints(template, template_kps, None)\n                cv2_utils.show_image(\n                    cv2.bitwise_and(template_with_keypoints, template_with_keypoints, mask=template_mask),\n                    win_name='template_with_keypoints_%s' % template_id)\n                all_result = cv2.drawMatches(template, template_kps, source, source_kps, good_matches, None, flags=2)\n                cv2_utils.show_image(all_result, win_name='all_match_%s' % template_id)\n\n                if offset_x is not None:\n                    cv2_utils.show_overlap(source, template, offset_x, offset_y, template_scale=scale, win_name='overlap_%s' % template_id)\n                cv2.waitKey(0)\n                cv2.destroyAllWindows()\n\n    mm_info.sp_mask = sp_mask\n    mm_info.sp_result = sp_match_result\n\n\ndef is_under_attack(mm: MatLike,\n                    strict: bool = False,\n                    show: bool = False) -> bool:\n    \"\"\"\n    根据小地图边缘 判断是否被锁定\n    红色色道应该有一个圆\n    约1ms\n    :param mm: 小地图截图\n    :param strict: 是否严格判断 只有红色的框认为是被锁定\n    :param show: debug用 显示中间结果图片\n    :return: 是否被锁定\n    \"\"\"\n    w, h = mm.shape[1], mm.shape[0]\n    cx, cy = w // 2, h // 2\n    r = (cx + cy) // 2\n\n    circle_mask = np.zeros(mm.shape[:2], dtype=np.uint8)\n    cv2.circle(circle_mask, (cx, cy), r, 255, 3)\n\n    circle_part = cv2.bitwise_and(mm, mm, mask=circle_mask)\n\n    # 提取红色部分\n    lower_color = np.array([0, 0, 200], dtype=np.uint8)\n    upper_color = np.array([100, 100, 255], dtype=np.uint8)\n    red = cv2.inRange(circle_part, lower_color, upper_color)\n\n    if strict:\n        mask = red\n    else:\n        # 提取橙色部分\n        lower_color = np.array([0, 150, 200], dtype=np.uint8)\n        upper_color = np.array([100, 180, 255], dtype=np.uint8)\n        orange = cv2.inRange(circle_part, lower_color, upper_color)\n\n        mask = cv2.bitwise_or(red, orange)\n\n    circles = cv2.HoughCircles(mask, cv2.HOUGH_GRADIENT, 0.3, 100, param1=10, param2=10,\n                               minRadius=r - 10, maxRadius=r + 10)\n    find: bool = circles is not None\n\n    if show:\n        cv2_utils.show_image(circle_part, win_name='circle_part')\n        cv2_utils.show_image(red, win_name='red')\n        if not strict:\n            cv2_utils.show_image(orange, win_name='orange')\n        cv2_utils.show_image(mask, win_name='mask')\n        find_circle = np.zeros(mm.shape[:2], dtype=np.uint8)\n        if circles is not None:\n            # 将检测到的圆形绘制在原始图像上\n            circles = np.round(circles[0, :]).astype(\"int\")\n            for (x, y, r) in circles:\n                cv2.circle(find_circle, (x, y), r, 255, 1)\n        cv2_utils.show_image(find_circle, win_name='find_circle')\n        cv2.waitKey(0)\n\n    return find\n\n\nmini_map_radio_to_del: Optional[MatLike] = None\n\n\n@lru_cache\ndef get_radio_to_del(angle: Optional[float] = None):\n    \"\"\"\n    根据人物朝向 获取对应的雷达区域颜色\n    :param angle: 人物朝向\n    :return:\n    \"\"\"\n    global mini_map_radio_to_del\n    if mini_map_radio_to_del is None:\n        path = os.path.join(os_utils.get_path_under_work_dir('images', 'template', 'mini_map_radio'), 'origin.png')\n        mini_map_radio_to_del = cv2_utils.read_image(path)\n    if angle is not None:\n        return cv2_utils.image_rotate(mini_map_radio_to_del, 360 - angle)\n    else:\n        return mini_map_radio_to_del\n\n\n@record_performance\ndef analyse_mini_map(origin: MatLike) -> MiniMapInfo:\n    \"\"\"\n    预处理 从小地图中提取出所有需要的信息\n    :param origin: 小地图 左上角的一个正方形区域\n    :return:\n    \"\"\"\n    info = MiniMapInfo()\n    info.origin = origin\n    info.center_arrow_mask, info.arrow_mask, info.angle = analyse_arrow_and_angle(origin)\n    info.origin_del_radio = remove_radio(info.origin, get_radio_to_del(info.angle))\n    init_circle_mask(info)\n\n    return info\n\n\ndef init_circle_mask(mm_info: MiniMapInfo):\n    h, w = mm_info.arrow_mask.shape[1], mm_info.arrow_mask.shape[0]\n    cx, cy = w // 2, h // 2\n\n    mm_info.circle_mask = np.zeros_like(mm_info.arrow_mask)\n    cv2.circle(mm_info.circle_mask, (cx, cy), h // 2 - 5, 255, -1)  # 忽略一点圆的边缘\n\n\ndef remove_radio(mm: MatLike, radio_to_del: MatLike) -> MatLike:\n    origin = mm.copy()\n    if radio_to_del is not None:\n        radius = radio_to_del.shape[0] // 2\n        d = radio_to_del.shape[0]\n\n        x1 = origin.shape[1] // 2 - radius\n        x2 = x1 + d\n        y1 = origin.shape[1] // 2 - radius\n        y2 = y1 + d\n\n        overlap = np.zeros_like(radio_to_del, dtype=np.uint16)\n        overlap[:, :] = origin[y1:y2, x1:x2]\n        overlap[:, :] -= radio_to_del\n        overlap[np.where(origin[y1:y2, x1:x2] < radio_to_del)] = 0\n        origin[y1:y2, x1:x2] = overlap.astype(dtype=np.uint8)\n\n    # cv2_utils.show_image(origin, win_name='origin')\n    return origin\n\n\n@record_performance\ndef init_road_mask_for_world_patrol(mm_info: MiniMapInfo, another_floor: bool = False):\n    \"\"\"\n    获取道路掩码 用于原图的模板匹配\n    不考虑特殊点\n    :param mm_info: 小地图信息\n    :param another_floor: 可能有另一层的地图\n    :return:\n    \"\"\"\n    if mm_info.road_mask is not None:\n        return\n\n    mm_del_radio = mm_info.origin_del_radio\n    b, g, r = cv2.split(mm_del_radio)\n\n    l = 45\n    u = 70  # 背景色 正常是55~60附近 太亮的时候会到达这个值 或者其它楼层也会达到这个值\n    lower_color = np.array([l, l, l], dtype=np.uint8)\n    upper_color = np.array([u, u, u], dtype=np.uint8)\n    road_mask_1 = cv2.inRange(mm_del_radio, lower_color, upper_color)  # 这是粗略的道路掩码\n    # cv2_utils.show_image(road_mask_1, win_name='road_mask_1')\n\n    max_rgb = np.max(mm_del_radio, axis=2)\n    min_rgb = np.min(mm_del_radio, axis=2)\n    road_mask_cf = np.zeros(road_mask_1.shape, dtype=np.uint8)\n    road_mask_cf[(max_rgb - min_rgb) <= 1] = 255  # rgb颜色差不超过1 当前层的道路就是这个颜色\n    # cv2_utils.show_image(road_mask_cf, win_name='road_mask_cf')\n    b_g = None\n    if another_floor:  # 多层地图时 另一层的颜色是递进的 R<=G<=B 且差值在2以内\n        b_g = b - g\n        g_r = g - r\n        road_mask_af = np.zeros(road_mask_1.shape, dtype=np.uint8)\n        road_mask_af[(b_g >= 0) & (b_g <= 2) & (g_r >= 0) & (g_r <= 2)] = 255\n        # cv2_utils.show_image(road_mask_af, win_name='road_mask_af')\n\n        road_mask_floor = cv2.bitwise_or(road_mask_cf, road_mask_af)\n    else:\n        road_mask_floor = road_mask_cf\n\n    road_mask_2 = cv2.bitwise_and(road_mask_1, road_mask_floor)  # 不同楼层的地图\n    # cv2_utils.show_image(road_mask_2, win_name='road_mask_2')\n\n    if b_g is None:\n        b_g = b - g\n    # 算敌人的掩码图\n    lower_color = np.array([45, 45, 80], dtype=np.uint8)\n    upper_color = np.array([70, 70, 255], dtype=np.uint8)\n    enemy_mask_1 = cv2.inRange(mm_del_radio, lower_color, upper_color)  # 这是粗略的敌人图\n    enemy_mask_2 = np.zeros(road_mask_1.shape, dtype=np.uint8)\n    enemy_mask_2[(b_g <= 2) | (b_g >= -2)] = 255  # 敌人的雷达图 g 约等于 b\n    enemy_mask = cv2.bitwise_and(enemy_mask_1, enemy_mask_2)\n    # cv2_utils.show_image(enemy_mask, win_name='enemy_mask')\n\n    mm_info.road_mask = cv2.bitwise_or(road_mask_2, enemy_mask)\n    mm_info.road_mask = cv2.bitwise_and(mm_info.road_mask, mm_info.circle_mask)  # 只考虑圆形内部分\n\n    lower_color = np.array([160, 160, 160], dtype=np.uint8)\n    upper_color = np.array([210, 210, 210], dtype=np.uint8)\n    edge_mask_rough = cv2.inRange(mm_del_radio, lower_color, upper_color)  # 这是粗略的边缘掩码\n    edge_mask = cv2.bitwise_and(edge_mask_rough, road_mask_cf)  # 三色差不超过1\n    mm_info.road_mask_with_edge = cv2.bitwise_or(mm_info.road_mask, edge_mask)\n\n\n@record_performance\ndef init_road_mask_for_sim_uni(mm_info: MiniMapInfo):\n    \"\"\"\n    获取道路掩码 模拟宇宙专用\n    不需要考虑特殊点 以及其它楼层\n    :param mm_info: 小地图信息\n    :return:\n    \"\"\"\n    init_road_mask_for_world_patrol(mm_info, another_floor=False)\n\n\ndef get_mini_map_radio_mask(mm: MatLike, angle: float = None, another_floor: bool = True):\n    \"\"\"\n    小地图中心雷达区的掩码\n    :param mm: 小地图图片\n    :param angle: 当前人物角度\n    :param another_floor: 是否有其它楼层\n    :return:\n    \"\"\"\n    radio_mask = np.zeros(mm.shape[:2], dtype=np.uint8)  # 圈出雷达区的掩码\n    center = (mm.shape[1] // 2, mm.shape[0] // 2)  # 中心点坐标\n    radius = 55  # 扇形半径 这个半径内\n    color = 255  # 扇形颜色（BGR格式）\n    thickness = -1  # 扇形边框线宽度（负值表示填充扇形）\n    if angle is not None:  # 知道当前角度的话 画扇形\n        start_angle = angle - 45  # 扇形起始角度（以度为单位）\n        end_angle = angle + 45  # 扇形结束角度（以度为单位）\n        cv2.ellipse(radio_mask, center, (radius, radius), 0, start_angle, end_angle, color, thickness)  # 画扇形\n    else:  # 圆形兜底\n        cv2.circle(radio_mask, center, radius, color, thickness)  # 画扇形\n    radio_map = cv2.bitwise_and(mm, mm, mask=radio_mask)\n    # cv2_utils.show_image(radio_map, win_name='radio_map')\n    # 当前层数的\n    lower_color = np.array([70, 70, 45], dtype=np.uint8)\n    upper_color = np.array([130, 130, 65], dtype=np.uint8)\n    road_radio_mask_1 = cv2.inRange(radio_map, lower_color, upper_color)\n\n    if another_floor:\n        # 其他层数的\n        lower_color = np.array([70, 70, 70], dtype=np.uint8)\n        upper_color = np.array([130, 130, 85], dtype=np.uint8)\n        road_radio_mask_2 = cv2.inRange(radio_map, lower_color, upper_color)\n\n        road_radio_mask = cv2.bitwise_or(road_radio_mask_1, road_radio_mask_2)\n    else:\n        road_radio_mask = road_radio_mask_1\n\n    return road_radio_mask\n\n\ndef merge_all_map_mask(gray_image: MatLike,\n                       road_mask, sp_mask):\n    \"\"\"\n    :param gray_image:\n    :param road_mask:\n    :param sp_mask:\n    :return:\n    \"\"\"\n    usage = gray_image.copy()\n\n    # 稍微膨胀一下\n    kernel = np.ones((5, 5), np.uint8)\n    expand_sp_mask = cv2.dilate(sp_mask, kernel, iterations=1)\n\n    all_mask = cv2.bitwise_or(road_mask, expand_sp_mask)\n    usage[np.where(all_mask == 0)] = const.COLOR_WHITE_GRAY\n    usage[np.where(road_mask == 255)] = const.COLOR_MAP_ROAD_GRAY\n    return usage, all_mask\n\n\ndef get_edge_mask(origin: MatLike, road_mask: MatLike, another_floor: bool = False):\n    \"\"\"\n    小地图道路边缘掩码 暂时不需要\n    :param origin: 小地图图片\n    :param road_mask: 道路掩码\n    :param another_floor: 是否有另一层\n    :return:\n    \"\"\"\n    lower_color = np.array([170, 170, 170], dtype=np.uint8)\n    upper_color = np.array([230, 230, 230], dtype=np.uint8)\n    edge_mask_1 = cv2.inRange(origin, lower_color, upper_color)\n    if another_floor:\n        lower_color = np.array([100, 100, 100], dtype=np.uint8)\n        upper_color = np.array([130, 130, 130], dtype=np.uint8)\n        edge_mask_2 = cv2.inRange(origin, lower_color, upper_color)\n\n        color_edge_mask = cv2.bitwise_or(edge_mask_1, edge_mask_2)\n    else:\n        color_edge_mask = edge_mask_1\n    # 稍微膨胀一下\n    color_edge_mask = cv2.dilate(color_edge_mask, np.ones((5, 5), np.uint8), iterations=1)\n\n    road_edge_mask = cv2.Canny(road_mask, threshold1=200, threshold2=230)\n    color_edge_mask = cv2.dilate(color_edge_mask, np.ones((2, 2), np.uint8), iterations=1)\n    cv2_utils.show_image(color_edge_mask, win_name='color_edge_mask')\n    cv2_utils.show_image(road_edge_mask, win_name='road_edge_mask')\n\n    final_edge_mask = cv2.bitwise_and(color_edge_mask, road_edge_mask)\n\n    return final_edge_mask\n\n\ndef find_one_enemy_pos(mm: Optional[MatLike] = None,\n                       mm_del_radio: Optional[MatLike] = None) -> Optional[Point]:\n    \"\"\"\n    在小地图上找到敌人红点的位置\n    目前只能处理一个红点的情况\n    :param mm: 小地图图片 与下二选一\n    :param mm_del_radio: 去除雷达的小地图图片 与上二选一\n    :param im: 图片匹配器\n    :return: 红点位置\n    \"\"\"\n    if mm is None and mm_del_radio is None:\n        return None\n    if mm_del_radio is None:\n        angle = analyse_angle(mm)\n        to_del = get_radio_to_del(angle)\n        mm_del_radio = remove_radio(mm, to_del)\n\n    lower_color = np.array([0, 0, 150], dtype=np.uint8)\n    upper_color = np.array([60, 60, 255], dtype=np.uint8)\n    red_part = cv2.inRange(mm_del_radio, lower_color, upper_color)\n    # cv2_utils.show_image(red_part, win_name='red_part')\n\n    # 膨胀一下找连通块\n    to_check = cv2_utils.dilate(red_part, 5)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(to_check, connectivity=8)\n\n    if num_labels <= 1:  # 没有连通块 走到敌人附近了\n        return None\n\n    # 找到最大的连通区域\n    largest_label = 1\n    max_area = stats[largest_label, cv2.CC_STAT_AREA]\n    for label in range(2, num_labels):\n        area = stats[label, cv2.CC_STAT_AREA]\n        if area > max_area:\n            max_area = area\n            largest_label = label\n\n    # 找到最大连通区域的中心点\n    center_x = int(centroids[largest_label, 0])\n    center_y = int(centroids[largest_label, 1])\n\n    return Point(center_x, center_y)\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to get the enemy positions from a given MiniMapInfo object.\n\nArgs:\n    mm_info (MiniMapInfo): An object containing information about the mini map.\n\nReturns:\n    List[Point]: A list of Point objects representing the positions of the enemies.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef get_enemy_pos(mm_info: MiniMapInfo) -> List[Point]:\n    enemy_mask = get_enemy_mask(mm_info)\n    # cv2_utils.show_image(enemy_mask, win_name='get_enemy_pos', wait=0)\n    cx = mm_info.origin.shape[1] // 2\n    cy = mm_info.origin.shape[0] // 2\n\n    # 膨胀一下找连通块\n    to_check = cv2_utils.dilate(enemy_mask, 5)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(to_check, connectivity=8)\n\n    pos_list: List[Point] = []\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    if num_labels <= 1:  # 没有连通块 走到敌人附近了\n        return pos_list\n\n    # 找到最大的连通区域\n    for label in range(1, num_labels):\n        # 找到各个连通区域的中心点\n        center_x = int(centroids[label, 0])\n        center_y = int(centroids[label, 1])\n        pos_list.append(Point(center_x - cx, center_y - cy))\n\n    return pos_list", "completions": ["  \n[PYTHON]\ndef get_enemy_pos(mm_info: MiniMapInfo) -> List[Point]:\n    enemy_mask = get_enemy_mask(mm_info)\n    # cv2_utils.show_image(enemy_mask, win_name='get_enemy_pos', wait=0)\n    cx = mm_info.origin.shape[1] // 2\n    cy = mm_info.origin.shape[0] // 2\n\n    # 膨胀一下找连通块\n    to_check = cv2_utils.dilate(enemy_mask, 5)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(to_check, connectivity=8)\n\n    pos_list: List[Point] = []\n    for label in range(1, num_labels):\n        area = stats[label, cv2.CC_STAT_AREA]\n        if area > 100:\n            x = int(centroids[label, 0])\n            y = int(centroids[label, 1])\n            pos_list.append(Point(x, y))\n\n    return pos_list\n[/PYTHON]\n"]}
{"id": 4, "name": "plot_turbine_points", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport math\nfrom typing import (\n    Any,\n    Dict,\n    List,\n    Tuple,\n)\n\nimport matplotlib.lines\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.spatial.distance import pdist, squareform\n\nfrom floris import FlorisModel\nfrom floris.utilities import rotate_coordinates_rel_west, wind_delta\n\n\ndef plot_turbine_points(\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function plots the turbine points on a matplotlib axes object.\n\nArgs:\n    fmodel (FlorisModel): An instance of the FlorisModel class.\n    ax (plt.Axes, optional): A matplotlib Axes object. If not provided, a new one will be created.\n    turbine_indices (List[int], optional): A list of indices of the turbines to plot. If not provided, all turbines will be plotted.\n    plotting_dict (Dict[str, Any], optional): A dictionary of plotting parameters. If not provided, default parameters will be used.\n\nReturns:\n    plt.Axes: The matplotlib Axes object on which the turbine points were plotted.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef plot_turbine_points(\n    fmodel: FlorisModel,\n    ax: plt.Axes = None,\n    turbine_indices: List[int] = None,\n    plotting_dict: Dict[str, Any] = {},\n) -> plt.Axes:\n\n    # Generate axis, if needed\n    if ax is None:\n        _, ax = plt.subplots()\n\n    # If turbine_indices is not none, make sure all elements correspond to real indices\n    if turbine_indices is not None:\n        try:\n            fmodel.layout_x[turbine_indices]\n        except IndexError:\n            raise IndexError(\"turbine_indices does not correspond to turbine indices in fi\")\n    else:\n        turbine_indices = list(range(len(fmodel.layout_x)))\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    # Generate plotting dictionary\n    default_plotting_dict = {\n        \"color\": \"black\",\n        \"marker\": \".\",\n        \"markersize\": 10,\n        \"label\": None,\n    }\n    plotting_dict = {**default_plotting_dict, **plotting_dict}\n\n    # Plot\n    ax.plot(\n        fmodel.layout_x[turbine_indices],\n        fmodel.layout_y[turbine_indices],\n        linestyle=\"None\",\n        **plotting_dict,\n    )\n\n    # Make sure axis set to equal\n    ax.axis(\"equal\")\n\n    return ax", "completions": ["  \n[PYTHON]\ndef plot_turbine_points(\n    fmodel: FlorisModel,\n    ax: plt.Axes = None,\n    turbine_indices: List[int] = None,\n    plotting_dict: Dict[str, Any] = {},\n) -> plt.Axes:\n    # Generate axis, if needed\n    if ax is None:\n        _, ax = plt.subplots()\n\n    # If turbine_indices is not none, make sure all elements correspond to real indices\n    if turbine_indices is not None:\n        try:\n            fmodel.layout_x[turbine_indices]\n        except IndexError:\n            raise IndexError(\"turbine_indices does not correspond to turbine indices in fmodel\")\n    else:\n        turbine_indices = list(range(len(fmodel.layout_x)))\n\n    # Plot turbine points\n    for i in turbine_indices:\n        x = fmodel.layout_x[i]\n        y = fmodel.layout_y[i]\n        ax.plot(x, y, \"bo\", label=f\"Turbine {i+1}\")\n\n    # Add title and legend\n    ax.set_title(\"Turbine Points\")\n    ax.legend()\n\n    return ax\n[/PYTHON]\n"]}
{"id": 5, "name": "build_shuffling_sampling_fn", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2023, Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Libraries for auditing FL models with canary insertion.\"\"\"\n\nimport collections\nfrom collections.abc import Callable\nimport math\nimport os.path\nimport time\nfrom typing import Any, Optional\n\nfrom absl import logging\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_federated as tff\n\nfrom one_shot_epe import dot_product_utils\nfrom utils import utils_impl\nfrom tensorboard.plugins.hparams import api as hp\n\n\ndef build_bernoulli_sampling_fn(\n    client_ids: list[str],\n    expected_clients_per_round: float,\n    seed: int,\n) -> Callable[[int], list[str]]:\n  \"\"\"Builds Bernoulli sampling function.\n\n  Args:\n    client_ids: A list of client_ids.\n    expected_clients_per_round: The expected number of clients per round.\n    seed: The random seed. If None, randomness is seeded nondeterministically.\n\n  Returns:\n    Sampling function that selects clients i.i.d. with mean\n    expected_clients_per_round.\n  \"\"\"\n  p_select = expected_clients_per_round / len(client_ids)\n  if p_select > 1:\n    raise ValueError(\n        'Expected clients per round cannot exceed number of client IDs. Found '\n        f'{len(client_ids)} client ids with {expected_clients_per_round} '\n        'expected_clients_per_round.'\n    )\n  uniform_sampling_fn = tff.simulation.build_uniform_sampling_fn(\n      client_ids, random_seed=seed\n  )\n\n  if seed is None:\n    seed = time.time_ns()\n\n  def sampling_fn(round_num):\n    size = tf.random.stateless_binomial(\n        (), (round_num, seed), len(client_ids), p_select\n    )\n    return uniform_sampling_fn(round_num, size)\n\n  return sampling_fn\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function builds a shuffling sampling function for a federated learning simulation.\n\nArgs:\n    real_client_ids (list[str]): A list of real client IDs.\n    canary_client_ids (list[str]): A list of canary client IDs.\n    total_rounds (int): The total number of rounds in the federated learning simulation.\n    num_real_epochs (int): The number of epochs for real clients.\n    canary_repeats (int): The number of times to repeat the canary clients.\n    seed (int): The seed for the random number generator.\n\nReturns:\n    tuple[Callable[[int], list[str]], float]: A tuple containing a function that samples clients for a given round and the mean number of clients per round.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef build_shuffling_sampling_fn(\n    real_client_ids: list[str],\n    canary_client_ids: list[str],\n    total_rounds: int,\n    num_real_epochs: int,\n    canary_repeats: int,\n    seed: int,\n) -> tuple[Callable[[int], list[str]], float]:\n  if not real_client_ids:\n    raise ValueError('`real_client_ids` cannot be empty.')\n  if total_rounds <= 0:\n    raise ValueError(\n        f'`total_rounds` must be greater than 0. Found `{total_rounds}`.'\n    )\n  if num_real_epochs <= 0:\n    raise ValueError(\n        f'`num_real_epochs` must be greater than 0. Found `{num_real_epochs}`.'\n    )\n  if canary_repeats < 0:\n    raise ValueError(\n        f'`canary_repeats` must be nonnegative. Found `{canary_repeats}`.'\n    )\n\n  rng = np.random.default_rng(seed)\n\n  num_real = len(real_client_ids)\n  real_order = rng.permutation(num_real)\n  num_canary = len(canary_client_ids)\n  canary_order = [rng.permutation(num_canary) for _ in range(canary_repeats)]\n\n  def sampling_fn(round_num: int) -> list[str]:\n    if not 1 <= round_num <= total_rounds:\n      raise ValueError(\n          f'round_num ({round_num}) must be between 1 and total_rounds'\n          f' ({total_rounds}).'\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "      )\n    # tff.simulation.run_training_process uses rounds 1 ... total_rounds.\n    # For the math here to work we need 0 ... (total_rounds - 1).\n    round_num -= 1\n\n    begin_real = math.ceil(\n        round_num * num_real * num_real_epochs / total_rounds\n    )\n    end_real = math.ceil(\n        (round_num + 1) * num_real * num_real_epochs / total_rounds\n    )\n    real_sample = [\n        real_client_ids[real_order[i % num_real]]\n        for i in range(begin_real, end_real)\n    ]\n\n    begin_canary = math.ceil(\n        round_num * num_canary * canary_repeats / total_rounds\n    )\n    end_canary = math.ceil(\n        (round_num + 1) * num_canary * canary_repeats / total_rounds\n    )\n    canary_sample = [\n        canary_client_ids[canary_order[i // num_canary][i % num_canary]]\n        for i in range(begin_canary, end_canary)\n    ]\n\n    return real_sample + canary_sample\n\n  mean_clients_per_round = (\n      len(real_client_ids) * num_real_epochs\n      + len(canary_client_ids) * canary_repeats\n  ) / total_rounds\n\n  return sampling_fn, mean_clients_per_round", "completions": ["  \n[PYTHON]\ndef sampling_fn(round_num: int) -> list[str]:\n    if not 1 <= round_num <= total_rounds:\n        raise ValueError(\n            f'round_num ({round_num}) must be between 1 and total_rounds'\n            f' ({total_rounds}).'\n        )\n    real_start = (round_num - 1) * num_real_epochs\n    real_end = round_num * num_real_epochs\n    real_clients = real_order[real_start:real_end]\n    canary_clients = canary_order[round_num - 1]\n    return real_clients + canary_clients\n[/PYTHON]\n"]}
{"id": 6, "name": "linear_to_mel_weight_matrix", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright © 2023 Apple Inc.\n#\n# Some of the code in this file is adapted from:\n#\n# tensorflow/tensorflow:\n# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n# Licensed under the Apache License, Version 2.0 (the \"License\").\n\n\"\"\"Feature extraction for audio tasks.\"\"\"\n\nimport enum\nimport math\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom numpy.typing import ArrayLike\n\nfrom axlearn.common.utils import Tensor\n\n\nclass WindowType(enum.Enum):\n    HANN = 0\n    HAMMING = 1\n\n\nclass FrequencyScale(enum.Enum):\n    # Mel scale (using natural log).\n    MEL_LN = 0\n\n\ndef hertz_to_warped_scale(freq: ArrayLike, *, freq_scale: FrequencyScale) -> ArrayLike:\n    \"\"\"Converts frequencies in Hz to the target frequency scale.\n\n    Args:\n        freq: Value(s) in Hz.\n        freq_scale: Target frequency scale.\n\n    Returns:\n        The frequency in the target scale.\n    \"\"\"\n    if freq_scale == FrequencyScale.MEL_LN:\n        return 1127.0 * np.log(1.0 + (freq / 700.0))\n    else:\n        raise NotImplementedError(f\"Unsupported target scale {freq_scale}.\")\n\n\ndef warped_to_hertz_scale(freq: ArrayLike, *, freq_scale: FrequencyScale) -> ArrayLike:\n    \"\"\"Converts frequencies from the source frequency scale to linear scale.\n\n    Args:\n        freq: Value(s) in the source scale.\n        freq_scale: Source frequency scale.\n\n    Returns:\n        The frequency in Hz.\n    \"\"\"\n    if freq_scale == FrequencyScale.MEL_LN:\n        return 700.0 * (np.exp(freq / 1127.0) - 1.0)\n    else:\n        raise NotImplementedError(f\"Unsupported source scale {freq_scale}.\")\n\n\ndef sliding_window(x: Tensor, *, window_size: int, stride: int) -> Tensor:\n    \"\"\"Computes sliding windows.\n\n    Args:\n        x: A Tensor of shape `[..., seq_len]`.\n        window_size: Size of sliding window.\n        stride: Stride of sliding window.\n\n    Returns:\n        Windows of shape `[..., num_windows, window_size]` via sliding window on the last axis.\n    \"\"\"\n    # NOTE: using `max` instead of `jnp.maximum` is necessary here to treat as constant for jit.\n    output_size = max(x.shape[-1] - window_size, 0) // stride + 1\n    idx = stride * jnp.arange(output_size)[:, None] + jnp.arange(window_size)[None, :]\n    return x[..., idx]\n\n\ndef pre_emphasis(x: Tensor, *, coeff: float) -> Tensor:\n    \"\"\"Applies a pre-emphasis filter to the input frames.\n\n    Args:\n        x: Input frames of shape `[..., frame_size]`.\n        coeff: Pre-emphasis coefficient.\n\n    Returns:\n        Frames of shape `[..., frame_size-1]`.\n    \"\"\"\n    return x[..., 1:] - coeff * x[..., :-1]\n\n\ndef windowing(x: Tensor, *, window_type: WindowType, periodic: bool = True) -> Tensor:\n    \"\"\"Applies windowing to the input frames of shape `[..., num_windows, window_size]`.\"\"\"\n    window_size = x.shape[-1]\n    is_even = (1 - window_size % 2) * periodic\n\n    if window_type == WindowType.HANN:\n        coeffs = jnp.hanning(window_size + is_even)[:window_size]\n    elif window_type == WindowType.HAMMING:\n        coeffs = jnp.hamming(window_size + is_even)[:window_size]\n    else:\n        raise NotImplementedError(f\"Unrecognized window_type {window_type}.\")\n\n    return (x * coeffs).astype(x.dtype)\n\n\ndef magnitude_spectrogram(x: Tensor, *, fft_size: int) -> Tensor:\n    \"\"\"Computes magnitude spectrogram from the input frames.\n\n    Args:\n        x: Input frames of shape `[..., num_frames, frame_size]`.\n        fft_size: Used to determine number of frequency bins. Should be a power of 2.\n\n    Returns:\n        A spectrogram of shape `[..., num_frames, num_spectrogram_bins=fft_size // 2 + 1]`.\n    \"\"\"\n    out = jnp.abs(jnp.fft.fft(x, n=fft_size))\n    out = out[..., : fft_size // 2 + 1]\n    return out.astype(x.dtype)\n\n\ndef linear_to_log_mel_spectrogram(\n    x: Tensor, *, weight_matrix: ArrayLike, mel_floor: float = 1.0\n) -> Tensor:\n    \"\"\"Converts linear scale spectrograms to log-mel spectrograms.\n\n    Args:\n        x: Magnitude or power spectrogram of shape `[..., num_frames, num_spectrogram_bins]`.\n        weight_matrix: A weight matrix (or config instantiating thereof) of shape\n            `[num_spectrogram_bins, num_filters]`.\n        mel_floor: Minimum value of the output spectrogram prior to taking log.\n\n    Returns:\n        A spectrogram of shape `[..., num_frames, num_filters]`.\n    \"\"\"\n    # Linear to mel spectrogram.\n    x = jnp.maximum(mel_floor, x @ weight_matrix).astype(x.dtype)\n    # Mel to log-mel spectrogram.\n    return jnp.log(jnp.maximum(x, jnp.finfo(x.dtype).tiny))\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes a weight matrix for converting linear frequency to mel frequency.\n\nArgs:\n    num_filters (int): The number of mel filters.\n    num_spectrogram_bins (int): The number of spectrogram bins.\n    sample_rate (float): The sample rate of the audio.\n    lower_edge_hertz (float): The lower edge of the mel spectrum in hertz.\n    upper_edge_hertz (float): The upper edge of the mel spectrum in hertz.\n    dtype (np.dtype): The data type of the output. Default is np.float64.\n\nReturns:\n    ArrayLike: A weight matrix for converting linear frequency to mel frequency.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef linear_to_mel_weight_matrix(\n    *,\n    num_filters: int,\n    num_spectrogram_bins: int,\n    sample_rate: float,\n    lower_edge_hertz: float,\n    upper_edge_hertz: float,\n    dtype: np.dtype = np.float64,\n) -> ArrayLike:\n    freq_scale = FrequencyScale.MEL_LN\n\n    # Compute mel spectrogram bins up to nyquist frequency. Drop the 0th bin.\n    linear_freqs = np.linspace(0, sample_rate // 2, num_spectrogram_bins)[1:].astype(dtype)\n    spectrogram_bins_mel = hertz_to_warped_scale(linear_freqs, freq_scale=freq_scale)[:, None]\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    # Compute lower and upper bound of the output mel spectrum.\n    lower_edge_mel = hertz_to_warped_scale(lower_edge_hertz, freq_scale=freq_scale)\n    upper_edge_mel = hertz_to_warped_scale(upper_edge_hertz, freq_scale=freq_scale)\n\n    # Compute num_filters triples of (lower_edge, center, upper_edge).\n    idx = np.arange(num_filters)[:, None] + np.arange(3)[None, :]\n    band_edges_mel = np.linspace(lower_edge_mel, upper_edge_mel, num_filters + 2)[idx].astype(dtype)\n    # Split the triples up and reshape them into [1, num_filters] tensors.\n    lower_edge_mel, center_mel, upper_edge_mel = tuple(\n        np.reshape(t, [1, num_filters]) for t in np.split(band_edges_mel, 3, axis=1)\n    )\n    upper_slopes = (upper_edge_mel - spectrogram_bins_mel) / (upper_edge_mel - center_mel)\n    lower_slopes = (spectrogram_bins_mel - lower_edge_mel) / (center_mel - lower_edge_mel)\n\n    # Add back the 0th bin dropped above.\n    return np.pad(np.maximum(np.minimum(upper_slopes, lower_slopes), 0.0), [[1, 0], [0, 0]])", "completions": ["  \n[PYTHON]\ndef linear_to_mel_weight_matrix(\n    *,\n    num_filters: int,\n    num_spectrogram_bins: int,\n    sample_rate: float,\n    lower_edge_hertz: float,\n    upper_edge_hertz: float,\n    dtype: np.dtype = np.float64,\n) -> ArrayLike:\n    freq_scale = FrequencyScale.MEL_LN\n\n    # Compute mel spectrogram bins up to nyquist frequency. Drop the 0th bin.\n    linear_freqs = np.linspace(0, sample_rate // 2, num_spectrogram_bins)[1:].astype(dtype)\n    spectrogram_bins_mel = hertz_to_warped_scale(linear_freqs, freq_scale=freq_scale)[:, None]\n\n    # Compute weights for each mel filter.\n    weights = np.zeros((num_filters, num_spectrogram_bins), dtype=dtype)\n    for i in range(num_filters):\n        lower_mel = spectrogram_bins_mel[i]\n        upper_mel = spectrogram_bins_mel[i + 1]\n        lower_hertz = warped_to_hertz_scale(lower_mel, freq_scale=freq_scale)\n        upper_hertz = warped_to_hertz_scale(upper_mel, freq_scale=freq_scale)\n        filter_bins = np.logical_and(\n            lower_hertz <= linear_freqs, linear_freqs < upper_hertz\n        ).astype(dtype)\n        weights[i] = filter_bins\n\n    return weights\n[/PYTHON]\n"]}
{"id": 7, "name": "iram", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport numpy as np\nfrom scipy.sparse.linalg import LinearOperator as LO\nfrom scipy.sparse.linalg import eigsh\nfrom cola.ops import LinearOperator\nfrom cola.ops import Array\nfrom cola.ops import Dense\nfrom cola.utils import export\n\n\n@export\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes the eigenvalues and eigenvectors of a linear operator using the Implicitly Restarted Arnoldi Method (IRAM).\n\nArgs:\n    A (LinearOperator): The linear operator for which the eigenvalues and eigenvectors are to be computed.\n    max_iters (int, optional): The maximum number of Arnoldi iterations. Defaults to 100.\n    tol (float, optional): The tolerance for the convergence of the Arnoldi process. Defaults to 1e-7.\n\nReturns:\n    tuple: A tuple containing the eigenvalues, eigenvectors, and a dictionary with additional information.\n        - eigvals (Array): The eigenvalues of the linear operator.\n        - eigvecs (Dense): The eigenvectors of the linear operator.\n        - info (dict): A dictionary containing additional information about the computation.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef iram(A: LinearOperator, start_vector: Array = None, max_iters: int = 100, tol: float = 1e-7, pbar: bool = False):\n    xnp = A.xnp\n    del pbar\n    del start_vector\n\n    def matvec(x):\n        X = xnp.array(x, dtype=A.dtype, device=A.device)\n        out = A @ X\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        return np.array(out, dtype=np.float32)\n\n    A2 = LO(shape=A.shape, dtype=np.float32, matvec=matvec)\n    k = min(A.shape[0] - 1, max_iters)\n    eigvals, eigvecs = eigsh(A2, k=k, M=None, sigma=None, which=\"LM\", v0=None, tol=tol)\n    eigvals, eigvecs = xnp.array(eigvals, dtype=A.dtype,\n                                 device=A.device), xnp.array(eigvecs, dtype=A.dtype, device=A.device)\n    info = {}\n    return eigvals, Dense(eigvecs), info", "completions": ["  \n[PYTHON]\ndef iram(A: LinearOperator, start_vector: Array = None, max_iters: int = 100, tol: float = 1e-7, pbar: bool = False):\n    xnp = A.xnp\n    del pbar\n    del start_vector\n\n    def matvec(x):\n        X = xnp.array(x, dtype=A.dtype, device=A.device)\n        out = A @ X\n        return out\n[/PYTHON]\n"]}
{"id": 8, "name": "model_name", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport re\nfrom collections import defaultdict\nfrom datetime import datetime, date, timedelta\nfrom enum import Enum\nfrom functools import lru_cache, reduce\nfrom pydoc import locate\nfrom typing import List, MutableSet, Union, Tuple, Dict, Set, Any, TypeVar, Type, Optional\nfrom typing import get_args, get_origin\n\nimport attrs\nfrom attr import resolve_types\nfrom attrs import Attribute\n\nfrom fixlib.baseresources import BaseResource\nfrom fixlib.json import from_json\nfrom fixlib.types import Json\nfrom fixlib.utils import type_str\n\nproperty_metadata_to_strip = [\"restart_required\", \"description\", \"required\", \"kind\"]\n\n\n# List[X] -> list, list -> list\ndef optional_origin(clazz: Type[Any]) -> Type[Any]:\n    maybe_optional = get_args(clazz)[0] if is_optional(clazz) else clazz\n    origin = get_origin(maybe_optional)\n    return origin if origin else maybe_optional  # type: ignore\n\n\n# Optional[x] -> true\ndef is_optional(clazz: Union[type, Tuple[Any]]) -> bool:\n    args = get_args(clazz)\n    return get_origin(clazz) is Union and type(None) in args and len(args) == 2\n\n\n# List[x] -> true, list -> true\ndef is_collection(clazz: type) -> bool:\n    return optional_origin(clazz) in [list, set, tuple]\n\n\n# Dict[x,y] -> true, dict -> true\ndef is_dict(clazz: type) -> bool:\n    return optional_origin(clazz) in [dict]\n\n\n# either enum or optional enum\ndef is_enum(clazz: type) -> bool:\n    origin = optional_origin(clazz)\n    return isinstance(origin, type) and issubclass(origin, Enum)\n\n\n# List[X] -> X, list -> object\ndef type_arg(clazz: type) -> type:\n    maybe_optional = get_args(clazz)[0] if is_optional(clazz) else clazz\n    args = get_args(maybe_optional)\n    return args[0] if args and len(args) == 1 else object  # type: ignore\n\n\n# Dict[X,Y] -> (X,Y), dict -> (object, object)\ndef dict_types(clazz: type) -> Tuple[type, type]:\n    maybe_optional = get_args(clazz)[0] if is_optional(clazz) else clazz\n    args = get_args(maybe_optional)\n    return (args[0], args[1]) if args and len(args) == 2 else (object, object)\n\n\n# walk class hierarchy, as well as all properties to find transitive data classes\ndef transitive_classes(classes: Set[type], walk_subclasses: bool = True) -> Set[type]:\n    all_classes: MutableSet[type] = set()\n\n    def check(to_check: type) -> None:\n        clazz = optional_origin(to_check)\n        if clazz in all_classes:\n            pass\n        elif is_dict(clazz):\n            key_type, value_type = dict_types(to_check)\n            check(key_type)\n            check(value_type)\n        elif is_collection(clazz):\n            check(type_arg(to_check))\n        elif attrs.has(clazz):\n            resolve_types(clazz)\n            all_classes.add(clazz)\n            for mro_clazz in clazz.mro()[1:]:\n                check(mro_clazz)\n            if walk_subclasses:\n                for subclass in clazz.__subclasses__():\n                    check(subclass)\n            for field in attrs.fields(clazz):\n                check(field.type)\n        elif is_enum(clazz):\n            all_classes.add(clazz)\n\n    for c in classes:\n        check(c)\n\n    return set(all_classes)\n\n\nlookup: Dict[type, str] = {\n    str: \"string\",\n    int: \"int64\",\n    bool: \"boolean\",\n    float: \"double\",\n    datetime: \"datetime\",\n    date: \"date\",\n    timedelta: \"duration\",\n}\nsimple_type = tuple(lookup.keys())\n\n\n# Model name from the internal python class name\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function generates a model name based on the provided class or type.\n\nArgs:\n    clazz (Union[type, Tuple[Any], None]): The class or type for which the model name is to be generated.\n\nReturns:\n    str: The generated model name.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef model_name(clazz: Union[type, Tuple[Any], None]) -> str:\n    if clazz is None:\n        return \"any\"\n    to_check = get_args(clazz)[0] if is_optional(clazz) else clazz\n    if is_collection(to_check):\n        return f\"{model_name(type_arg(to_check))}[]\"\n    elif is_dict(to_check):\n        key_type, value_type = dict_types(to_check)\n        return f\"dictionary[{model_name(key_type)}, {model_name(value_type)}]\"\n    elif is_enum(to_check):\n        # camel case to snake case\n        return re.sub(r\"(?<!^)(?=[A-Z])\", \"_\", to_check.__name__).lower()\n    elif get_origin(to_check) == Union:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        # this is a union of different types other than none.\n        # since union types are not supported, we fallback to any here\n        return \"any\"\n    elif isinstance(to_check, TypeVar):\n        return model_name(get_args(to_check))\n    elif isinstance(to_check, type) and issubclass(to_check, simple_type):\n        return lookup[to_check]\n    elif attrs.has(to_check):\n        name = getattr(to_check, \"kind\", None)\n        if not name:\n            raise AttributeError(f\"dataclass {to_check} need to define a ClassVar kind!\")\n        return name  # type: ignore\n    else:\n        return \"any\"", "completions": ["  \n[PYTHON]\n```\ndef model_name(clazz: Union[type, Tuple[Any], None]) -> str:\n    if clazz is None:\n        return \"any\"\n    to_check = get_args(clazz)[0] if is_optional(clazz) else clazz\n    if is_collection(to_check):\n        return f\"{model_name(type_arg(to_check))}[]\"\n    elif is_dict(to_check):\n        key_type, value_type = dict_types(to_check)\n        return f\"dictionary[{model_name(key_type)}, {model_name(value_type)}]\"\n    elif is_enum(to_check):\n        # camel case to snake case\n        return re.sub(r\"(?<!^)(?=[A-Z])\", \"_\", to_check.__name__).lower()\n    elif get_origin(to_check) == Union:\n        return \" | \".join(model_name(arg) for arg in get_args(to_check))\n    else:\n        return lookup.get(to_check, to_check.__name__)\n```\n[/PYTHON]\n"]}
{"id": 9, "name": "dedup_by_vid", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2024 The Scenic Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Contains postprocessing utility functions.\"\"\"\n\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nimport ml_collections\nimport numpy as np\nfrom scenic.projects.unloc import model_utils\nimport tensorflow as tf\n\nPyModule = Any\nArray = Union[jnp.ndarray, np.ndarray]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to deduplicate logits, labels, and video IDs based on the video IDs.\n\nArgs:\n    logits (np.ndarray): The logits to be deduplicated.\n    labels (np.ndarray): The labels to be deduplicated.\n    batch_masks (np.ndarray): A boolean mask indicating which elements to consider.\n    vids (np.ndarray): The video IDs corresponding to the logits and labels.\n    frame_masks (Optional[np.ndarray]): An optional boolean mask indicating which frames to consider.\n\nReturns:\n    Tuple[np.ndarray, np.ndarray, np.ndarray]: A tuple containing the deduplicated logits, labels, and video IDs.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef dedup_by_vid(\n    logits: np.ndarray,\n    labels: np.ndarray,\n    batch_masks: np.ndarray,\n    vids: np.ndarray,\n    frame_masks: Optional[np.ndarray] = None\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\n  batch_masks = batch_masks.astype(bool)\n  vids = vids[batch_masks]\n  logits = logits[batch_masks]\n  labels = labels[batch_masks]\n  if frame_masks is not None:\n    frame_masks = frame_masks.astype(bool)\n    frame_masks = frame_masks[batch_masks]\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "  vid_set = set()\n  deduped_logits, deduped_labels, deduped_vids = [], [], []\n  for idx, vid in enumerate(vids):\n    if vid in vid_set:\n      continue\n    if frame_masks is None:\n      deduped_logits.append(logits[idx][np.newaxis, :])\n      deduped_labels.append(labels[idx][np.newaxis, :])\n    else:\n      frame_mask = frame_masks[idx]\n      deduped_logits.append(logits[idx][frame_mask])\n      deduped_labels.append(labels[idx][frame_mask])\n    vid_set.add(vid)\n    deduped_vids.append(vid)\n  return (np.concatenate(deduped_logits, axis=0),\n          np.concatenate(deduped_labels, axis=0), np.array(deduped_vids))", "completions": ["  \n[markdown]```\ndef dedup_by_vid(\n    logits: np.ndarray,\n    labels: np.ndarray,\n    batch_masks: np.ndarray,\n    vids: np.ndarray,\n    frame_masks: Optional[np.ndarray] = None\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\n  batch_masks = batch_masks.astype(bool)\n  vids = vids[batch_masks]\n  logits = logits[batch_masks]\n  labels = labels[batch_masks]\n  if frame_masks is not None:\n    frame_masks = frame_masks.astype(bool)\n    frame_masks = frame_masks[batch_masks]\n  return logits, labels, vids\n```"]}
{"id": 10, "name": "informedness_statistic", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# BSD 2-CLAUSE LICENSE\n\n# Redistribution and use in source and binary forms, with or without modification,\n# are permitted provided that the following conditions are met:\n\n# Redistributions of source code must retain the above copyright notice, this\n# list of conditions and the following disclaimer.\n# Redistributions in binary form must reproduce the above copyright notice,\n# this list of conditions and the following disclaimer in the documentation\n# and/or other materials provided with the distribution.\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n# #ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n# original author: Saad Eddin Al Orjany, Sayan Patra, Reza Hosseini, Kaixu Yang\n\n\"\"\"Evaluation functions.\"\"\"\n\nimport functools\nimport warnings\nfrom typing import Optional\nfrom typing import Union\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\n\nfrom greykite.detection.common.ad_evaluation_utils import compute_range_based_score\nfrom greykite.detection.common.ad_evaluation_utils import prepare_anomaly_ranges\n\n\nINPUT_COL_NAME = \"input_col\"\n\n\ndef validate_categorical_input(score_func):\n    \"\"\"Decorator function to validate categorical scoring function input,\n    and unifies the input type to pandas.Series.\n    \"\"\"\n\n    @functools.wraps(score_func)\n    def score_func_wrapper(\n            y_true: Union[list, np.array, pd.Series, pd.DataFrame],\n            y_pred: Union[list, np.array, pd.Series, pd.DataFrame],\n            *args,\n            **kwargs) -> np.array:\n        actual = pd.DataFrame(y_true).reset_index(drop=True)\n        pred = pd.DataFrame(y_pred).reset_index(drop=True)\n        if actual.shape[-1] != 1 or pred.shape[-1] != 1:\n            raise ValueError(f\"The input for scoring must be 1-D array, found {actual.shape} and {pred.shape}\")\n        if actual.shape != pred.shape:\n            raise ValueError(f\"The input lengths must be the same, found {actual.shape} and {pred.shape}\")\n        actual.columns = [INPUT_COL_NAME]\n        pred.columns = [INPUT_COL_NAME]\n        # Drop rows with NA values in either actual or pred\n        merged_df = pd.concat([actual, pred], axis=1).dropna()\n        actual = merged_df.iloc[:, [0]]\n        pred = merged_df.iloc[:, [1]]\n        category_in_actual_set = set(actual[INPUT_COL_NAME])\n        category_in_pred_set = set(pred[INPUT_COL_NAME])\n        pred_minus_actual = category_in_pred_set.difference(category_in_actual_set)\n        if pred_minus_actual:\n            warnings.warn(f\"The following categories do not appear in y_true column, \"\n                          f\"the recall may be undefined.\\n{pred_minus_actual}\")\n        actual_minus_pred = category_in_actual_set.difference(category_in_pred_set)\n        if actual_minus_pred:\n            warnings.warn(f\"The following categories do not appear in y_pred column, \"\n                          f\"the precision may be undefined.\\n{actual_minus_pred}\")\n        # Adds a list wrapper below since `sklearn >= 1.1` restricts the input types and shapes.\n        return score_func(\n            y_true=list(actual[INPUT_COL_NAME].reset_index(drop=True)),\n            y_pred=list(pred[INPUT_COL_NAME].reset_index(drop=True)),\n            *args,\n            **kwargs\n        )\n\n    return score_func_wrapper\n\n\n@validate_categorical_input\ndef precision_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the precision scores for two arrays.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D\n        The sample weight.\n\n    Returns\n    -------\n    precision : `dict`\n        The precision score for different categories.\n        The keys are the categories, and the values are the precisions.\n    \"\"\"\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    precisions_array = metrics.precision_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    precisions = {}\n    for label, precision in zip(labels, precisions_array):\n        precisions[label] = precision\n    return precisions\n\n\n@validate_categorical_input\ndef recall_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the recall scores for two arrays.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D\n        The sample weight.\n\n    Returns\n    -------\n    recall : `dict`\n        The recall score for different categories.\n        The keys are the categories, and the values are the recalls.\n    \"\"\"\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    recalls_array = metrics.recall_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    recalls = {}\n    for label, recall in zip(labels, recalls_array):\n        recalls[label] = recall\n    return recalls\n\n\n@validate_categorical_input\ndef f1_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the F1 scores for two arrays.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D\n        The sample weight.\n\n    Returns\n    -------\n    recall : `dict`\n        The recall score for different categories.\n        The keys are the categories, and the values are the recalls.\n    \"\"\"\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    f1s_array = metrics.f1_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    f1_scores = {}\n    for label, f1 in zip(labels, f1s_array):\n        f1_scores[label] = f1\n    return f1_scores\n\n\n@validate_categorical_input\ndef matthews_corrcoef(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the Matthews correlation coefficient for two arrays.\n    The statistic is also known as the phi coefficient.\n    The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary and multiclass classifications.\n    It takes into account true and false positives and negatives and is generally regarded as a balanced measure\n    which can be used even if the classes are of very different sizes.\n    The MCC is in essence a correlation coefficient value between -1 and +1 (inclusive).\n    One can interpret this coefficient as follows:\n\n        - +1 represents a perfect prediction.\n        - 0 represents an average random prediction.\n        - -1 represents an inverse prediction.\n\n    For more information, please consult the `wiki page <https://en.wikipedia.org/wiki/Phi_coefficient>`_.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D or None, default None\n        The sample weight.\n\n    Returns\n    -------\n    result : `float`\n        The Matthews correlation coefficient.\n    \"\"\"\n    return metrics.matthews_corrcoef(\n        y_true=y_true,\n        y_pred=y_pred,\n        sample_weight=sample_weight)\n\n\n@validate_categorical_input\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the informedness statistic, which is a balanced accuracy score adjusted for imbalanced datasets.\n\nArgs:\n    y_true (array-like of shape (n_samples,)): Ground truth (correct) target values.\n    y_pred (array-like of shape (n_samples,)): Estimated targets as returned by a classifier.\n    sample_weight (array-like of shape (n_samples,), optional): Sample weights.\n\nReturns:\n    float: The informedness statistic, which is a balanced accuracy score adjusted for imbalanced datasets.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef informedness_statistic(\n        y_true,\n        y_pred,\n        sample_weight=None):\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    return metrics.balanced_accuracy_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        sample_weight=sample_weight,\n        adjusted=True)", "completions": ["  \n[PYTHON]\ndef informedness_statistic(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"\n    Calculates the informedness statistic, which is a balanced accuracy score adjusted for imbalanced datasets.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,)\n        Ground truth (correct) target values.\n    y_pred : array-like of shape (n_samples,)\n        Estimated targets as returned by a classifier.\n    sample_weight : array-like of shape (n_samples,), optional\n        Sample weights.\n\n    Returns\n    -------\n    float\n        The informedness statistic, which is a balanced accuracy score adjusted for imbalanced datasets.\n    \"\"\"\n    # Calculate the balanced accuracy score\n    balanced_accuracy = metrics.balanced_accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n\n    # Calculate the number of true positives, false positives, true negatives, and false negatives\n    tp = metrics.confusion_matrix(y_true, y_pred, sample_weight=sample_weight).ravel()[0]\n    fp = metrics.confusion_matrix(y_true, y_pred, sample_weight=sample_weight).ravel()[1]\n    tn = metrics.confusion_matrix(y_true, y_pred, sample_weight=sample_weight).ravel()[2]\n    fn = metrics.confusion_matrix(y_true, y_pred, sample_weight=sample_weight).ravel()[3]\n\n    # Calculate the informedness statistic\n    informedness = balanced_accuracy - (tp / (tp + fp)) - (tn / (tn + fn))\n\n    return informedness\n[/PYTHON]\n"]}
{"id": 11, "name": "run", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom typing import Optional, Sequence\n\nimport pandas as pd\n\nfrom ...datasets.base import Dataset\nfrom ...models.base import BaseModel\nfrom ...slicing.slice_finder import SliceFinder\nfrom ...testing.tests.statistic import _cramer_v, _mutual_information, _theil_u\nfrom ..common.examples import ExampleExtractor\nfrom ..decorators import detector\nfrom ..issues import Issue, IssueLevel, SpuriousCorrelation\nfrom ..logger import logger\nfrom ..registry import Detector\n\n\n@detector(name=\"spurious_correlation\", tags=[\"spurious_correlation\", \"classification\"])\nclass SpuriousCorrelationDetector(Detector):\n    def __init__(\n        self, method: Optional[str] = \"theil\", threshold: Optional[float] = 0.5, min_slice_size: Optional[float] = None\n    ):\n        self.threshold = threshold\n        self.method = method\n        self.min_slice_size = min_slice_size\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function runs a model on a dataset and identifies spurious correlations between features and the model's predictions.\n\nArgs:\n    model (BaseModel): The model to run the predictions on.\n    dataset (Dataset): The dataset to run the model on.\n    features (Sequence[str]): The features to consider for spurious correlation detection.\n\nReturns:\n    list: A list of issues, where each issue is an instance of the Issue class, representing a spurious correlation found in the data.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n    def run(self, model: BaseModel, dataset: Dataset, features: Sequence[str]):\n        logger.info(f\"{self.__class__.__name__}: Running\")\n\n        # Dataset prediction\n        ds_predictions = pd.Series(model.predict(dataset).prediction, dataset.df.index)\n\n        # Warm up text metadata\n        for f in features:\n            if dataset.column_types[f] == \"text\":\n                dataset.column_meta[f, \"text\"]\n\n        # Prepare dataset for slicing\n        df = dataset.df.copy()\n        if dataset.target is not None:\n            df.drop(columns=dataset.target, inplace=True)\n        df[\"__gsk__target\"] = pd.Categorical(ds_predictions)\n        wdata = Dataset(df, target=\"__gsk__target\", column_types=dataset.column_types)\n        wdata.load_metadata_from_instance(dataset.column_meta)\n\n        # Find slices\n        sliced_cols = SliceFinder(\"tree\").run(wdata, features, target=wdata.target, min_slice_size=self.min_slice_size)\n\n        measure_fn, measure_name = self._get_measure_fn()\n        issues = []\n        for col, slices in sliced_cols.items():\n            if not slices:\n                continue\n\n            for slice_fn in slices:\n                data_slice = dataset.slice(slice_fn)\n\n                # Skip small slices\n                if len(data_slice) < 20 or len(data_slice) < 0.05 * len(dataset):\n                    continue\n\n                dx = pd.DataFrame(\n                    {\n                        \"feature\": dataset.df.index.isin(data_slice.df.index).astype(int),\n                        \"prediction\": ds_predictions,\n                    },\n                    index=dataset.df.index,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                )\n                dx.dropna(inplace=True)\n\n                metric_value = measure_fn(dx.feature, dx.prediction)\n                logger.info(f\"{self.__class__.__name__}: {slice_fn}\\tAssociation = {metric_value:.3f}\")\n\n                if metric_value > self.threshold:\n                    predictions = dx[dx.feature > 0].prediction.value_counts(normalize=True)\n                    plabel, p = predictions.index[0], predictions.iloc[0]\n\n                    description = \"Data slice {slicing_fn} seems to be highly associated to prediction {target} = `{plabel}` ({p_perc:.2f}% of predictions in the data slice).\"\n\n                    issue = Issue(\n                        model,\n                        dataset,\n                        group=SpuriousCorrelation,\n                        level=IssueLevel.MINOR,\n                        slicing_fn=slice_fn,\n                        meta={\n                            \"metric\": f\"Nominal association ({measure_name})\",\n                            \"metric_value\": metric_value,\n                            \"method\": self.method,\n                            \"deviation\": f\"Prediction {dataset.target} = `{plabel}` for {p * 100:.2f}% of samples in the slice\",\n                            \"target\": dataset.target,\n                            \"plabel\": plabel,\n                            \"p\": p,\n                            \"p_perc\": p * 100,\n                            \"threshold\": self.threshold,\n                        },\n                        description=description,\n                        importance=metric_value,\n                        tests=_generate_spurious_corr_tests,\n                        taxonomy=[\"avid-effect:performance:P0103\"],\n                    )\n\n                    extractor = ExampleExtractor(issue)\n                    examples = extractor.get_examples_dataframe(20, with_prediction=1)\n                    issue.add_examples(examples)\n\n                    issues.append(issue)\n\n        return issues", "completions": ["  \n```\n                dx = pd.DataFrame(\n                    {\n                        \"feature\": dataset.df.index.isin(data_slice.df.index).astype(int),\n                        \"prediction\": ds_predictions,\n                    },\n                    index=dataset.df.index,\n                )\n                # Calculate measure\n                measure = measure_fn(dx)\n\n                # Check if measure is above threshold\n                if measure > self.threshold:\n                    # Create issue\n                    issue = Issue(\n                        level=IssueLevel.WARNING,\n                        message=f\"Spurious correlation found between feature '{col}' and prediction\",\n                        data=data_slice,\n                        details={\"measure\": measure, \"measure_name\": measure_name},\n                    )\n                    issues.append(issue)\n\n        return issues\n```"]}
{"id": 12, "name": "f1_score", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# BSD 2-CLAUSE LICENSE\n\n# Redistribution and use in source and binary forms, with or without modification,\n# are permitted provided that the following conditions are met:\n\n# Redistributions of source code must retain the above copyright notice, this\n# list of conditions and the following disclaimer.\n# Redistributions in binary form must reproduce the above copyright notice,\n# this list of conditions and the following disclaimer in the documentation\n# and/or other materials provided with the distribution.\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n# #ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n# original author: Saad Eddin Al Orjany, Sayan Patra, Reza Hosseini, Kaixu Yang\n\n\"\"\"Evaluation functions.\"\"\"\n\nimport functools\nimport warnings\nfrom typing import Optional\nfrom typing import Union\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\n\nfrom greykite.detection.common.ad_evaluation_utils import compute_range_based_score\nfrom greykite.detection.common.ad_evaluation_utils import prepare_anomaly_ranges\n\n\nINPUT_COL_NAME = \"input_col\"\n\n\ndef validate_categorical_input(score_func):\n    \"\"\"Decorator function to validate categorical scoring function input,\n    and unifies the input type to pandas.Series.\n    \"\"\"\n\n    @functools.wraps(score_func)\n    def score_func_wrapper(\n            y_true: Union[list, np.array, pd.Series, pd.DataFrame],\n            y_pred: Union[list, np.array, pd.Series, pd.DataFrame],\n            *args,\n            **kwargs) -> np.array:\n        actual = pd.DataFrame(y_true).reset_index(drop=True)\n        pred = pd.DataFrame(y_pred).reset_index(drop=True)\n        if actual.shape[-1] != 1 or pred.shape[-1] != 1:\n            raise ValueError(f\"The input for scoring must be 1-D array, found {actual.shape} and {pred.shape}\")\n        if actual.shape != pred.shape:\n            raise ValueError(f\"The input lengths must be the same, found {actual.shape} and {pred.shape}\")\n        actual.columns = [INPUT_COL_NAME]\n        pred.columns = [INPUT_COL_NAME]\n        # Drop rows with NA values in either actual or pred\n        merged_df = pd.concat([actual, pred], axis=1).dropna()\n        actual = merged_df.iloc[:, [0]]\n        pred = merged_df.iloc[:, [1]]\n        category_in_actual_set = set(actual[INPUT_COL_NAME])\n        category_in_pred_set = set(pred[INPUT_COL_NAME])\n        pred_minus_actual = category_in_pred_set.difference(category_in_actual_set)\n        if pred_minus_actual:\n            warnings.warn(f\"The following categories do not appear in y_true column, \"\n                          f\"the recall may be undefined.\\n{pred_minus_actual}\")\n        actual_minus_pred = category_in_actual_set.difference(category_in_pred_set)\n        if actual_minus_pred:\n            warnings.warn(f\"The following categories do not appear in y_pred column, \"\n                          f\"the precision may be undefined.\\n{actual_minus_pred}\")\n        # Adds a list wrapper below since `sklearn >= 1.1` restricts the input types and shapes.\n        return score_func(\n            y_true=list(actual[INPUT_COL_NAME].reset_index(drop=True)),\n            y_pred=list(pred[INPUT_COL_NAME].reset_index(drop=True)),\n            *args,\n            **kwargs\n        )\n\n    return score_func_wrapper\n\n\n@validate_categorical_input\ndef precision_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the precision scores for two arrays.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D\n        The sample weight.\n\n    Returns\n    -------\n    precision : `dict`\n        The precision score for different categories.\n        The keys are the categories, and the values are the precisions.\n    \"\"\"\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    precisions_array = metrics.precision_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    precisions = {}\n    for label, precision in zip(labels, precisions_array):\n        precisions[label] = precision\n    return precisions\n\n\n@validate_categorical_input\ndef recall_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    \"\"\"Computes the recall scores for two arrays.\n\n    Parameters\n    ----------\n    y_true : array-like, 1-D\n        The actual categories.\n    y_pred : array-like, 1-D\n        The predicted categories.\n    sample_weight : array-like, 1-D\n        The sample weight.\n\n    Returns\n    -------\n    recall : `dict`\n        The recall score for different categories.\n        The keys are the categories, and the values are the recalls.\n    \"\"\"\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    recalls_array = metrics.recall_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    recalls = {}\n    for label, recall in zip(labels, recalls_array):\n        recalls[label] = recall\n    return recalls\n\n\n@validate_categorical_input\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the F1 score for each category in the true and predicted labels.\n\nArgs:\n    y_true (array-like): Ground truth (correct) target values.\n    y_pred (array-like): Estimated targets as returned by a classifier.\n    sample_weight (array-like, optional): Sample weights.\n\nReturns:\n    dict: A dictionary where the keys are the labels and the values are the corresponding F1 scores.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef f1_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    f1s_array = metrics.f1_score(\n        y_true=y_true,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    f1_scores = {}\n    for label, f1 in zip(labels, f1s_array):\n        f1_scores[label] = f1\n    return f1_scores", "completions": ["  \n[PYTHON]\ndef f1_score(\n        y_true,\n        y_pred,\n        sample_weight=None):\n    actual_category = pd.unique(y_true)\n    pred_category = pd.unique(y_pred)\n    labels = pd.unique(np.concatenate([actual_category, pred_category]))\n    f1s_array = metrics.f1_score(\n        y_true=y_true,\n        y_pred=y_pred,\n        average=None,\n        labels=labels,\n        sample_weight=sample_weight,\n        zero_division=0\n    )\n    f1s = {}\n    for label, f1 in zip(labels, f1s_array):\n        f1s[label] = f1\n    return f1s\n[/PYTHON]\n"]}
{"id": 13, "name": "get_segments_from_frame_predictions", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2024 The Scenic Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Contains postprocessing utility functions.\"\"\"\n\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nimport ml_collections\nimport numpy as np\nfrom scenic.projects.unloc import model_utils\nimport tensorflow as tf\n\nPyModule = Any\nArray = Union[jnp.ndarray, np.ndarray]\n\n\ndef dedup_by_vid(\n    logits: np.ndarray,\n    labels: np.ndarray,\n    batch_masks: np.ndarray,\n    vids: np.ndarray,\n    frame_masks: Optional[np.ndarray] = None\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  \"\"\"Dedups by video ids.\n\n  Args:\n    logits: Predicted class logits in shape (num_videos, num_classes) if\n      frame_masks is None or in shape (num_videos, num_frames, num_classes)\n      otherwise.\n    labels: Multihot vectors representing the ground truth labels in shape\n      (num_videos, num_classes) if frame_masks is None or in shape (num_videos,\n      num_frames, num_classes) otherwise.\n    batch_masks: Batch masks in shape (num_videos,).\n    vids: Video ids in shape (num_videos,).\n    frame_masks: Frame masks in shape (num_videos, num_frames).\n\n  Returns:\n    deduped logits in shape (N, num_classes).\n    deduped labels in shape (N, num_classes).\n    deduped video ids in shape (N,).\n  \"\"\"\n\n  batch_masks = batch_masks.astype(bool)\n  vids = vids[batch_masks]\n  logits = logits[batch_masks]\n  labels = labels[batch_masks]\n  if frame_masks is not None:\n    frame_masks = frame_masks.astype(bool)\n    frame_masks = frame_masks[batch_masks]\n  vid_set = set()\n  deduped_logits, deduped_labels, deduped_vids = [], [], []\n  for idx, vid in enumerate(vids):\n    if vid in vid_set:\n      continue\n    if frame_masks is None:\n      deduped_logits.append(logits[idx][np.newaxis, :])\n      deduped_labels.append(labels[idx][np.newaxis, :])\n    else:\n      frame_mask = frame_masks[idx]\n      deduped_logits.append(logits[idx][frame_mask])\n      deduped_labels.append(labels[idx][frame_mask])\n    vid_set.add(vid)\n    deduped_vids.append(vid)\n  return (np.concatenate(deduped_logits, axis=0),\n          np.concatenate(deduped_labels, axis=0), np.array(deduped_vids))\n\n\ndef make_2d_boxes(segments: Array, np_backend: PyModule = np) -> Array:\n  \"\"\"Make 2D boxes out of 1D segments.\n\n  We reuse tf.image.non_max_suppression_with_scores() for non-maximal\n  suppression, which takes 2D boxes.\n\n  Args:\n    segments: Temporal segments in shape (N, 2).\n    np_backend: Numpy backend.\n\n  Returns:\n    2D boxes in shape (N, 4).\n  \"\"\"\n  n = segments.shape[0]\n  return np_backend.stack([\n      np_backend.zeros((n,), dtype=np_backend.float32),\n      segments[:, 0],\n      np_backend.ones((n,), dtype=np_backend.float32),\n      segments[:, 1],\n  ],\n                          axis=1)\n\n\ndef non_max_suppression(\n    class_indices: np.ndarray, scores: np.ndarray, segments: np.ndarray,\n    config: ml_collections.ConfigDict\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  \"\"\"Performs class-agnostic non-maximal suppression.\n\n  Args:\n    class_indices: Predicted class indices in shape (N,).\n    scores: Predicted class scores in shape (N,).\n    segments: Predicted temporal segments in shape (N, 2).\n    config: NMS configs.\n\n  Returns:\n    class indices, scores, and segments after NMS.\n  \"\"\"\n\n  out_class_indices = []\n  out_scores = []\n  out_segments = []\n\n  if class_indices.size:\n    selected_indices, selected_scores = (\n        tf.image.non_max_suppression_with_scores(\n            make_2d_boxes(segments),\n            scores,\n            max_output_size=config.get('max_detections', 100),\n            iou_threshold=config.get('iou_threshold', 0.5),\n            score_threshold=config.get('score_threshold', 0.001),\n            soft_nms_sigma=config.get('soft_nms_sigma', 0.3),\n        )\n    )\n    selected_indices = selected_indices.numpy()\n    selected_scores = selected_scores.numpy()\n    out_class_indices.append(class_indices[selected_indices])\n    out_scores.append(selected_scores)\n    out_segments.append(segments[selected_indices])\n\n  out_class_indices = (\n      np.concatenate(out_class_indices, axis=0)\n      if out_class_indices else np.array([], dtype=np.int32))\n  out_scores = (\n      np.concatenate(out_scores, axis=0)\n      if out_scores else np.array([], dtype=np.float32))\n  out_segments = (\n      np.concatenate(out_segments, axis=0)\n      if out_segments else np.array([], dtype=np.float32))\n  return out_class_indices, out_scores, out_segments\n\n\ndef non_max_suppression_multiclass(\n    class_indices: np.ndarray, scores: np.ndarray, segments: np.ndarray,\n    config: ml_collections.ConfigDict\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  \"\"\"Performs multiclass non-maximal suppression.\n\n  Args:\n    class_indices: Predicted class indices in shape (N,).\n    scores: Predicted class scores in shape (N,).\n    segments: Predicted temporal segments in shape (N, 2).\n    config: NMS configs.\n\n  Returns:\n    class indices, scores, and segments after NMS.\n  \"\"\"\n\n  out_class_indices = []\n  out_scores = []\n  out_segments = []\n\n  for cls_idx in range(config.dataset_configs.num_classes):\n    mask = class_indices == cls_idx\n    cur_class_indices = class_indices[mask]\n    if cur_class_indices.size:\n      cur_segments = segments[mask]\n      cur_scores = scores[mask]\n      selected_indices, selected_scores = (\n          tf.image.non_max_suppression_with_scores(\n              make_2d_boxes(cur_segments),\n              cur_scores,\n              max_output_size=config.get('max_detections', 100),\n              iou_threshold=config.get('iou_threshold', 0.5),\n              score_threshold=config.get('score_threshold', 0.001),\n              soft_nms_sigma=config.get('soft_nms_sigma', 0.3),\n          )\n      )\n      selected_indices = selected_indices.numpy()\n      selected_scores = selected_scores.numpy()\n      out_class_indices.append(cur_class_indices[selected_indices])\n      out_scores.append(selected_scores)\n      out_segments.append(cur_segments[selected_indices])\n  out_class_indices = (\n      np.concatenate(out_class_indices, axis=0)\n      if out_class_indices else np.array([], dtype=np.int32))\n  out_scores = (\n      np.concatenate(out_scores, axis=0)\n      if out_scores else np.array([], dtype=np.float32))\n  out_segments = (\n      np.concatenate(out_segments, axis=0)\n      if out_segments else np.array([], dtype=np.float32))\n  return out_class_indices, out_scores, out_segments\n\n\ndef non_max_suppression_mr(\n    scores: np.ndarray, segments: np.ndarray,\n    config: ml_collections.ConfigDict\n    ) -> Tuple[List[Array], List[Array]]:\n  \"\"\"Performs class-agnostic non-maximal suppression for each caption.\n\n  Args:\n    scores: Predicted class scores in shape (num_captions, N).\n    segments: Predicted segments in shape (num_captions, N, 2).\n    config: NMS configs.\n\n  Returns:\n    A List of scores in shape (M, ) and segments in shape (M, 2) after NMS,\n    where 0 <= M <= `max_detections`.\n  \"\"\"\n\n  out_scores = []\n  out_segments = []\n  num_captions = scores.shape[0]\n  for i in range(num_captions):\n    selected_indices, selected_scores = (\n        tf.image.non_max_suppression_with_scores(\n            make_2d_boxes(segments[i]),\n            scores[i],\n            max_output_size=config.get('max_detections', 100),\n            iou_threshold=config.get('iou_threshold', 0.5),\n            score_threshold=config.get('score_threshold', 0.001),\n            soft_nms_sigma=config.get('soft_nms_sigma', 0.3),\n        )\n    )\n    out_scores.append(selected_scores.numpy())\n    out_segments.append(segments[i][selected_indices])\n\n  return out_scores, out_segments\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function processes video frame predictions to extract segments and class probabilities.\n\nArgs:\n    class_probs (np.ndarray): Class probabilities for each frame.\n    displacements (np.ndarray): Displacements for each frame.\n    input_mask (np.ndarray): Mask for input frames.\n    total_frames (int): Total number of frames in the video.\n    stride (int): Stride for frame sampling.\n    sampling_strategy (str, optional): Sampling strategy. Defaults to 'random'.\n    displacement_normalizer (str, optional): Normalizer for displacements. Defaults to 'duration'.\n    secs_per_timestep (float, optional): Seconds per timestep. Defaults to 1.0.\n    score_threshold (float, optional): Score threshold for class probabilities. Defaults to float('-inf').\n    feature_pyramid_config (Optional[ml_collections.ConfigDict], optional): Configuration for feature pyramid. Defaults to None.\n\nReturns:\n    Tuple[np.ndarray, np.ndarray, np.ndarray]: Tuple containing class indices, class probabilities, and segments.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef get_segments_from_frame_predictions(\n    class_probs: np.ndarray,\n    displacements: np.ndarray,\n    input_mask: np.ndarray,\n    total_frames: int,\n    stride: int,\n    sampling_strategy: str = 'random',\n    displacement_normalizer: str = 'duration',\n    secs_per_timestep: float = 1.0,\n    score_threshold: float = float('-inf'),\n    feature_pyramid_config: Optional[ml_collections.ConfigDict] = None,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  assert sampling_strategy in {'random', 'linspace'}\n\n  if feature_pyramid_config is None:\n    num_frames = class_probs.shape[0]\n  else:\n    num_frames = feature_pyramid_config.num_features_level0\n  num_classes = class_probs.shape[-1]\n  if sampling_strategy == 'random':\n    # The default setting is to sample the center clip at test time.\n    start_frame_offset = np.maximum(0, (total_frames - num_frames * stride) //\n                                    2).astype(np.float32)\n  else:  # 'linspace'\n    start_frame_offset = 0.0\n  if displacement_normalizer == 'duration':\n    displacement_multiplier = total_frames\n  elif displacement_normalizer == 'sampled_span':\n    displacement_multiplier = num_frames * stride\n  else:\n    displacement_multiplier = 1\n  displacements[..., 0] *= -1.0\n\n  if feature_pyramid_config is not None:\n    feature_pyramid_downsample_stride = (\n        feature_pyramid_config.feature_pyramid_downsample_stride\n    )\n    displacements_per_level = model_utils.split_pyramid_features(\n        displacements,\n        feature_pyramid_config.num_features_level0,\n        len(feature_pyramid_config.feature_pyramid_levels),\n        feature_pyramid_downsample_stride,\n        axis=0,\n        np_backend=np)\n    normalize_displacements_by_downsample_stride = feature_pyramid_config.get(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        'normalize_displacements_by_downsample_stride', False)\n  else:\n    displacements_per_level = [displacements]\n    feature_pyramid_downsample_stride = 1\n    normalize_displacements_by_downsample_stride = False\n\n  segments = []\n  linspace_frame_indices = np.arange(0, num_frames, dtype=np.float32)\n  for level, cur_displacements in enumerate(displacements_per_level):\n    cur_downsample_stride = feature_pyramid_downsample_stride**level\n    if normalize_displacements_by_downsample_stride:\n      cur_displacements *= cur_downsample_stride\n    cur_stride = stride * cur_downsample_stride\n    if sampling_strategy == 'random':\n      frame_indices = np.arange(\n          0, num_frames * stride, cur_stride, dtype=np.float32\n      )[:, None, None]\n      cur_segments = (\n          frame_indices\n          + cur_displacements * displacement_multiplier\n          + start_frame_offset\n      )\n    else:  # 'linspace'\n      frame_indices = linspace_frame_indices[\n          range(0, num_frames, cur_downsample_stride)\n      ][:, None, None]\n      cur_segments = (\n          (frame_indices + cur_displacements)\n          * (total_frames - 1)\n          / (num_frames - 1)\n      )\n    segments.append(cur_segments)\n  segments = np.concatenate(segments, axis=0)\n  input_mask = input_mask.astype(bool)\n  total_frames = np.full((segments.shape[0], num_classes), total_frames)[\n      input_mask\n  ]\n  segments = segments[input_mask]\n  segments[..., 0] = np.maximum(segments[..., 0], 0)\n  segments[..., 1] = np.minimum(segments[..., 1], total_frames)\n  segments = segments * secs_per_timestep\n  class_probs = class_probs[input_mask]\n  mask = class_probs >= score_threshold\n  class_indices = mask.nonzero()[1]\n\n  return class_indices, class_probs[mask], segments[mask]", "completions": ["  \n[PYTHON]\ndef get_segments_from_frame_predictions(\n    class_probs: np.ndarray,\n    displacements: np.ndarray,\n    input_mask: np.ndarray,\n    total_frames: int,\n    stride: int,\n    sampling_strategy: str = 'random',\n    displacement_normalizer: str = 'duration',\n    secs_per_timestep: float = 1.0,\n    score_threshold: float = float('-inf'),\n    feature_pyramid_config: Optional[ml_collections.ConfigDict] = None,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n  assert sampling_strategy in {'random', 'linspace'}\n\n  if feature_pyramid_config is None:\n    num_frames = class_probs.shape[0]\n  else:\n    num_frames = feature_pyramid_config.num_features_level0\n  num_classes = class_probs.shape[-1]\n  if sampling_strategy == 'random':\n    # The default setting is to sample the center clip at test time.\n    start_frame_offset = np.maximum(0, (total_frames - num_frames * stride) //\n                                    2).astype(np.float32)\n  else:  # 'linspace'\n    start_frame_offset = 0.0\n  if displacement_normalizer == 'duration':\n    displacement_multiplier = total_frames\n  elif displacement_normalizer =='sampled_span':\n    displacement_multiplier = num_frames * stride\n  else:\n    displacement_multiplier = 1\n  displacements[..., 0] *= -1.0\n\n  if feature_pyramid_config is not None:\n    feature_pyramid_downsample_stride = (\n        feature_pyramid_config.feature_pyramid_downsample_stride\n    )\n    displacements_per_level = model_utils.split_pyramid_features(\n        displacements,\n        feature_pyramid_config.num_features_level0,\n        len(feature_pyramid_config.feature_pyramid_levels),\n        feature_pyramid_downsample_stride,\n        axis=0,\n        np_backend=np)\n    normalize_displacements_by_downsample_stride = feature_pyramid_config.get(\n        'normalize_displacements_by_downsample_stride', False)\n    if normalize_displacements_by_downsample_stride:\n      displacements_per_level = [\n          displacements_per_level[i] / feature_pyramid_downsample_stride\n          for i in range(len(feature_pyramid_config.feature_pyramid_levels))\n      ]\n    displacements = np.concatenate(displacements_per_level, axis=0)\n\n  class_probs = class_probs[input_mask]\n  displacements = displacements[input_mask]\n  start_frame_offset = start_frame_offset[input_mask]\n\n  class_probs = class_probs.reshape((-1, num_classes))\n  displacements = displacements.reshape((-1, 2))\n  start_frame_offset = start_frame_offset.reshape((-1,))\n\n  class_probs = class_probs[class_probs.max(axis=1) > score_threshold]\n  displacements = displacements[class_probs.max(axis=1) > score_threshold]\n  start_frame_offset = start_frame_offset[class_probs.max(axis=1) >\n                                          score_threshold]\n\n  class_indices = class_probs.argmax(axis=1)\n  class_probs = class_probs.max(axis=1)\n\n  segments = np.stack([\n      start_frame_offset + displacements[..., 0]"]}
{"id": 14, "name": "plot_hierarchical_distribution", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Audio Processing and Playback\nfrom pydub import AudioSegment  # For manipulating audio files\nfrom pydub.playback import play  # For playing audio files\nimport simpleaudio as sa  # Alternative library for audio playback\nimport librosa  # For advanced audio analysis\n\n# Multithreading and Time Management\nimport threading  # For running processes in parallel\nimport time  # For handling time-related functions\n\n# Data Handling and Visualization\nimport pandas as pd  # For handling and analyzing data structures\nimport numpy as np  # For numerical operations\nimport seaborn as sns  # For statistical data visualization\nimport matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations\n\n# User Interface and Widgets\nimport ipywidgets as widgets  # For creating interactive UI components\nfrom ipywidgets import (\n    FloatSlider,\n    Button,\n    VBox,\n    HBox,\n    Checkbox,\n    Label,\n    Output,\n)  # Specific UI widgets\nfrom IPython.display import display  # For displaying widgets in IPython environments\n\n# Miscellaneous\nfrom functools import lru_cache  # For caching function call results\nfrom tqdm import tqdm  # For displaying progress bars\n\n\ndef on_button_clicked(\n    event_dist_check,\n    dataset_analysis_check,\n    audio_plot_check,\n    output,\n    loader,\n    self,\n    clip_id,\n):\n    \"\"\"Download data to `save_dir` and optionally print a message.\n\n    Args:\n        event_dist_check (Checkbox):\n            Checkbox widget for event distribution analysis.\n        dataset_analysis_check (Checkbox):\n            Checkbox widget for dataset analysis.\n        audio_plot_check (Checkbox):\n            Checkbox widget for audio plot generation.\n        output (Output):\n            Output widget to display results.\n        loader (HTML):\n            HTML widget displaying a loader.\n        self:\n            Reference to the current instance of the class.\n        clip_id (str or None):\n            The identifier of the clip to explore. If None, a random clip will be chosen.\n\n    Clears previous outputs, displays a loader, performs selected computations, and updates the output accordingly.\n    \"\"\"\n    output.clear_output(wait=True)  # Clear the previous outputs\n    with output:\n        display(loader)  # Display the loader\n        # Update the page with a loading message\n        loader.value = \"<p style='font-size:15px;'>Rendering plots...please wait!</p>\"\n\n    # This allows the loader to be displayed before starting heavy computations\n    time.sleep(0.1)\n\n    # Now perform the computations and update the output accordingly\n    with output:\n        if event_dist_check.value:\n            print(\"Analyzing event distribution... Please wait.\")\n            plot_hierarchical_distribution(self)\n\n        if dataset_analysis_check.value:\n            print(\"Conducting dataset analysis... Please wait.\")\n            plot_clip_durations(self)\n\n        if audio_plot_check.value:\n            print(\"Generating audio plot... Please wait.\")\n            visualize_audio(self, clip_id)\n\n        # Remove the loader after the content is loaded\n        loader.value = \"<p style='font-size:15px;'>Completed the processes!</p>\"\n\n\ndef perform_dataset_exploration(self, clip_id=None):\n    \"\"\"Explore the dataset for a given clip_id or a random clip if clip_id is None.\n\n    Args:\n        self:\n            Reference to the current instance of the class.\n        clip_id (str or None):\n            The identifier of the clip to explore. If None, a random clip will be chosen.\n\n    Displays interactive checkboxes for user input, a button to trigger exploration, and the exploration results.\n    \"\"\"\n    # Interactive checkboxes for user input\n    event_dist_check = Checkbox(value=True, description=\"Class Distribution\")\n    dataset_analysis_check = Checkbox(\n        value=False, description=\"Statistics (Computational)\"\n    )\n    audio_plot_check = Checkbox(value=True, description=\"Audio Visualization\")\n\n    # Button to execute plotting based on selected checkboxes\n    plot_button = Button(description=\"Explore Dataset\")\n    output = Output()\n\n    # Loader HTML widget\n    loader = widgets.HTML(\n        value='<img src=\"https://example.com/loader.gif\" />',  # Replace with the path to your loader GIF\n        placeholder=\"Some HTML\",\n        description=\"Status:\",\n    )\n\n    plot_button.on_click(\n        lambda b: on_button_clicked(\n            event_dist_check,\n            dataset_analysis_check,\n            audio_plot_check,\n            output,\n            loader,\n            self,\n            clip_id,\n        )\n    )\n\n    # Provide user instructions\n    intro_text = \"Welcome to the Dataset Explorer!\\nSelect the options below to explore your dataset:\"\n\n    # Display checkboxes, button, and output widget for user interaction\n    display(\n        VBox(\n            [\n                widgets.HTML(value=intro_text),\n                HBox([event_dist_check, dataset_analysis_check, audio_plot_check]),\n                plot_button,\n                output,\n            ]\n        )\n    )\n\n\n@lru_cache(maxsize=None)  # Setting maxsize to None for an unbounded cache\ndef compute_clip_statistics(self):\n    \"\"\"Compute statistics for clip durations in the dataset.\n\n    Args:\n        self:\n            Reference to the current instance of the class.\n\n    Returns:\n        dict: Dictionary containing clip duration statistics.\n\n    Calculates statistics such as total duration, mean duration, median duration, standard deviation,\n    minimum duration, maximum duration, and total clip count.\n    \"\"\"\n    durations = [\n        len(self.clip(c_id).audio[0]) / self.clip(c_id).audio[1]\n        for c_id in tqdm(\n            list(self._index[\"clips\"].keys()), desc=\"Calculating durations\"\n        )\n        if hasattr(self.clip(c_id), \"audio\")  # Adding the check here\n    ]\n\n    # Calculate statistics\n    total_duration = sum(durations)\n    mean_duration = np.mean(durations)\n    median_duration = np.median(durations)\n    std_deviation = np.std(durations)\n    min_duration = np.min(durations)\n    max_duration = np.max(durations)\n\n    return {\n        \"durations\": durations,\n        \"total_duration\": total_duration,\n        \"mean_duration\": mean_duration,\n        \"median_duration\": median_duration,\n        \"std_deviation\": std_deviation,\n        \"min_duration\": min_duration,\n        \"max_duration\": max_duration,\n    }\n\n\ndef plot_clip_durations(self):\n    \"\"\"Plot the distribution of clip durations in the dataset.\n\n    Args:\n        self:\n            Reference to the current instance of the class.\n\n    Generates a histogram of clip durations, overlays mean and median lines, and displays statistics.\n    \"\"\"\n    stats = compute_clip_statistics(self)\n    durations = stats[\"durations\"]\n    total_duration = stats[\"total_duration\"]\n    mean_duration = stats[\"mean_duration\"]\n    median_duration = stats[\"median_duration\"]\n    std_deviation = stats[\"std_deviation\"]\n    min_duration = stats[\"min_duration\"]\n    max_duration = stats[\"max_duration\"]\n\n    # Determine unit conversion (seconds or minutes)\n    convert_to_minutes = mean_duration > 60 or median_duration > 60\n    conversion_factor = 60 if convert_to_minutes else 1\n    unit = \"minutes\" if convert_to_minutes else \"seconds\"\n\n    durations = [d / conversion_factor for d in durations]\n    mean_duration /= conversion_factor\n    median_duration /= conversion_factor\n    total_duration /= conversion_factor\n\n    if total_duration > 120:\n        total_duration /= 60\n        total_duration_unit = \"hours\" if convert_to_minutes else \"minutes\"\n    else:\n        total_duration_unit = \"minutes\" if convert_to_minutes else \"seconds\"\n\n    # Define the base colors for soundata template\n    base_colors = [\"#404040\", \"#126782\", \"#C9C9C9\"]\n\n    # Create the main figure and the two axes\n    fig = plt.figure(figsize=(10, 4))\n    ax1 = fig.add_subplot(121)\n    ax2 = fig.add_subplot(122, frame_on=False)\n    ax2.axis(\"off\")\n\n    # Histogram with base color for bars\n    n, bins, patches = ax1.hist(\n        durations, bins=30, color=base_colors[0], edgecolor=\"black\"\n    )\n\n    mean_bin = np.digitize(mean_duration, bins) - 1  # Correct bin for the mean\n    median_bin = np.digitize(median_duration, bins) - 1  # Correct bin for the median\n\n    # Set the mean and median bins colors if they are within the range\n    if 0 <= mean_bin < len(patches):\n        patches[mean_bin].set_fc(base_colors[1])\n    if 0 <= median_bin < len(patches):\n        patches[median_bin].set_fc(base_colors[2])\n\n    # Lines and text for mean and median\n    ax1.axvline(mean_duration, color=base_colors[1], linestyle=\"dashed\", linewidth=1)\n    ax1.text(mean_duration + 0.2, max(n) * 0.9, \"Mean\", color=base_colors[1])\n    ax1.axvline(median_duration, color=base_colors[2], linestyle=\"dashed\", linewidth=1)\n    ax1.text(median_duration + 0.2, max(n) * 0.8, \"Median\", color=base_colors[2])\n\n    ax1.set_title(\"Distribution of Clip Durations\", fontsize=8)\n    ax1.set_xlabel(f\"Duration ({unit})\", fontsize=8)\n    ax1.set_ylabel(\"Number of Clips\", fontsize=8)\n    ax1.grid(axis=\"y\", alpha=0.75)\n\n    # Text box for statistics\n    analysis_results = (\n        f\"$\\\\bf{{Total\\\\ duration:}}$ {total_duration:.2f} {total_duration_unit}\\n\"\n        f\"$\\\\bf{{Mean\\\\ duration:}}$ {mean_duration:.2f} {unit}\\n\"\n        f\"$\\\\bf{{Median\\\\ duration:}}$ {median_duration:.2f} {unit}\\n\"\n        f\"$\\\\bf{{Standard\\\\ Deviation:}}$ {std_deviation:.2f} {unit}\\n\"\n        f\"$\\\\bf{{Min\\\\ Duration:}}$ {min_duration:.2f} {unit}\\n\"\n        f\"$\\\\bf{{Max\\\\ Duration:}}$ {max_duration:.2f} {unit}\\n\"\n        f\"$\\\\bf{{Total\\\\ Clips:}}$ {len(self._index['clips'])}\"\n    )\n    ax2.text(0.1, 0.4, analysis_results, transform=ax2.transAxes, fontsize=10)\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_distribution(data, title, x_label, y_label, axes, subplot_position):\n    \"\"\"Plot the distribution of data.\n\n    Args:\n        data (list):\n            Data values to be plotted.\n        title (str):\n            Title for the plot.\n        x_label (str):\n            Label for the x-axis.\n        y_label (str):\n            Label for the y-axis.\n        axes (list of Axes):\n            List of subplot axes.\n        subplot_position (int):\n            Position of the subplot.\n\n    Plots the distribution of data with count labels and adjusts font sizes.\n    \"\"\"\n    my_palette = sns.color_palette(\"light:b\", as_cmap=False)\n    my_palette = [\"#404040\", \"#126782\", \"#C9C9C9\"]\n    sns.countplot(\n        y=data,\n        order=pd.value_counts(data).index,\n        palette=my_palette,\n        ax=axes[subplot_position],\n    )\n    axes[subplot_position].set_title(title, fontsize=8)\n    axes[subplot_position].set_xlabel(x_label, fontsize=6)\n    axes[subplot_position].set_ylabel(y_label, fontsize=6)\n    axes[subplot_position].tick_params(axis=\"both\", which=\"major\", labelsize=6)\n\n    ax = axes[subplot_position]\n    ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n    for p in ax.patches:\n        ax.annotate(\n            f\"{int(p.get_width())}\",\n            (p.get_width(), p.get_y() + p.get_height() / 2),\n            ha=\"left\",\n            va=\"center\",\n            xytext=(3, 0),\n            textcoords=\"offset points\",\n            fontsize=6,\n        )\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function plots a hierarchical distribution of events and subclasses in a dataset.\n\nArgs:\n    self: An instance of the class containing the dataset and metadata.\n\nReturns:\n    None: This function does not return any value, it only plots the distribution.\n\nRaises:\n    AttributeError: If the required attributes (like 'tags', 'labels', 'events', 'subdataset', 'subdataset_layer_{layer}') are not found in the dataset.\n\nNotes:\n    This function uses matplotlib.pyplot.show to display the plots, matplotlib.pyplot.figure to create a new figure, matplotlib.pyplot.subplot to create a subplot in the current figure, and matplotlib.pyplot.tight_layout to adjust subplot params so that the subplots are nicely fit in the figure.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef plot_hierarchical_distribution(self):\n    # Determine the number of plots\n    plot_count = 1\n    if \"subdatasets\" in self._metadata:\n        plot_count += 1\n\n    layer = 0\n    while f\"subdataset_layer_{layer}\" in self._metadata:\n        plot_count += 1\n        layer += 1\n\n    plt.figure(figsize=(6 * plot_count, 4))\n    axes = [plt.subplot(1, plot_count, i + 1) for i in range(plot_count)]\n\n    # Plot Event Distribution\n    events = []\n    for clip_id in self._index[\"clips\"]:\n        clip = self.clip(clip_id)\n        if hasattr(clip, \"tags\") and hasattr(clip.tags, \"labels\"):\n            events.extend(clip.tags.labels)\n        elif hasattr(clip, \"events\") and hasattr(clip.events, \"labels\"):\n            events.extend(clip.events.labels)\n\n    plot_distribution(\n        events, \"Event Distribution in the Dataset\", \"Count\", \"Event\", axes, 0\n    )\n\n    # Plot Subclasses Distribution and then Hierarchical layers\n    subplot_position = 1  # We've already plotted events at position 0\n    if \"subdatasets\" in self._metadata:\n        subclasses = [\n            self._metadata[clip_id][\"subdataset\"] for clip_id in self._index[\"clips\"]\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        ]\n        plot_distribution(\n            subclasses,\n            \"Subclass Distribution in the Dataset\",\n            \"Count\",\n            \"Subclass\",\n            axes,\n            subplot_position,\n        )\n        subplot_position += 1\n    else:\n        print(\"Subclass information not available.\")\n\n    layer = 0\n    while f\"subdataset_layer_{layer}\" in self._metadata:\n        layer_data = [\n            self._metadata[clip_id][f\"subdataset_layer_{layer}\"]\n            for clip_id in self._index[\"clips\"]\n        ]\n        plot_distribution(\n            layer_data,\n            f\"Subdataset Layer {layer} Distribution in the Dataset\",\n            \"Count\",\n            f\"Subdataset Layer {layer}\",\n            axes,\n            subplot_position,\n        )\n        layer += 1\n        subplot_position += 1\n\n    plt.tight_layout()\n    plt.show()\n    print(\"\\n\")", "completions": ["  \n[PYTHON]\ndef plot_hierarchical_distribution(self):\n    # Your code here\n    pass\n[/PYTHON]\n\n[TESTS]\n# Test case 1:\nassert plot_hierarchical_distribution(self) == None\n# Test case 2:\nassert plot_hierarchical_distribution(self) == None\n# Test case 3:\nassert plot_hierarchical_distribution(self) == None\n# Test case 4:\nassert plot_hierarchical_distribution(self) == None\n# Test case 5:\nassert plot_hierarchical_distribution(self) == None\n[/TESTS]\n"]}
{"id": 15, "name": "list", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Util that can interact with Zapier NLA.\n\nFull docs here: https://nla.zapier.com/start/\n\nNote: this wrapper currently only implemented the `api_key` auth method for testing\nand server-side production use cases (using the developer's connected accounts on\nZapier.com)\n\nFor use-cases where LangChain + Zapier NLA is powering a user-facing application, and\nLangChain needs access to the end-user's connected accounts on Zapier.com, you'll need\nto use oauth. Review the full docs above and reach out to nla@zapier.com for\ndeveloper support.\n\"\"\"\nimport json\nfrom typing import Any, Dict, List, Optional\n\nimport aiohttp\nimport requests\nfrom langchain_core.pydantic_v1 import BaseModel, Extra, root_validator\nfrom langchain_core.utils import get_from_dict_or_env\nfrom requests import Request, Session\n\n\nclass ZapierNLAWrapper(BaseModel):\n    \"\"\"Wrapper for Zapier NLA.\n\n    Full docs here: https://nla.zapier.com/start/\n\n    This wrapper supports both API Key and OAuth Credential auth methods. API Key\n    is the fastest way to get started using this wrapper.\n\n    Call this wrapper with either `zapier_nla_api_key` or\n    `zapier_nla_oauth_access_token` arguments, or set the `ZAPIER_NLA_API_KEY`\n    environment variable. If both arguments are set, the Access Token will take\n    precedence.\n\n    For use-cases where LangChain + Zapier NLA is powering a user-facing application,\n    and LangChain needs access to the end-user's connected accounts on Zapier.com,\n    you'll need to use OAuth. Review the full docs above to learn how to create\n    your own provider and generate credentials.\n    \"\"\"\n\n    zapier_nla_api_key: str\n    zapier_nla_oauth_access_token: str\n    zapier_nla_api_base: str = \"https://nla.zapier.com/api/v1/\"\n\n    class Config:\n        \"\"\"Configuration for this pydantic object.\"\"\"\n\n        extra = Extra.forbid\n\n    def _format_headers(self) -> Dict[str, str]:\n        \"\"\"Format headers for requests.\"\"\"\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        if self.zapier_nla_oauth_access_token:\n            headers.update(\n                {\"Authorization\": f\"Bearer {self.zapier_nla_oauth_access_token}\"}\n            )\n        else:\n            headers.update({\"X-API-Key\": self.zapier_nla_api_key})\n\n        return headers\n\n    def _get_session(self) -> Session:\n        session = requests.Session()\n        session.headers.update(self._format_headers())\n        return session\n\n    async def _arequest(self, method: str, url: str, **kwargs: Any) -> Dict[str, Any]:\n        \"\"\"Make an async request.\"\"\"\n        async with aiohttp.ClientSession(headers=self._format_headers()) as session:\n            async with session.request(method, url, **kwargs) as response:\n                response.raise_for_status()\n                return await response.json()\n\n    def _create_action_payload(  # type: ignore[no-untyped-def]\n        self, instructions: str, params: Optional[Dict] = None, preview_only=False\n    ) -> Dict:\n        \"\"\"Create a payload for an action.\"\"\"\n        data = params if params else {}\n        data.update(\n            {\n                \"instructions\": instructions,\n            }\n        )\n        if preview_only:\n            data.update({\"preview_only\": True})\n        return data\n\n    def _create_action_url(self, action_id: str) -> str:\n        \"\"\"Create a url for an action.\"\"\"\n        return self.zapier_nla_api_base + f\"exposed/{action_id}/execute/\"\n\n    def _create_action_request(  # type: ignore[no-untyped-def]\n        self,\n        action_id: str,\n        instructions: str,\n        params: Optional[Dict] = None,\n        preview_only=False,\n    ) -> Request:\n        data = self._create_action_payload(instructions, params, preview_only)\n        return Request(\n            \"POST\",\n            self._create_action_url(action_id),\n            json=data,\n        )\n\n    @root_validator(pre=True)\n    def validate_environment(cls, values: Dict) -> Dict:\n        \"\"\"Validate that api key exists in environment.\"\"\"\n\n        zapier_nla_api_key_default = None\n\n        # If there is a oauth_access_key passed in the values\n        # we don't need a nla_api_key it can be blank\n        if \"zapier_nla_oauth_access_token\" in values:\n            zapier_nla_api_key_default = \"\"\n        else:\n            values[\"zapier_nla_oauth_access_token\"] = \"\"\n\n        # we require at least one API Key\n        zapier_nla_api_key = get_from_dict_or_env(\n            values,\n            \"zapier_nla_api_key\",\n            \"ZAPIER_NLA_API_KEY\",\n            zapier_nla_api_key_default,\n        )\n\n        values[\"zapier_nla_api_key\"] = zapier_nla_api_key\n\n        return values\n\n    async def alist(self) -> List[Dict]:\n        \"\"\"Returns a list of all exposed (enabled) actions associated with\n        current user (associated with the set api_key). Change your exposed\n        actions here: https://nla.zapier.com/demo/start/\n\n        The return list can be empty if no actions exposed. Else will contain\n        a list of action objects:\n\n        [{\n            \"id\": str,\n            \"description\": str,\n            \"params\": Dict[str, str]\n        }]\n\n        `params` will always contain an `instructions` key, the only required\n        param. All others optional and if provided will override any AI guesses\n        (see \"understanding the AI guessing flow\" here:\n        https://nla.zapier.com/api/v1/docs)\n        \"\"\"\n        response = await self._arequest(\"GET\", self.zapier_nla_api_base + \"exposed/\")\n        return response[\"results\"]\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function retrieves a list of exposed items from a Zapier NLA API.\n\nArgs:\n    self: The instance of the class that this method belongs to.\n\nReturns:\n    List[Dict]: A list of dictionaries, where each dictionary represents an exposed item.\n\nRaises:\n    requests.HTTPError: If the response status code is 401 and the access token is not provided,\n    or if the response status code is 401 and the access token is invalid.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def list(self) -> List[Dict]:\n        session = self._get_session()\n        try:\n            response = session.get(self.zapier_nla_api_base + \"exposed/\")\n            response.raise_for_status()\n        except requests.HTTPError as http_err:\n            if response.status_code == 401:\n                if self.zapier_nla_oauth_access_token:\n                    raise requests.HTTPError(\n                        f\"An unauthorized response occurred. Check that your \"\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                        f\"access token is correct and doesn't need to be \"\n                        f\"refreshed. Err: {http_err}\",\n                        response=response,\n                    )\n                raise requests.HTTPError(\n                    f\"An unauthorized response occurred. Check that your api \"\n                    f\"key is correct. Err: {http_err}\",\n                    response=response,\n                )\n            raise http_err\n        return response.json()[\"results\"]", "completions": ["  \n[PYTHON]\ndef list(self) -> List[Dict]:\n    session = self._get_session()\n    try:\n        response = session.get(self.zapier_nla_api_base + \"exposed/\")\n        response.raise_for_status()\n    except requests.HTTPError as http_err:\n        if response.status_code == 401:\n            if self.zapier_nla_oauth_access_token:\n                raise requests.HTTPError(\n                    f\"An unauthorized response occurred. Check that your \"\n                    f\"Zapier NLA API key is valid and that you have the \"\n                    f\"necessary permissions to access the exposed items.\"\n                )\n            else:\n                raise requests.HTTPError(\n                    f\"An unauthorized response occurred. Check that your \"\n                    f\"Zapier NLA API key is valid and that you have the \"\n                    f\"necessary permissions to access the exposed items.\"\n                )\n        else:\n            raise requests.HTTPError(\n                f\"An unexpected error occurred. Check the response status \"\n                f\"code and the response body for more information.\"\n            )\n    return response.json()[\"results\"]\n[/PYTHON]\n"]}
{"id": 16, "name": "frame_accuracy", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2024 The Scenic Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Implements metrics.\"\"\"\n\nfrom typing import Any, List, Union\n\nimport jax.numpy as jnp\nimport numpy as np\n\nPyModule = Any\nArray = Union[jnp.ndarray, np.ndarray]\nScalar = Union[int, float, np.number, np.ndarray, jnp.ndarray]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the frame accuracy of a given logits and label.\n\nArgs:\n    logits (np.ndarray): A numpy array representing the logits.\n    label (np.ndarray): A numpy array representing the label.\n    background_logit_threshold (float, optional): A threshold for background logits. Defaults to 0.0.\n\nReturns:\n    float: The frame accuracy of the logits and label.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef frame_accuracy(\n    logits: np.ndarray,\n    label: np.ndarray,\n    background_logit_threshold: float = 0.0,\n) -> float:\n  top1_idx = np.argmax(logits, axis=-1)\n  background_label = np.sum(label, axis=-1) == 0\n  pred_background = (\n      np.max(logits, axis=-1) <= background_logit_threshold\n  ).astype(np.int32)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n  # Extracts the label at the highest logit index for each input.\n  top1_correct = np.take_along_axis(label, top1_idx[..., None], axis=-1)\n  top1_correct = np.squeeze(top1_correct)\n  foreground_correct = ~pred_background.astype(bool) * top1_correct\n\n  # Count correctly classified background samples.\n  background_correct = pred_background * background_label\n  correct = foreground_correct + background_correct\n  return np.sum(correct) / len(logits)", "completions": ["  \n[PYTHON]\n```\ndef frame_accuracy(\n    logits: np.ndarray,\n    label: np.ndarray,\n    background_logit_threshold: float = 0.0,\n) -> float:\n  top1_idx = np.argmax(logits, axis=-1)\n  background_label = np.sum(label, axis=-1) == 0\n  pred_background = (\n      np.max(logits, axis=-1) <= background_logit_threshold\n  ).astype(np.int32)\n\n  # Calculate the frame accuracy\n  accuracy = np.mean(top1_idx == label)\n\n  # If the background label is present, calculate the background accuracy\n  if np.any(background_label):\n    background_accuracy = np.mean(pred_background == background_label)\n    accuracy = (accuracy + background_accuracy) / 2\n\n  return accuracy\n```\n[/PYTHON]\n"]}
{"id": 17, "name": "julian2num", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\nMatplotlib provides sophisticated date plotting capabilities, standing on the\nshoulders of python :mod:`datetime` and the add-on module dateutil_.\n\nBy default, Matplotlib uses the units machinery described in\n`~matplotlib.units` to convert `datetime.datetime`, and `numpy.datetime64`\nobjects when plotted on an x- or y-axis. The user does not\nneed to do anything for dates to be formatted, but dates often have strict\nformatting needs, so this module provides many axis locators and formatters.\nA basic example using `numpy.datetime64` is::\n\n    import numpy as np\n\n    times = np.arange(np.datetime64('2001-01-02'),\n                      np.datetime64('2002-02-03'), np.timedelta64(75, 'm'))\n    y = np.random.randn(len(times))\n\n    fig, ax = plt.subplots()\n    ax.plot(times, y)\n\n.. seealso::\n\n    - :doc:`/gallery/text_labels_and_annotations/date`\n    - :doc:`/gallery/ticks/date_concise_formatter`\n    - :doc:`/gallery/ticks/date_demo_convert`\n\n.. _date-format:\n\nMatplotlib date format\n----------------------\n\nMatplotlib represents dates using floating point numbers specifying the number\nof days since a default epoch of 1970-01-01 UTC; for example,\n1970-01-01, 06:00 is the floating point number 0.25. The formatters and\nlocators require the use of `datetime.datetime` objects, so only dates between\nyear 0001 and 9999 can be represented.  Microsecond precision\nis achievable for (approximately) 70 years on either side of the epoch, and\n20 microseconds for the rest of the allowable range of dates (year 0001 to\n9999). The epoch can be changed at import time via `.dates.set_epoch` or\n:rc:`dates.epoch` to other dates if necessary; see\n:doc:`/gallery/ticks/date_precision_and_epochs` for a discussion.\n\n.. note::\n\n   Before Matplotlib 3.3, the epoch was 0000-12-31 which lost modern\n   microsecond precision and also made the default axis limit of 0 an invalid\n   datetime.  In 3.3 the epoch was changed as above.  To convert old\n   ordinal floats to the new epoch, users can do::\n\n     new_ordinal = old_ordinal + mdates.date2num(np.datetime64('0000-12-31'))\n\n\nThere are a number of helper functions to convert between :mod:`datetime`\nobjects and Matplotlib dates:\n\n.. currentmodule:: matplotlib.dates\n\n.. autosummary::\n   :nosignatures:\n\n   datestr2num\n   date2num\n   num2date\n   num2timedelta\n   drange\n   set_epoch\n   get_epoch\n\n.. note::\n\n   Like Python's `datetime.datetime`, Matplotlib uses the Gregorian calendar\n   for all conversions between dates and floating point numbers. This practice\n   is not universal, and calendar differences can cause confusing\n   differences between what Python and Matplotlib give as the number of days\n   since 0001-01-01 and what other software and databases yield.  For\n   example, the US Naval Observatory uses a calendar that switches\n   from Julian to Gregorian in October, 1582.  Hence, using their\n   calculator, the number of days between 0001-01-01 and 2006-04-01 is\n   732403, whereas using the Gregorian calendar via the datetime\n   module we find::\n\n     In [1]: date(2006, 4, 1).toordinal() - date(1, 1, 1).toordinal()\n     Out[1]: 732401\n\nAll the Matplotlib date converters, tickers and formatters are timezone aware.\nIf no explicit timezone is provided, :rc:`timezone` is assumed, provided as a\nstring.  If you want to use a different timezone, pass the *tz* keyword\nargument of `num2date` to any date tickers or locators you create.  This can\nbe either a `datetime.tzinfo` instance or a string with the timezone name that\ncan be parsed by `~dateutil.tz.gettz`.\n\nA wide range of specific and general purpose date tick locators and\nformatters are provided in this module.  See\n:mod:`matplotlib.ticker` for general information on tick locators\nand formatters.  These are described below.\n\nThe dateutil_ module provides additional code to handle date ticking, making it\neasy to place ticks on any kinds of dates.  See examples below.\n\n.. _dateutil: https://dateutil.readthedocs.io\n\nDate tickers\n------------\n\nMost of the date tickers can locate single or multiple values.  For example::\n\n    # import constants for the days of the week\n    from matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\n\n    # tick on Mondays every week\n    loc = WeekdayLocator(byweekday=MO, tz=tz)\n\n    # tick on Mondays and Saturdays\n    loc = WeekdayLocator(byweekday=(MO, SA))\n\nIn addition, most of the constructors take an interval argument::\n\n    # tick on Mondays every second week\n    loc = WeekdayLocator(byweekday=MO, interval=2)\n\nThe rrule locator allows completely general date ticking::\n\n    # tick every 5th easter\n    rule = rrulewrapper(YEARLY, byeaster=1, interval=5)\n    loc = RRuleLocator(rule)\n\nThe available date tickers are:\n\n* `MicrosecondLocator`: Locate microseconds.\n\n* `SecondLocator`: Locate seconds.\n\n* `MinuteLocator`: Locate minutes.\n\n* `HourLocator`: Locate hours.\n\n* `DayLocator`: Locate specified days of the month.\n\n* `WeekdayLocator`: Locate days of the week, e.g., MO, TU.\n\n* `MonthLocator`: Locate months, e.g., 7 for July.\n\n* `YearLocator`: Locate years that are multiples of base.\n\n* `RRuleLocator`: Locate using a `rrulewrapper`.\n  `rrulewrapper` is a simple wrapper around dateutil_'s `dateutil.rrule`\n  which allow almost arbitrary date tick specifications.\n  See :doc:`rrule example </gallery/ticks/date_demo_rrule>`.\n\n* `AutoDateLocator`: On autoscale, this class picks the best `DateLocator`\n  (e.g., `RRuleLocator`) to set the view limits and the tick locations.  If\n  called with ``interval_multiples=True`` it will make ticks line up with\n  sensible multiples of the tick intervals.  For example, if the interval is\n  4 hours, it will pick hours 0, 4, 8, etc. as ticks.  This behaviour is not\n  guaranteed by default.\n\nDate formatters\n---------------\n\nThe available date formatters are:\n\n* `AutoDateFormatter`: attempts to figure out the best format to use.  This is\n  most useful when used with the `AutoDateLocator`.\n\n* `ConciseDateFormatter`: also attempts to figure out the best format to use,\n  and to make the format as compact as possible while still having complete\n  date information.  This is most useful when used with the `AutoDateLocator`.\n\n* `DateFormatter`: use `~datetime.datetime.strftime` format strings.\n\"\"\"\n\nimport datetime\nimport functools\nimport logging\nimport math\nimport re\n\nfrom dateutil.rrule import (rrule, MO, TU, WE, TH, FR, SA, SU, YEARLY,\n                            MONTHLY, WEEKLY, DAILY, HOURLY, MINUTELY,\n                            SECONDLY)\nfrom dateutil.relativedelta import relativedelta\nimport dateutil.parser\nimport dateutil.tz\nimport numpy as np\n\nimport matplotlib as mpl\nfrom matplotlib import _api, cbook, ticker, units\n\n__all__ = ('datestr2num', 'date2num', 'num2date', 'num2timedelta', 'drange',\n           'set_epoch', 'get_epoch', 'DateFormatter', 'ConciseDateFormatter',\n           'AutoDateFormatter', 'DateLocator', 'RRuleLocator',\n           'AutoDateLocator', 'YearLocator', 'MonthLocator', 'WeekdayLocator',\n           'DayLocator', 'HourLocator', 'MinuteLocator',\n           'SecondLocator', 'MicrosecondLocator',\n           'rrule', 'MO', 'TU', 'WE', 'TH', 'FR', 'SA', 'SU',\n           'YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY',\n           'HOURLY', 'MINUTELY', 'SECONDLY', 'MICROSECONDLY', 'relativedelta',\n           'DateConverter', 'ConciseDateConverter', 'rrulewrapper')\n\n\n_log = logging.getLogger(__name__)\nUTC = datetime.timezone.utc\n\n\n@_api.caching_module_getattr\nclass __getattr__:\n    JULIAN_OFFSET = _api.deprecated(\"3.7\")(property(lambda self: 1721424.5))\n    # Julian date at 0000-12-31\n    # note that the Julian day epoch is achievable w/\n    # np.datetime64('-4713-11-24T12:00:00'); datetime64 is proleptic\n    # Gregorian and BC has a one-year offset.  So\n    # np.datetime64('0000-12-31') - np.datetime64('-4713-11-24T12:00') =\n    # 1721424.5\n    # Ref: https://en.wikipedia.org/wiki/Julian_day\n\n\ndef _get_tzinfo(tz=None):\n    \"\"\"\n    Generate `~datetime.tzinfo` from a string or return `~datetime.tzinfo`.\n    If None, retrieve the preferred timezone from the rcParams dictionary.\n    \"\"\"\n    if tz is None:\n        tz = mpl.rcParams['timezone']\n        if tz == 'UTC':\n            return UTC\n    if isinstance(tz, str):\n        tzinfo = dateutil.tz.gettz(tz)\n        if tzinfo is None:\n            raise ValueError(f\"{tz} is not a valid timezone as parsed by\"\n                             \" dateutil.tz.gettz.\")\n        return tzinfo\n    if isinstance(tz, datetime.tzinfo):\n        return tz\n    raise TypeError(\"tz must be string or tzinfo subclass.\")\n\n\n# Time-related constants.\nEPOCH_OFFSET = float(datetime.datetime(1970, 1, 1).toordinal())\n# EPOCH_OFFSET is not used by matplotlib\nMICROSECONDLY = SECONDLY + 1\nHOURS_PER_DAY = 24.\nMIN_PER_HOUR = 60.\nSEC_PER_MIN = 60.\nMONTHS_PER_YEAR = 12.\n\nDAYS_PER_WEEK = 7.\nDAYS_PER_MONTH = 30.\nDAYS_PER_YEAR = 365.0\n\nMINUTES_PER_DAY = MIN_PER_HOUR * HOURS_PER_DAY\n\nSEC_PER_HOUR = SEC_PER_MIN * MIN_PER_HOUR\nSEC_PER_DAY = SEC_PER_HOUR * HOURS_PER_DAY\nSEC_PER_WEEK = SEC_PER_DAY * DAYS_PER_WEEK\n\nMUSECONDS_PER_DAY = 1e6 * SEC_PER_DAY\n\nMONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY = (\n    MO, TU, WE, TH, FR, SA, SU)\nWEEKDAYS = (MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY)\n\n# default epoch: passed to np.datetime64...\n_epoch = None\n\n\ndef _reset_epoch_test_example():\n    \"\"\"\n    Reset the Matplotlib date epoch so it can be set again.\n\n    Only for use in tests and examples.\n    \"\"\"\n    global _epoch\n    _epoch = None\n\n\ndef set_epoch(epoch):\n    \"\"\"\n    Set the epoch (origin for dates) for datetime calculations.\n\n    The default epoch is :rc:`dates.epoch` (by default 1970-01-01T00:00).\n\n    If microsecond accuracy is desired, the date being plotted needs to be\n    within approximately 70 years of the epoch. Matplotlib internally\n    represents dates as days since the epoch, so floating point dynamic\n    range needs to be within a factor of 2^52.\n\n    `~.dates.set_epoch` must be called before any dates are converted\n    (i.e. near the import section) or a RuntimeError will be raised.\n\n    See also :doc:`/gallery/ticks/date_precision_and_epochs`.\n\n    Parameters\n    ----------\n    epoch : str\n        valid UTC date parsable by `numpy.datetime64` (do not include\n        timezone).\n\n    \"\"\"\n    global _epoch\n    if _epoch is not None:\n        raise RuntimeError('set_epoch must be called before dates plotted.')\n    _epoch = epoch\n\n\ndef get_epoch():\n    \"\"\"\n    Get the epoch used by `.dates`.\n\n    Returns\n    -------\n    epoch : str\n        String for the epoch (parsable by `numpy.datetime64`).\n    \"\"\"\n    global _epoch\n\n    if _epoch is None:\n        _epoch = mpl.rcParams['date.epoch']\n    return _epoch\n\n\ndef _dt64_to_ordinalf(d):\n    \"\"\"\n    Convert `numpy.datetime64` or an `numpy.ndarray` of those types to\n    Gregorian date as UTC float relative to the epoch (see `.get_epoch`).\n    Roundoff is float64 precision.  Practically: microseconds for dates\n    between 290301 BC, 294241 AD, milliseconds for larger dates\n    (see `numpy.datetime64`).\n    \"\"\"\n\n    # the \"extra\" ensures that we at least allow the dynamic range out to\n    # seconds.  That should get out to +/-2e11 years.\n    dseconds = d.astype('datetime64[s]')\n    extra = (d - dseconds).astype('timedelta64[ns]')\n    t0 = np.datetime64(get_epoch(), 's')\n    dt = (dseconds - t0).astype(np.float64)\n    dt += extra.astype(np.float64) / 1.0e9\n    dt = dt / SEC_PER_DAY\n\n    NaT_int = np.datetime64('NaT').astype(np.int64)\n    d_int = d.astype(np.int64)\n    dt[d_int == NaT_int] = np.nan\n    return dt\n\n\ndef _from_ordinalf(x, tz=None):\n    \"\"\"\n    Convert Gregorian float of the date, preserving hours, minutes,\n    seconds and microseconds.  Return value is a `.datetime`.\n\n    The input date *x* is a float in ordinal days at UTC, and the output will\n    be the specified `.datetime` object corresponding to that time in\n    timezone *tz*, or if *tz* is ``None``, in the timezone specified in\n    :rc:`timezone`.\n    \"\"\"\n\n    tz = _get_tzinfo(tz)\n\n    dt = (np.datetime64(get_epoch()) +\n          np.timedelta64(int(np.round(x * MUSECONDS_PER_DAY)), 'us'))\n    if dt < np.datetime64('0001-01-01') or dt >= np.datetime64('10000-01-01'):\n        raise ValueError(f'Date ordinal {x} converts to {dt} (using '\n                         f'epoch {get_epoch()}), but Matplotlib dates must be '\n                          'between year 0001 and 9999.')\n    # convert from datetime64 to datetime:\n    dt = dt.tolist()\n\n    # datetime64 is always UTC:\n    dt = dt.replace(tzinfo=dateutil.tz.gettz('UTC'))\n    # but maybe we are working in a different timezone so move.\n    dt = dt.astimezone(tz)\n    # fix round off errors\n    if np.abs(x) > 70 * 365:\n        # if x is big, round off to nearest twenty microseconds.\n        # This avoids floating point roundoff error\n        ms = round(dt.microsecond / 20) * 20\n        if ms == 1000000:\n            dt = dt.replace(microsecond=0) + datetime.timedelta(seconds=1)\n        else:\n            dt = dt.replace(microsecond=ms)\n\n    return dt\n\n\n# a version of _from_ordinalf that can operate on numpy arrays\n_from_ordinalf_np_vectorized = np.vectorize(_from_ordinalf, otypes=\"O\")\n\n\n# a version of dateutil.parser.parse that can operate on numpy arrays\n_dateutil_parser_parse_np_vectorized = np.vectorize(dateutil.parser.parse)\n\n\ndef datestr2num(d, default=None):\n    \"\"\"\n    Convert a date string to a datenum using `dateutil.parser.parse`.\n\n    Parameters\n    ----------\n    d : str or sequence of str\n        The dates to convert.\n\n    default : datetime.datetime, optional\n        The default date to use when fields are missing in *d*.\n    \"\"\"\n    if isinstance(d, str):\n        dt = dateutil.parser.parse(d, default=default)\n        return date2num(dt)\n    else:\n        if default is not None:\n            d = [date2num(dateutil.parser.parse(s, default=default))\n                 for s in d]\n            return np.asarray(d)\n        d = np.asarray(d)\n        if not d.size:\n            return d\n        return date2num(_dateutil_parser_parse_np_vectorized(d))\n\n\ndef date2num(d):\n    \"\"\"\n    Convert datetime objects to Matplotlib dates.\n\n    Parameters\n    ----------\n    d : `datetime.datetime` or `numpy.datetime64` or sequences of these\n\n    Returns\n    -------\n    float or sequence of floats\n        Number of days since the epoch.  See `.get_epoch` for the\n        epoch, which can be changed by :rc:`date.epoch` or `.set_epoch`.  If\n        the epoch is \"1970-01-01T00:00:00\" (default) then noon Jan 1 1970\n        (\"1970-01-01T12:00:00\") returns 0.5.\n\n    Notes\n    -----\n    The Gregorian calendar is assumed; this is not universal practice.\n    For details see the module docstring.\n    \"\"\"\n    # Unpack in case of e.g. Pandas or xarray object\n    d = cbook._unpack_to_numpy(d)\n\n    # make an iterable, but save state to unpack later:\n    iterable = np.iterable(d)\n    if not iterable:\n        d = [d]\n\n    masked = np.ma.is_masked(d)\n    mask = np.ma.getmask(d)\n    d = np.asarray(d)\n\n    # convert to datetime64 arrays, if not already:\n    if not np.issubdtype(d.dtype, np.datetime64):\n        # datetime arrays\n        if not d.size:\n            # deals with an empty array...\n            return d\n        tzi = getattr(d[0], 'tzinfo', None)\n        if tzi is not None:\n            # make datetime naive:\n            d = [dt.astimezone(UTC).replace(tzinfo=None) for dt in d]\n            d = np.asarray(d)\n        d = d.astype('datetime64[us]')\n\n    d = np.ma.masked_array(d, mask=mask) if masked else d\n    d = _dt64_to_ordinalf(d)\n\n    return d if iterable else d[0]\n\n\n@_api.deprecated(\"3.7\")\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function converts Julian date to a numerical representation.\n\nArgs:\n    j (numpy.datetime64): The Julian date to be converted.\n\nReturns:\n    numpy.ndarray: The numerical representation of the Julian date, adjusted for the epoch and Julian offset.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef julian2num(j):\n    ep = np.datetime64(get_epoch(), 'h').astype(float) / 24.\n    ep0 = np.datetime64('0000-12-31T00:00:00', 'h').astype(float) / 24.\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    # Julian offset defined above is relative to 0000-12-31, but we need\n    # relative to our current epoch:\n    dt = __getattr__(\"JULIAN_OFFSET\") - ep0 + ep\n    return np.subtract(j, dt)  # Handles both scalar & nonscalar j.", "completions": ["  \n[PYTHON]\ndef julian2num(j):\n    ep = np.datetime64(get_epoch(), 'h').astype(float) / 24.\n    ep0 = np.datetime64('0000-12-31T00:00:00', 'h').astype(float) / 24.\n    return (j - ep0) + ep\n[/PYTHON]\n"]}
{"id": 18, "name": "format_template", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom enum import StrEnum\nfrom pathlib import Path\n\nfrom jinja2 import Template\nfrom pydantic import BaseModel\n\n\nclass EditorType(StrEnum):\n    VSCODE = \"vscode\"\n    VIM = \"vim\"\n    ZED = \"zed\"\n\n\nclass ProjectMetadata(BaseModel):\n    project_name: str\n    author_name: str\n    author_email: str\n    use_poetry: bool\n    use_tailwind: bool\n    editor_config: EditorType | None\n    project_path: Path\n\n    postgres_password: str = \"mysecretpassword\"\n    postgres_port: int = 5432\n\n    create_stub_files: bool\n\n    # Current version of mountaineer tied to CMA version\n    mountaineer_min_version: str\n\n    # Path components to the project's default virtual environment\n    # Not set until after the environment is created\n    venv_base: str | None = None\n    venv_name: str | None = None\n\n    # If specified, will install mountaineer in development mode pointing to a local path\n    # This is useful for testing changes to mountaineer itself\n    mountaineer_dev_path: Path | None = None\n\n\nclass TemplateOutput(BaseModel):\n    content: str\n    path: str\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function formats a template file using Jinja2.\n\nArgs:\n    path (Path): The path to the template file.\n    base_path (Path): The base path to the template file.\n    project_metadata (ProjectMetadata): The metadata for the project.\n\nReturns:\n    TemplateOutput: The formatted content and the output path of the template file.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef format_template(\n    path: Path, base_path: Path, project_metadata: ProjectMetadata\n) -> TemplateOutput:\n    if not path.exists():\n        raise FileNotFoundError(f\"Template file {path} does not exist\")\n\n    metadata_variables = project_metadata.model_dump()\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    template = Template(path.read_text())\n    content = template.render(metadata_variables)\n\n    output_name = str(path.relative_to(base_path))\n    for key, value in metadata_variables.items():\n        output_name = output_name.replace(f\"[{key}]\", str(value))\n\n    return TemplateOutput(content=content, path=output_name)", "completions": ["  \n[PYTHON]\n```\ndef format_template(path: Path, base_path: Path, project_metadata: ProjectMetadata) -> TemplateOutput:\n    if not path.exists():\n        raise FileNotFoundError(f\"Template file {path} does not exist\")\n\n    metadata_variables = project_metadata.model_dump()\n    template = Template(path.read_text())\n    content = template.render(metadata_variables)\n    return TemplateOutput(content=content, path=path.relative_to(base_path))\n```\n[/PYTHON]\n"]}
{"id": 19, "name": "res_block", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom functools import partial\nfrom typing import Sequence\n\nimport torch\nfrom torch import nn, Tensor\nfrom torchmultimodal.diffusion_labs.models.vae.attention import attention_res_block\nfrom torchmultimodal.diffusion_labs.models.vae.res_block import ResBlock\nfrom torchmultimodal.diffusion_labs.models.vae.residual_sampling import (\n    Downsample2D,\n    Upsample2D,\n)\nfrom torchmultimodal.modules.layers.normalizations import Fp32GroupNorm\n\n\nclass ResNetEncoder(nn.Module):\n    \"\"\"Resnet encoder used in the LDM Autoencoder that consists of a init convolution,\n    downsampling resnet blocks, middle resnet blocks with attention and output convolution block\n    with group normalization and nonlinearity.\n\n    Follows the architecture described in \"High-Resolution Image Synthesis with Latent\n    Diffusion Models\" (https://arxiv.org/abs/2112.10752)\n\n    Code ref:\n    https://github.com/CompVis/latent-diffusion/blob/a506df5756472e2ebaf9078affdde2c4f1502cd4/ldm/modules/diffusionmodules/model.py#L368\n\n    Attributes:\n        in_channels (int): number of input channels.\n        z_channels (int): number of latent channels.\n        channels (int): number of channels in the initial convolution layer.\n        num_res_block (int): number of residual blocks at each resolution.\n        channel_multipliers (Sequence[int]): list of channel multipliers. Defaults to [1, 2, 4, 8].\n        dropout (float): dropout probability. Defaults to 0.0.\n        double_z (bool): whether to use double z_channels for images or not. Defaults to True.\n        norm_groups (int): number of groups used in GroupNorm layer. Defaults to 32.\n        norm_eps (float): epsilon used in the GroupNorm layer. Defaults to 1e-6.\n\n    Args:\n        x (Tensor): input Tensor of shape [b, c, h, w]\n\n    Raises:\n        ValueError: If `channels` * `channel_multipliers[-1]` is not divisible by `norm_groups`.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        z_channels: int,\n        channels: int,\n        num_res_blocks: int,\n        channel_multipliers: Sequence[int] = (\n            1,\n            2,\n            4,\n            8,\n        ),\n        dropout: float = 0.0,\n        double_z: bool = True,\n        norm_groups: int = 32,\n        norm_eps: float = 1e-6,\n    ):\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torchmultimodal.{self.__class__.__name__}\")\n\n        # initial convolution\n        self.init_conv = nn.Conv2d(in_channels, channels, kernel_size=3, padding=1)\n\n        # downsampling block\n        self.down_block = nn.Sequential()\n        channels_list = tuple(\n            [channels * multiplier for multiplier in [1] + list(channel_multipliers)]\n        )\n        num_resolutions = len(channel_multipliers)\n        for level_idx in range(num_resolutions):\n            block_in = channels_list[level_idx]\n            block_out = channels_list[level_idx + 1]\n            self.down_block.append(\n                res_block_stack(\n                    block_in,\n                    block_out,\n                    num_res_blocks,\n                    dropout,\n                    needs_downsample=(\n                        True if level_idx != num_resolutions - 1 else False\n                    ),\n                    norm_groups=norm_groups,\n                    norm_eps=norm_eps,\n                )\n            )\n\n        mid_channels = channels_list[-1]\n        self.mid_block = nn.Sequential(\n            res_block(mid_channels, mid_channels, dropout, norm_groups, norm_eps),\n            attention_res_block(mid_channels, norm_groups, norm_eps),\n            res_block(mid_channels, mid_channels, dropout, norm_groups, norm_eps),\n        )\n\n        if mid_channels % norm_groups != 0:\n            raise ValueError(\n                \"Channel dims obtained by multiplying channels with last\"\n                \" item in channel_multipliers needs to be divisible by norm_groups\"\n            )\n\n        self.out_block = nn.Sequential(\n            Fp32GroupNorm(\n                num_groups=norm_groups, num_channels=mid_channels, eps=norm_eps\n            ),\n            nn.SiLU(),\n            nn.Conv2d(\n                mid_channels,\n                out_channels=2 * z_channels if double_z else z_channels,\n                kernel_size=3,\n                padding=1,\n            ),\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        h = self.init_conv(x)\n        h = self.down_block(h)\n        h = self.mid_block(h)\n        h = self.out_block(h)\n        return h\n\n\nclass ResNetDecoder(nn.Module):\n    \"\"\"Resnet decoder used in the LDM Autoencoder that consists of a init convolution,\n    middle resnet blocks with attention, upsamling resnet blocks and output convolution\n    block with group normalization and nonlinearity. Optionally, also supports alpha\n    channel in output.\n\n    Follows the architecture described in \"High-Resolution Image Synthesis with Latent\n    Diffusion Models\" (https://arxiv.org/abs/2112.10752)\n\n    Code ref:\n    https://github.com/CompVis/latent-diffusion/blob/a506df5756472e2ebaf9078affdde2c4f1502cd4/ldm/modules/diffusionmodules/model.py#L462\n\n    Attributes:\n        out_channels (int): number of channels in output image.\n        z_channels (int): number of latent channels.\n        channels (int): number of channels to be used with channel multipliers.\n        num_res_block (int): number of residual blocks at each resolution.\n        channel_multipliers (Sequence[int]): list of channel multipliers used by the encoder.\n            Decoder uses them in reverse order. Defaults to [1, 2, 4, 8].\n        dropout (float): dropout probability. Defaults to 0.0.\n        norm_groups (int): number of groups used in GroupNorm layer. Defaults to 32.\n        norm_eps (float): epsilon used in the GroupNorm layer. Defaults to 1e-6.\n        output_alpha_channel (bool): whether to include an alpha channel in the output.\n            Defaults to False.\n\n    Args:\n        z (Tensor): input Tensor of shape [b, c, h, w]\n\n    Raises:\n        ValueError: If `channels` * `channel_multipliers[-1]` is not divisible by `norm_groups`.\n    \"\"\"\n\n    def __init__(\n        self,\n        out_channels: int,\n        z_channels: int,\n        channels: int,\n        num_res_blocks: int,\n        channel_multipliers: Sequence[int] = (\n            1,\n            2,\n            4,\n            8,\n        ),\n        dropout: float = 0.0,\n        norm_groups: int = 32,\n        norm_eps: float = 1e-6,\n        output_alpha_channel: bool = False,\n    ):\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torchmultimodal.{self.__class__.__name__}\")\n        self.output_alpha_channel = output_alpha_channel\n\n        channels_list = tuple(\n            reversed(\n                [\n                    channels * multiplier\n                    for multiplier in list(channel_multipliers)\n                    + [channel_multipliers[-1]]\n                ]\n            )\n        )\n        mid_channels = channels_list[0]\n\n        # initial convolution\n        self.init_conv = nn.Conv2d(z_channels, mid_channels, kernel_size=3, padding=1)\n\n        # middle block\n        self.mid_block = nn.Sequential(\n            res_block(mid_channels, mid_channels, dropout, norm_groups, norm_eps),\n            attention_res_block(mid_channels, norm_groups, norm_eps),\n            res_block(mid_channels, mid_channels, dropout, norm_groups, norm_eps),\n        )\n\n        # upsample block\n        self.up_block = nn.Sequential()\n        num_resolutions = len(channel_multipliers)\n        for level_idx in range(num_resolutions):\n            block_in = channels_list[level_idx]\n            block_out = channels_list[level_idx + 1]\n            self.up_block.append(\n                res_block_stack(\n                    block_in,\n                    block_out,\n                    # decoder creates 1 additional res block compared to encoder.\n                    # not sure about intuition, but seems to be used everywhere in OSS.\n                    num_res_blocks + 1,\n                    dropout,\n                    needs_upsample=True if level_idx != num_resolutions - 1 else False,\n                    norm_groups=norm_groups,\n                    norm_eps=norm_eps,\n                )\n            )\n\n        # output nonlinearity block\n        post_upsample_channels = channels_list[-1]\n        if post_upsample_channels % norm_groups != 0:\n            raise ValueError(\n                \"Channel dims obtained by multiplying channels with first\"\n                \" item in channel_multipliers needs to be divisible by norm_groups\"\n            )\n        self.out_nonlinearity_block = nn.Sequential(\n            Fp32GroupNorm(\n                num_groups=norm_groups,\n                num_channels=post_upsample_channels,\n                eps=norm_eps,\n            ),\n            nn.SiLU(),\n        )\n\n        # output projections\n        self.conv_out = nn.Conv2d(\n            post_upsample_channels, out_channels, kernel_size=3, padding=1\n        )\n        if self.output_alpha_channel:\n            self.alpha_conv_out = nn.Conv2d(\n                post_upsample_channels, 1, kernel_size=3, padding=1\n            )\n\n    def forward(self, z: Tensor) -> Tensor:\n        h = self.init_conv(z)\n        h = self.mid_block(h)\n        h = self.up_block(h)\n        h = self.out_nonlinearity_block(h)\n\n        # If alpha channel is required as output, compute it separately with its\n        # own conv layer and concatenate with the output from the out convolulution\n        if self.output_alpha_channel:\n            h = torch.cat((self.conv_out(h), self.alpha_conv_out(h)), dim=1)\n        else:\n            h = self.conv_out(h)\n\n        return h\n\n\ndef res_block_stack(\n    in_channels: int,\n    out_channels: int,\n    num_blocks: int,\n    dropout: float = 0.0,\n    needs_upsample: bool = False,\n    needs_downsample: bool = False,\n    norm_groups: int = 32,\n    norm_eps: float = 1e-6,\n) -> nn.Module:\n    if needs_upsample and needs_downsample:\n        raise ValueError(\"Cannot use both upsample and downsample in res block\")\n    block_in, block_out = in_channels, out_channels\n    block_stack = nn.Sequential()\n    for _ in range(num_blocks):\n        block_stack.append(\n            res_block(block_in, block_out, dropout, norm_groups, norm_eps)\n        )\n        block_in = block_out\n    if needs_downsample:\n        block_stack.append(Downsample2D(out_channels))\n    if needs_upsample:\n        block_stack.append(Upsample2D(out_channels))\n    return block_stack\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function creates a residual block with optional skip connection.\n\nArgs:\n    in_channels (int): Number of channels in the input tensor.\n    out_channels (int): Number of channels produced by the convolution.\n    dropout (float, optional): Probability for the dropout layer. Defaults to 0.0.\n    norm_groups (int, optional): Number of groups for group normalization. Defaults to 32.\n    norm_eps (float, optional): A value added to the denominator for numerical stability in group normalization. Defaults to 1e-6.\n\nReturns:\n    ResBlock: A residual block with optional skip connection.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef res_block(\n    in_channels: int,\n    out_channels: int,\n    dropout: float = 0.0,\n    norm_groups: int = 32,\n    norm_eps: float = 1e-6,\n) -> ResBlock:\n    res_block_partial = partial(\n        ResBlock,\n        in_channels=in_channels,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        out_channels=out_channels,\n        pre_outconv_dropout=dropout,\n        scale_shift_conditional=False,\n        norm_groups=norm_groups,\n        norm_eps=norm_eps,\n    )\n    if in_channels != out_channels:\n        return res_block_partial(\n            skip_conv=nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        )\n    else:\n        return res_block_partial()", "completions": ["  \n[PYTHON]\ndef res_block(in_channels, out_channels, dropout=0.0, norm_groups=32, norm_eps=1e-6):\n    return ResBlock(\n        in_channels=in_channels,\n        out_channels=out_channels,\n        dropout=dropout,\n        norm_groups=norm_groups,\n        norm_eps=norm_eps,\n    )\n[/PYTHON]\n"]}
{"id": 20, "name": "process", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2023-present, Argilla, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport sys\n\nif sys.version_info < (3, 9):\n    import importlib_resources\nelse:\n    import importlib.resources as importlib_resources\n\nfrom functools import cached_property\nfrom typing import TYPE_CHECKING, Any, Dict, List, Optional\n\nimport numpy as np\nfrom pydantic import Field, PrivateAttr\nfrom typing_extensions import override\n\nfrom distilabel.mixins.runtime_parameters import RuntimeParameter\nfrom distilabel.steps.tasks.base import GeneratorTask\nfrom distilabel.steps.tasks.evol_instruct.utils import GENERATION_MUTATION_TEMPLATES\nfrom distilabel.utils.lists import flatten_responses\n\nif TYPE_CHECKING:\n    from distilabel.steps.tasks.typing import ChatType\n    from distilabel.steps.typing import GeneratorStepOutput\n\n\nclass EvolInstructGenerator(GeneratorTask):\n    \"\"\"WizardLM: Empowering Large Language Models to Follow Complex Instructions\n\n    Attributes:\n        num_instructions: The number of instructions to be generated.\n        generate_answers: Whether to generate answers for the instructions or not. Defaults\n            to `False`.\n        mutation_templates: The mutation templates to be used for the generation of the\n            instructions.\n        min_length: Defines the length (in bytes) that the generated instruction needs to\n            be higher than, to be considered valid. Defaults to `512`.\n        max_length: Defines the length (in bytes) that the generated instruction needs to\n            be lower than, to be considered valid. Defaults to `1024`.\n        seed: The seed to be set for `numpy` in order to randomly pick a mutation method.\n            Defaults to `42`.\n\n    Runtime parameters:\n        - `min_length`: Defines the length (in bytes) that the generated instruction needs\n            to be higher than, to be considered valid.\n        - `max_length`: Defines the length (in bytes) that the generated instruction needs\n            to be lower than, to be considered valid.\n        - `seed`: The seed to be set for `numpy` in order to randomly pick a mutation method.\n\n    Output columns:\n        - instruction (`str`): The generated instruction if `generate_answers=False`.\n        - answer (`str`): The generated answer if `generate_answers=True`.\n        - instructions (`List[str]`): The generated instructions if `generate_answers=True`.\n        - model_name (`str`): The name of the LLM used to generate and evolve the instructions.\n\n    References:\n        - [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244)\n        - [GitHub: h2oai/h2o-wizardlm](https://github.com/h2oai/h2o-wizardlm)\n    \"\"\"\n\n    num_instructions: int\n    generate_answers: bool = False\n    mutation_templates: Dict[str, str] = GENERATION_MUTATION_TEMPLATES\n\n    min_length: RuntimeParameter[int] = Field(\n        default=512,\n        description=\"Defines the length (in bytes) that the generated instruction needs to be higher than, to be considered valid.\",\n    )\n    max_length: RuntimeParameter[int] = Field(\n        default=1024,\n        description=\"Defines the length (in bytes) that the generated instruction needs to be lower than, to be considered valid.\",\n    )\n\n    seed: RuntimeParameter[int] = Field(\n        default=42,\n        description=\"As `numpy` is being used in order to randomly pick a mutation method, then is nice to seed a random seed.\",\n    )\n    _seed_texts: Optional[List[str]] = PrivateAttr(default_factory=list)\n    _prompts: Optional[List[str]] = PrivateAttr(default_factory=list)\n\n    def _generate_seed_texts(self) -> List[str]:\n        \"\"\"Generates a list of seed texts to be used as part of the starting prompts for the task.\n\n        It will use the `FRESH_START` mutation template, as it needs to generate text from scratch; and\n        a list of English words will be used to generate the seed texts that will be provided to the\n        mutation method and included within the prompt.\n\n        Returns:\n            A list of seed texts to be used as part of the starting prompts for the task.\n        \"\"\"\n        seed_texts = []\n        for _ in range(self.num_instructions * 10):\n            num_words = np.random.choice([1, 2, 3, 4])\n            seed_texts.append(\n                self.mutation_templates[\"FRESH_START\"].replace(  # type: ignore\n                    \"<PROMPT>\",\n                    \", \".join(\n                        [\n                            np.random.choice(self._english_nouns).strip()\n                            for _ in range(num_words)\n                        ]\n                    ),\n                )\n            )\n        return seed_texts\n\n    @override\n    def model_post_init(self, __context: Any) -> None:\n        \"\"\"Override this method to perform additional initialization after `__init__` and `model_construct`.\n        This is useful if you want to do some validation that requires the entire model to be initialized.\n        \"\"\"\n        super().model_post_init(__context)\n\n        np.random.seed(self.seed)\n\n        self._seed_texts = self._generate_seed_texts()\n        self._prompts = [\n            np.random.choice(self._seed_texts) for _ in range(self.num_instructions)\n        ]\n\n    @cached_property\n    def _english_nouns(self) -> List[str]:\n        \"\"\"A list of English nouns to be used as part of the starting prompts for the task.\n\n        References:\n            - https://github.com/h2oai/h2o-wizardlm\n        \"\"\"\n        _path = str(\n            importlib_resources.files(\"distilabel\")\n            / \"steps/tasks/evol_instruct/english_nouns.txt\"\n        )\n        with open(_path, mode=\"r\") as f:\n            return [line.strip() for line in f.readlines()]\n\n    @property\n    def outputs(self) -> List[str]:\n        \"\"\"The output for the task are the `instruction`, the `answer` if `generate_answers=True`\n        and the `model_name`.\"\"\"\n        _outputs = [\"instruction\", \"model_name\"]\n        if self.generate_answers:\n            _outputs.append(\"answer\")\n        return _outputs\n\n    def format_output(  # type: ignore\n        self, instruction: str, answer: Optional[str] = None\n    ) -> Dict[str, Any]:\n        \"\"\"The output for the task is a dict with: `instruction`; `answer` if `generate_answers=True`;\n        and, finally, the `model_name`.\n\n        Args:\n            instruction: The instruction to be included within the output.\n            answer: The answer to be included within the output if `generate_answers=True`.\n\n        Returns:\n            If `generate_answers=True` return {\"instruction\": ..., \"answer\": ..., \"model_name\": ...};\n            if `generate_answers=False` return {\"instruction\": ..., \"model_name\": ...};\n        \"\"\"\n        _output = {\n            \"instruction\": instruction,\n            \"model_name\": self.llm.model_name,\n        }\n        if self.generate_answers and answer is not None:\n            _output[\"answer\"] = answer\n        return _output\n\n    @property\n    def mutation_templates_names(self) -> List[str]:\n        \"\"\"Returns the names i.e. keys of the provided `mutation_templates`.\"\"\"\n        return list(self.mutation_templates.keys())\n\n    def _apply_random_mutation(self, iter_no: int) -> List[\"ChatType\"]:\n        \"\"\"Applies a random mutation from the ones provided as part of the `mutation_templates`\n        enum, and returns the provided instruction within the mutation prompt.\n\n        Args:\n            iter_no: The iteration number to be used to check whether the iteration is the\n                first one i.e. FRESH_START, or not.\n\n        Returns:\n            A random mutation prompt with the provided instruction formatted as an OpenAI conversation.\n        \"\"\"\n        prompts = []\n        for idx in range(self.num_instructions):\n            if (\n                iter_no == 0\n                or \"Write one question or request containing\" in self._prompts[idx]  # type: ignore\n            ):\n                mutation = \"FRESH_START\"\n            else:\n                mutation = np.random.choice(self.mutation_templates_names)\n                if mutation == \"FRESH_START\":\n                    self._prompts[idx] = np.random.choice(self._seed_texts)  # type: ignore\n\n            prompt_with_template = (\n                self.mutation_templates[mutation].replace(  # type: ignore\n                    \"<PROMPT>\",\n                    self._prompts[idx],  # type: ignore\n                )  # type: ignore\n                if iter_no != 0\n                else self._prompts[idx]  # type: ignore\n            )\n            prompts.append([{\"role\": \"user\", \"content\": prompt_with_template}])\n        return prompts\n\n    def _generate_answers(self, instructions: List[List[str]]) -> List[str]:\n        \"\"\"Generates the answer for the last instruction in `instructions`.\n\n        Args:\n            instructions: A list of lists where each item is a list with either the last\n                evolved instruction if `store_evolutions=False` or all the evolved instructions\n                if `store_evolutions=True`.\n\n        Returns:\n            A list of answers for the last instruction in `instructions`.\n        \"\"\"\n        # TODO: update to generate answers for all the instructions\n        _formatted_instructions = [\n            [{\"role\": \"user\", \"content\": instruction[-1]}]\n            for instruction in instructions\n        ]\n        responses = self.llm.generate(\n            _formatted_instructions,\n            **self.llm.generation_kwargs,  # type: ignore\n        )\n        return flatten_responses(responses)\n\n    @override\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to process and evolve a set of instructions based on random mutations.\n\nArgs:\n    self: The instance of the class that this method belongs to.\n    offset (int): The offset value for the process. Defaults to 0.\n\nReturns:\n    GeneratorStepOutput: A generator that yields a tuple containing a list of formatted output and a boolean indicating whether the process is finished.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def process(self, offset: int = 0) -> \"GeneratorStepOutput\":  # type: ignore\n        instructions = []\n        mutation_no = 0\n\n        iter_no = 0\n        while len(instructions) < self.num_instructions:\n            prompts = self._apply_random_mutation(iter_no=iter_no)\n\n            generated_prompts = flatten_responses(\n                self.llm.generate(prompts, **self.llm.generation_kwargs)  # type: ignore\n            )\n            for idx, generated_prompt in enumerate(generated_prompts):\n                generated_prompt = generated_prompt.split(\"Prompt#:\")[-1].strip()\n                if self.max_length >= len(generated_prompt) >= self.min_length:  # type: ignore\n                    instructions.append(generated_prompt)\n                    self._prompts[idx] = np.random.choice(self._seed_texts)  # type: ignore\n                else:\n                    self._prompts[idx] = generated_prompt  # type: ignore\n\n            self._logger.info(\n                f\"🔄 Ran iteration {iter_no} with {len(instructions)} instructions already evolved!\"\n            )\n            iter_no += 1\n\n            if len(instructions) > self.num_instructions:\n                instructions = instructions[: self.num_instructions]\n            if len(instructions) > mutation_no:\n                mutation_no = len(instructions) - mutation_no\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            if not self.generate_answers and len(instructions[-mutation_no:]) > 0:\n                yield (\n                    [\n                        self.format_output(mutated_instruction)\n                        for mutated_instruction in instructions[-mutation_no:]\n                    ],\n                    len(instructions) >= self.num_instructions,\n                )\n\n        self._logger.info(f\"🎉 Finished evolving {len(instructions)} instructions!\")\n\n        if self.generate_answers:\n            self._logger.info(\n                f\"🧠 Generating answers for the {len(instructions)} evolved instructions!\"\n            )\n\n            answers = self._generate_answers(instructions)\n\n            self._logger.info(\n                f\"🎉 Finished generating answers for the {len(instructions)} evolved instructions!\"\n            )\n\n            yield (\n                [\n                    self.format_output(instruction, answer)\n                    for instruction, answer in zip(instructions, answers)\n                ],\n                True,\n            )", "completions": ["  \n[PYTHON]\ndef process(self, offset: int = 0) -> \"GeneratorStepOutput\":  # type: ignore\n    instructions = []\n    mutation_no = 0\n\n    iter_no = 0\n    while len(instructions) < self.num_instructions:\n        prompts = self._apply_random_mutation(iter_no=iter_no)\n\n        generated_prompts = flatten_responses(\n            self.llm.generate(prompts, **self.llm.generation_kwargs)  # type: ignore\n        )\n        for idx, generated_prompt in enumerate(generated_prompts):\n            generated_prompt = generated_prompt.split(\"Prompt#:\")[-1].strip()\n            if self.max_length >= len(generated_prompt) >= self.min_length:  # type: ignore\n                instructions.append(generated_prompt)\n                self._prompts[idx] = np.random.choice(self._seed_texts)  # type: ignore\n            else:\n                self._prompts[idx] = generated_prompt  # type: ignore\n\n        self._logger.info(\n            f\"🔄 Ran iteration {iter_no} with {len(instructions)} instructions already evolved!\"\n        )\n        iter_no += 1\n\n        if len(instructions) > self.num_instructions:\n            instructions = instructions[: self.num_instructions]\n        if len(instructions) > mutation_no:\n            mutation_no = len(instructions) - mutation_no\n\n    if self.generate_answers:\n        answers = self._generate_answers(instructions)\n        for idx, answer in enumerate(answers):\n            instructions[idx] = self.format_output(instructions[idx], answer)\n    else:\n        for idx, instruction in enumerate(instructions):\n            instructions[idx] = self.format_output(instruction)\n\n    return GeneratorStepOutput(\n        outputs=instructions,\n        finished=len(instructions) >= self.num_instructions,\n    )\n[/PYTHON]\n"]}
{"id": 21, "name": "query_tags_from_docker_hub", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport subprocess\nimport docker\nimport re\nfrom datetime import datetime\nfrom typing import List, Optional, Callable, Tuple\nimport os\nimport sys\nfrom dateutil import parser\nimport runfiles\nimport platform\n\nimport requests\n\nfrom ci.ray_ci.utils import logger\nfrom ci.ray_ci.builder_container import DEFAULT_ARCHITECTURE, DEFAULT_PYTHON_VERSION\nfrom ci.ray_ci.docker_container import (\n    GPU_PLATFORM,\n    PYTHON_VERSIONS_RAY,\n    PYTHON_VERSIONS_RAY_ML,\n    PLATFORMS_RAY,\n    PLATFORMS_RAY_ML,\n    ARCHITECTURES_RAY,\n    ARCHITECTURES_RAY_ML,\n    RayType,\n)\n\nbazel_workspace_dir = os.environ.get(\"BUILD_WORKSPACE_DIRECTORY\", \"\")\nSHA_LENGTH = 6\n\n\ndef _check_python_version(python_version: str, ray_type: str) -> None:\n    if ray_type == RayType.RAY and python_version not in PYTHON_VERSIONS_RAY:\n        raise ValueError(\n            f\"Python version {python_version} not supported for ray image.\"\n        )\n    if ray_type == RayType.RAY_ML and python_version not in PYTHON_VERSIONS_RAY_ML:\n        raise ValueError(\n            f\"Python version {python_version} not supported for ray-ml image.\"\n        )\n\n\ndef _check_platform(platform: str, ray_type: str) -> None:\n    if ray_type == RayType.RAY and platform not in PLATFORMS_RAY:\n        raise ValueError(f\"Platform {platform} not supported for ray image.\")\n    if ray_type == RayType.RAY_ML and platform not in PLATFORMS_RAY_ML:\n        raise ValueError(f\"Platform {platform} not supported for ray-ml image.\")\n\n\ndef _check_architecture(architecture: str, ray_type: str) -> None:\n    if ray_type == RayType.RAY and architecture not in ARCHITECTURES_RAY:\n        raise ValueError(f\"Architecture {architecture} not supported for ray image.\")\n    if ray_type == RayType.RAY_ML and architecture not in ARCHITECTURES_RAY_ML:\n        raise ValueError(f\"Architecture {architecture} not supported for ray-ml image.\")\n\n\ndef _get_python_version_tag(python_version: str) -> str:\n    return f\"-py{python_version.replace('.', '')}\"  # 3.x -> py3x\n\n\ndef _get_platform_tag(platform: str) -> str:\n    if platform == \"cpu\":\n        return \"-cpu\"\n    versions = platform.split(\".\")\n    return f\"-{versions[0]}{versions[1]}\"  # cu11.8.0 -> cu118\n\n\ndef _get_architecture_tag(architecture: str) -> str:\n    return f\"-{architecture}\" if architecture != DEFAULT_ARCHITECTURE else \"\"\n\n\ndef list_image_tag_suffixes(\n    ray_type: str, python_version: str, platform: str, architecture: str\n) -> List[str]:\n    \"\"\"\n    Get image tags & alias suffixes for the container image.\n    \"\"\"\n    _check_python_version(python_version, ray_type)\n    _check_platform(platform, ray_type)\n    _check_architecture(architecture, ray_type)\n\n    python_version_tags = [_get_python_version_tag(python_version)]\n    platform_tags = [_get_platform_tag(platform)]\n    architecture_tags = [_get_architecture_tag(architecture)]\n\n    if python_version == DEFAULT_PYTHON_VERSION:\n        python_version_tags.append(\"\")\n    if platform == \"cpu\" and ray_type == RayType.RAY:\n        platform_tags.append(\"\")  # no tag is alias to cpu for ray image\n    if platform == GPU_PLATFORM:\n        platform_tags.append(\"-gpu\")  # gpu is alias for cu11.8.0\n        if ray_type == RayType.RAY_ML:\n            platform_tags.append(\"\")  # no tag is alias to gpu for ray-ml image\n\n    tag_suffixes = []\n    for platform in platform_tags:\n        for py_version in python_version_tags:\n            for architecture in architecture_tags:\n                tag_suffix = f\"{py_version}{platform}{architecture}\"\n                tag_suffixes.append(tag_suffix)\n    return tag_suffixes\n\n\ndef pull_image(image_name: str) -> None:\n    logger.info(f\"Pulling image {image_name}\")\n    client = docker.from_env()\n    client.images.pull(image_name)\n\n\ndef remove_image(image_name: str) -> None:\n    logger.info(f\"Removing image {image_name}\")\n    client = docker.from_env()\n    client.images.remove(image_name)\n\n\ndef get_ray_commit(image_name: str) -> str:\n    \"\"\"\n    Get the commit hash of Ray in the image.\n    \"\"\"\n    client = docker.from_env()\n\n    # Command to grab commit hash from ray image\n    command = \"python -u -c 'import ray; print(ray.__commit__)'\"\n\n    container = client.containers.run(\n        image=image_name, command=command, remove=True, stdout=True, stderr=True\n    )\n    output = container.decode(\"utf-8\").strip()\n    match = re.search(\n        r\"^[a-f0-9]{40}$\", output, re.MULTILINE\n    )  # Grab commit hash from output\n\n    if not match:\n        raise Exception(\n            f\"Failed to get commit hash from image {image_name}. Output: {output}\"\n        )\n    return match.group(0)\n\n\ndef check_image_ray_commit(prefix: str, ray_type: str, expected_commit: str) -> None:\n    if ray_type == RayType.RAY:\n        tags = list_image_tags(\n            prefix, ray_type, PYTHON_VERSIONS_RAY, PLATFORMS_RAY, ARCHITECTURES_RAY\n        )\n    elif ray_type == RayType.RAY_ML:\n        tags = list_image_tags(\n            prefix,\n            ray_type,\n            PYTHON_VERSIONS_RAY_ML,\n            PLATFORMS_RAY_ML,\n            ARCHITECTURES_RAY_ML,\n        )\n    tags = [f\"rayproject/{ray_type}:{tag}\" for tag in tags]\n\n    for i, tag in enumerate(tags):\n        logger.info(f\"{i+1}/{len(tags)} Checking commit for tag {tag} ....\")\n\n        pull_image(tag)\n        commit = get_ray_commit(tag)\n\n        if commit != expected_commit:\n            print(f\"Ray commit mismatch for tag {tag}!\")\n            print(\"Expected:\", expected_commit)\n            print(\"Actual:\", commit)\n            sys.exit(42)  # Not retrying the check on Buildkite jobs\n        else:\n            print(f\"Commit {commit} match for tag {tag}!\")\n\n        if i != 0:  # Only save first pulled image for caching\n            remove_image(tag)\n\n\ndef list_image_tags(\n    prefix: str,\n    ray_type: str,\n    python_versions: List[str],\n    platforms: List[str],\n    architectures: List[str],\n) -> List[str]:\n    \"\"\"\n    List all tags for a Docker build version.\n\n    An image tag is composed by ray version tag, python version and platform.\n    See https://docs.ray.io/en/latest/ray-overview/installation.html for\n    more information on the image tags.\n\n    Args:\n        prefix: The build version of the image tag (e.g. nightly, abc123).\n        ray_type: The type of the ray image. It can be \"ray\" or \"ray-ml\".\n    \"\"\"\n    if ray_type not in RayType.__members__.values():\n        raise ValueError(f\"Ray type {ray_type} not supported.\")\n\n    tag_suffixes = []\n    for python_version in python_versions:\n        for platf in platforms:\n            for architecture in architectures:\n                tag_suffixes += list_image_tag_suffixes(\n                    ray_type, python_version, platf, architecture\n                )\n    return sorted([f\"{prefix}{tag_suffix}\" for tag_suffix in tag_suffixes])\n\n\nclass DockerHubRateLimitException(Exception):\n    \"\"\"\n    Exception for Docker Hub rate limit exceeded.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\"429: Rate limit exceeded for Docker Hub.\")\n\n\nclass RetrieveImageConfigException(Exception):\n    \"\"\"\n    Exception for failing to retrieve image config.\n    \"\"\"\n\n    def __init__(self, message: str):\n        super().__init__(f\"Failed to retrieve {message}\")\n\n\nclass AuthTokenException(Exception):\n    \"\"\"\n    Exception for failing to retrieve auth token.\n    \"\"\"\n\n    def __init__(self, message: str):\n        super().__init__(f\"Failed to retrieve auth token from {message}.\")\n\n\ndef _get_docker_auth_token(namespace: str, repository: str) -> Optional[str]:\n    service, scope = (\n        \"registry.docker.io\",\n        f\"repository:{namespace}/{repository}:pull\",\n    )\n    auth_url = f\"https://auth.docker.io/token?service={service}&scope={scope}\"\n    response = requests.get(auth_url)\n    if response.status_code != 200:\n        raise AuthTokenException(f\"Docker. Error code: {response.status_code}\")\n    token = response.json().get(\"token\", None)\n    return token\n\n\ndef _get_docker_hub_auth_token(username: str, password: str) -> Optional[str]:\n    url = \"https://hub.docker.com/v2/users/login\"\n    json_body = {\n        \"username\": username,\n        \"password\": password,\n    }\n    headers = {\"Content-Type\": \"application/json\"}\n    response = requests.post(url, headers=headers, json=json_body)\n    if response.status_code != 200:\n        raise AuthTokenException(f\"Docker Hub. Error code: {response.status_code}\")\n    return response.json().get(\"token\", None)\n\n\ndef _get_git_log(n_days: int = 30) -> str:\n    return subprocess.check_output(\n        [\n            \"git\",\n            \"log\",\n            f\"--until='{n_days} days ago'\",\n            \"--pretty=format:%H\",\n        ],\n        text=True,\n    )\n\n\ndef _list_recent_commit_short_shas(n_days: int = 30) -> List[str]:\n    \"\"\"\n    Get list of recent commit SHAs (short version) on ray master branch.\n\n    Args:\n        n_days: Number of days to go back in git log.\n\n    Returns:\n        List of recent commit SHAs (short version).\n    \"\"\"\n    commit_shas = _get_git_log(n_days=n_days)\n    short_commit_shas = [\n        commit_sha[:SHA_LENGTH] for commit_sha in commit_shas.split(\"\\n\") if commit_sha\n    ]\n    return short_commit_shas\n\n\ndef _get_config_docker_oci(tag: str, namespace: str, repository: str):\n    \"\"\"Get Docker image config from tag using OCI API.\"\"\"\n    token = _get_docker_auth_token(namespace, repository)\n\n    # Pull image manifest to get config digest\n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Accept\": \"application/vnd.docker.distribution.manifest.v2+json\",\n    }\n    image_manifest_url = (\n        f\"https://registry-1.docker.io/v2/{namespace}/{repository}/manifests/{tag}\"\n    )\n    response = requests.get(image_manifest_url, headers=headers)\n    if response.status_code != 200:\n        raise RetrieveImageConfigException(\"image manifest.\")\n    config_blob_digest = response.json()[\"config\"][\"digest\"]\n\n    # Pull image config\n    config_blob_url = f\"https://registry-1.docker.io/v2/{namespace}/{repository}/blobs/{config_blob_digest}\"  # noqa E501\n    config_headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Accept\": \"application/vnd.docker.container.image.v1+json\",\n    }\n    response = requests.get(config_blob_url, headers=config_headers)\n    if response.status_code != 200:\n        raise RetrieveImageConfigException(\"image config.\")\n    return response.json()\n\n\ndef _get_image_creation_time(tag: str) -> datetime:\n    namespace, repo_tag = tag.split(\"/\")\n    repository, tag = repo_tag.split(\":\")\n    config = _get_config_docker_oci(tag=tag, namespace=namespace, repository=repository)\n    if \"created\" not in config:\n        raise RetrieveImageConfigException(\"image creation time.\")\n    return parser.isoparse(config[\"created\"])\n\n\ndef delete_tag(tag: str, docker_hub_token: str) -> bool:\n    \"\"\"Delete tag from Docker Hub repo.\"\"\"\n    headers = {\n        \"Authorization\": f\"Bearer {docker_hub_token}\",\n    }\n    namespace, repo_tag = tag.split(\"/\")\n    repository, tag_name = repo_tag.split(\":\")\n\n    url = f\"https://hub.docker.com/v2/repositories/{namespace}/{repository}/tags/{tag_name}\"  # noqa E501\n    response = requests.delete(url, headers=headers)\n    if response.status_code == 429:\n        raise DockerHubRateLimitException()\n    if response.status_code != 204:\n        logger.info(f\"Failed to delete {tag}, status code: {response.json()}\")\n        return False\n    logger.info(f\"Deleted tag {tag}\")\n    return True\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function queries tags from Docker Hub based on a filter function, namespace, repository, Docker Hub token, and the number of tags to return.\n\nArgs:\n    filter_func (Callable[[str], bool]): A function that takes a string (tag name) and returns a boolean indicating whether the tag should be included.\n    namespace (str): The namespace of the Docker Hub repository.\n    repository (str): The name of the Docker Hub repository.\n    docker_hub_token (str): The Docker Hub API token for authentication.\n    num_tags (Optional[int]): The maximum number of tags to return. If None, all tags are returned.\n\nReturns:\n    List[str]: A list of fully qualified Docker image tags (in the format 'namespace/repository:tag') that pass the filter function and are sorted in ascending order.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef query_tags_from_docker_hub(\n    filter_func: Callable[[str], bool],\n    namespace: str,\n    repository: str,\n    docker_hub_token: str,\n    num_tags: Optional[int] = None,\n) -> List[str]:\n    filtered_tags = []\n    headers = {\n        \"Authorization\": f\"Bearer {docker_hub_token}\",\n    }\n\n    page_count = 1\n    while page_count:\n        logger.info(f\"Querying page {page_count}\")\n        url = f\"https://hub.docker.com/v2/namespaces/{namespace}/repositories/{repository}/tags?page={page_count}&page_size=100\"  # noqa E501\n\n        response = requests.get(url, headers=headers)\n        response_json = response.json()\n\n        # Stop querying if Docker Hub API returns an error\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        if response.status_code != 200:\n            logger.info(f\"Failed to query tags from Docker Hub: Error: {response_json}\")\n            return sorted([f\"{namespace}/{repository}:{t}\" for t in filtered_tags])\n\n        result = response_json[\"results\"]\n        tags = [tag[\"name\"] for tag in result]\n        filtered_tags_page = list(filter(filter_func, tags))  # Filter tags\n\n        # Add enough tags to not exceed num_tags if num_tags is specified\n        if num_tags:\n            if len(filtered_tags) + len(filtered_tags_page) > num_tags:\n                filtered_tags.extend(\n                    filtered_tags_page[: num_tags - len(filtered_tags)]\n                )\n                break\n        filtered_tags.extend(filtered_tags_page)\n\n        logger.info(f\"Tag count: {len(filtered_tags)}\")\n        if not response_json[\"next\"]:\n            break\n        page_count += 1\n    return sorted([f\"{namespace}/{repository}:{t}\" for t in filtered_tags])", "completions": ["  \n[PYTHON]\ndef query_tags_from_docker_hub(\n    filter_func: Callable[[str], bool],\n    namespace: str,\n    repository: str,\n    docker_hub_token: str,\n    num_tags: Optional[int] = None,\n) -> List[str]:\n    filtered_tags = []\n    headers = {\n        \"Authorization\": f\"Bearer {docker_hub_token}\",\n    }\n\n    page_count = 1\n    while page_count:\n        logger.info(f\"Querying page {page_count}\")\n        url = f\"https://hub.docker.com/v2/namespaces/{namespace}/repositories/{repository}/tags?page={page_count}&page_size=100\"  # noqa E501\n\n        response = requests.get(url, headers=headers)\n        response_json = response.json()\n\n        # Stop querying if Docker Hub API returns an error\n        if response.status_code!= 200:\n            break\n\n        # Filter tags\n        for tag in response_json[\"results\"]:\n            if filter_func(tag[\"name\"]):\n                filtered_tags.append(f\"{namespace}/{repository}:{tag['name']}\")\n\n        # Stop querying if the number of tags is reached\n        if num_tags and len(filtered_tags) >= num_tags:\n            break\n\n        # Increment page count\n        page_count += 1\n\n    return filtered_tags\n[/PYTHON]\n"]}
{"id": 22, "name": "evaluate", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\nNumerical Python functions written for compatibility with MATLAB\ncommands with the same names. Most numerical Python functions can be found in\nthe `NumPy`_ and `SciPy`_ libraries. What remains here is code for performing\nspectral computations and kernel density estimations.\n\n.. _NumPy: https://numpy.org\n.. _SciPy: https://www.scipy.org\n\nSpectral functions\n------------------\n\n`cohere`\n    Coherence (normalized cross spectral density)\n\n`csd`\n    Cross spectral density using Welch's average periodogram\n\n`detrend`\n    Remove the mean or best fit line from an array\n\n`psd`\n    Power spectral density using Welch's average periodogram\n\n`specgram`\n    Spectrogram (spectrum over segments of time)\n\n`complex_spectrum`\n    Return the complex-valued frequency spectrum of a signal\n\n`magnitude_spectrum`\n    Return the magnitude of the frequency spectrum of a signal\n\n`angle_spectrum`\n    Return the angle (wrapped phase) of the frequency spectrum of a signal\n\n`phase_spectrum`\n    Return the phase (unwrapped angle) of the frequency spectrum of a signal\n\n`detrend_mean`\n    Remove the mean from a line.\n\n`detrend_linear`\n    Remove the best fit line from a line.\n\n`detrend_none`\n    Return the original line.\n\n`stride_windows`\n    Get all windows in an array in a memory-efficient manner\n\"\"\"\n\nimport functools\nfrom numbers import Number\n\nimport numpy as np\n\nfrom matplotlib import _api, _docstring, cbook\n\n\ndef window_hanning(x):\n    \"\"\"\n    Return *x* times the Hanning (or Hann) window of len(*x*).\n\n    See Also\n    --------\n    window_none : Another window algorithm.\n    \"\"\"\n    return np.hanning(len(x))*x\n\n\ndef window_none(x):\n    \"\"\"\n    No window function; simply return *x*.\n\n    See Also\n    --------\n    window_hanning : Another window algorithm.\n    \"\"\"\n    return x\n\n\ndef detrend(x, key=None, axis=None):\n    \"\"\"\n    Return *x* with its trend removed.\n\n    Parameters\n    ----------\n    x : array or sequence\n        Array or sequence containing the data.\n\n    key : {'default', 'constant', 'mean', 'linear', 'none'} or function\n        The detrending algorithm to use. 'default', 'mean', and 'constant' are\n        the same as `detrend_mean`. 'linear' is the same as `detrend_linear`.\n        'none' is the same as `detrend_none`. The default is 'mean'. See the\n        corresponding functions for more details regarding the algorithms. Can\n        also be a function that carries out the detrend operation.\n\n    axis : int\n        The axis along which to do the detrending.\n\n    See Also\n    --------\n    detrend_mean : Implementation of the 'mean' algorithm.\n    detrend_linear : Implementation of the 'linear' algorithm.\n    detrend_none : Implementation of the 'none' algorithm.\n    \"\"\"\n    if key is None or key in ['constant', 'mean', 'default']:\n        return detrend(x, key=detrend_mean, axis=axis)\n    elif key == 'linear':\n        return detrend(x, key=detrend_linear, axis=axis)\n    elif key == 'none':\n        return detrend(x, key=detrend_none, axis=axis)\n    elif callable(key):\n        x = np.asarray(x)\n        if axis is not None and axis + 1 > x.ndim:\n            raise ValueError(f'axis(={axis}) out of bounds')\n        if (axis is None and x.ndim == 0) or (not axis and x.ndim == 1):\n            return key(x)\n        # try to use the 'axis' argument if the function supports it,\n        # otherwise use apply_along_axis to do it\n        try:\n            return key(x, axis=axis)\n        except TypeError:\n            return np.apply_along_axis(key, axis=axis, arr=x)\n    else:\n        raise ValueError(\n            f\"Unknown value for key: {key!r}, must be one of: 'default', \"\n            f\"'constant', 'mean', 'linear', or a function\")\n\n\ndef detrend_mean(x, axis=None):\n    \"\"\"\n    Return *x* minus the mean(*x*).\n\n    Parameters\n    ----------\n    x : array or sequence\n        Array or sequence containing the data\n        Can have any dimensionality\n\n    axis : int\n        The axis along which to take the mean.  See `numpy.mean` for a\n        description of this argument.\n\n    See Also\n    --------\n    detrend_linear : Another detrend algorithm.\n    detrend_none : Another detrend algorithm.\n    detrend : A wrapper around all the detrend algorithms.\n    \"\"\"\n    x = np.asarray(x)\n\n    if axis is not None and axis+1 > x.ndim:\n        raise ValueError('axis(=%s) out of bounds' % axis)\n\n    return x - x.mean(axis, keepdims=True)\n\n\ndef detrend_none(x, axis=None):\n    \"\"\"\n    Return *x*: no detrending.\n\n    Parameters\n    ----------\n    x : any object\n        An object containing the data\n\n    axis : int\n        This parameter is ignored.\n        It is included for compatibility with detrend_mean\n\n    See Also\n    --------\n    detrend_mean : Another detrend algorithm.\n    detrend_linear : Another detrend algorithm.\n    detrend : A wrapper around all the detrend algorithms.\n    \"\"\"\n    return x\n\n\ndef detrend_linear(y):\n    \"\"\"\n    Return *x* minus best fit line; 'linear' detrending.\n\n    Parameters\n    ----------\n    y : 0-D or 1-D array or sequence\n        Array or sequence containing the data\n\n    See Also\n    --------\n    detrend_mean : Another detrend algorithm.\n    detrend_none : Another detrend algorithm.\n    detrend : A wrapper around all the detrend algorithms.\n    \"\"\"\n    # This is faster than an algorithm based on linalg.lstsq.\n    y = np.asarray(y)\n\n    if y.ndim > 1:\n        raise ValueError('y cannot have ndim > 1')\n\n    # short-circuit 0-D array.\n    if not y.ndim:\n        return np.array(0., dtype=y.dtype)\n\n    x = np.arange(y.size, dtype=float)\n\n    C = np.cov(x, y, bias=1)\n    b = C[0, 1]/C[0, 0]\n\n    a = y.mean() - b*x.mean()\n    return y - (b*x + a)\n\n\n@_api.deprecated(\"3.6\")\ndef stride_windows(x, n, noverlap=None, axis=0):\n    \"\"\"\n    Get all windows of *x* with length *n* as a single array,\n    using strides to avoid data duplication.\n\n    .. warning::\n\n        It is not safe to write to the output array.  Multiple\n        elements may point to the same piece of memory,\n        so modifying one value may change others.\n\n    Parameters\n    ----------\n    x : 1D array or sequence\n        Array or sequence containing the data.\n    n : int\n        The number of data points in each window.\n    noverlap : int, default: 0 (no overlap)\n        The overlap between adjacent windows.\n    axis : int\n        The axis along which the windows will run.\n\n    References\n    ----------\n    `stackoverflow: Rolling window for 1D arrays in Numpy?\n    <https://stackoverflow.com/a/6811241>`_\n    `stackoverflow: Using strides for an efficient moving average filter\n    <https://stackoverflow.com/a/4947453>`_\n    \"\"\"\n    if noverlap is None:\n        noverlap = 0\n    if np.ndim(x) != 1:\n        raise ValueError('only 1-dimensional arrays can be used')\n    return _stride_windows(x, n, noverlap, axis)\n\n\ndef _stride_windows(x, n, noverlap=0, axis=0):\n    # np>=1.20 provides sliding_window_view, and we only ever use axis=0.\n    if hasattr(np.lib.stride_tricks, \"sliding_window_view\") and axis == 0:\n        if noverlap >= n:\n            raise ValueError('noverlap must be less than n')\n        return np.lib.stride_tricks.sliding_window_view(\n            x, n, axis=0)[::n - noverlap].T\n\n    if noverlap >= n:\n        raise ValueError('noverlap must be less than n')\n    if n < 1:\n        raise ValueError('n cannot be less than 1')\n\n    x = np.asarray(x)\n\n    if n == 1 and noverlap == 0:\n        if axis == 0:\n            return x[np.newaxis]\n        else:\n            return x[np.newaxis].T\n    if n > x.size:\n        raise ValueError('n cannot be greater than the length of x')\n\n    # np.lib.stride_tricks.as_strided easily leads to memory corruption for\n    # non integer shape and strides, i.e. noverlap or n. See #3845.\n    noverlap = int(noverlap)\n    n = int(n)\n\n    step = n - noverlap\n    if axis == 0:\n        shape = (n, (x.shape[-1]-noverlap)//step)\n        strides = (x.strides[0], step*x.strides[0])\n    else:\n        shape = ((x.shape[-1]-noverlap)//step, n)\n        strides = (step*x.strides[0], x.strides[0])\n    return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)\n\n\ndef _spectral_helper(x, y=None, NFFT=None, Fs=None, detrend_func=None,\n                     window=None, noverlap=None, pad_to=None,\n                     sides=None, scale_by_freq=None, mode=None):\n    \"\"\"\n    Private helper implementing the common parts between the psd, csd,\n    spectrogram and complex, magnitude, angle, and phase spectrums.\n    \"\"\"\n    if y is None:\n        # if y is None use x for y\n        same_data = True\n    else:\n        # The checks for if y is x are so that we can use the same function to\n        # implement the core of psd(), csd(), and spectrogram() without doing\n        # extra calculations.  We return the unaveraged Pxy, freqs, and t.\n        same_data = y is x\n\n    if Fs is None:\n        Fs = 2\n    if noverlap is None:\n        noverlap = 0\n    if detrend_func is None:\n        detrend_func = detrend_none\n    if window is None:\n        window = window_hanning\n\n    # if NFFT is set to None use the whole signal\n    if NFFT is None:\n        NFFT = 256\n\n    if mode is None or mode == 'default':\n        mode = 'psd'\n    _api.check_in_list(\n        ['default', 'psd', 'complex', 'magnitude', 'angle', 'phase'],\n        mode=mode)\n\n    if not same_data and mode != 'psd':\n        raise ValueError(\"x and y must be equal if mode is not 'psd'\")\n\n    # Make sure we're dealing with a numpy array. If y and x were the same\n    # object to start with, keep them that way\n    x = np.asarray(x)\n    if not same_data:\n        y = np.asarray(y)\n\n    if sides is None or sides == 'default':\n        if np.iscomplexobj(x):\n            sides = 'twosided'\n        else:\n            sides = 'onesided'\n    _api.check_in_list(['default', 'onesided', 'twosided'], sides=sides)\n\n    # zero pad x and y up to NFFT if they are shorter than NFFT\n    if len(x) < NFFT:\n        n = len(x)\n        x = np.resize(x, NFFT)\n        x[n:] = 0\n\n    if not same_data and len(y) < NFFT:\n        n = len(y)\n        y = np.resize(y, NFFT)\n        y[n:] = 0\n\n    if pad_to is None:\n        pad_to = NFFT\n\n    if mode != 'psd':\n        scale_by_freq = False\n    elif scale_by_freq is None:\n        scale_by_freq = True\n\n    # For real x, ignore the negative frequencies unless told otherwise\n    if sides == 'twosided':\n        numFreqs = pad_to\n        if pad_to % 2:\n            freqcenter = (pad_to - 1)//2 + 1\n        else:\n            freqcenter = pad_to//2\n        scaling_factor = 1.\n    elif sides == 'onesided':\n        if pad_to % 2:\n            numFreqs = (pad_to + 1)//2\n        else:\n            numFreqs = pad_to//2 + 1\n        scaling_factor = 2.\n\n    if not np.iterable(window):\n        window = window(np.ones(NFFT, x.dtype))\n    if len(window) != NFFT:\n        raise ValueError(\n            \"The window length must match the data's first dimension\")\n\n    result = _stride_windows(x, NFFT, noverlap)\n    result = detrend(result, detrend_func, axis=0)\n    result = result * window.reshape((-1, 1))\n    result = np.fft.fft(result, n=pad_to, axis=0)[:numFreqs, :]\n    freqs = np.fft.fftfreq(pad_to, 1/Fs)[:numFreqs]\n\n    if not same_data:\n        # if same_data is False, mode must be 'psd'\n        resultY = _stride_windows(y, NFFT, noverlap)\n        resultY = detrend(resultY, detrend_func, axis=0)\n        resultY = resultY * window.reshape((-1, 1))\n        resultY = np.fft.fft(resultY, n=pad_to, axis=0)[:numFreqs, :]\n        result = np.conj(result) * resultY\n    elif mode == 'psd':\n        result = np.conj(result) * result\n    elif mode == 'magnitude':\n        result = np.abs(result) / window.sum()\n    elif mode == 'angle' or mode == 'phase':\n        # we unwrap the phase later to handle the onesided vs. twosided case\n        result = np.angle(result)\n    elif mode == 'complex':\n        result /= window.sum()\n\n    if mode == 'psd':\n\n        # Also include scaling factors for one-sided densities and dividing by\n        # the sampling frequency, if desired. Scale everything, except the DC\n        # component and the NFFT/2 component:\n\n        # if we have a even number of frequencies, don't scale NFFT/2\n        if not NFFT % 2:\n            slc = slice(1, -1, None)\n        # if we have an odd number, just don't scale DC\n        else:\n            slc = slice(1, None, None)\n\n        result[slc] *= scaling_factor\n\n        # MATLAB divides by the sampling frequency so that density function\n        # has units of dB/Hz and can be integrated by the plotted frequency\n        # values. Perform the same scaling here.\n        if scale_by_freq:\n            result /= Fs\n            # Scale the spectrum by the norm of the window to compensate for\n            # windowing loss; see Bendat & Piersol Sec 11.5.2.\n            result /= (window**2).sum()\n        else:\n            # In this case, preserve power in the segment, not amplitude\n            result /= window.sum()**2\n\n    t = np.arange(NFFT/2, len(x) - NFFT/2 + 1, NFFT - noverlap)/Fs\n\n    if sides == 'twosided':\n        # center the frequency range at zero\n        freqs = np.roll(freqs, -freqcenter, axis=0)\n        result = np.roll(result, -freqcenter, axis=0)\n    elif not pad_to % 2:\n        # get the last value correctly, it is negative otherwise\n        freqs[-1] *= -1\n\n    # we unwrap the phase here to handle the onesided vs. twosided case\n    if mode == 'phase':\n        result = np.unwrap(result, axis=0)\n\n    return result, freqs, t\n\n\ndef _single_spectrum_helper(\n        mode, x, Fs=None, window=None, pad_to=None, sides=None):\n    \"\"\"\n    Private helper implementing the commonality between the complex, magnitude,\n    angle, and phase spectrums.\n    \"\"\"\n    _api.check_in_list(['complex', 'magnitude', 'angle', 'phase'], mode=mode)\n\n    if pad_to is None:\n        pad_to = len(x)\n\n    spec, freqs, _ = _spectral_helper(x=x, y=None, NFFT=len(x), Fs=Fs,\n                                      detrend_func=detrend_none, window=window,\n                                      noverlap=0, pad_to=pad_to,\n                                      sides=sides,\n                                      scale_by_freq=False,\n                                      mode=mode)\n    if mode != 'complex':\n        spec = spec.real\n\n    if spec.ndim == 2 and spec.shape[1] == 1:\n        spec = spec[:, 0]\n\n    return spec, freqs\n\n\n# Split out these keyword docs so that they can be used elsewhere\n_docstring.interpd.update(\n    Spectral=\"\"\"\\\nFs : float, default: 2\n    The sampling frequency (samples per time unit).  It is used to calculate\n    the Fourier frequencies, *freqs*, in cycles per time unit.\n\nwindow : callable or ndarray, default: `.window_hanning`\n    A function or a vector of length *NFFT*.  To create window vectors see\n    `.window_hanning`, `.window_none`, `numpy.blackman`, `numpy.hamming`,\n    `numpy.bartlett`, `scipy.signal`, `scipy.signal.get_window`, etc.  If a\n    function is passed as the argument, it must take a data segment as an\n    argument and return the windowed version of the segment.\n\nsides : {'default', 'onesided', 'twosided'}, optional\n    Which sides of the spectrum to return. 'default' is one-sided for real\n    data and two-sided for complex data. 'onesided' forces the return of a\n    one-sided spectrum, while 'twosided' forces two-sided.\"\"\",\n\n    Single_Spectrum=\"\"\"\\\npad_to : int, optional\n    The number of points to which the data segment is padded when performing\n    the FFT.  While not increasing the actual resolution of the spectrum (the\n    minimum distance between resolvable peaks), this can give more points in\n    the plot, allowing for more detail. This corresponds to the *n* parameter\n    in the call to `~numpy.fft.fft`.  The default is None, which sets *pad_to*\n    equal to the length of the input signal (i.e. no padding).\"\"\",\n\n    PSD=\"\"\"\\\npad_to : int, optional\n    The number of points to which the data segment is padded when performing\n    the FFT.  This can be different from *NFFT*, which specifies the number\n    of data points used.  While not increasing the actual resolution of the\n    spectrum (the minimum distance between resolvable peaks), this can give\n    more points in the plot, allowing for more detail. This corresponds to\n    the *n* parameter in the call to `~numpy.fft.fft`. The default is None,\n    which sets *pad_to* equal to *NFFT*\n\nNFFT : int, default: 256\n    The number of data points used in each block for the FFT.  A power 2 is\n    most efficient.  This should *NOT* be used to get zero padding, or the\n    scaling of the result will be incorrect; use *pad_to* for this instead.\n\ndetrend : {'none', 'mean', 'linear'} or callable, default: 'none'\n    The function applied to each segment before fft-ing, designed to remove\n    the mean or linear trend.  Unlike in MATLAB, where the *detrend* parameter\n    is a vector, in Matplotlib it is a function.  The :mod:`~matplotlib.mlab`\n    module defines `.detrend_none`, `.detrend_mean`, and `.detrend_linear`,\n    but you can use a custom function as well.  You can also use a string to\n    choose one of the functions: 'none' calls `.detrend_none`. 'mean' calls\n    `.detrend_mean`. 'linear' calls `.detrend_linear`.\n\nscale_by_freq : bool, default: True\n    Whether the resulting density values should be scaled by the scaling\n    frequency, which gives density in units of 1/Hz.  This allows for\n    integration over the returned frequency values.  The default is True for\n    MATLAB compatibility.\"\"\")\n\n\n@_docstring.dedent_interpd\ndef psd(x, NFFT=None, Fs=None, detrend=None, window=None,\n        noverlap=None, pad_to=None, sides=None, scale_by_freq=None):\n    r\"\"\"\n    Compute the power spectral density.\n\n    The power spectral density :math:`P_{xx}` by Welch's average\n    periodogram method.  The vector *x* is divided into *NFFT* length\n    segments.  Each segment is detrended by function *detrend* and\n    windowed by function *window*.  *noverlap* gives the length of\n    the overlap between segments.  The :math:`|\\mathrm{fft}(i)|^2`\n    of each segment :math:`i` are averaged to compute :math:`P_{xx}`.\n\n    If len(*x*) < *NFFT*, it will be zero padded to *NFFT*.\n\n    Parameters\n    ----------\n    x : 1-D array or sequence\n        Array or sequence containing the data\n\n    %(Spectral)s\n\n    %(PSD)s\n\n    noverlap : int, default: 0 (no overlap)\n        The number of points of overlap between segments.\n\n    Returns\n    -------\n    Pxx : 1-D array\n        The values for the power spectrum :math:`P_{xx}` (real valued)\n\n    freqs : 1-D array\n        The frequencies corresponding to the elements in *Pxx*\n\n    References\n    ----------\n    Bendat & Piersol -- Random Data: Analysis and Measurement Procedures, John\n    Wiley & Sons (1986)\n\n    See Also\n    --------\n    specgram\n        `specgram` differs in the default overlap; in not returning the mean of\n        the segment periodograms; and in returning the times of the segments.\n\n    magnitude_spectrum : returns the magnitude spectrum.\n\n    csd : returns the spectral density between two signals.\n    \"\"\"\n    Pxx, freqs = csd(x=x, y=None, NFFT=NFFT, Fs=Fs, detrend=detrend,\n                     window=window, noverlap=noverlap, pad_to=pad_to,\n                     sides=sides, scale_by_freq=scale_by_freq)\n    return Pxx.real, freqs\n\n\n@_docstring.dedent_interpd\ndef csd(x, y, NFFT=None, Fs=None, detrend=None, window=None,\n        noverlap=None, pad_to=None, sides=None, scale_by_freq=None):\n    \"\"\"\n    Compute the cross-spectral density.\n\n    The cross spectral density :math:`P_{xy}` by Welch's average\n    periodogram method.  The vectors *x* and *y* are divided into\n    *NFFT* length segments.  Each segment is detrended by function\n    *detrend* and windowed by function *window*.  *noverlap* gives\n    the length of the overlap between segments.  The product of\n    the direct FFTs of *x* and *y* are averaged over each segment\n    to compute :math:`P_{xy}`, with a scaling to correct for power\n    loss due to windowing.\n\n    If len(*x*) < *NFFT* or len(*y*) < *NFFT*, they will be zero\n    padded to *NFFT*.\n\n    Parameters\n    ----------\n    x, y : 1-D arrays or sequences\n        Arrays or sequences containing the data\n\n    %(Spectral)s\n\n    %(PSD)s\n\n    noverlap : int, default: 0 (no overlap)\n        The number of points of overlap between segments.\n\n    Returns\n    -------\n    Pxy : 1-D array\n        The values for the cross spectrum :math:`P_{xy}` before scaling (real\n        valued)\n\n    freqs : 1-D array\n        The frequencies corresponding to the elements in *Pxy*\n\n    References\n    ----------\n    Bendat & Piersol -- Random Data: Analysis and Measurement Procedures, John\n    Wiley & Sons (1986)\n\n    See Also\n    --------\n    psd : equivalent to setting ``y = x``.\n    \"\"\"\n    if NFFT is None:\n        NFFT = 256\n    Pxy, freqs, _ = _spectral_helper(x=x, y=y, NFFT=NFFT, Fs=Fs,\n                                     detrend_func=detrend, window=window,\n                                     noverlap=noverlap, pad_to=pad_to,\n                                     sides=sides, scale_by_freq=scale_by_freq,\n                                     mode='psd')\n\n    if Pxy.ndim == 2:\n        if Pxy.shape[1] > 1:\n            Pxy = Pxy.mean(axis=1)\n        else:\n            Pxy = Pxy[:, 0]\n    return Pxy, freqs\n\n\n_single_spectrum_docs = \"\"\"\\\nCompute the {quantity} of *x*.\nData is padded to a length of *pad_to* and the windowing function *window* is\napplied to the signal.\n\nParameters\n----------\nx : 1-D array or sequence\n    Array or sequence containing the data\n\n{Spectral}\n\n{Single_Spectrum}\n\nReturns\n-------\nspectrum : 1-D array\n    The {quantity}.\nfreqs : 1-D array\n    The frequencies corresponding to the elements in *spectrum*.\n\nSee Also\n--------\npsd\n    Returns the power spectral density.\ncomplex_spectrum\n    Returns the complex-valued frequency spectrum.\nmagnitude_spectrum\n    Returns the absolute value of the `complex_spectrum`.\nangle_spectrum\n    Returns the angle of the `complex_spectrum`.\nphase_spectrum\n    Returns the phase (unwrapped angle) of the `complex_spectrum`.\nspecgram\n    Can return the complex spectrum of segments within the signal.\n\"\"\"\n\n\ncomplex_spectrum = functools.partial(_single_spectrum_helper, \"complex\")\ncomplex_spectrum.__doc__ = _single_spectrum_docs.format(\n    quantity=\"complex-valued frequency spectrum\",\n    **_docstring.interpd.params)\nmagnitude_spectrum = functools.partial(_single_spectrum_helper, \"magnitude\")\nmagnitude_spectrum.__doc__ = _single_spectrum_docs.format(\n    quantity=\"magnitude (absolute value) of the frequency spectrum\",\n    **_docstring.interpd.params)\nangle_spectrum = functools.partial(_single_spectrum_helper, \"angle\")\nangle_spectrum.__doc__ = _single_spectrum_docs.format(\n    quantity=\"angle of the frequency spectrum (wrapped phase spectrum)\",\n    **_docstring.interpd.params)\nphase_spectrum = functools.partial(_single_spectrum_helper, \"phase\")\nphase_spectrum.__doc__ = _single_spectrum_docs.format(\n    quantity=\"phase of the frequency spectrum (unwrapped phase spectrum)\",\n    **_docstring.interpd.params)\n\n\n@_docstring.dedent_interpd\ndef specgram(x, NFFT=None, Fs=None, detrend=None, window=None,\n             noverlap=None, pad_to=None, sides=None, scale_by_freq=None,\n             mode=None):\n    \"\"\"\n    Compute a spectrogram.\n\n    Compute and plot a spectrogram of data in *x*.  Data are split into\n    *NFFT* length segments and the spectrum of each section is\n    computed.  The windowing function *window* is applied to each\n    segment, and the amount of overlap of each segment is\n    specified with *noverlap*.\n\n    Parameters\n    ----------\n    x : array-like\n        1-D array or sequence.\n\n    %(Spectral)s\n\n    %(PSD)s\n\n    noverlap : int, default: 128\n        The number of points of overlap between blocks.\n    mode : str, default: 'psd'\n        What sort of spectrum to use:\n            'psd'\n                Returns the power spectral density.\n            'complex'\n                Returns the complex-valued frequency spectrum.\n            'magnitude'\n                Returns the magnitude spectrum.\n            'angle'\n                Returns the phase spectrum without unwrapping.\n            'phase'\n                Returns the phase spectrum with unwrapping.\n\n    Returns\n    -------\n    spectrum : array-like\n        2D array, columns are the periodograms of successive segments.\n\n    freqs : array-like\n        1-D array, frequencies corresponding to the rows in *spectrum*.\n\n    t : array-like\n        1-D array, the times corresponding to midpoints of segments\n        (i.e the columns in *spectrum*).\n\n    See Also\n    --------\n    psd : differs in the overlap and in the return values.\n    complex_spectrum : similar, but with complex valued frequencies.\n    magnitude_spectrum : similar single segment when *mode* is 'magnitude'.\n    angle_spectrum : similar to single segment when *mode* is 'angle'.\n    phase_spectrum : similar to single segment when *mode* is 'phase'.\n\n    Notes\n    -----\n    *detrend* and *scale_by_freq* only apply when *mode* is set to 'psd'.\n\n    \"\"\"\n    if noverlap is None:\n        noverlap = 128  # default in _spectral_helper() is noverlap = 0\n    if NFFT is None:\n        NFFT = 256  # same default as in _spectral_helper()\n    if len(x) <= NFFT:\n        _api.warn_external(\"Only one segment is calculated since parameter \"\n                           f\"NFFT (={NFFT}) >= signal length (={len(x)}).\")\n\n    spec, freqs, t = _spectral_helper(x=x, y=None, NFFT=NFFT, Fs=Fs,\n                                      detrend_func=detrend, window=window,\n                                      noverlap=noverlap, pad_to=pad_to,\n                                      sides=sides,\n                                      scale_by_freq=scale_by_freq,\n                                      mode=mode)\n\n    if mode != 'complex':\n        spec = spec.real  # Needed since helper implements generically\n\n    return spec, freqs, t\n\n\n@_docstring.dedent_interpd\ndef cohere(x, y, NFFT=256, Fs=2, detrend=detrend_none, window=window_hanning,\n           noverlap=0, pad_to=None, sides='default', scale_by_freq=None):\n    r\"\"\"\n    The coherence between *x* and *y*.  Coherence is the normalized\n    cross spectral density:\n\n    .. math::\n\n        C_{xy} = \\frac{|P_{xy}|^2}{P_{xx}P_{yy}}\n\n    Parameters\n    ----------\n    x, y\n        Array or sequence containing the data\n\n    %(Spectral)s\n\n    %(PSD)s\n\n    noverlap : int, default: 0 (no overlap)\n        The number of points of overlap between segments.\n\n    Returns\n    -------\n    Cxy : 1-D array\n        The coherence vector.\n    freqs : 1-D array\n            The frequencies for the elements in *Cxy*.\n\n    See Also\n    --------\n    :func:`psd`, :func:`csd` :\n        For information about the methods used to compute :math:`P_{xy}`,\n        :math:`P_{xx}` and :math:`P_{yy}`.\n    \"\"\"\n    if len(x) < 2 * NFFT:\n        raise ValueError(\n            \"Coherence is calculated by averaging over *NFFT* length \"\n            \"segments.  Your signal is too short for your choice of *NFFT*.\")\n    Pxx, f = psd(x, NFFT, Fs, detrend, window, noverlap, pad_to, sides,\n                 scale_by_freq)\n    Pyy, f = psd(y, NFFT, Fs, detrend, window, noverlap, pad_to, sides,\n                 scale_by_freq)\n    Pxy, f = csd(x, y, NFFT, Fs, detrend, window, noverlap, pad_to, sides,\n                 scale_by_freq)\n    Cxy = np.abs(Pxy) ** 2 / (Pxx * Pyy)\n    return Cxy, f\n\n\nclass GaussianKDE:\n    \"\"\"\n    Representation of a kernel-density estimate using Gaussian kernels.\n\n    Parameters\n    ----------\n    dataset : array-like\n        Datapoints to estimate from. In case of univariate data this is a 1-D\n        array, otherwise a 2D array with shape (# of dims, # of data).\n    bw_method : str, scalar or callable, optional\n        The method used to calculate the estimator bandwidth.  This can be\n        'scott', 'silverman', a scalar constant or a callable.  If a\n        scalar, this will be used directly as `kde.factor`.  If a\n        callable, it should take a `GaussianKDE` instance as only\n        parameter and return a scalar. If None (default), 'scott' is used.\n\n    Attributes\n    ----------\n    dataset : ndarray\n        The dataset passed to the constructor.\n    dim : int\n        Number of dimensions.\n    num_dp : int\n        Number of datapoints.\n    factor : float\n        The bandwidth factor, obtained from `kde.covariance_factor`, with which\n        the covariance matrix is multiplied.\n    covariance : ndarray\n        The covariance matrix of *dataset*, scaled by the calculated bandwidth\n        (`kde.factor`).\n    inv_cov : ndarray\n        The inverse of *covariance*.\n\n    Methods\n    -------\n    kde.evaluate(points) : ndarray\n        Evaluate the estimated pdf on a provided set of points.\n    kde(points) : ndarray\n        Same as kde.evaluate(points)\n    \"\"\"\n\n    # This implementation with minor modification was too good to pass up.\n    # from scipy: https://github.com/scipy/scipy/blob/master/scipy/stats/kde.py\n\n    def __init__(self, dataset, bw_method=None):\n        self.dataset = np.atleast_2d(dataset)\n        if not np.array(self.dataset).size > 1:\n            raise ValueError(\"`dataset` input should have multiple elements.\")\n\n        self.dim, self.num_dp = np.array(self.dataset).shape\n\n        if bw_method is None:\n            pass\n        elif cbook._str_equal(bw_method, 'scott'):\n            self.covariance_factor = self.scotts_factor\n        elif cbook._str_equal(bw_method, 'silverman'):\n            self.covariance_factor = self.silverman_factor\n        elif isinstance(bw_method, Number):\n            self._bw_method = 'use constant'\n            self.covariance_factor = lambda: bw_method\n        elif callable(bw_method):\n            self._bw_method = bw_method\n            self.covariance_factor = lambda: self._bw_method(self)\n        else:\n            raise ValueError(\"`bw_method` should be 'scott', 'silverman', a \"\n                             \"scalar or a callable\")\n\n        # Computes the covariance matrix for each Gaussian kernel using\n        # covariance_factor().\n\n        self.factor = self.covariance_factor()\n        # Cache covariance and inverse covariance of the data\n        if not hasattr(self, '_data_inv_cov'):\n            self.data_covariance = np.atleast_2d(\n                np.cov(\n                    self.dataset,\n                    rowvar=1,\n                    bias=False))\n            self.data_inv_cov = np.linalg.inv(self.data_covariance)\n\n        self.covariance = self.data_covariance * self.factor ** 2\n        self.inv_cov = self.data_inv_cov / self.factor ** 2\n        self.norm_factor = (np.sqrt(np.linalg.det(2 * np.pi * self.covariance))\n                            * self.num_dp)\n\n    def scotts_factor(self):\n        return np.power(self.num_dp, -1. / (self.dim + 4))\n\n    def silverman_factor(self):\n        return np.power(\n            self.num_dp * (self.dim + 2.0) / 4.0, -1. / (self.dim + 4))\n\n    #  Default method to calculate bandwidth, can be overwritten by subclass\n    covariance_factor = scotts_factor\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function evaluates the Gaussian distribution of a given set of points.\n\nArgs:\n    points (numpy.ndarray): The points to be evaluated.\n\nReturns:\n    numpy.ndarray: The result of the evaluation.\n\nRaises:\n    ValueError: If the dimension of the points does not match the dimension of the dataset.\n\nNotes:\n    This function uses numpy.sum and numpy.exp for the calculation.\n    The function first checks if the dimension of the points matches the dimension of the dataset.\n    If the number of points is greater than or equal to the number of data points, it loops over the data points.\n    Otherwise, it loops over the points.\n    For each iteration, it calculates the difference between the dataset and the points,\n    the transpose of the inverse covariance matrix of the difference,\n    and the energy.\n    The energy is then used to calculate the result.\n    The result is normalized by the normalization factor.\n    The function returns the result.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def evaluate(self, points):\n        points = np.atleast_2d(points)\n\n        dim, num_m = np.array(points).shape\n        if dim != self.dim:\n            raise ValueError(\"points have dimension {}, dataset has dimension \"\n                             \"{}\".format(dim, self.dim))\n\n        result = np.zeros(num_m)\n\n        if num_m >= self.num_dp:\n            # there are more points than data, so loop over data\n            for i in range(self.num_dp):\n                diff = self.dataset[:, i, np.newaxis] - points\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                tdiff = np.dot(self.inv_cov, diff)\n                energy = np.sum(diff * tdiff, axis=0) / 2.0\n                result = result + np.exp(-energy)\n        else:\n            # loop over points\n            for i in range(num_m):\n                diff = self.dataset - points[:, i, np.newaxis]\n                tdiff = np.dot(self.inv_cov, diff)\n                energy = np.sum(diff * tdiff, axis=0) / 2.0\n                result[i] = np.sum(np.exp(-energy), axis=0)\n\n        result = result / self.norm_factor\n\n        return result", "completions": ["  \n[PYTHON]\ndef evaluate(self, points):\n    points = np.atleast_2d(points)\n\n    dim, num_m = np.array(points).shape\n    if dim!= self.dim:\n        raise ValueError(\"points have dimension {}, dataset has dimension \"\n                         \"{}\".format(dim, self.dim))\n\n    result = np.zeros(num_m)\n\n    if num_m >= self.num_dp:\n        # there are more points than data, so loop over data\n        for i in range(self.num_dp):\n            diff = self.dataset[:, i, np.newaxis] - points\n            result += np.sum(np.exp(-0.5 * np.dot(diff, np.dot(self.inv_cov, diff.T))), axis=0)\n    else:\n        # there are more points than data, so loop over points\n        for i in range(num_m):\n            diff = self.dataset - points[:, i, np.newaxis]\n            result[i] = np.sum(np.exp(-0.5 * np.dot(diff, np.dot(self.inv_cov, diff.T))))\n\n    result /= self.norm_factor\n    return result\n[/PYTHON]\n"]}
{"id": 23, "name": "_get_device_type_from_env", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nfrom typing import Optional\n\nimport torch\n\n\ndef _get_local_rank() -> Optional[int]:\n    \"\"\"Function that gets the local rank from the environment.\n\n    Returns:\n        local_rank int or None if not set.\n    \"\"\"\n    local_rank = os.environ.get(\"LOCAL_RANK\")\n    if local_rank is not None:\n        local_rank = int(local_rank)\n    return local_rank\n\n\ndef _setup_cuda_device(device: torch.device) -> torch.device:\n    \"\"\"Function that sets the CUDA device and infers the cuda\n    index if not set.\n\n    Args:\n        device (torch.device): The device to set.\n\n    Raises:\n        RuntimeError: If device index is not available.\n\n    Returns:\n        device\n    \"\"\"\n    local_rank = _get_local_rank() or 0\n    if device.index is None:\n        device = torch.device(type=\"cuda\", index=local_rank)\n\n    # Ensure index is available before setting device\n    if device.index >= torch.cuda.device_count():\n        raise RuntimeError(\n            \"The local rank is larger than the number of available GPUs.\"\n        )\n\n    torch.cuda.set_device(device)\n    return device\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function checks if CUDA is available and returns the device type accordingly.\n\nReturns:\n    str: Returns 'cuda' if CUDA is available, otherwise returns 'cpu'.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef _get_device_type_from_env() -> str:\n    if torch.cuda.is_available():\n        device = \"cuda\"\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    else:\n        device = \"cpu\"\n    return device", "completions": ["  \n[PYTHON]\n```\ndef _get_device_type_from_env() -> str:\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    return device\n```\n[/PYTHON]\n"]}
{"id": 25, "name": "run_calc", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Utility functions for running ASE calculators with ASE-based methods.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom shutil import copy, copytree\nfrom typing import TYPE_CHECKING\n\nimport numpy as np\nfrom ase.filters import FrechetCellFilter\nfrom ase.io import Trajectory, read\nfrom ase.optimize import BFGS\nfrom ase.vibrations import Vibrations\nfrom monty.dev import requires\nfrom monty.os.path import zpath\n\nfrom quacc import SETTINGS\nfrom quacc.atoms.core import copy_atoms, get_final_atoms_from_dynamics\nfrom quacc.runners.prep import calc_cleanup, calc_setup\nfrom quacc.utils.dicts import recursive_dict_merge\n\ntry:\n    from sella import Sella\n\nexcept ImportError:\n    Sella = None\n\nif TYPE_CHECKING:\n    from pathlib import Path\n    from typing import Any, TypedDict\n\n    from ase.atoms import Atoms\n    from ase.optimize.optimize import Optimizer\n\n    from quacc.utils.files import Filenames, SourceDirectory\n\n    class OptimizerKwargs(TypedDict, total=False):\n        \"\"\"\n        Type hint for `optimizer_kwargs` in [quacc.runners.ase.run_opt][].\n        \"\"\"\n\n        restart: Path | str | None  # default = None\n        append_trajectory: bool  # default = False\n\n    class VibKwargs(TypedDict, total=False):\n        \"\"\"\n        Type hint for `vib_kwargs` in [quacc.runners.ase.run_vib][].\n        \"\"\"\n\n        indices: list[int] | None  # default = None\n        delta: float  # default = 0.01\n        nfree: int  # default = 2\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function runs a calculation on an Atoms object.\n\nArgs:\n    atoms (Atoms): The Atoms object to be calculated.\n    geom_file (str | None, optional): The path to a file containing the final geometry. Defaults to None.\n    copy_files (SourceDirectory | dict[SourceDirectory, Filenames] | None, optional): Files to be copied. Defaults to None.\n    get_forces (bool, optional): If True, forces are calculated. Otherwise, the potential energy is calculated. Defaults to False.\n\nReturns:\n    Atoms: The updated Atoms object.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Copy atoms so we don't modify it in-place\n    atoms = copy_atoms(atoms)\n\n    # Perform staging operations\n    tmpdir, job_results_dir = calc_setup(atoms, copy_files=copy_files)\n\n    # Run calculation\n    if get_forces:\n        atoms.get_forces()\n    else:\n        atoms.get_potential_energy()\n\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to .get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    # Note: We have to be careful to make sure we don't lose the calculator\n    # object, as this contains important information such as the parameters\n    # and output properties (e.g. final magnetic moments).\n    if geom_file:\n        atoms_new = read(zpath(tmpdir / geom_file))\n        if isinstance(atoms_new, list):\n            atoms_new = atoms_new[-1]\n\n        # Make sure the atom indices didn't get updated somehow (sanity check).\n        # If this happens, there is a serious problem.\n        if (\n            np.array_equal(atoms_new.get_atomic_numbers(), atoms.get_atomic_numbers())\n            is False\n        ):\n            raise ValueError(\"Atomic numbers do not match between atoms and geom_file.\")\n\n        atoms.positions = atoms_new.positions\n        atoms.cell = atoms_new.cell\n\n    # Perform cleanup operations\n    calc_cleanup(atoms, tmpdir, job_results_dir)\n\n    return atoms", "completions": ["  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to.get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n    if geom_file is not None:\n        atoms = get_final_atoms_from_dynamics(atoms, geom_file)\n\n    return atoms\n```\n[/markdown]  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to.get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n    if geom_file is not None:\n        atoms = get_final_atoms_from_dynamics(atoms, geom_file)\n\n    return atoms\n```\n[/markdown]  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to.get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n    if geom_file is not None:\n        atoms = get_final_atoms_from_dynamics(atoms, geom_file)\n\n    return atoms\n```\n[/markdown]  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to.get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n    if geom_file is not None:\n        atoms = get_final_atoms_from_dynamics(atoms, geom_file)\n\n    return atoms\n```\n[/markdown]  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None = None,\n    copy_files: SourceDirectory | dict[SourceDirectory, Filenames] | None = None,\n    get_forces: bool = False,\n) -> Atoms:\n    # Most ASE calculators do not update the atoms object in-place with a call\n    # to.get_potential_energy(), which is important if an internal optimizer is\n    # used. This section is done to ensure that the atoms object is updated to\n    # the final geometry if `geom_file` is provided.\n    if geom_file is not None:\n        atoms = get_final_atoms_from_dynamics(atoms, geom_file)\n\n    return atoms\n```\n[/markdown]  \n[markdown]```\ndef run_calc(\n    atoms: Atoms,\n    geom_file: str | None ="]}
{"id": 26, "name": "plan", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom typing import Optional\n\nfrom langchain.llms.base import LLM\nfrom loguru import logger\n\nfrom sherpa_ai.actions.planning import TaskPlanning\nfrom sherpa_ai.agents.agent_pool import AgentPool\nfrom sherpa_ai.agents.base import BaseAgent\nfrom sherpa_ai.events import Event, EventType\nfrom sherpa_ai.memory import Belief, SharedMemory\nfrom sherpa_ai.verbose_loggers.verbose_loggers import DummyVerboseLogger\n\nPLANNER_DESCRIPTION = \"\"\"You are a **task decomposition assistant** who simplifies complex tasks into sequential steps, assigning roles or agents to each.\nBy analyzing user-defined tasks and agent capabilities, you provide structured plans, enhancing project clarity and efficiency.\nYour adaptability ensures customized solutions for diverse needs. \n\"\"\"  # noqa: E501\n\n\nclass Planner(BaseAgent):\n    def __init__(\n        self,\n        agent_pool: AgentPool,\n        name: str = \"Planner\",\n        description: str = PLANNER_DESCRIPTION,\n        shared_memory: SharedMemory = None,\n        belief: Belief = None,\n        action_selector=None,\n        llm=LLM,\n        num_steps: int = 5,\n        verbose_logger=DummyVerboseLogger(),\n    ):\n        self.name = name\n        self.description = description\n        self.agent_pool = agent_pool\n        self.shared_memory = shared_memory\n        self.belief = belief\n        self.action_selector = action_selector\n\n        self.planning = TaskPlanning(llm, num_steps)\n        self.verbose_logger = verbose_logger\n\n    def get_last_feedback(self) -> Optional[str]:\n        \"\"\"\n        Get the last feedback from the shared memory\n        \"\"\"\n        feedback_events = self.shared_memory.get_by_type(EventType.feedback)\n        if len(feedback_events) == 0:\n            return None\n        else:\n            return feedback_events[-1].content\n\n    def get_last_plan(self) -> Optional[str]:\n        \"\"\"\n        Get the last plan from the shared memory\n        \"\"\"\n        plan_events = self.shared_memory.get_by_type(EventType.planning)\n        if len(plan_events) == 0:\n            return None\n        else:\n            return plan_events[-1].content\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to plan a task using the agent pool description, last feedback, and last plan.\n\nArgs:\n    task (str): The task to be planned.\n\nReturns:\n    plan: The plan generated by the planning algorithm.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def plan(self, task: str):\n        agent_pool_description = self.agent_pool.get_agent_pool_description()\n        feedback = self.get_last_feedback()\n        last_plan = self.get_last_plan()\n\n        # run the planning\n        plan = self.planning.execute(task, agent_pool_description, last_plan, feedback)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n        logger.info(f\"Plan: {plan}\")\n\n        self.shared_memory.add(\n            event_type=EventType.planning, agent=self.name, content=str(plan)\n        )\n\n        return plan", "completions": ["  \n[PYTHON]\ndef plan(self, task: str):\n    agent_pool_description = self.agent_pool.get_agent_pool_description()\n    feedback = self.get_last_feedback()\n    last_plan = self.get_last_plan()\n\n    # run the planning\n    plan = self.planning.execute(task, agent_pool_description, last_plan, feedback)\n    return plan\n[/PYTHON]\n"]}
{"id": 27, "name": "load", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom typing import Any, Dict, List, Literal, Optional, Tuple\n\nimport json\nimport os\nimport requests\nimport yaml\n\nfrom .callback import CallbackEvent, CallbackManager\nfrom .default_parsers.anyscale_endpoint import (\n    DefaultAnyscaleEndpointParser,\n)\nfrom .default_parsers.claude import ClaudeBedrockModelParser\nfrom .default_parsers.dalle import DalleImageGenerationParser\nfrom .default_parsers.openai import DefaultOpenAIParser\nfrom .default_parsers.openai_vision import OpenAIVisionParser\nfrom .default_parsers.gemini import GeminiModelParser\nfrom .default_parsers.hf import HuggingFaceTextGenerationParser\nfrom .default_parsers.palm import PaLMChatParser, PaLMTextParser\nfrom .model_parser import InferenceOptions, ModelParser\n\nfrom .registry import (\n    ModelParserRegistry,\n    update_model_parser_registry_with_config_runtime,\n)\nfrom .schema import AIConfig, JSONObject, Prompt\nfrom .util.config_utils import is_yaml_ext\n\ngpt_models_main = [\n    \"gpt-3.5-turbo\",\n    \"gpt-4\",\n]\ngpt_models_extra = [\n    \"gpt-3.5-turbo-16k\",\n    \"gpt-3.5-turbo-0301\",\n    \"gpt-3.5-turbo-0613\",\n    \"gpt-3.5-turbo-16k-0613\",\n    \"gpt-4-0314\",\n    \"gpt-4-0613\",\n    \"gpt-4-32k\",\n    \"gpt-4-32k-0314\",\n    \"gpt-4-32k-0613\",\n]\nfor model in gpt_models_main:\n    ModelParserRegistry.register_model_parser(DefaultOpenAIParser(model))\n\nModelParserRegistry.register_model_parser(\n    OpenAIVisionParser(\"gpt-4-vision-preview\")\n)\nModelParserRegistry.register_model_parser(\n    GeminiModelParser(\"gemini-pro\"), [\"gemini-pro\"]\n)\ndalle_image_generation_models = [\n    \"dall-e-2\",\n    \"dall-e-3\",\n]\nfor model in dalle_image_generation_models:\n    ModelParserRegistry.register_model_parser(\n        DalleImageGenerationParser(model)\n    )\nModelParserRegistry.register_model_parser(\n    DefaultAnyscaleEndpointParser(\"AnyscaleEndpoint\")\n)\nModelParserRegistry.register_model_parser(ClaudeBedrockModelParser())\nfor model in gpt_models_extra:\n    ModelParserRegistry.register_model_parser(DefaultOpenAIParser(model))\n\nModelParserRegistry.register_model_parser(HuggingFaceTextGenerationParser())\nModelParserRegistry.register_model_parser(PaLMChatParser())\nModelParserRegistry.register_model_parser(PaLMTextParser())\n\n\nclass AIConfigRuntime(AIConfig):\n    # A mapping of model names to their respective parsers\n\n    # TODO: Define a default constructor that will construct with default values. This seems a little complicated because of the way pydantic works. Pydantic creates its own constructors.\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.file_path = None\n        # AIConfigRuntime will always have a callback manager. Ae default one is be created when initialized.\n        self.callback_manager = CallbackManager.create_default_manager()\n\n    @classmethod\n    def create(\n        cls,\n        name: str = \"\",\n        description: str = \"\",\n        schema_version: str = \"latest\",\n        metadata={},\n        prompts=[],\n    ) -> \"AIConfigRuntime\":\n        \"\"\"\n        Creates a new AIConfigRuntime and returns it.\n\n        Args:\n            name (str): The name of the AI configuration.\n            description (str): A description of the AI configuration.\n            schema_version (str): The schema version to use for the configuration.\n\n        This method creates a new AI configuration with the provided parameters and sets it as the current AI configuration.\n        \"\"\"\n        config: \"AIConfigRuntime\" = cls(\n            **{\n                \"name\": name,\n                \"description\": description,\n                \"schema_version\": schema_version,\n                \"metadata\": metadata,\n                \"prompts\": prompts,\n            }\n        )\n        update_model_parser_registry_with_config_runtime(config)\n        return config\n\n    @classmethod\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function loads AI configuration from a file.\n\nArgs:\n    cls (type): The class of the object to be loaded.\n    config_filepath (str): The file path of the configuration file.\n\nReturns:\n    AIConfigRuntime: The loaded AI configuration runtime object.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def load(cls, config_filepath: str) -> \"AIConfigRuntime\":\n\n        with open(config_filepath) as file:\n            if is_yaml_ext(config_filepath):\n                yaml_data = yaml.safe_load(file)\n                data = json.dumps(yaml_data)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            else:\n                data = file.read()\n\n        config_runtime = cls.load_json(data)\n        # set the file path. This is used when saving the config\n        config_runtime.file_path = config_filepath\n        return config_runtime", "completions": ["  \n[PYTHON]\ndef load(cls, config_filepath: str) -> \"AIConfigRuntime\":\n    with open(config_filepath) as file:\n        if is_yaml_ext(config_filepath):\n            yaml_data = yaml.safe_load(file)\n            data = json.dumps(yaml_data)\n        else:\n            data = file.read()\n    config = cls.parse_obj(json.loads(data))\n    return config\n[/PYTHON]\n"]}
{"id": 28, "name": "unique", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\nMasked arrays add-ons.\n\nA collection of utilities for `numpy.ma`.\n\n:author: Pierre Gerard-Marchant\n:contact: pierregm_at_uga_dot_edu\n:version: $Id: extras.py 3473 2007-10-29 15:18:13Z jarrod.millman $\n\n\"\"\"\n__all__ = [\n    'apply_along_axis', 'apply_over_axes', 'atleast_1d', 'atleast_2d',\n    'atleast_3d', 'average', 'clump_masked', 'clump_unmasked', 'column_stack',\n    'compress_cols', 'compress_nd', 'compress_rowcols', 'compress_rows',\n    'count_masked', 'corrcoef', 'cov', 'diagflat', 'dot', 'dstack', 'ediff1d',\n    'flatnotmasked_contiguous', 'flatnotmasked_edges', 'hsplit', 'hstack',\n    'isin', 'in1d', 'intersect1d', 'mask_cols', 'mask_rowcols', 'mask_rows',\n    'masked_all', 'masked_all_like', 'median', 'mr_', 'ndenumerate',\n    'notmasked_contiguous', 'notmasked_edges', 'polyfit', 'row_stack',\n    'setdiff1d', 'setxor1d', 'stack', 'unique', 'union1d', 'vander', 'vstack',\n    ]\n\nimport itertools\nimport warnings\n\nfrom . import core as ma\nfrom .core import (\n    MaskedArray, MAError, add, array, asarray, concatenate, filled, count,\n    getmask, getmaskarray, make_mask_descr, masked, masked_array, mask_or,\n    nomask, ones, sort, zeros, getdata, get_masked_subclass, dot,\n    mask_rowcols\n    )\n\nimport numpy as np\nfrom numpy import ndarray, array as nxarray\nfrom numpy.core.multiarray import normalize_axis_index\nfrom numpy.core.numeric import normalize_axis_tuple\nfrom numpy.lib.function_base import _ureduce\nfrom numpy.lib.index_tricks import AxisConcatenator\n\n\ndef issequence(seq):\n    \"\"\"\n    Is seq a sequence (ndarray, list or tuple)?\n\n    \"\"\"\n    return isinstance(seq, (ndarray, tuple, list))\n\n\ndef count_masked(arr, axis=None):\n    \"\"\"\n    Count the number of masked elements along the given axis.\n\n    Parameters\n    ----------\n    arr : array_like\n        An array with (possibly) masked elements.\n    axis : int, optional\n        Axis along which to count. If None (default), a flattened\n        version of the array is used.\n\n    Returns\n    -------\n    count : int, ndarray\n        The total number of masked elements (axis=None) or the number\n        of masked elements along each slice of the given axis.\n\n    See Also\n    --------\n    MaskedArray.count : Count non-masked elements.\n\n    Examples\n    --------\n    >>> import numpy.ma as ma\n    >>> a = np.arange(9).reshape((3,3))\n    >>> a = ma.array(a)\n    >>> a[1, 0] = ma.masked\n    >>> a[1, 2] = ma.masked\n    >>> a[2, 1] = ma.masked\n    >>> a\n    masked_array(\n      data=[[0, 1, 2],\n            [--, 4, --],\n            [6, --, 8]],\n      mask=[[False, False, False],\n            [ True, False,  True],\n            [False,  True, False]],\n      fill_value=999999)\n    >>> ma.count_masked(a)\n    3\n\n    When the `axis` keyword is used an array is returned.\n\n    >>> ma.count_masked(a, axis=0)\n    array([1, 1, 1])\n    >>> ma.count_masked(a, axis=1)\n    array([0, 2, 1])\n\n    \"\"\"\n    m = getmaskarray(arr)\n    return m.sum(axis)\n\n\ndef masked_all(shape, dtype=float):\n    \"\"\"\n    Empty masked array with all elements masked.\n\n    Return an empty masked array of the given shape and dtype, where all the\n    data are masked.\n\n    Parameters\n    ----------\n    shape : int or tuple of ints\n        Shape of the required MaskedArray, e.g., ``(2, 3)`` or ``2``.\n    dtype : dtype, optional\n        Data type of the output.\n\n    Returns\n    -------\n    a : MaskedArray\n        A masked array with all data masked.\n\n    See Also\n    --------\n    masked_all_like : Empty masked array modelled on an existing array.\n\n    Examples\n    --------\n    >>> import numpy.ma as ma\n    >>> ma.masked_all((3, 3))\n    masked_array(\n      data=[[--, --, --],\n            [--, --, --],\n            [--, --, --]],\n      mask=[[ True,  True,  True],\n            [ True,  True,  True],\n            [ True,  True,  True]],\n      fill_value=1e+20,\n      dtype=float64)\n\n    The `dtype` parameter defines the underlying data type.\n\n    >>> a = ma.masked_all((3, 3))\n    >>> a.dtype\n    dtype('float64')\n    >>> a = ma.masked_all((3, 3), dtype=np.int32)\n    >>> a.dtype\n    dtype('int32')\n\n    \"\"\"\n    a = masked_array(np.empty(shape, dtype),\n                     mask=np.ones(shape, make_mask_descr(dtype)))\n    return a\n\n\ndef masked_all_like(arr):\n    \"\"\"\n    Empty masked array with the properties of an existing array.\n\n    Return an empty masked array of the same shape and dtype as\n    the array `arr`, where all the data are masked.\n\n    Parameters\n    ----------\n    arr : ndarray\n        An array describing the shape and dtype of the required MaskedArray.\n\n    Returns\n    -------\n    a : MaskedArray\n        A masked array with all data masked.\n\n    Raises\n    ------\n    AttributeError\n        If `arr` doesn't have a shape attribute (i.e. not an ndarray)\n\n    See Also\n    --------\n    masked_all : Empty masked array with all elements masked.\n\n    Examples\n    --------\n    >>> import numpy.ma as ma\n    >>> arr = np.zeros((2, 3), dtype=np.float32)\n    >>> arr\n    array([[0., 0., 0.],\n           [0., 0., 0.]], dtype=float32)\n    >>> ma.masked_all_like(arr)\n    masked_array(\n      data=[[--, --, --],\n            [--, --, --]],\n      mask=[[ True,  True,  True],\n            [ True,  True,  True]],\n      fill_value=1e+20,\n      dtype=float32)\n\n    The dtype of the masked array matches the dtype of `arr`.\n\n    >>> arr.dtype\n    dtype('float32')\n    >>> ma.masked_all_like(arr).dtype\n    dtype('float32')\n\n    \"\"\"\n    a = np.empty_like(arr).view(MaskedArray)\n    a._mask = np.ones(a.shape, dtype=make_mask_descr(a.dtype))\n    return a\n\n\n#####--------------------------------------------------------------------------\n#---- --- Standard functions ---\n#####--------------------------------------------------------------------------\nclass _fromnxfunction:\n    \"\"\"\n    Defines a wrapper to adapt NumPy functions to masked arrays.\n\n\n    An instance of `_fromnxfunction` can be called with the same parameters\n    as the wrapped NumPy function. The docstring of `newfunc` is adapted from\n    the wrapped function as well, see `getdoc`.\n\n    This class should not be used directly. Instead, one of its extensions that\n    provides support for a specific type of input should be used.\n\n    Parameters\n    ----------\n    funcname : str\n        The name of the function to be adapted. The function should be\n        in the NumPy namespace (i.e. ``np.funcname``).\n\n    \"\"\"\n\n    def __init__(self, funcname):\n        self.__name__ = funcname\n        self.__doc__ = self.getdoc()\n\n    def getdoc(self):\n        \"\"\"\n        Retrieve the docstring and signature from the function.\n\n        The ``__doc__`` attribute of the function is used as the docstring for\n        the new masked array version of the function. A note on application\n        of the function to the mask is appended.\n\n        Parameters\n        ----------\n        None\n\n        \"\"\"\n        npfunc = getattr(np, self.__name__, None)\n        doc = getattr(npfunc, '__doc__', None)\n        if doc:\n            sig = self.__name__ + ma.get_object_signature(npfunc)\n            doc = ma.doc_note(doc, \"The function is applied to both the _data \"\n                                   \"and the _mask, if any.\")\n            return '\\n\\n'.join((sig, doc))\n        return\n\n    def __call__(self, *args, **params):\n        pass\n\n\nclass _fromnxfunction_single(_fromnxfunction):\n    \"\"\"\n    A version of `_fromnxfunction` that is called with a single array\n    argument followed by auxiliary args that are passed verbatim for\n    both the data and mask calls.\n    \"\"\"\n    def __call__(self, x, *args, **params):\n        func = getattr(np, self.__name__)\n        if isinstance(x, ndarray):\n            _d = func(x.__array__(), *args, **params)\n            _m = func(getmaskarray(x), *args, **params)\n            return masked_array(_d, mask=_m)\n        else:\n            _d = func(np.asarray(x), *args, **params)\n            _m = func(getmaskarray(x), *args, **params)\n            return masked_array(_d, mask=_m)\n\n\nclass _fromnxfunction_seq(_fromnxfunction):\n    \"\"\"\n    A version of `_fromnxfunction` that is called with a single sequence\n    of arrays followed by auxiliary args that are passed verbatim for\n    both the data and mask calls.\n    \"\"\"\n    def __call__(self, x, *args, **params):\n        func = getattr(np, self.__name__)\n        _d = func(tuple([np.asarray(a) for a in x]), *args, **params)\n        _m = func(tuple([getmaskarray(a) for a in x]), *args, **params)\n        return masked_array(_d, mask=_m)\n\n\nclass _fromnxfunction_args(_fromnxfunction):\n    \"\"\"\n    A version of `_fromnxfunction` that is called with multiple array\n    arguments. The first non-array-like input marks the beginning of the\n    arguments that are passed verbatim for both the data and mask calls.\n    Array arguments are processed independently and the results are\n    returned in a list. If only one array is found, the return value is\n    just the processed array instead of a list.\n    \"\"\"\n    def __call__(self, *args, **params):\n        func = getattr(np, self.__name__)\n        arrays = []\n        args = list(args)\n        while len(args) > 0 and issequence(args[0]):\n            arrays.append(args.pop(0))\n        res = []\n        for x in arrays:\n            _d = func(np.asarray(x), *args, **params)\n            _m = func(getmaskarray(x), *args, **params)\n            res.append(masked_array(_d, mask=_m))\n        if len(arrays) == 1:\n            return res[0]\n        return res\n\n\nclass _fromnxfunction_allargs(_fromnxfunction):\n    \"\"\"\n    A version of `_fromnxfunction` that is called with multiple array\n    arguments. Similar to `_fromnxfunction_args` except that all args\n    are converted to arrays even if they are not so already. This makes\n    it possible to process scalars as 1-D arrays. Only keyword arguments\n    are passed through verbatim for the data and mask calls. Arrays\n    arguments are processed independently and the results are returned\n    in a list. If only one arg is present, the return value is just the\n    processed array instead of a list.\n    \"\"\"\n    def __call__(self, *args, **params):\n        func = getattr(np, self.__name__)\n        res = []\n        for x in args:\n            _d = func(np.asarray(x), **params)\n            _m = func(getmaskarray(x), **params)\n            res.append(masked_array(_d, mask=_m))\n        if len(args) == 1:\n            return res[0]\n        return res\n\n\natleast_1d = _fromnxfunction_allargs('atleast_1d')\natleast_2d = _fromnxfunction_allargs('atleast_2d')\natleast_3d = _fromnxfunction_allargs('atleast_3d')\n\nvstack = row_stack = _fromnxfunction_seq('vstack')\nhstack = _fromnxfunction_seq('hstack')\ncolumn_stack = _fromnxfunction_seq('column_stack')\ndstack = _fromnxfunction_seq('dstack')\nstack = _fromnxfunction_seq('stack')\n\nhsplit = _fromnxfunction_single('hsplit')\n\ndiagflat = _fromnxfunction_single('diagflat')\n\n\n#####--------------------------------------------------------------------------\n#----\n#####--------------------------------------------------------------------------\ndef flatten_inplace(seq):\n    \"\"\"Flatten a sequence in place.\"\"\"\n    k = 0\n    while (k != len(seq)):\n        while hasattr(seq[k], '__iter__'):\n            seq[k:(k + 1)] = seq[k]\n        k += 1\n    return seq\n\n\ndef apply_along_axis(func1d, axis, arr, *args, **kwargs):\n    \"\"\"\n    (This docstring should be overwritten)\n    \"\"\"\n    arr = array(arr, copy=False, subok=True)\n    nd = arr.ndim\n    axis = normalize_axis_index(axis, nd)\n    ind = [0] * (nd - 1)\n    i = np.zeros(nd, 'O')\n    indlist = list(range(nd))\n    indlist.remove(axis)\n    i[axis] = slice(None, None)\n    outshape = np.asarray(arr.shape).take(indlist)\n    i.put(indlist, ind)\n    res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n    #  if res is a number, then we have a smaller output array\n    asscalar = np.isscalar(res)\n    if not asscalar:\n        try:\n            len(res)\n        except TypeError:\n            asscalar = True\n    # Note: we shouldn't set the dtype of the output from the first result\n    # so we force the type to object, and build a list of dtypes.  We'll\n    # just take the largest, to avoid some downcasting\n    dtypes = []\n    if asscalar:\n        dtypes.append(np.asarray(res).dtype)\n        outarr = zeros(outshape, object)\n        outarr[tuple(ind)] = res\n        Ntot = np.product(outshape)\n        k = 1\n        while k < Ntot:\n            # increment the index\n            ind[-1] += 1\n            n = -1\n            while (ind[n] >= outshape[n]) and (n > (1 - nd)):\n                ind[n - 1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(ind)] = res\n            dtypes.append(asarray(res).dtype)\n            k += 1\n    else:\n        res = array(res, copy=False, subok=True)\n        j = i.copy()\n        j[axis] = ([slice(None, None)] * res.ndim)\n        j.put(indlist, ind)\n        Ntot = np.product(outshape)\n        holdshape = outshape\n        outshape = list(arr.shape)\n        outshape[axis] = res.shape\n        dtypes.append(asarray(res).dtype)\n        outshape = flatten_inplace(outshape)\n        outarr = zeros(outshape, object)\n        outarr[tuple(flatten_inplace(j.tolist()))] = res\n        k = 1\n        while k < Ntot:\n            # increment the index\n            ind[-1] += 1\n            n = -1\n            while (ind[n] >= holdshape[n]) and (n > (1 - nd)):\n                ind[n - 1] += 1\n                ind[n] = 0\n                n -= 1\n            i.put(indlist, ind)\n            j.put(indlist, ind)\n            res = func1d(arr[tuple(i.tolist())], *args, **kwargs)\n            outarr[tuple(flatten_inplace(j.tolist()))] = res\n            dtypes.append(asarray(res).dtype)\n            k += 1\n    max_dtypes = np.dtype(np.asarray(dtypes).max())\n    if not hasattr(arr, '_mask'):\n        result = np.asarray(outarr, dtype=max_dtypes)\n    else:\n        result = asarray(outarr, dtype=max_dtypes)\n        result.fill_value = ma.default_fill_value(result)\n    return result\napply_along_axis.__doc__ = np.apply_along_axis.__doc__\n\n\ndef apply_over_axes(func, a, axes):\n    \"\"\"\n    (This docstring will be overwritten)\n    \"\"\"\n    val = asarray(a)\n    N = a.ndim\n    if array(axes).ndim == 0:\n        axes = (axes,)\n    for axis in axes:\n        if axis < 0:\n            axis = N + axis\n        args = (val, axis)\n        res = func(*args)\n        if res.ndim == val.ndim:\n            val = res\n        else:\n            res = ma.expand_dims(res, axis)\n            if res.ndim == val.ndim:\n                val = res\n            else:\n                raise ValueError(\"function is not returning \"\n                        \"an array of the correct shape\")\n    return val\n\n\nif apply_over_axes.__doc__ is not None:\n    apply_over_axes.__doc__ = np.apply_over_axes.__doc__[\n        :np.apply_over_axes.__doc__.find('Notes')].rstrip() + \\\n    \"\"\"\n\n    Examples\n    --------\n    >>> a = np.ma.arange(24).reshape(2,3,4)\n    >>> a[:,0,1] = np.ma.masked\n    >>> a[:,1,:] = np.ma.masked\n    >>> a\n    masked_array(\n      data=[[[0, --, 2, 3],\n             [--, --, --, --],\n             [8, 9, 10, 11]],\n            [[12, --, 14, 15],\n             [--, --, --, --],\n             [20, 21, 22, 23]]],\n      mask=[[[False,  True, False, False],\n             [ True,  True,  True,  True],\n             [False, False, False, False]],\n            [[False,  True, False, False],\n             [ True,  True,  True,  True],\n             [False, False, False, False]]],\n      fill_value=999999)\n    >>> np.ma.apply_over_axes(np.ma.sum, a, [0,2])\n    masked_array(\n      data=[[[46],\n             [--],\n             [124]]],\n      mask=[[[False],\n             [ True],\n             [False]]],\n      fill_value=999999)\n\n    Tuple axis arguments to ufuncs are equivalent:\n\n    >>> np.ma.sum(a, axis=(0,2)).reshape((1,-1,1))\n    masked_array(\n      data=[[[46],\n             [--],\n             [124]]],\n      mask=[[[False],\n             [ True],\n             [False]]],\n      fill_value=999999)\n    \"\"\"\n\n\ndef average(a, axis=None, weights=None, returned=False, *,\n            keepdims=np._NoValue):\n    \"\"\"\n    Return the weighted average of array over the given axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Data to be averaged.\n        Masked entries are not taken into account in the computation.\n    axis : int, optional\n        Axis along which to average `a`. If None, averaging is done over\n        the flattened array.\n    weights : array_like, optional\n        The importance that each element has in the computation of the average.\n        The weights array can either be 1-D (in which case its length must be\n        the size of `a` along the given axis) or of the same shape as `a`.\n        If ``weights=None``, then all data in `a` are assumed to have a\n        weight equal to one.  The 1-D calculation is::\n\n            avg = sum(a * weights) / sum(weights)\n\n        The only constraint on `weights` is that `sum(weights)` must not be 0.\n    returned : bool, optional\n        Flag indicating whether a tuple ``(result, sum of weights)``\n        should be returned as output (True), or just the result (False).\n        Default is False.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the original `a`.\n        *Note:* `keepdims` will not work with instances of `numpy.matrix`\n        or other classes whose methods do not support `keepdims`.\n\n        .. versionadded:: 1.23.0\n\n    Returns\n    -------\n    average, [sum_of_weights] : (tuple of) scalar or MaskedArray\n        The average along the specified axis. When returned is `True`,\n        return a tuple with the average as the first element and the sum\n        of the weights as the second element. The return type is `np.float64`\n        if `a` is of integer type and floats smaller than `float64`, or the\n        input data-type, otherwise. If returned, `sum_of_weights` is always\n        `float64`.\n\n    Examples\n    --------\n    >>> a = np.ma.array([1., 2., 3., 4.], mask=[False, False, True, True])\n    >>> np.ma.average(a, weights=[3, 1, 0, 0])\n    1.25\n\n    >>> x = np.ma.arange(6.).reshape(3, 2)\n    >>> x\n    masked_array(\n      data=[[0., 1.],\n            [2., 3.],\n            [4., 5.]],\n      mask=False,\n      fill_value=1e+20)\n    >>> avg, sumweights = np.ma.average(x, axis=0, weights=[1, 2, 3],\n    ...                                 returned=True)\n    >>> avg\n    masked_array(data=[2.6666666666666665, 3.6666666666666665],\n                 mask=[False, False],\n           fill_value=1e+20)\n\n    With ``keepdims=True``, the following result has shape (3, 1).\n\n    >>> np.ma.average(x, axis=1, keepdims=True)\n    masked_array(\n      data=[[0.5],\n            [2.5],\n            [4.5]],\n      mask=False,\n      fill_value=1e+20)\n    \"\"\"\n    a = asarray(a)\n    m = getmask(a)\n\n    # inspired by 'average' in numpy/lib/function_base.py\n\n    if keepdims is np._NoValue:\n        # Don't pass on the keepdims argument if one wasn't given.\n        keepdims_kw = {}\n    else:\n        keepdims_kw = {'keepdims': keepdims}\n\n    if weights is None:\n        avg = a.mean(axis, **keepdims_kw)\n        scl = avg.dtype.type(a.count(axis))\n    else:\n        wgt = asarray(weights)\n\n        if issubclass(a.dtype.type, (np.integer, np.bool_)):\n            result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')\n        else:\n            result_dtype = np.result_type(a.dtype, wgt.dtype)\n\n        # Sanity checks\n        if a.shape != wgt.shape:\n            if axis is None:\n                raise TypeError(\n                    \"Axis must be specified when shapes of a and weights \"\n                    \"differ.\")\n            if wgt.ndim != 1:\n                raise TypeError(\n                    \"1D weights expected when shapes of a and weights differ.\")\n            if wgt.shape[0] != a.shape[axis]:\n                raise ValueError(\n                    \"Length of weights not compatible with specified axis.\")\n\n            # setup wgt to broadcast along axis\n            wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape, subok=True)\n            wgt = wgt.swapaxes(-1, axis)\n\n        if m is not nomask:\n            wgt = wgt*(~a.mask)\n            wgt.mask |= a.mask\n\n        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n        avg = np.multiply(a, wgt,\n                          dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n\n    if returned:\n        if scl.shape != avg.shape:\n            scl = np.broadcast_to(scl, avg.shape).copy()\n        return avg, scl\n    else:\n        return avg\n\n\ndef median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \"\"\"\n    Compute the median along the specified axis.\n\n    Returns the median of the array elements.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : int, optional\n        Axis along which the medians are computed. The default (None) is\n        to compute the median along a flattened version of the array.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output\n        but the type will be cast if necessary.\n    overwrite_input : bool, optional\n        If True, then allow use of memory of input array (a) for\n        calculations. The input array will be modified by the call to\n        median. This will save memory when you do not need to preserve\n        the contents of the input array. Treat the input as undefined,\n        but it will probably be fully or partially sorted. Default is\n        False. Note that, if `overwrite_input` is True, and the input\n        is not already an `ndarray`, an error will be raised.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n\n        .. versionadded:: 1.10.0\n\n    Returns\n    -------\n    median : ndarray\n        A new array holding the result is returned unless out is\n        specified, in which case a reference to out is returned.\n        Return data-type is `float64` for integers and floats smaller than\n        `float64`, or the input data-type, otherwise.\n\n    See Also\n    --------\n    mean\n\n    Notes\n    -----\n    Given a vector ``V`` with ``N`` non masked values, the median of ``V``\n    is the middle value of a sorted copy of ``V`` (``Vs``) - i.e.\n    ``Vs[(N-1)/2]``, when ``N`` is odd, or ``{Vs[N/2 - 1] + Vs[N/2]}/2``\n    when ``N`` is even.\n\n    Examples\n    --------\n    >>> x = np.ma.array(np.arange(8), mask=[0]*4 + [1]*4)\n    >>> np.ma.median(x)\n    1.5\n\n    >>> x = np.ma.array(np.arange(10).reshape(2, 5), mask=[0]*6 + [1]*4)\n    >>> np.ma.median(x)\n    2.5\n    >>> np.ma.median(x, axis=-1, overwrite_input=True)\n    masked_array(data=[2.0, 5.0],\n                 mask=[False, False],\n           fill_value=1e+20)\n\n    \"\"\"\n    if not hasattr(a, 'mask'):\n        m = np.median(getdata(a, subok=True), axis=axis,\n                      out=out, overwrite_input=overwrite_input,\n                      keepdims=keepdims)\n        if isinstance(m, np.ndarray) and 1 <= m.ndim:\n            return masked_array(m, copy=False)\n        else:\n            return m\n\n    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n                    overwrite_input=overwrite_input)\n\n\ndef _median(a, axis=None, out=None, overwrite_input=False):\n    # when an unmasked NaN is present return it, so we need to sort the NaN\n    # values behind the mask\n    if np.issubdtype(a.dtype, np.inexact):\n        fill_value = np.inf\n    else:\n        fill_value = None\n    if overwrite_input:\n        if axis is None:\n            asorted = a.ravel()\n            asorted.sort(fill_value=fill_value)\n        else:\n            a.sort(axis=axis, fill_value=fill_value)\n            asorted = a\n    else:\n        asorted = sort(a, axis=axis, fill_value=fill_value)\n\n    if axis is None:\n        axis = 0\n    else:\n        axis = normalize_axis_index(axis, asorted.ndim)\n\n    if asorted.shape[axis] == 0:\n        # for empty axis integer indices fail so use slicing to get same result\n        # as median (which is mean of empty slice = nan)\n        indexer = [slice(None)] * asorted.ndim\n        indexer[axis] = slice(0, 0)\n        indexer = tuple(indexer)\n        return np.ma.mean(asorted[indexer], axis=axis, out=out)\n\n    if asorted.ndim == 1:\n        idx, odd = divmod(count(asorted), 2)\n        mid = asorted[idx + odd - 1:idx + 1]\n        if np.issubdtype(asorted.dtype, np.inexact) and asorted.size > 0:\n            # avoid inf / x = masked\n            s = mid.sum(out=out)\n            if not odd:\n                s = np.true_divide(s, 2., casting='safe', out=out)\n            s = np.lib.utils._median_nancheck(asorted, s, axis)\n        else:\n            s = mid.mean(out=out)\n\n        # if result is masked either the input contained enough\n        # minimum_fill_value so that it would be the median or all values\n        # masked\n        if np.ma.is_masked(s) and not np.all(asorted.mask):\n            return np.ma.minimum_fill_value(asorted)\n        return s\n\n    counts = count(asorted, axis=axis, keepdims=True)\n    h = counts // 2\n\n    # duplicate high if odd number of elements so mean does nothing\n    odd = counts % 2 == 1\n    l = np.where(odd, h, h-1)\n\n    lh = np.concatenate([l,h], axis=axis)\n\n    # get low and high median\n    low_high = np.take_along_axis(asorted, lh, axis=axis)\n\n    def replace_masked(s):\n        # Replace masked entries with minimum_full_value unless it all values\n        # are masked. This is required as the sort order of values equal or\n        # larger than the fill value is undefined and a valid value placed\n        # elsewhere, e.g. [4, --, inf].\n        if np.ma.is_masked(s):\n            rep = (~np.all(asorted.mask, axis=axis, keepdims=True)) & s.mask\n            s.data[rep] = np.ma.minimum_fill_value(asorted)\n            s.mask[rep] = False\n\n    replace_masked(low_high)\n\n    if np.issubdtype(asorted.dtype, np.inexact):\n        # avoid inf / x = masked\n        s = np.ma.sum(low_high, axis=axis, out=out)\n        np.true_divide(s.data, 2., casting='unsafe', out=s.data)\n\n        s = np.lib.utils._median_nancheck(asorted, s, axis)\n    else:\n        s = np.ma.mean(low_high, axis=axis, out=out)\n\n    return s\n\n\ndef compress_nd(x, axis=None):\n    \"\"\"Suppress slices from multiple dimensions which contain masked values.\n\n    Parameters\n    ----------\n    x : array_like, MaskedArray\n        The array to operate on. If not a MaskedArray instance (or if no array\n        elements are masked), `x` is interpreted as a MaskedArray with `mask`\n        set to `nomask`.\n    axis : tuple of ints or int, optional\n        Which dimensions to suppress slices from can be configured with this\n        parameter.\n        - If axis is a tuple of ints, those are the axes to suppress slices from.\n        - If axis is an int, then that is the only axis to suppress slices from.\n        - If axis is None, all axis are selected.\n\n    Returns\n    -------\n    compress_array : ndarray\n        The compressed array.\n    \"\"\"\n    x = asarray(x)\n    m = getmask(x)\n    # Set axis to tuple of ints\n    if axis is None:\n        axis = tuple(range(x.ndim))\n    else:\n        axis = normalize_axis_tuple(axis, x.ndim)\n\n    # Nothing is masked: return x\n    if m is nomask or not m.any():\n        return x._data\n    # All is masked: return empty\n    if m.all():\n        return nxarray([])\n    # Filter elements through boolean indexing\n    data = x._data\n    for ax in axis:\n        axes = tuple(list(range(ax)) + list(range(ax + 1, x.ndim)))\n        data = data[(slice(None),)*ax + (~m.any(axis=axes),)]\n    return data\n\n\ndef compress_rowcols(x, axis=None):\n    \"\"\"\n    Suppress the rows and/or columns of a 2-D array that contain\n    masked values.\n\n    The suppression behavior is selected with the `axis` parameter.\n\n    - If axis is None, both rows and columns are suppressed.\n    - If axis is 0, only rows are suppressed.\n    - If axis is 1 or -1, only columns are suppressed.\n\n    Parameters\n    ----------\n    x : array_like, MaskedArray\n        The array to operate on.  If not a MaskedArray instance (or if no array\n        elements are masked), `x` is interpreted as a MaskedArray with\n        `mask` set to `nomask`. Must be a 2D array.\n    axis : int, optional\n        Axis along which to perform the operation. Default is None.\n\n    Returns\n    -------\n    compressed_array : ndarray\n        The compressed array.\n\n    Examples\n    --------\n    >>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0],\n    ...                                                   [1, 0, 0],\n    ...                                                   [0, 0, 0]])\n    >>> x\n    masked_array(\n      data=[[--, 1, 2],\n            [--, 4, 5],\n            [6, 7, 8]],\n      mask=[[ True, False, False],\n            [ True, False, False],\n            [False, False, False]],\n      fill_value=999999)\n\n    >>> np.ma.compress_rowcols(x)\n    array([[7, 8]])\n    >>> np.ma.compress_rowcols(x, 0)\n    array([[6, 7, 8]])\n    >>> np.ma.compress_rowcols(x, 1)\n    array([[1, 2],\n           [4, 5],\n           [7, 8]])\n\n    \"\"\"\n    if asarray(x).ndim != 2:\n        raise NotImplementedError(\"compress_rowcols works for 2D arrays only.\")\n    return compress_nd(x, axis=axis)\n\n\ndef compress_rows(a):\n    \"\"\"\n    Suppress whole rows of a 2-D array that contain masked values.\n\n    This is equivalent to ``np.ma.compress_rowcols(a, 0)``, see\n    `compress_rowcols` for details.\n\n    See Also\n    --------\n    compress_rowcols\n\n    \"\"\"\n    a = asarray(a)\n    if a.ndim != 2:\n        raise NotImplementedError(\"compress_rows works for 2D arrays only.\")\n    return compress_rowcols(a, 0)\n\n\ndef compress_cols(a):\n    \"\"\"\n    Suppress whole columns of a 2-D array that contain masked values.\n\n    This is equivalent to ``np.ma.compress_rowcols(a, 1)``, see\n    `compress_rowcols` for details.\n\n    See Also\n    --------\n    compress_rowcols\n\n    \"\"\"\n    a = asarray(a)\n    if a.ndim != 2:\n        raise NotImplementedError(\"compress_cols works for 2D arrays only.\")\n    return compress_rowcols(a, 1)\n\n\ndef mask_rows(a, axis=np._NoValue):\n    \"\"\"\n    Mask rows of a 2D array that contain masked values.\n\n    This function is a shortcut to ``mask_rowcols`` with `axis` equal to 0.\n\n    See Also\n    --------\n    mask_rowcols : Mask rows and/or columns of a 2D array.\n    masked_where : Mask where a condition is met.\n\n    Examples\n    --------\n    >>> import numpy.ma as ma\n    >>> a = np.zeros((3, 3), dtype=int)\n    >>> a[1, 1] = 1\n    >>> a\n    array([[0, 0, 0],\n           [0, 1, 0],\n           [0, 0, 0]])\n    >>> a = ma.masked_equal(a, 1)\n    >>> a\n    masked_array(\n      data=[[0, 0, 0],\n            [0, --, 0],\n            [0, 0, 0]],\n      mask=[[False, False, False],\n            [False,  True, False],\n            [False, False, False]],\n      fill_value=1)\n\n    >>> ma.mask_rows(a)\n    masked_array(\n      data=[[0, 0, 0],\n            [--, --, --],\n            [0, 0, 0]],\n      mask=[[False, False, False],\n            [ True,  True,  True],\n            [False, False, False]],\n      fill_value=1)\n\n    \"\"\"\n    if axis is not np._NoValue:\n        # remove the axis argument when this deprecation expires\n        # NumPy 1.18.0, 2019-11-28\n        warnings.warn(\n            \"The axis argument has always been ignored, in future passing it \"\n            \"will raise TypeError\", DeprecationWarning, stacklevel=2)\n    return mask_rowcols(a, 0)\n\n\ndef mask_cols(a, axis=np._NoValue):\n    \"\"\"\n    Mask columns of a 2D array that contain masked values.\n\n    This function is a shortcut to ``mask_rowcols`` with `axis` equal to 1.\n\n    See Also\n    --------\n    mask_rowcols : Mask rows and/or columns of a 2D array.\n    masked_where : Mask where a condition is met.\n\n    Examples\n    --------\n    >>> import numpy.ma as ma\n    >>> a = np.zeros((3, 3), dtype=int)\n    >>> a[1, 1] = 1\n    >>> a\n    array([[0, 0, 0],\n           [0, 1, 0],\n           [0, 0, 0]])\n    >>> a = ma.masked_equal(a, 1)\n    >>> a\n    masked_array(\n      data=[[0, 0, 0],\n            [0, --, 0],\n            [0, 0, 0]],\n      mask=[[False, False, False],\n            [False,  True, False],\n            [False, False, False]],\n      fill_value=1)\n    >>> ma.mask_cols(a)\n    masked_array(\n      data=[[0, --, 0],\n            [0, --, 0],\n            [0, --, 0]],\n      mask=[[False,  True, False],\n            [False,  True, False],\n            [False,  True, False]],\n      fill_value=1)\n\n    \"\"\"\n    if axis is not np._NoValue:\n        # remove the axis argument when this deprecation expires\n        # NumPy 1.18.0, 2019-11-28\n        warnings.warn(\n            \"The axis argument has always been ignored, in future passing it \"\n            \"will raise TypeError\", DeprecationWarning, stacklevel=2)\n    return mask_rowcols(a, 1)\n\n\n#####--------------------------------------------------------------------------\n#---- --- arraysetops ---\n#####--------------------------------------------------------------------------\n\ndef ediff1d(arr, to_end=None, to_begin=None):\n    \"\"\"\n    Compute the differences between consecutive elements of an array.\n\n    This function is the equivalent of `numpy.ediff1d` that takes masked\n    values into account, see `numpy.ediff1d` for details.\n\n    See Also\n    --------\n    numpy.ediff1d : Equivalent function for ndarrays.\n\n    \"\"\"\n    arr = ma.asanyarray(arr).flat\n    ed = arr[1:] - arr[:-1]\n    arrays = [ed]\n    #\n    if to_begin is not None:\n        arrays.insert(0, to_begin)\n    if to_end is not None:\n        arrays.append(to_end)\n    #\n    if len(arrays) != 1:\n        # We'll save ourselves a copy of a potentially large array in the common\n        # case where neither to_begin or to_end was given.\n        ed = hstack(arrays)\n    #\n    return ed\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to find the unique elements of an array.\n\nArgs:\n    ar1 (array_like): Input array. This will be flattened if it is not already 1-D.\n    return_index (bool, optional): If True, also return the indices of ar1 that result in the unique array.\n    return_inverse (bool, optional): If True, also return the indices of the unique array that can be used to reconstruct ar1.\n\nReturns:\n    tuple or MaskedArray: The sorted unique values. If return_index or return_inverse are True, also return the indices of the unique array or the indices of the first occurrences of the unique values in the original array.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef unique(ar1, return_index=False, return_inverse=False):\n    output = np.unique(ar1,\n                       return_index=return_index,\n                       return_inverse=return_inverse)\n    if isinstance(output, tuple):\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        output = list(output)\n        output[0] = output[0].view(MaskedArray)\n        output = tuple(output)\n    else:\n        output = output.view(MaskedArray)\n    return output", "completions": ["  \n[PYTHON]\ndef unique(ar1, return_index=False, return_inverse=False):\n    ar1 = np.asarray(ar1).flatten()\n\n    optional_indices = return_index or return_inverse\n    if optional_indices:\n        perm = ar1.argsort()\n        aux = ar1[perm]\n    else:\n        ar1.sort()\n        aux = ar1\n\n    flag = np.concatenate(([True], aux[1:]!= aux[:-1]))\n\n    if return_index:\n        index_array = perm[flag]\n    if return_inverse:\n        inverse_array = np.cumsum(flag) - 1\n\n    return (aux[flag],\n            index_array,\n            inverse_array)\n[/PYTHON]\n"]}
{"id": 29, "name": "metadata_and_cell_to_header", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Parse header of text notebooks\n\"\"\"\n\nimport re\n\nimport nbformat\nimport yaml\nfrom nbformat.v4.nbbase import new_raw_cell\nfrom yaml.representer import SafeRepresenter\n\nfrom .languages import (\n    _SCRIPT_EXTENSIONS,\n    comment_lines,\n    default_language_from_metadata_and_ext,\n)\nfrom .metadata_filter import _DEFAULT_NOTEBOOK_METADATA, filter_metadata\nfrom .pep8 import pep8_lines_between_cells\nfrom .version import __version__\n\nSafeRepresenter.add_representer(nbformat.NotebookNode, SafeRepresenter.represent_dict)\n\n_HEADER_RE = re.compile(r\"^---\\s*$\")\n_BLANK_RE = re.compile(r\"^\\s*$\")\n_JUPYTER_RE = re.compile(r\"^jupyter\\s*:\\s*$\")\n_LEFTSPACE_RE = re.compile(r\"^\\s\")\n_UTF8_HEADER = \" -*- coding: utf-8 -*-\"\n\n# Change this to False in tests\nINSERT_AND_CHECK_VERSION_NUMBER = True\n\n\ndef insert_or_test_version_number():\n    \"\"\"Should the format name and version number be inserted in text\n    representations (not in tests!)\"\"\"\n    return INSERT_AND_CHECK_VERSION_NUMBER\n\n\ndef uncomment_line(line, prefix, suffix=\"\"):\n    \"\"\"Remove prefix (and space) from line\"\"\"\n    if prefix:\n        if line.startswith(prefix + \" \"):\n            line = line[len(prefix) + 1 :]\n        elif line.startswith(prefix):\n            line = line[len(prefix) :]\n    if suffix:\n        if line.endswith(suffix + \" \"):\n            line = line[: -(1 + len(suffix))]\n        elif line.endswith(suffix):\n            line = line[: -len(suffix)]\n    return line\n\n\ndef encoding_and_executable(notebook, metadata, ext):\n    \"\"\"Return encoding and executable lines for a notebook, if applicable\"\"\"\n    lines = []\n    comment = _SCRIPT_EXTENSIONS.get(ext, {}).get(\"comment\")\n    jupytext_metadata = metadata.get(\"jupytext\", {})\n\n    if comment is not None and \"executable\" in jupytext_metadata:\n        lines.append(\"#!\" + jupytext_metadata.pop(\"executable\"))\n\n    if comment is not None:\n        if \"encoding\" in jupytext_metadata:\n            lines.append(jupytext_metadata.pop(\"encoding\"))\n        elif default_language_from_metadata_and_ext(metadata, ext) != \"python\":\n            for cell in notebook.cells:\n                try:\n                    cell.source.encode(\"ascii\")\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    lines.append(comment + _UTF8_HEADER)\n                    break\n\n    return lines\n\n\ndef insert_jupytext_info_and_filter_metadata(\n    metadata, fmt, text_format, unsupported_keys\n):\n    \"\"\"Update the notebook metadata to include Jupytext information, and filter\n    the notebook metadata according to the default or user filter\"\"\"\n    if insert_or_test_version_number():\n        metadata.setdefault(\"jupytext\", {})[\"text_representation\"] = {\n            \"extension\": fmt[\"extension\"],\n            \"format_name\": text_format.format_name,\n            \"format_version\": text_format.current_version_number,\n            \"jupytext_version\": __version__,\n        }\n\n    if \"jupytext\" in metadata and not metadata[\"jupytext\"]:\n        del metadata[\"jupytext\"]\n\n    notebook_metadata_filter = fmt.get(\"notebook_metadata_filter\")\n    return filter_metadata(\n        metadata,\n        notebook_metadata_filter,\n        _DEFAULT_NOTEBOOK_METADATA,\n        unsupported_keys=unsupported_keys,\n    )\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is for converting metadata and cell to header in a notebook.\n\nArgs:\n    notebook (type): The notebook object.\n    metadata (type): The metadata of the notebook.\n    text_format (type): The format of the text.\n    fmt (type): The format of the notebook.\n    unsupported_keys (type, optional): The unsupported keys. Defaults to None.\n\nReturns:\n    tuple: A tuple containing the header and the lines to the next cell.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef metadata_and_cell_to_header(\n    notebook, metadata, text_format, fmt, unsupported_keys=None\n):\n\n    header = []\n\n    lines_to_next_cell = None\n    root_level_metadata = {}\n    root_level_metadata_as_raw_cell = fmt.get(\"root_level_metadata_as_raw_cell\", True)\n\n    if not root_level_metadata_as_raw_cell:\n        root_level_metadata = metadata.get(\"jupytext\", {}).pop(\n            \"root_level_metadata\", {}\n        )\n    elif notebook.cells:\n        cell = notebook.cells[0]\n        if cell.cell_type == \"raw\":\n            lines = cell.source.strip(\"\\n\\t \").splitlines()\n            if (\n                len(lines) >= 2\n                and _HEADER_RE.match(lines[0])\n                and _HEADER_RE.match(lines[-1])\n            ):\n                header = lines[1:-1]\n                lines_to_next_cell = cell.metadata.get(\"lines_to_next_cell\")\n                notebook.cells = notebook.cells[1:]\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    metadata = insert_jupytext_info_and_filter_metadata(\n        metadata, fmt, text_format, unsupported_keys\n    )\n\n    if metadata:\n        root_level_metadata[\"jupyter\"] = metadata\n\n    if root_level_metadata:\n        header.extend(\n            yaml.safe_dump(root_level_metadata, default_flow_style=False).splitlines()\n        )\n\n    if header:\n        header = [\"---\"] + header + [\"---\"]\n\n        if (\n            fmt.get(\"hide_notebook_metadata\", False)\n            and text_format.format_name == \"markdown\"\n        ):\n            header = [\"<!--\", \"\"] + header + [\"\", \"-->\"]\n\n    return (\n        comment_lines(header, text_format.header_prefix, text_format.header_suffix),\n        lines_to_next_cell,\n    )", "completions": ["  \n[PYTHON]\n```\ndef metadata_and_cell_to_header(\n    notebook, metadata, text_format, fmt, unsupported_keys=None\n):\n    header = []\n    lines_to_next_cell = None\n    root_level_metadata = {}\n    root_level_metadata_as_raw_cell = fmt.get(\"root_level_metadata_as_raw_cell\", True)\n\n    if not root_level_metadata_as_raw_cell:\n        root_level_metadata = metadata.get(\"jupytext\", {}).pop(\n            \"root_level_metadata\", {}\n        )\n    elif notebook.cells:\n        cell = notebook.cells[0]\n        if cell.cell_type == \"raw\":\n            lines = cell.source.strip(\"\\n\\t \").splitlines()\n            if (\n                len(lines) >= 2\n                and _HEADER_RE.match(lines[0])\n                and _HEADER_RE.match(lines[-1])\n            ):\n                header = lines[1:-1]\n                lines_to_next_cell = cell.metadata.get(\"lines_to_next_cell\")\n                notebook.cells = notebook.cells[1:]\n\n    return header, lines_to_next_cell\n```\n[/PYTHON]\n"]}
{"id": 30, "name": "spectrogram", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# coding=utf-8\n# Copyright 2023 The HuggingFace Inc. team and the librosa & torchaudio authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nAudio processing functions to extract features from audio waveforms. This code is pure numpy to support all frameworks\nand remove unnecessary dependencies.\n\"\"\"\nimport warnings\nfrom typing import Optional, Tuple, Union\n\nimport numpy as np\n\n\ndef hertz_to_mel(freq: Union[float, np.ndarray], mel_scale: str = \"htk\") -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert frequency from hertz to mels.\n\n    Args:\n        freq (`float` or `np.ndarray`):\n            The frequency, or multiple frequencies, in hertz (Hz).\n        mel_scale (`str`, *optional*, defaults to `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"`, `\"kaldi\"` or `\"slaney\"`.\n\n    Returns:\n        `float` or `np.ndarray`: The frequencies on the mel scale.\n    \"\"\"\n\n    if mel_scale not in [\"slaney\", \"htk\", \"kaldi\"]:\n        raise ValueError('mel_scale should be one of \"htk\", \"slaney\" or \"kaldi\".')\n\n    if mel_scale == \"htk\":\n        return 2595.0 * np.log10(1.0 + (freq / 700.0))\n    elif mel_scale == \"kaldi\":\n        return 1127.0 * np.log(1.0 + (freq / 700.0))\n\n    min_log_hertz = 1000.0\n    min_log_mel = 15.0\n    logstep = 27.0 / np.log(6.4)\n    mels = 3.0 * freq / 200.0\n\n    if isinstance(freq, np.ndarray):\n        log_region = freq >= min_log_hertz\n        mels[log_region] = min_log_mel + np.log(freq[log_region] / min_log_hertz) * logstep\n    elif freq >= min_log_hertz:\n        mels = min_log_mel + np.log(freq / min_log_hertz) * logstep\n\n    return mels\n\n\ndef mel_to_hertz(mels: Union[float, np.ndarray], mel_scale: str = \"htk\") -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert frequency from mels to hertz.\n\n    Args:\n        mels (`float` or `np.ndarray`):\n            The frequency, or multiple frequencies, in mels.\n        mel_scale (`str`, *optional*, `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"`, `\"kaldi\"` or `\"slaney\"`.\n\n    Returns:\n        `float` or `np.ndarray`: The frequencies in hertz.\n    \"\"\"\n\n    if mel_scale not in [\"slaney\", \"htk\", \"kaldi\"]:\n        raise ValueError('mel_scale should be one of \"htk\", \"slaney\" or \"kaldi\".')\n\n    if mel_scale == \"htk\":\n        return 700.0 * (np.power(10, mels / 2595.0) - 1.0)\n    elif mel_scale == \"kaldi\":\n        return 700.0 * (np.exp(mels / 1127.0) - 1.0)\n\n    min_log_hertz = 1000.0\n    min_log_mel = 15.0\n    logstep = np.log(6.4) / 27.0\n    freq = 200.0 * mels / 3.0\n\n    if isinstance(mels, np.ndarray):\n        log_region = mels >= min_log_mel\n        freq[log_region] = min_log_hertz * np.exp(logstep * (mels[log_region] - min_log_mel))\n    elif mels >= min_log_mel:\n        freq = min_log_hertz * np.exp(logstep * (mels - min_log_mel))\n\n    return freq\n\n\ndef hertz_to_octave(\n    freq: Union[float, np.ndarray], tuning: Optional[float] = 0.0, bins_per_octave: Optional[int] = 12\n):\n    \"\"\"\n    Convert frequency from hertz to fractional octave numbers.\n    Adapted from *librosa*.\n\n    Args:\n        freq (`float` or `np.ndarray`):\n            The frequency, or multiple frequencies, in hertz (Hz).\n        tuning (`float`, defaults to `0.`):\n            Tuning deviation from the Stuttgart pitch (A440) in (fractional) bins per octave.\n        bins_per_octave (`int`, defaults to `12`):\n            Number of bins per octave.\n\n    Returns:\n        `float` or `np.ndarray`: The frequencies on the octave scale.\n    \"\"\"\n    stuttgart_pitch = 440.0 * 2.0 ** (tuning / bins_per_octave)\n    octave = np.log2(freq / (float(stuttgart_pitch) / 16))\n    return octave\n\n\ndef _create_triangular_filter_bank(fft_freqs: np.ndarray, filter_freqs: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Creates a triangular filter bank.\n\n    Adapted from *torchaudio* and *librosa*.\n\n    Args:\n        fft_freqs (`np.ndarray` of shape `(num_frequency_bins,)`):\n            Discrete frequencies of the FFT bins in Hz.\n        filter_freqs (`np.ndarray` of shape `(num_mel_filters,)`):\n            Center frequencies of the triangular filters to create, in Hz.\n\n    Returns:\n        `np.ndarray` of shape `(num_frequency_bins, num_mel_filters)`\n    \"\"\"\n    filter_diff = np.diff(filter_freqs)\n    slopes = np.expand_dims(filter_freqs, 0) - np.expand_dims(fft_freqs, 1)\n    down_slopes = -slopes[:, :-2] / filter_diff[:-1]\n    up_slopes = slopes[:, 2:] / filter_diff[1:]\n    return np.maximum(np.zeros(1), np.minimum(down_slopes, up_slopes))\n\n\ndef chroma_filter_bank(\n    num_frequency_bins: int,\n    num_chroma: int,\n    sampling_rate: int,\n    tuning: float = 0.0,\n    power: Optional[float] = 2.0,\n    weighting_parameters: Optional[Tuple[float]] = (5.0, 2),\n    start_at_c_chroma: Optional[bool] = True,\n):\n    \"\"\"\n    Creates a chroma filter bank, i.e a linear transformation to project spectrogram bins onto chroma bins.\n\n    Adapted from *librosa*.\n\n    Args:\n        num_frequency_bins (`int`):\n            Number of frequencies used to compute the spectrogram (should be the same as in `stft`).\n        num_chroma (`int`):\n            Number of chroma bins (i.e pitch classes).\n        sampling_rate (`float`):\n            Sample rate of the audio waveform.\n        tuning (`float`):\n            Tuning deviation from A440 in fractions of a chroma bin.\n        power (`float`, *optional*, defaults to 2.0):\n            If 12.0, normalizes each column with their L2 norm. If 1.0, normalizes each column with their L1 norm.\n        weighting_parameters (`Tuple[float]`, *optional*, defaults to `(5., 2.)`):\n            If specified, apply a Gaussian weighting parameterized by the first element of the tuple being the center and\n            the second element being the Gaussian half-width.\n        start_at_c_chroma (`float`, *optional*, defaults to `True`):\n            If True, the filter bank will start at the 'C' pitch class. Otherwise, it will start at 'A'.\n    Returns:\n        `np.ndarray` of shape `(num_frequency_bins, num_chroma)`\n    \"\"\"\n    # Get the FFT bins, not counting the DC component\n    frequencies = np.linspace(0, sampling_rate, num_frequency_bins, endpoint=False)[1:]\n\n    freq_bins = num_chroma * hertz_to_octave(frequencies, tuning=tuning, bins_per_octave=num_chroma)\n\n    # make up a value for the 0 Hz bin = 1.5 octaves below bin 1\n    # (so chroma is 50% rotated from bin 1, and bin width is broad)\n    freq_bins = np.concatenate(([freq_bins[0] - 1.5 * num_chroma], freq_bins))\n\n    bins_width = np.concatenate((np.maximum(freq_bins[1:] - freq_bins[:-1], 1.0), [1]))\n\n    chroma_filters = np.subtract.outer(freq_bins, np.arange(0, num_chroma, dtype=\"d\")).T\n\n    num_chroma2 = np.round(float(num_chroma) / 2)\n\n    # Project into range -num_chroma/2 .. num_chroma/2\n    # add on fixed offset of 10*num_chroma to ensure all values passed to\n    # rem are positive\n    chroma_filters = np.remainder(chroma_filters + num_chroma2 + 10 * num_chroma, num_chroma) - num_chroma2\n\n    # Gaussian bumps - 2*D to make them narrower\n    chroma_filters = np.exp(-0.5 * (2 * chroma_filters / np.tile(bins_width, (num_chroma, 1))) ** 2)\n\n    # normalize each column\n    if power is not None:\n        chroma_filters = chroma_filters / np.sum(chroma_filters**power, axis=0, keepdims=True) ** (1.0 / power)\n\n    # Maybe apply scaling for fft bins\n    if weighting_parameters is not None:\n        center, half_width = weighting_parameters\n        chroma_filters *= np.tile(\n            np.exp(-0.5 * (((freq_bins / num_chroma - center) / half_width) ** 2)),\n            (num_chroma, 1),\n        )\n\n    if start_at_c_chroma:\n        chroma_filters = np.roll(chroma_filters, -3 * (num_chroma // 12), axis=0)\n\n    # remove aliasing columns, copy to ensure row-contiguity\n    return np.ascontiguousarray(chroma_filters[:, : int(1 + num_frequency_bins / 2)])\n\n\ndef mel_filter_bank(\n    num_frequency_bins: int,\n    num_mel_filters: int,\n    min_frequency: float,\n    max_frequency: float,\n    sampling_rate: int,\n    norm: Optional[str] = None,\n    mel_scale: str = \"htk\",\n    triangularize_in_mel_space: bool = False,\n) -> np.ndarray:\n    \"\"\"\n    Creates a frequency bin conversion matrix used to obtain a mel spectrogram. This is called a *mel filter bank*, and\n    various implementation exist, which differ in the number of filters, the shape of the filters, the way the filters\n    are spaced, the bandwidth of the filters, and the manner in which the spectrum is warped. The goal of these\n    features is to approximate the non-linear human perception of the variation in pitch with respect to the frequency.\n\n    Different banks of mel filters were introduced in the literature. The following variations are supported:\n\n    - MFCC FB-20: introduced in 1980 by Davis and Mermelstein, it assumes a sampling frequency of 10 kHz and a speech\n      bandwidth of `[0, 4600]` Hz.\n    - MFCC FB-24 HTK: from the Cambridge HMM Toolkit (HTK) (1995) uses a filter bank of 24 filters for a speech\n      bandwidth of `[0, 8000]` Hz. This assumes sampling rate ≥ 16 kHz.\n    - MFCC FB-40: from the Auditory Toolbox for MATLAB written by Slaney in 1998, assumes a sampling rate of 16 kHz and\n      speech bandwidth of `[133, 6854]` Hz. This version also includes area normalization.\n    - HFCC-E FB-29 (Human Factor Cepstral Coefficients) of Skowronski and Harris (2004), assumes a sampling rate of\n      12.5 kHz and speech bandwidth of `[0, 6250]` Hz.\n\n    This code is adapted from *torchaudio* and *librosa*. Note that the default parameters of torchaudio's\n    `melscale_fbanks` implement the `\"htk\"` filters while librosa uses the `\"slaney\"` implementation.\n\n    Args:\n        num_frequency_bins (`int`):\n            Number of frequencies used to compute the spectrogram (should be the same as in `stft`).\n        num_mel_filters (`int`):\n            Number of mel filters to generate.\n        min_frequency (`float`):\n            Lowest frequency of interest in Hz.\n        max_frequency (`float`):\n            Highest frequency of interest in Hz. This should not exceed `sampling_rate / 2`.\n        sampling_rate (`int`):\n            Sample rate of the audio waveform.\n        norm (`str`, *optional*):\n            If `\"slaney\"`, divide the triangular mel weights by the width of the mel band (area normalization).\n        mel_scale (`str`, *optional*, defaults to `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"`, `\"kaldi\"` or `\"slaney\"`.\n        triangularize_in_mel_space (`bool`, *optional*, defaults to `False`):\n            If this option is enabled, the triangular filter is applied in mel space rather than frequency space. This\n            should be set to `true` in order to get the same results as `torchaudio` when computing mel filters.\n\n    Returns:\n        `np.ndarray` of shape (`num_frequency_bins`, `num_mel_filters`): Triangular filter bank matrix. This is a\n        projection matrix to go from a spectrogram to a mel spectrogram.\n    \"\"\"\n    if norm is not None and norm != \"slaney\":\n        raise ValueError('norm must be one of None or \"slaney\"')\n\n    # center points of the triangular mel filters\n    mel_min = hertz_to_mel(min_frequency, mel_scale=mel_scale)\n    mel_max = hertz_to_mel(max_frequency, mel_scale=mel_scale)\n    mel_freqs = np.linspace(mel_min, mel_max, num_mel_filters + 2)\n    filter_freqs = mel_to_hertz(mel_freqs, mel_scale=mel_scale)\n\n    if triangularize_in_mel_space:\n        # frequencies of FFT bins in Hz, but filters triangularized in mel space\n        fft_bin_width = sampling_rate / (num_frequency_bins * 2)\n        fft_freqs = hertz_to_mel(fft_bin_width * np.arange(num_frequency_bins), mel_scale=mel_scale)\n        filter_freqs = mel_freqs\n    else:\n        # frequencies of FFT bins in Hz\n        fft_freqs = np.linspace(0, sampling_rate // 2, num_frequency_bins)\n\n    mel_filters = _create_triangular_filter_bank(fft_freqs, filter_freqs)\n\n    if norm is not None and norm == \"slaney\":\n        # Slaney-style mel is scaled to be approx constant energy per channel\n        enorm = 2.0 / (filter_freqs[2 : num_mel_filters + 2] - filter_freqs[:num_mel_filters])\n        mel_filters *= np.expand_dims(enorm, 0)\n\n    if (mel_filters.max(axis=0) == 0.0).any():\n        warnings.warn(\n            \"At least one mel filter has all zero values. \"\n            f\"The value for `num_mel_filters` ({num_mel_filters}) may be set too high. \"\n            f\"Or, the value for `num_frequency_bins` ({num_frequency_bins}) may be set too low.\"\n        )\n\n    return mel_filters\n\n\ndef optimal_fft_length(window_length: int) -> int:\n    \"\"\"\n    Finds the best FFT input size for a given `window_length`. This function takes a given window length and, if not\n    already a power of two, rounds it up to the next power or two.\n\n    The FFT algorithm works fastest when the length of the input is a power of two, which may be larger than the size\n    of the window or analysis frame. For example, if the window is 400 samples, using an FFT input size of 512 samples\n    is more optimal than an FFT size of 400 samples. Using a larger FFT size does not affect the detected frequencies,\n    it simply gives a higher frequency resolution (i.e. the frequency bins are smaller).\n    \"\"\"\n    return 2 ** int(np.ceil(np.log2(window_length)))\n\n\ndef window_function(\n    window_length: int,\n    name: str = \"hann\",\n    periodic: bool = True,\n    frame_length: Optional[int] = None,\n    center: bool = True,\n) -> np.ndarray:\n    \"\"\"\n    Returns an array containing the specified window. This window is intended to be used with `stft`.\n\n    The following window types are supported:\n\n        - `\"boxcar\"`: a rectangular window\n        - `\"hamming\"`: the Hamming window\n        - `\"hann\"`: the Hann window\n        - `\"povey\"`: the Povey window\n\n    Args:\n        window_length (`int`):\n            The length of the window in samples.\n        name (`str`, *optional*, defaults to `\"hann\"`):\n            The name of the window function.\n        periodic (`bool`, *optional*, defaults to `True`):\n            Whether the window is periodic or symmetric.\n        frame_length (`int`, *optional*):\n            The length of the analysis frames in samples. Provide a value for `frame_length` if the window is smaller\n            than the frame length, so that it will be zero-padded.\n        center (`bool`, *optional*, defaults to `True`):\n            Whether to center the window inside the FFT buffer. Only used when `frame_length` is provided.\n\n    Returns:\n        `np.ndarray` of shape `(window_length,)` or `(frame_length,)` containing the window.\n    \"\"\"\n    length = window_length + 1 if periodic else window_length\n\n    if name == \"boxcar\":\n        window = np.ones(length)\n    elif name in [\"hamming\", \"hamming_window\"]:\n        window = np.hamming(length)\n    elif name in [\"hann\", \"hann_window\"]:\n        window = np.hanning(length)\n    elif name in [\"povey\"]:\n        window = np.power(np.hanning(length), 0.85)\n    else:\n        raise ValueError(f\"Unknown window function '{name}'\")\n\n    if periodic:\n        window = window[:-1]\n\n    if frame_length is None:\n        return window\n\n    if window_length > frame_length:\n        raise ValueError(\n            f\"Length of the window ({window_length}) may not be larger than frame_length ({frame_length})\"\n        )\n\n    padded_window = np.zeros(frame_length)\n    offset = (frame_length - window_length) // 2 if center else 0\n    padded_window[offset : offset + window_length] = window\n    return padded_window\n\n\n# TODO This method does not support batching yet as we are mainly focused on inference.\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes a spectrogram from a waveform using a sliding window and FFT.\n\nArgs:\n    waveform (np.ndarray): The input waveform.\n    window (np.ndarray): The window function to apply to each frame.\n    frame_length (int): The length of each frame.\n    hop_length (int): The number of samples to advance between frames.\n    fft_length (Optional[int]): The length of the FFT. If not provided, it defaults to frame_length.\n    power (Optional[float]): The exponent for the magnitude spectrogram. Defaults to 1.0.\n    center (bool): Whether to center pad the waveform. Defaults to True.\n    pad_mode (str): The mode for padding. Defaults to \"reflect\".\n    onesided (bool): Whether to return a one-sided spectrum for real data. Defaults to True.\n    preemphasis (Optional[float]): The preemphasis coefficient. Defaults to None.\n    mel_filters (Optional[np.ndarray]): The Mel filters to apply. Defaults to None.\n    mel_floor (float): The floor value for the Mel spectrogram. Defaults to 1e-10.\n    log_mel (Optional[str]): The type of logarithmic scaling to apply to the Mel spectrogram. Defaults to None.\n    reference (float): The reference value for dB conversion. Defaults to 1.0.\n    min_value (float): The minimum value for dB conversion. Defaults to 1e-10.\n    db_range (Optional[float]): The range for dB conversion. Defaults to None.\n    remove_dc_offset (Optional[bool]): Whether to remove the DC offset. Defaults to None.\n    dtype (np.dtype): The data type for the output spectrogram. Defaults to np.float32.\n\nReturns:\n    np.ndarray: The computed spectrogram.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef spectrogram(\n    waveform: np.ndarray,\n    window: np.ndarray,\n    frame_length: int,\n    hop_length: int,\n    fft_length: Optional[int] = None,\n    power: Optional[float] = 1.0,\n    center: bool = True,\n    pad_mode: str = \"reflect\",\n    onesided: bool = True,\n    preemphasis: Optional[float] = None,\n    mel_filters: Optional[np.ndarray] = None,\n    mel_floor: float = 1e-10,\n    log_mel: Optional[str] = None,\n    reference: float = 1.0,\n    min_value: float = 1e-10,\n    db_range: Optional[float] = None,\n    remove_dc_offset: Optional[bool] = None,\n    dtype: np.dtype = np.float32,\n) -> np.ndarray:\n    window_length = len(window)\n\n    if fft_length is None:\n        fft_length = frame_length\n\n    if frame_length > fft_length:\n        raise ValueError(f\"frame_length ({frame_length}) may not be larger than fft_length ({fft_length})\")\n\n    if window_length != frame_length:\n        raise ValueError(f\"Length of the window ({window_length}) must equal frame_length ({frame_length})\")\n\n    if hop_length <= 0:\n        raise ValueError(\"hop_length must be greater than zero\")\n\n    if waveform.ndim != 1:\n        raise ValueError(f\"Input waveform must have only one dimension, shape is {waveform.shape}\")\n\n    if np.iscomplexobj(waveform):\n        raise ValueError(\"Complex-valued input waveforms are not currently supported\")\n\n    if power is None and mel_filters is not None:\n        raise ValueError(\n            \"You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram.\"\n            \"Specify `power` to fix this issue.\"\n        )\n\n    # center pad the waveform\n    if center:\n        padding = [(int(frame_length // 2), int(frame_length // 2))]\n        waveform = np.pad(waveform, padding, mode=pad_mode)\n\n    # promote to float64, since np.fft uses float64 internally\n    waveform = waveform.astype(np.float64)\n    window = window.astype(np.float64)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    # split waveform into frames of frame_length size\n    num_frames = int(1 + np.floor((waveform.size - frame_length) / hop_length))\n\n    num_frequency_bins = (fft_length // 2) + 1 if onesided else fft_length\n    spectrogram = np.empty((num_frames, num_frequency_bins), dtype=np.complex64)\n\n    # rfft is faster than fft\n    fft_func = np.fft.rfft if onesided else np.fft.fft\n    buffer = np.zeros(fft_length)\n\n    timestep = 0\n    for frame_idx in range(num_frames):\n        buffer[:frame_length] = waveform[timestep : timestep + frame_length]\n\n        if remove_dc_offset:\n            buffer[:frame_length] = buffer[:frame_length] - buffer[:frame_length].mean()\n\n        if preemphasis is not None:\n            buffer[1:frame_length] -= preemphasis * buffer[: frame_length - 1]\n            buffer[0] *= 1 - preemphasis\n\n        buffer[:frame_length] *= window\n\n        spectrogram[frame_idx] = fft_func(buffer)\n        timestep += hop_length\n\n    # note: ** is much faster than np.power\n    if power is not None:\n        spectrogram = np.abs(spectrogram, dtype=np.float64) ** power\n\n    spectrogram = spectrogram.T\n\n    if mel_filters is not None:\n        spectrogram = np.maximum(mel_floor, np.dot(mel_filters.T, spectrogram))\n\n    if power is not None and log_mel is not None:\n        if log_mel == \"log\":\n            spectrogram = np.log(spectrogram)\n        elif log_mel == \"log10\":\n            spectrogram = np.log10(spectrogram)\n        elif log_mel == \"dB\":\n            if power == 1.0:\n                spectrogram = amplitude_to_db(spectrogram, reference, min_value, db_range)\n            elif power == 2.0:\n                spectrogram = power_to_db(spectrogram, reference, min_value, db_range)\n            else:\n                raise ValueError(f\"Cannot use log_mel option '{log_mel}' with power {power}\")\n        else:\n            raise ValueError(f\"Unknown log_mel option: {log_mel}\")\n\n        spectrogram = np.asarray(spectrogram, dtype)\n\n    return spectrogram", "completions": ["  \n[PYTHON]\ndef spectrogram(\n    waveform: np.ndarray,\n    window: np.ndarray,\n    frame_length: int,\n    hop_length: int,\n    fft_length: Optional[int] = None,\n    power: Optional[float] = 1.0,\n    center: bool = True,\n    pad_mode: str = \"reflect\",\n    onesided: bool = True,\n    preemphasis: Optional[float] = None,\n    mel_filters: Optional[np.ndarray] = None,\n    mel_floor: float = 1e-10,\n    log_mel: Optional[str] = None,\n    reference: float = 1.0,\n    min_value: float = 1e-10,\n    db_range: Optional[float] = None,\n    remove_dc_offset: Optional[bool] = None,\n    dtype: np.dtype = np.float32,\n) -> np.ndarray:\n    # Implement your code here\n    pass\n[/PYTHON]\n"]}
{"id": 31, "name": "dump_yaml", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom __future__ import annotations\n\nimport fnmatch\nimport logging\nimport re\nfrom logging.handlers import RotatingFileHandler\nfrom pathlib import Path\nfrom typing import Any, MutableSequence, Optional, Sequence, TextIO\n\nimport yaml\nfrom rich.logging import RichHandler\n\n\nclass Filter:\n    \"\"\"Inclusion/exclusion filtering.\"\"\"\n\n    def __init__(\n        self,\n        include: Optional[Sequence[str]] = None,\n        exclude: Optional[Sequence[str]] = None,\n    ):\n        \"\"\"Inclusion/exclusion filtering.\n\n        Args:\n            include (Optional[Sequence[str]], optional): Optional inclusions (i.e. include only these). Defaults to None.\n            exclude (Optional[Sequence[str]], optional): Optional exclusion list (i.e. exclude these, even if in inclusion list). Defaults to None.\n        \"\"\"\n        self.include = self._norm_arg(include)\n        self.exclude = self._norm_arg(exclude)\n\n    def match(self, item: str) -> bool:\n        item = self._norm_item(item)\n\n        for exclude in self.exclude:\n            if fnmatch.fnmatch(item, exclude):\n                return False\n\n        if self.include:\n            for include in self.include:\n                if fnmatch.fnmatch(item, include):\n                    return True\n            return False\n\n        return True\n\n    @staticmethod\n    def _norm_arg(arg: Optional[Sequence[str]]) -> Sequence[str]:\n        if isinstance(arg, str):\n            arg = [arg]\n        return [Filter._norm_item(x) for x in arg or []]\n\n    @staticmethod\n    def _norm_item(x: str) -> str:\n        return x.upper()\n\n\nclass _YAMLDumper(yaml.Dumper):\n    \"\"\"Custom YAML dumper for uniform formatting.\"\"\"\n\n    def increase_indent(self, flow=False, indentless=False):\n        return super().increase_indent(flow, indentless=False)\n\n\nclass _NullValue(str):\n    \"\"\"Explicitly null field value.\"\"\"\n\n    def __eq__(self, other: object) -> bool:\n        return other is None\n\n\nNullValue = _NullValue()\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to dump data into a YAML format.\n\nArgs:\n    data (Any): The data to be dumped into YAML format.\n    stream (TextIO): The stream where the YAML data will be written.\n\nReturns:\n    None: This function does not return any value.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef dump_yaml(data: Any, stream: TextIO):\n    yaml.dump(\n        data,\n        stream,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        Dumper=_YAMLDumper,\n        default_flow_style=False,\n        allow_unicode=True,\n        sort_keys=False,\n    )", "completions": ["  \n[PYTHON]\n```\nyaml.dump(\n    data,\n    stream,\n    Dumper=_YAMLDumper,\n    default_flow_style=False,\n    indent=4,\n    explicit_start=True,\n    explicit_end=True,\n    allow_unicode=True,\n    encoding=\"utf-8\",\n)\n```\n[/PYTHON]\n"]}
{"id": 32, "name": "load", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport numpy as np\nimport bpy\nfrom .. import color\nfrom ..blender import (\n    obj, coll, nodes\n)\n\nbpy.types.Scene.MN_import_oxdna_topology = bpy.props.StringProperty(\n    name='Toplogy',\n    description='File path for the topology to import (.top)',\n    subtype='FILE_PATH',\n    maxlen=0\n)\nbpy.types.Scene.MN_import_oxdna_trajectory = bpy.props.StringProperty(\n    name='Trajectory',\n    description='File path for the trajectory to import (.oxdna / .dat)',\n    subtype='FILE_PATH',\n    maxlen=0\n)\nbpy.types.Scene.MN_import_oxdna_name = bpy.props.StringProperty(\n    name='Name',\n    description='Name of the created object.',\n    default='NewOrigami',\n    maxlen=0\n)\n\n\ndef base_to_int(bases: np.array) -> np.array:\n    \"\"\"\n    Convert an array of DNA bases to their corresponding MN integer values.\n\n    Parameters\n    ----------\n    bases : np.array\n        Array of DNA bases.\n\n    Returns\n    -------\n    np.array\n        Array of corresponding integer values for the DNA bases.\n    \"\"\"\n    # Values for internal Molecular Nodes use. Defined in data.py\n    base_lookup = {\n        'A': 30,\n        'C': 31,\n        'G': 32,\n        'T': 33\n    }\n\n    ints = np.array([base_lookup.get(base, -1) for base in bases])\n\n    return ints\n\n\ndef is_new_topology(filepath):\n    with open(filepath) as f:\n        firstline = f.readline()\n\n    return \"5 -> 3\" in firstline\n\n\ndef read_topology_new(filepath):\n    with open(filepath, 'r') as file:\n        contents = file.read()\n\n    lines = np.array(contents.split('\\n'))\n\n    def read_seq_line(line):\n        sequence = line.split(\" \")[0]\n        return np.array([c for c in sequence])\n\n    strands = []\n    counter = 0\n\n    for i, line in enumerate(lines[1:]):\n        bases = read_seq_line(line)\n        arr = np.zeros((len(bases), 4), dtype=int)\n        idx = np.array(range(len(bases)), dtype=int)\n        arr[:, 0] = i + 1  # strand ID\n        arr[:, 1] = base_to_int(bases)  # base\n        bond_3 = idx - 1 + counter\n        bond_5 = idx + 1 + counter\n        bond_3[0] = -1\n        bond_5[-1] = -1\n        arr[:, 2] = bond_3\n        arr[:, 3] = bond_5\n\n        strands.append(arr)\n        counter += len(bases)\n\n    return np.vstack(strands)\n\n\ndef read_topology_old(filepath):\n    \"\"\"\n    Read the topology from a file and convert it to a numpy array.\n\n\n    Strand assignment\n    |  Base assignment\n    |  |  3' Bonded base to the current base (index based on row)\n    |  |  |   5' Bonded base to the current base (index based on row)\n    |  |  |   |\n    S  B  3'  5'\n    S  B  3'  5'\n    S  B  3'  5'\n\n    Parameters\n    ----------\n    filepath : str\n        The path to the file containing the topology.\n\n    Returns\n    -------\n    numpy.ndarray\n        The topology as a integer numpy array. Base assignment is (30, 31, 32, 33) where \n        this corresponds to (A, C, G, T) for use inside of Molecular Nodes.\n\n    \"\"\"\n\n    with open(filepath, 'r') as file:\n        contents = file.read()\n\n    lines = np.array(contents.split('\\n'))\n    # metadata = lines[0]\n\n    # read the topology from the file sans the first metadata line\n    # have to initially read as strings, then convert bases to numeric later\n    array_str = np.loadtxt(lines[1:], dtype=str)\n\n    # convert the columns to numeric\n    array_int = np.zeros(array_str.shape, dtype=int)\n    array_int[:, (0, 2, 3)] = array_str[:, (0, 2, 3)].astype(\n        int)  # easy convert numeric columns to int\n    # convert bases (A, C, G, T) to (30, 31, 32, 33)\n    array_int[:, 1] = base_to_int(array_str[:, 1])\n\n    return array_int\n\n\ndef read_trajectory(filepath):\n    \"\"\"\n    Read an oxDNA trajectory file and return an array of frames.\n\n    Each frame becomes a 2D array in a stack. Each frame has 5 three-component vectors. \n    The vectors are: (position, base_vector, base_normal, veclocity, angular_velocity), \n    which totals 15 columns in the array. The (velocity, angular_velocity) are optional\n    and can sometimes not appear in the trajectory.\n\n    Parameters\n    ----------\n    filepath : str\n        The path to the trajectory file.\n\n    Returns\n    -------\n    frames : ndarray\n        An array of frames, where each frame is a 2D array of positions \n\n    \"\"\"\n    # Open the file and read its contents\n    with open(filepath, 'r') as file:\n        contents = file.read()\n\n    # Split the contents into lines\n    lines = np.array(contents.split('\\n'))\n    is_meta = np.char.find(lines, '=') > 0\n\n    group_id = np.cumsum(np.append([True], np.diff(is_meta)))\n    groups = np.unique(group_id)\n\n    frames = []\n\n    for group in groups:\n        mask = group == group_id\n        if \"=\" in lines[mask][0]:\n            continue\n\n        arr = np.loadtxt(lines[mask])\n        frames.append(arr)\n\n    return np.stack(frames)\n\n\ndef set_attributes_to_dna_mol(mol, frame, scale_dna=0.1):\n    attributes = ('base_vector', 'base_normal', 'velocity', 'angular_velocity')\n    for i, att in enumerate(attributes):\n        col_idx = np.array([3, 4, 5]) + i * 3\n\n        try:\n            data = frame[:, col_idx]\n        except IndexError as e:\n            print(\n                f\"Unable to get {att} attribute from coordinates. Error: {e}\")\n            continue\n\n        if att != \"angular_velocity\":\n            data *= scale_dna\n\n        obj.set_attribute(mol, att, data, type=\"FLOAT_VECTOR\")\n\n\ndef toplogy_to_bond_idx_pairs(topology: np.ndarray):\n    \"\"\"\n    Convert the given topology array into pairs of indices representing each distinct bond.\n\n    Strand assignment\n    |  Base assignment\n    |  |  3' Bonded base to the current base (index based on row)\n    |  |  |  5' Bonded base to the current base (index based on row)\n    |  |  |  |\n    1  A -1  1\n    1  G  0  2\n    1  C  1 -1\n\n    The topology above becomes:\n    np.array([[0, 1], [2, 1]])\n\n    The order of the bond indices doesn't matter to Blender.\n\n    Parameters:\n    topology (np.ndarray): Numeric numpy array representing the topology.\n\n    Returns:\n    np.ndarray: Array of pairs of indices representing each distinct bond.\n    \"\"\"\n\n    # to get pairs of indices which represent each distinct bond, which are needed for\n    # edge creation in Blender, take each bonded column and create a 'bond' with itself\n    idx = np.array(list(range(topology.shape[0])))\n    bond_3 = np.vstack((idx, topology[:, 2])).reshape((len(idx), 2))\n    bond_5 = np.vstack((idx, topology[:, 3])).reshape((len(idx), 2))\n    bonds = np.vstack((bond_3, bond_5))\n\n    # drop where either bond is -1 (not bonded) from the bond indices\n    mask = bonds == -1\n    mask = np.logical_not(mask.any(axis=1))\n\n    bond_idxs = np.unique(bonds[mask, :], axis=0)\n\n    return np.sort(bond_idxs, axis=1)\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function loads DNA topology and trajectory data from files and creates a molecular object and a collection of frame objects.\n\nArgs:\n    top (str): The path to the topology file.\n    traj (str): The path to the trajectory file.\n    name (str, optional): The name of the molecular object. Defaults to 'oxDNA'.\n    setup_nodes (bool, optional): Whether to set up node trees for the molecular object and frames. Defaults to True.\n    world_scale (float, optional): The scale factor for the molecular object. Defaults to 0.01.\n\nReturns:\n    tuple: A tuple containing the molecular object and the collection of frame objects.\n\nNotes:\n    - The scale of the oxDNA files seems to be based on nanometres rather than angstroms, so the world_scale is adjusted to compensate.\n    - The molecular object is created with the positions of the first frame and the bonds from the topology object.\n    - Additional topology information from the topology and frames objects is added to the molecular object.\n    - If the 'frames' file only contained one timepoint, the function returns the object without creating a collection for storing multiple frames from a trajectory.\n    - A collection is created to store all of the frame objects that are part of the trajectory.\n    - The frame objects contain all of the possible attributes which can be interpolated between frames such as position, base_vector, base_normal, velocity, angular_velocity.\n    - If setup_nodes is True, node trees are set up for the molecular object and frames.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef load(top, traj, name='oxDNA', setup_nodes=True, world_scale=0.01):\n\n    # the scale of the oxDNA files seems to be based on nanometres rather than angstrongs\n    # like most structural biology files, so currently adjusting the world_scale to\n    # compensate\n    scale_dna = world_scale * 10\n\n    # read in the topology and trajectory files\n    is_new_top = is_new_topology(top)\n    if is_new_top:\n        topology = read_topology_new(top)\n    else:\n        topology = read_topology_old(top)\n\n    trajectory = read_trajectory(traj)\n    n_frames = trajectory.shape[0]\n\n    # creat toplogy object with positions of the first frame, and the bonds from the\n    # topology object\n    mol = obj.create_object(\n        name=name,\n        collection=coll.mn(),\n        vertices=trajectory[0][:, 0:3] * scale_dna,\n        edges=toplogy_to_bond_idx_pairs(topology)\n    )\n\n    # adding additional toplogy information from the topology and frames objects\n    obj.set_attribute(mol, 'res_name', topology[:, 1], \"INT\")\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    obj.set_attribute(mol, 'chain_id', topology[:, 0], \"INT\")\n    obj.set_attribute(mol, 'Color', data=color.color_chains_equidistant(\n        topology[:, 0]), type='FLOAT_COLOR')\n    set_attributes_to_dna_mol(mol, trajectory[0], scale_dna=scale_dna)\n\n    # if the 'frames' file only contained one timepoint, return the object without creating\n    # any kind of collection for storing multiple frames from a trajectory, and a None\n    # object in place of the frames collection\n    if n_frames == 1:\n        if setup_nodes:\n            nodes.create_starting_node_tree(\n                mol, style=\"oxdna\", set_color=False)\n        return mol, None\n\n    # create a collection to store all of the frame objects that are part of the trajectory\n    # they will contain all of the possible attributes which can be interpolated betewen\n    # frames such as position, base_vector, base_normal, velocity, angular_velocity\n    collection = coll.frames(f\"{name}_frames\", parent=coll.data())\n    for i, frame in enumerate(trajectory):\n        fill_n = int(np.ceil(np.log10(n_frames)))\n        frame_name = f\"{name}_frame_{str(i).zfill(fill_n)}\"\n        frame_mol = obj.create_object(\n            frame[:, 0:3] * scale_dna, name=frame_name, collection=collection)\n        set_attributes_to_dna_mol(frame_mol, frame, scale_dna)\n\n    if setup_nodes:\n        nodes.create_starting_node_tree(\n            mol, coll_frames=collection, style=\"oxdna\", set_color=False)\n\n    return mol, collection", "completions": ["  \n[PYTHON]\ndef load(top, traj, name='oxDNA', setup_nodes=True, world_scale=0.01):\n    # your code here\n    pass\n[/PYTHON]\n"]}
{"id": 33, "name": "collate_fn", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport torch, logging, concurrent.futures, numpy as np\nfrom os import environ\nfrom helpers.training.state_tracker import StateTracker\nfrom helpers.training.multi_process import rank_info\nfrom helpers.multiaspect.image import MultiaspectImage\nfrom helpers.image_manipulation.brightness import calculate_batch_luminance\nfrom accelerate.logging import get_logger\nfrom concurrent.futures import ThreadPoolExecutor\n\nlogger = logging.getLogger(\"collate_fn\")\nlogger.setLevel(environ.get(\"SIMPLETUNER_COLLATE_LOG_LEVEL\", \"INFO\"))\nrank_text = rank_info()\nfrom torchvision.transforms import ToTensor\n\n# Convert PIL Image to PyTorch Tensor\nto_tensor = ToTensor()\n\n\ndef debug_log(msg: str):\n    logger.debug(f\"{rank_text}{msg}\")\n\n\ndef compute_time_ids(\n    original_size: tuple,\n    target_size: tuple,\n    weight_dtype,\n    vae_downscale_factor: int = 8,\n    crop_coordinates: list = None,\n):\n    if original_size is None or target_size is None:\n        raise Exception(\n            f\"Cannot continue, the original_size or target_size were not provided: {original_size}, {target_size}\"\n        )\n    logger.debug(\n        f\"Computing time ids for:\"\n        f\"\\n-> original_size = {original_size}\"\n        f\"\\n-> target_size = {target_size}\"\n    )\n    # The dimensions of tensors are \"transposed\", as:\n    # (batch_size, height, width)\n    # An image would look like:\n    # (width, height)\n    # SDXL conditions are:\n    # [h, w, h, w, h, w]\n    original_width = original_size[0]\n    original_height = original_size[1]\n    target_width = int(target_size[2] * vae_downscale_factor)\n    target_height = int(target_size[1] * vae_downscale_factor)\n    final_target_size = (target_height, target_width)\n    if original_width is None:\n        raise ValueError(\"Original width must be specified.\")\n    if original_height is None:\n        raise ValueError(\"Original height must be specified.\")\n    if crop_coordinates is None:\n        raise ValueError(\"Crop coordinates were not collected during collate.\")\n    add_time_ids = list(\n        (original_height, original_width) + tuple(crop_coordinates) + final_target_size\n    )\n    add_time_ids = torch.tensor([add_time_ids], dtype=weight_dtype)\n    logger.debug(\n        f\"compute_time_ids returning {add_time_ids.shape} shaped time ids: {add_time_ids}\"\n    )\n    return add_time_ids\n\n\ndef extract_filepaths(examples):\n    filepaths = []\n    for example in examples:\n        filepaths.append(example[\"image_path\"])\n    return filepaths\n\n\ndef fetch_pixel_values(fp, data_backend_id: str):\n    \"\"\"Worker method to fetch pixel values for a single image.\"\"\"\n    debug_log(\n        f\" -> pull pixels for fp {fp} from cache via data backend {data_backend_id}\"\n    )\n    pixels = StateTracker.get_data_backend(data_backend_id)[\"data_backend\"].read_image(\n        fp\n    )\n    \"\"\"\n        def prepare_image(\n        resolution: float,\n        image: Image = None,\n        image_metadata: dict = None,\n        resolution_type: str = \"pixel\",\n        id: str = \"foo\",\n    ):\n\n    \"\"\"\n    backend_config = StateTracker.get_data_backend_config(data_backend_id)\n    reformed_image, _, _ = MultiaspectImage.prepare_image(\n        resolution=backend_config[\"resolution\"],\n        image=pixels,\n        image_metadata=None,\n        resolution_type=backend_config[\"resolution_type\"],\n        id=data_backend_id,\n    )\n    image_transform = MultiaspectImage.get_image_transforms()(reformed_image)\n\n    return image_transform\n\n\ndef fetch_latent(fp, data_backend_id: str):\n    \"\"\"Worker method to fetch latent for a single image.\"\"\"\n    debug_log(\n        f\" -> pull latents for fp {fp} from cache via data backend {data_backend_id}\"\n    )\n    latent = StateTracker.get_vaecache(id=data_backend_id).retrieve_from_cache(fp)\n\n    # Move to CPU and pin memory if it's not on the GPU\n    if not torch.backends.mps.is_available():\n        debug_log(\" -> push latents to GPU via pinned memory\")\n        latent = latent.to(\"cpu\").pin_memory()\n    return latent\n\n\ndef deepfloyd_pixels(filepaths, data_backend_id: str):\n    \"\"\"DeepFloyd doesn't use the VAE. We retrieve, normalise, and stack the pixel tensors directly.\"\"\"\n    # Use a thread pool to fetch latents concurrently\n    try:\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            pixels = list(\n                executor.map(\n                    fetch_pixel_values, filepaths, [data_backend_id] * len(filepaths)\n                )\n            )\n    except Exception as e:\n        logger.error(f\"(id={data_backend_id}) Error while computing pixels: {e}\")\n        raise\n    pixels = torch.stack(pixels)\n    pixels = pixels.to(memory_format=torch.contiguous_format).float()\n\n    return pixels\n\n\ndef compute_latents(filepaths, data_backend_id: str):\n    # Use a thread pool to fetch latents concurrently\n    try:\n        if \"deepfloyd\" in StateTracker.get_args().model_type:\n            latents = deepfloyd_pixels(filepaths, data_backend_id)\n\n            return latents\n        if not StateTracker.get_args().vae_cache_preprocess:\n            latents = StateTracker.get_vaecache(id=data_backend_id).encode_images(\n                [None] * len(filepaths), filepaths\n            )\n        else:\n            with concurrent.futures.ThreadPoolExecutor() as executor:\n                latents = list(\n                    executor.map(\n                        fetch_latent, filepaths, [data_backend_id] * len(filepaths)\n                    )\n                )\n    except Exception as e:\n        logger.error(f\"(id={data_backend_id}) Error while computing latents: {e}\")\n        raise\n\n    return latents\n\n\ndef compute_single_embedding(caption, text_embed_cache, is_sdxl):\n    \"\"\"Worker function to compute embedding for a single caption.\"\"\"\n    if caption == \"\" or not caption:\n        # Grab the default text embed backend for null caption.\n        text_embed_cache = StateTracker.get_default_text_embed_cache()\n        debug_log(\n            f\"Hashing caption '{caption}' on text embed cache: {text_embed_cache.id} using data backend {text_embed_cache.data_backend.id}\"\n        )\n    if is_sdxl:\n        (\n            prompt_embeds,\n            add_text_embeds,\n        ) = text_embed_cache.compute_embeddings_for_sdxl_prompts([caption])\n        return (\n            prompt_embeds[0],\n            add_text_embeds[0],\n        )  # Unpack the first (and only) element\n    else:\n        prompt_embeds = text_embed_cache.compute_embeddings_for_legacy_prompts(\n            [caption]\n        )\n        result = torch.squeeze(prompt_embeds[0])\n        debug_log(f\"Torch shape: {result.shape}\")\n        return result, None  # Unpack and return None for the second element\n\n\ndef compute_prompt_embeddings(captions, text_embed_cache):\n    \"\"\"\n    Retrieve / compute text embeds in parallel.\n    Args:\n        captions: List of strings\n        text_embed_cache: TextEmbedCache instance\n\n    Returns:\n        prompt_embeds_all: Tensor of shape (batch_size, 512)\n        add_text_embeds_all: Tensor of shape (batch_size, 512)\n    \"\"\"\n    debug_log(\" -> get embed from cache\")\n    is_sdxl = text_embed_cache.model_type == \"sdxl\"\n\n    # Use a thread pool to compute embeddings concurrently\n    with ThreadPoolExecutor() as executor:\n        embeddings = list(\n            executor.map(\n                compute_single_embedding,\n                captions,\n                [text_embed_cache] * len(captions),\n                [is_sdxl] * len(captions),\n            )\n        )\n\n    debug_log(f\"Got embeddings: {embeddings}\")\n    if is_sdxl:\n        # Separate the tuples\n        prompt_embeds = [t[0] for t in embeddings]\n        add_text_embeds = [t[1] for t in embeddings]\n        return (torch.stack(prompt_embeds), torch.stack(add_text_embeds))\n    else:\n        # Separate the tuples\n        prompt_embeds = [t[0] for t in embeddings]\n        return (torch.stack(prompt_embeds), None)\n\n\ndef gather_conditional_size_features(examples, latents, weight_dtype):\n    batch_time_ids_list = []\n    if len(examples) != len(latents):\n        raise ValueError(\n            f\"Number of examples ({len(examples)}) and latents ({len(latents)}) must match.\"\n        )\n\n    for idx, example in enumerate(examples):\n        # Compute time IDs for all examples\n        time_ids = compute_time_ids(\n            original_size=tuple(example[\"original_size\"]),\n            target_size=latents[idx].shape,\n            crop_coordinates=example[\"crop_coordinates\"],\n            weight_dtype=weight_dtype,\n        )\n\n        # Overwrite with zeros if conditioning is to be dropped\n        if example[\"drop_conditioning\"]:\n            time_ids = torch.zeros_like(time_ids)\n\n        batch_time_ids_list.append(time_ids)\n\n    return torch.stack(batch_time_ids_list, dim=0)\n\n\ndef check_latent_shapes(latents, filepaths, data_backend_id, batch):\n    # Validate shapes\n    test_shape = latents[0].shape\n    # Check all \"aspect_ratio\" values and raise error if any differ, with the two differing values:\n    for example in batch[0]:\n        if example[\"aspect_ratio\"] != batch[0][0][\"aspect_ratio\"]:\n            raise ValueError(\n                f\"Aspect ratio mismatch: {example['aspect_ratio']} != {batch[0][0]['aspect_ratio']}\"\n            )\n    for idx, latent in enumerate(latents):\n        # Are there any inf or nan positions?\n        if torch.isnan(latent).any() or torch.isinf(latent).any():\n            # get the data_backend\n            data_backend = StateTracker.get_data_backend(data_backend_id)\n            # remove the object\n            data_backend[\"vaecache\"].data_backend.delete(filepaths[idx])\n            raise ValueError(\n                f\"(id={data_backend_id}) Deleted cache file {filepaths[idx]}: contains NaN or Inf values: {latent}\"\n            )\n        if latent.shape != test_shape:\n            raise ValueError(\n                f\"(id={data_backend_id}) File {filepaths[idx]} latent shape mismatch: {latent.shape} != {test_shape}\"\n            )\n\n    debug_log(f\" -> stacking {len(latents)} latents\")\n    return torch.stack(\n        [latent.to(StateTracker.get_accelerator().device) for latent in latents]\n    )\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to collate a batch of data for training a model.\n\nArgs:\n    batch (list): A list of examples to be collated.\n\nReturns:\n    dict: A dictionary containing the collated data. The keys are:\n        - 'latent_batch': The latent representations of the examples.\n        - 'prompt_embeds': The text embeddings of the examples.\n        - 'add_text_embeds': Additional text embeddings of the examples.\n        - 'batch_time_ids': The time ids of the examples.\n        - 'batch_luminance': The average luminance of the examples.\n\nRaises:\n    ValueError: If the batch contains more than one example.\n\nNotes:\n    - The function uses numpy.random.rand to randomly drop captions/conditioning based on a dropout probability.\n    - The function computes the latents, captions, and text embeddings of the examples.\n    - The function checks the shapes of the latents and handles dropped conditionings.\n    - The function computes and stacks SDXL time ids.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef collate_fn(batch):\n    if len(batch) != 1:\n        raise ValueError(\n            \"This trainer is not designed to handle multiple batches in a single collate.\"\n        )\n    debug_log(\"Begin collate_fn on batch\")\n\n    # SDXL Dropout\n    dropout_probability = StateTracker.get_args().caption_dropout_probability\n    examples = batch[0]\n\n    # Randomly drop captions/conditioning based on dropout_probability\n    for example in examples:\n        data_backend_id = example[\"data_backend_id\"]\n        if (\n            dropout_probability > 0\n            and dropout_probability is not None\n            and np.random.rand() < dropout_probability\n        ):\n            example[\"instance_prompt_text\"] = \"\"  # Drop caption\n            example[\"drop_conditioning\"] = True  # Flag to drop conditioning\n        else:\n            example[\"drop_conditioning\"] = False\n\n    debug_log(\"Collect luminance values\")\n    if \"luminance\" in examples[0]:\n        batch_luminance = [example[\"luminance\"] for example in examples]\n    else:\n        batch_luminance = [0] * len(examples)\n    # average it\n    batch_luminance = sum(batch_luminance) / len(batch_luminance)\n    debug_log(\"Extract filepaths\")\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    filepaths = extract_filepaths(examples)\n    debug_log(\"Compute latents\")\n    latent_batch = compute_latents(filepaths, data_backend_id)\n    if \"deepfloyd\" not in StateTracker.get_args().model_type:\n        debug_log(\"Check latents\")\n        latent_batch = check_latent_shapes(\n            latent_batch, filepaths, data_backend_id, batch\n        )\n\n    # Compute embeddings and handle dropped conditionings\n    debug_log(\"Extract captions\")\n    captions = [example[\"instance_prompt_text\"] for example in examples]\n    debug_log(\"Pull cached text embeds\")\n    text_embed_cache = StateTracker.get_data_backend(data_backend_id)[\n        \"text_embed_cache\"\n    ]\n    prompt_embeds_all, add_text_embeds_all = compute_prompt_embeddings(\n        captions, text_embed_cache\n    )\n    batch_time_ids = None\n    if add_text_embeds_all is not None:\n        debug_log(\"Compute and stack SDXL time ids\")\n        batch_time_ids = gather_conditional_size_features(\n            examples, latent_batch, StateTracker.get_weight_dtype()\n        )\n        debug_log(f\"Time ids stacked to {batch_time_ids.shape}: {batch_time_ids}\")\n\n    return {\n        \"latent_batch\": latent_batch,\n        \"prompt_embeds\": prompt_embeds_all,\n        \"add_text_embeds\": add_text_embeds_all,\n        \"batch_time_ids\": batch_time_ids,\n        \"batch_luminance\": batch_luminance,\n    }", "completions": ["  \n[PYTHON]\ndef collate_fn(batch):\n    if len(batch)!= 1:\n        raise ValueError(\n            \"This trainer is not designed to handle multiple batches in a single collate.\"\n        )\n    debug_log(\"Begin collate_fn on batch\")\n\n    # SDXL Dropout\n    dropout_probability = StateTracker.get_args().caption_dropout_probability\n    examples = batch[0]\n\n    # Randomly drop captions/conditioning based on dropout_probability\n    for example in examples:\n        data_backend_id = example[\"data_backend_id\"]\n        if (\n            dropout_probability > 0\n            and dropout_probability is not None\n            and np.random.rand() < dropout_probability\n        ):\n            example[\"instance_prompt_text\"] = \"\"  # Drop caption\n            example[\"drop_conditioning\"] = True  # Flag to drop conditioning\n        else:\n            example[\"drop_conditioning\"] = False\n\n    debug_log(\"Collect luminance values\")\n    if \"luminance\" in examples[0]:\n        batch_luminance = [example[\"luminance\"] for example in examples]\n    else:\n        batch_luminance = [0] * len(examples)\n    # average it\n    batch_luminance = sum(batch_luminance) / len(batch_luminance)\n    debug_log(\"Extract filepaths\")\n\n    filepaths = extract_filepaths(examples)\n    debug_log(\"Fetch latents\")\n    latents = compute_latents(filepaths, data_backend_id)\n    debug_log(\"Fetch text embeddings\")\n    text_embed_cache = StateTracker.get_text_embed_cache(data_backend_id)\n    prompt_embeds, add_text_embeds = compute_prompt_embeddings(\n        [example[\"instance_prompt_text\"] for example in examples], text_embed_cache\n    )\n    debug_log(\"Gather conditional size features\")\n    batch_time_ids = gather_conditional_size_features(\n        examples, latents, text_embed_cache.weight_dtype\n    )\n\n    debug_log(\"Check latent shapes\")\n    latents = check_latent_shapes(latents, filepaths, data_backend_id, batch)\n\n    debug_log(\"Return collated data\")\n    return {\n        \"latent_batch\": latents,\n        \"prompt_embeds\": prompt_embeds,\n        \"add_text_embeds\": add_text_embeds,\n        \"batch_time_ids\": batch_time_ids,\n        \"batch_luminance\": batch_luminance,\n    }\n[/PYTHON]\n"]}
{"id": 34, "name": "compute_parameter_entropy", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2024 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Utilities for computing exploration scores.\"\"\"\n\nfrom typing import Iterable, Optional\n\nimport numpy as np\nimport scipy\nfrom vizier import pyvizier as vz\n\nBenchmarkResults = dict[str, dict[str, dict[int, vz.ProblemAndTrials]]]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes the entropy of a parameter based on its configuration and values.\n\nArgs:\n    parameter_config (vz.ParameterConfig): The configuration of the parameter.\n    parameter_values (Iterable[Optional[vz.ParameterValue]]): The values of the parameter.\n\nReturns:\n    float: The entropy of the parameter.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef compute_parameter_entropy(\n    parameter_config: vz.ParameterConfig,\n    parameter_values: Iterable[Optional[vz.ParameterValue]],\n) -> float:\n  values = [pv.value for pv in parameter_values if pv is not None]\n  if not values:\n    return 0.0\n  if parameter_config.type in [\n      vz.ParameterType.CATEGORICAL,\n      vz.ParameterType.DISCRETE,\n  ] and hasattr(parameter_config, 'feasible_values'):\n    if any([value not in parameter_config.feasible_values for value in values]):\n      raise ValueError(\n          f'Parameter values: {parameter_values} contain out-of-bound values.'\n          f' Feasible values: {parameter_config.feasible_values}'\n      )\n    _, counts = np.unique(values, return_counts=True)\n  elif hasattr(parameter_config, 'bounds'):\n    min_val = parameter_config.bounds[0]\n    max_val = parameter_config.bounds[1]\n    if any([value < min_val or value > max_val for value in values]):\n      raise ValueError(\n          f'Parameter values: {parameter_values} contain out-of-bound values.'\n          f' Bound: [{min_val}, {max_val}]'\n      )\n    if parameter_config.type == vz.ParameterType.INTEGER:\n      _, counts = np.unique(values, return_counts=True)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    else:\n      # Sets the number of fixed-width bins as c * sample_size ** (1.0 / 3.0).\n      # The cubic-root dependency on the sample size appears in several common\n      # bin-size selection strategies, e.g.\n      # https://en.wikipedia.org/wiki/Histogram#Number_of_bins_and_width\n      # The multiplier `c` is chosen such that for a small sample size, say 100,\n      # we still get a reasonable number of bins, say 30.\n      alpha = 1.0 / 3.0\n      c = 30.0 / (100**alpha)\n      n_sample = len(values)\n      # We also ensure that the number of bins is at most the sample size.\n      num_bins = np.min((int(c * n_sample**alpha), n_sample))\n      counts, _ = np.histogram(\n          values,\n          bins=np.linspace(\n              min_val,\n              max_val,\n              num=num_bins + 1,\n              dtype=np.float32,\n          ),\n      )\n  else:\n    raise ValueError(\n        'Invalid parameter config: either `feasible_values` or'\n        '`bounds` is expected to be set, but both are unset. '\n        f'Parameter config: {parameter_config}'\n    )\n  return float(scipy.stats.entropy(counts))", "completions": ["  \n[markdown]```\ndef compute_parameter_entropy(parameter_config, parameter_values):\n  values = [pv.value for pv in parameter_values if pv is not None]\n  if not values:\n    return 0.0\n  if parameter_config.type in [vz.ParameterType.CATEGORICAL, vz.ParameterType.DISCRETE] and hasattr(parameter_config, 'feasible_values'):\n    if any([value not in parameter_config.feasible_values for value in values]):\n      raise ValueError(f'Parameter values: {parameter_values} contain out-of-bound values. Feasible values: {parameter_config.feasible_values}')\n    _, counts = np.unique(values, return_counts=True)\n  elif hasattr(parameter_config, 'bounds'):\n    min_val = parameter_config.bounds[0]\n    max_val = parameter_config.bounds[1]\n    if any([value < min_val or value > max_val for value in values]):\n      raise ValueError(f'Parameter values: {parameter_values} contain out-of-bound values. Bound: [{min_val}, {max_val}]')\n    if parameter_config.type == vz.ParameterType.INTEGER:\n      _, counts = np.unique(values, return_counts=True)\n  entropy = scipy.stats.entropy(counts)\n  return entropy\n```"]}
{"id": 35, "name": "download_profile", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Any, cast\n\nimport aiohttp\nfrom homeassistant.core import HomeAssistant\nfrom homeassistant.helpers.storage import STORAGE_DIR\n\nfrom custom_components.powercalc.helpers import get_library_json_path\nfrom custom_components.powercalc.power_profile.error import LibraryLoadingError, ProfileDownloadError\nfrom custom_components.powercalc.power_profile.loader.protocol import Loader\nfrom custom_components.powercalc.power_profile.power_profile import DeviceType\n\n_LOGGER = logging.getLogger(__name__)\n\nDOWNLOAD_PROXY = \"https://powercalc.lauwbier.nl/api\"\nENDPOINT_LIBRARY = f\"{DOWNLOAD_PROXY}/library\"\nENDPOINT_DOWNLOAD = f\"{DOWNLOAD_PROXY}/download\"\n\n\nclass RemoteLoader(Loader):\n    def __init__(self, hass: HomeAssistant) -> None:\n        self.hass = hass\n        self.library_contents: dict = {}\n        self.model_infos: dict[str, dict] = {}\n        self.manufacturer_models: dict[str, list[dict]] = {}\n\n    async def initialize(self) -> None:\n        self.library_contents = await self.load_library_json()\n\n        # Load contents of library JSON into memory\n        manufacturers: list[dict] = self.library_contents.get(\"manufacturers\", [])\n        for manufacturer in manufacturers:\n            models: list[dict] = manufacturer.get(\"models\", [])\n            for model in models:\n                manufacturer_name = str(manufacturer.get(\"name\"))\n                model_id = str(model.get(\"id\"))\n                self.model_infos[f\"{manufacturer_name}/{model_id}\"] = model\n                if manufacturer_name not in self.manufacturer_models:\n                    self.manufacturer_models[manufacturer_name] = []\n                self.manufacturer_models[manufacturer_name].append(model)\n\n    @staticmethod\n    async def load_library_json() -> dict[str, Any]:\n        \"\"\"Load library.json file\"\"\"\n\n        async with aiohttp.ClientSession() as session, session.get(ENDPOINT_LIBRARY) as resp:\n            if resp.status != 200:\n                _LOGGER.error(\"Failed to download library.json from github, falling back to local copy\")\n                with open(get_library_json_path()) as f:\n                    return cast(dict[str, Any], json.load(f))\n            return cast(dict[str, Any], await resp.json())\n\n    async def get_manufacturer_listing(self, device_type: DeviceType | None) -> set[str]:\n        \"\"\"Get listing of available manufacturers.\"\"\"\n\n        return {\n            manufacturer[\"name\"] for manufacturer\n            in self.library_contents.get(\"manufacturers\", [])\n            if not device_type or device_type in manufacturer.get(\"device_types\", [])\n        }\n\n    async def get_model_listing(self, manufacturer: str, device_type: DeviceType | None) -> set[str]:\n        \"\"\"Get listing of available models for a given manufacturer.\"\"\"\n\n        return {\n            model[\"id\"] for model\n            in self.manufacturer_models.get(manufacturer, [])\n            if not device_type or device_type in model.get(\"device_type\", DeviceType.LIGHT)\n        }\n\n    async def load_model(self, manufacturer: str, model: str) -> tuple[dict, str] | None:\n        model_info = self.model_infos.get(f\"{manufacturer}/{model}\")\n        if not model_info:\n            raise LibraryLoadingError(\"Model not found in library: %s/%s\", manufacturer, model)\n\n        storage_path = self.get_storage_path(manufacturer, model)\n\n        needs_update = False\n        path_exists = os.path.exists(storage_path)\n        if not path_exists:\n            needs_update = True\n\n        if path_exists:\n            remote_modification_time = model_info.get(\"update_timestamp\", time.time())\n            local_modification_time = self._get_local_modification_time(storage_path)\n            if remote_modification_time > local_modification_time:\n                _LOGGER.debug(\"Remote profile is newer than local profile\")\n                needs_update = True\n\n        if needs_update:\n            try:\n                await self.download_profile(manufacturer, model, storage_path)\n            except ProfileDownloadError as e:\n                if not path_exists:\n                    raise e\n                _LOGGER.error(\"Failed to download profile, falling back to local profile\")\n\n        model_path = os.path.join(storage_path, \"model.json\")\n\n        with open(model_path) as f:\n            json_data = json.load(f)\n\n        return json_data, storage_path\n\n    def get_storage_path(self, manufacturer: str, model: str) -> str:\n        return str(self.hass.config.path(STORAGE_DIR, \"powercalc_profiles\", manufacturer, model))\n\n    async def find_model(self, manufacturer: str, search: set[str]) -> str | None:\n        \"\"\"Find the model in the library.\"\"\"\n\n        models = self.manufacturer_models.get(manufacturer, [])\n        if not models:\n            return None\n\n        return next((model.get(\"id\") for model in models for string in search\n                     if string == model.get(\"id\") or string in model.get(\"aliases\", [])), None)\n\n    @staticmethod\n    def _get_local_modification_time(folder: str) -> float:\n        \"\"\"Get the latest modification time of the local profile directory.\"\"\"\n        times = [os.path.getmtime(os.path.join(folder, f)) for f in os.listdir(folder)]\n        times.sort(reverse=True)\n        return times[0] if times else 0\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to download a profile from a specified manufacturer and model from Github.\n\nArgs:\n    self: The instance of the class that this method belongs to.\n    manufacturer (str): The name of the manufacturer of the device.\n    model (str): The model of the device.\n    storage_path (str): The local storage path where the downloaded profile will be saved.\n\nReturns:\n    None: This function does not return anything.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    async def download_profile(self, manufacturer: str, model: str, storage_path: str) -> None:\n\n        _LOGGER.info(\"Downloading profile: %s/%s from github\", manufacturer, model)\n\n        endpoint = f\"{ENDPOINT_DOWNLOAD}/{manufacturer}/{model}\"\n\n        def _save_file(data: bytes, directory: str) -> None:\n            \"\"\"Save file from Github to local storage directory\"\"\"\n            path = os.path.join(storage_path, directory)\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            with open(path, \"wb\") as f:\n                f.write(data)\n\n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.get(endpoint) as resp:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                    if resp.status != 200:\n                        raise ProfileDownloadError(f\"Failed to download profile: {manufacturer}/{model}\")\n                    resources = await resp.json()\n\n                await self.hass.async_add_executor_job(lambda: os.makedirs(storage_path, exist_ok=True))  # type: ignore\n\n                # Download the files\n                for resource in resources:\n                    url = resource.get(\"url\")\n                    async with session.get(url) as resp:\n                        if resp.status != 200:\n                            raise ProfileDownloadError(f\"Failed to download github URL: {url}\")\n\n                        contents = await resp.read()\n                        await self.hass.async_add_executor_job(_save_file, contents, resource.get(\"path\"))  # type: ignore\n            except aiohttp.ClientError as e:\n                raise ProfileDownloadError(f\"Failed to download profile: {manufacturer}/{model}\") from e", "completions": ["  \n[PYTHON]\n```\nasync with session.get(endpoint) as resp:\n    if resp.status!= 200:\n        raise ProfileDownloadError(\"Failed to download profile from github\")\n    data = await resp.read()\n    _save_file(data, \"model.json\")\n```\n[/PYTHON]\n"]}
{"id": 36, "name": "iterate_segmented_dataset", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n\n   Copyright 2014-2024 OpenEEmeter contributors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\"\"\"\nfrom collections import namedtuple\n\nimport pandas as pd\nfrom patsy import dmatrix\n\n__all__ = (\n    \"iterate_segmented_dataset\",\n    \"segment_time_series\",\n    \"CalTRACKSegmentModel\",\n    \"SegmentedModel\",\n    \"HourlyModelPrediction\",\n)\n\n\nHourlyModelPrediction = namedtuple(\"HourlyModelPrediction\", [\"result\"])\n\n\nclass CalTRACKSegmentModel(object):\n    \"\"\"An object that captures the model fit for one segment.\n\n    Attributes\n    ----------\n    segment_name : :any:`str`\n        The name of the segment of data this model was fit to.\n    model : :any:`object`\n        The fitted model object.\n    formula : :any:`str`\n        The formula of the model regression.\n    model_param : :any:`dict`\n        A dictionary of parameters\n    warnings : :any:`list`\n        A list of eemeter warnings.\n    \"\"\"\n\n    def __init__(self, segment_name, model, formula, model_params, warnings=None):\n        self.segment_name = segment_name\n        self.model = model\n        self.formula = formula\n        self.model_params = model_params\n\n        if warnings is None:\n            warnings = []\n        self.warnings = warnings\n\n    def predict(self, data):\n        \"\"\"A function which takes input data and predicts for this segment model.\"\"\"\n        if self.formula is None:\n            var_str = \"\"\n        else:\n            var_str = self.formula.split(\"~\", 1)[1]\n\n        design_matrix_granular = dmatrix(var_str, data, return_type=\"dataframe\")\n        parameters = pd.Series(self.model_params)\n\n        # Step 1, slice\n        col_type = \"C(hour_of_week)\"\n        hour_of_week_cols = [\n            c\n            for c in design_matrix_granular.columns\n            if col_type in c and c in parameters.keys()\n        ]\n\n        # Step 2, cut out all 0s\n        design_matrix_granular = design_matrix_granular[\n            (design_matrix_granular[hour_of_week_cols] != 0).any(axis=1)\n        ]\n\n        cols_to_predict = list(\n            set(parameters.keys()).intersection(set(design_matrix_granular.keys()))\n        )\n        design_matrix_granular = design_matrix_granular[cols_to_predict]\n        parameters = parameters[cols_to_predict]\n\n        # Step 3, predict\n        prediction = design_matrix_granular.dot(parameters).rename(\"predicted_usage\")\n\n        # Step 4, put nans back in\n        prediction = prediction.reindex(data.index)\n\n        return prediction\n\n    def json(self):\n        \"\"\"Return a JSON-serializable representation of this result.\n\n        The output of this function can be converted to a serialized string\n        with :any:`json.dumps`.\n        \"\"\"\n\n        data = {\n            \"segment_name\": self.segment_name,\n            \"formula\": self.formula,\n            \"warnings\": [w.json() for w in self.warnings],\n            \"model_params\": self.model_params,\n        }\n        return data\n\n    @classmethod\n    def from_json(cls, data):\n        \"\"\"Loads a JSON-serializable representation into the model state.\n\n        The input of this function is a dict which can be the result\n        of :any:`json.loads`.\n        \"\"\"\n\n        c = cls(\n            data.get(\"segment_name\"),\n            None,\n            data.get(\"formula\"),\n            data.get(\"model_params\"),\n            warnings=data.get(\"warnings\"),\n        )\n\n        return c\n\n\nclass SegmentedModel(object):\n    \"\"\"Represent a model which has been broken into multiple model segments (for\n    CalTRACK Hourly, these are month-by-month segments, each of which is associated\n    with a different model.\n\n    Parameters\n    ----------\n    segment_models : :any:`dict` of :any:`eemeter.CalTRACKSegmentModel`\n        Dictionary of segment models, keyed by segment name.\n    prediction_segment_type : :any:`str`\n        Any segment_type that can be passed to :any:`eemeter.segment_time_series`,\n        currently \"single\", \"one_month\", \"three_month\", or \"three_month_weighted\".\n    prediction_segment_name_mapping : :any:`dict` of :any:`str`\n        A dictionary mapping the segment names for the segment type used for predicting to the\n        segment names for the segment type used for fitting,\n        e.g., `{\"<predict_segment_name>\": \"<fit_segment_name>\"}`.\n    prediction_feature_processor : :any:`function`\n        A function that transforms raw inputs (temperatures) into features for each\n        segment.\n    prediction_feature_processor_kwargs : :any:`dict`\n        A dict of keyword arguments to be passed as `**kwargs` to the\n        `prediction_feature_processor` function.\n    \"\"\"\n\n    def __init__(\n        self,\n        segment_models,\n        prediction_segment_type,\n        prediction_segment_name_mapping=None,\n        prediction_feature_processor=None,\n        prediction_feature_processor_kwargs=None,\n    ):\n        self.segment_models = segment_models\n\n        fitted_model_lookup = {\n            segment_model.segment_name: segment_model\n            for segment_model in segment_models\n        }\n        if prediction_segment_name_mapping is None:\n            self.model_lookup = fitted_model_lookup\n        else:\n            self.model_lookup = {\n                pred_name: fitted_model_lookup.get(fit_name)\n                for pred_name, fit_name in prediction_segment_name_mapping.items()\n            }\n        self.prediction_segment_type = prediction_segment_type\n        self.prediction_segment_name_mapping = prediction_segment_name_mapping\n        self.prediction_feature_processor = prediction_feature_processor\n        self.prediction_feature_processor_kwargs = prediction_feature_processor_kwargs\n\n    def predict(\n        self, prediction_index, temperature, **kwargs\n    ):  # ignore extra args with kwargs\n        \"\"\"Predict over a prediction index by combining results from all models.\n\n        Parameters\n        ----------\n        prediction_index : :any:`pandas.DatetimeIndex`\n            The index over which to predict.\n        temperature : :any:`pandas.Series`\n            Hourly temperatures.\n        **kwargs\n            Extra argmuents will be ignored\n        \"\"\"\n        prediction_segmentation = segment_time_series(\n            temperature.index,\n            self.prediction_segment_type,\n            drop_zero_weight_segments=True,\n        )\n\n        iterator = iterate_segmented_dataset(\n            temperature.to_frame(\"temperature_mean\"),\n            segmentation=prediction_segmentation,\n            feature_processor=self.prediction_feature_processor,\n            feature_processor_kwargs=self.prediction_feature_processor_kwargs,\n            feature_processor_segment_name_mapping=self.prediction_segment_name_mapping,\n        )\n\n        predictions = {}\n        for segment_name, segmented_data in iterator:\n            segment_model = self.model_lookup.get(segment_name)\n            if segment_model is None:\n                continue\n            prediction = segment_model.predict(segmented_data) * segmented_data.weight\n            # NaN the zero weights and reindex\n            prediction = prediction[segmented_data.weight > 0].reindex(prediction_index)\n            predictions[segment_name] = prediction\n\n        predictions = pd.DataFrame(predictions)\n        result = pd.DataFrame({\"predicted_usage\": predictions.sum(axis=1, min_count=1)})\n        return HourlyModelPrediction(result=result)\n\n    def json(self):\n        \"\"\"Return a JSON-serializable representation of this result.\n\n        The output of this function can be converted to a serialized string\n        with :any:`json.dumps`.\n        \"\"\"\n\n        def _json_or_none(obj):\n            return None if obj is None else obj.json()\n\n        data = {\n            \"segment_models\": [_json_or_none(m) for m in self.segment_models],\n            \"model_lookup\": {\n                key: _json_or_none(val) for key, val in self.model_lookup.items()\n            },\n            \"prediction_segment_type\": self.prediction_segment_type,\n            \"prediction_segment_name_mapping\": self.prediction_segment_name_mapping,\n            \"prediction_feature_processor\": self.prediction_feature_processor.__name__,\n        }\n        return data\n\n\ndef filter_zero_weights_feature_processor(segment_name, segment_data):\n    \"\"\"A default segment processor to use if none is provided.\"\"\"\n    return segment_data[segment_data.weight > 0]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function iterates over a segmented dataset and applies a feature processor to each segment.\n\nArgs:\n    data (pandas.DataFrame): The dataset to be segmented and processed.\n    segmentation (dict): A dictionary where keys are segment names and values are pandas.Series of weights.\n    feature_processor (callable): A function that processes the features of the dataset.\n    feature_processor_kwargs (dict): Keyword arguments to be passed to the feature processor.\n    feature_processor_segment_name_mapping (dict): A mapping from segment names to feature processor segment names.\n\nReturns:\n    generator: A generator that yields tuples of segment name and processed segment data.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef iterate_segmented_dataset(\n    data,\n    segmentation=None,\n    feature_processor=None,\n    feature_processor_kwargs=None,\n    feature_processor_segment_name_mapping=None,\n):\n    if feature_processor is None:\n        feature_processor = filter_zero_weights_feature_processor\n\n    if feature_processor_kwargs is None:\n        feature_processor_kwargs = {}\n\n    if feature_processor_segment_name_mapping is None:\n        feature_processor_segment_name_mapping = {}\n\n    def _apply_feature_processor(segment_name, segment_data):\n        feature_processor_segment_name = feature_processor_segment_name_mapping.get(\n            segment_name, segment_name\n        )\n\n        if feature_processor is not None:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            segment_data = feature_processor(\n                feature_processor_segment_name, segment_data, **feature_processor_kwargs\n            )\n        return segment_data\n\n    def _add_weights(data, weights):\n        return pd.merge(data, weights, left_index=True, right_index=True)\n\n    if segmentation is None:\n        # spoof segment name and weights column\n        segment_name = None\n        weights = pd.DataFrame({\"weight\": 1}, index=data.index)\n        segment_data = _add_weights(data, weights)\n\n        segment_data = _apply_feature_processor(segment_name, segment_data)\n        yield segment_name, segment_data\n    else:\n        for segment_name, segment_weights in segmentation.items():\n            weights = segment_weights.to_frame(\"weight\")\n            segment_data = _add_weights(data, weights)\n            segment_data = _apply_feature_processor(segment_name, segment_data)\n            yield segment_name, segment_data", "completions": ["  \n[PYTHON]\ndef iterate_segmented_dataset(\n    data,\n    segmentation=None,\n    feature_processor=None,\n    feature_processor_kwargs=None,\n    feature_processor_segment_name_mapping=None,\n):\n    if feature_processor is None:\n        feature_processor = filter_zero_weights_feature_processor\n\n    if feature_processor_kwargs is None:\n        feature_processor_kwargs = {}\n\n    if feature_processor_segment_name_mapping is None:\n        feature_processor_segment_name_mapping = {}\n\n    def _apply_feature_processor(segment_name, segment_data):\n        feature_processor_segment_name = feature_processor_segment_name_mapping.get(\n            segment_name, segment_name\n        )\n\n        if feature_processor is not None:\n            segment_data = feature_processor(\n                feature_processor_segment_name, segment_data, **feature_processor_kwargs\n            )\n\n        return segment_data\n\n    if segmentation is None:\n        segmentation = segment_time_series(data.index, \"single\")\n\n    for segment_name, segment_data in segmentation.items():\n        segment_data = _apply_feature_processor(segment_name, segment_data)\n        yield segment_name, segment_data\n[/PYTHON]\n"]}
{"id": 38, "name": "spectrogram", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# coding=utf-8\n# Copyright 2023 The HuggingFace Inc. team and the librosa & torchaudio authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nAudio processing functions to extract features from audio waveforms. This code is pure numpy to support all frameworks\nand remove unnecessary dependencies.\n\"\"\"\nimport warnings\nfrom typing import Optional, Union\n\nimport numpy as np\n\n\ndef hertz_to_mel(freq: Union[float, np.ndarray], mel_scale: str = \"htk\") -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert frequency from hertz to mels.\n\n    Args:\n        freq (`float` or `np.ndarray`):\n            The frequency, or multiple frequencies, in hertz (Hz).\n        mel_scale (`str`, *optional*, defaults to `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"` or `\"slaney\"`.\n\n    Returns:\n        `float` or `np.ndarray`: The frequencies on the mel scale.\n    \"\"\"\n\n    if mel_scale not in [\"slaney\", \"htk\"]:\n        raise ValueError('mel_scale should be one of \"htk\" or \"slaney\".')\n\n    if mel_scale == \"htk\":\n        return 2595.0 * np.log10(1.0 + (freq / 700.0))\n\n    min_log_hertz = 1000.0\n    min_log_mel = 15.0\n    logstep = 27.0 / np.log(6.4)\n    mels = 3.0 * freq / 200.0\n\n    if isinstance(freq, np.ndarray):\n        log_region = freq >= min_log_hertz\n        mels[log_region] = min_log_mel + np.log(freq[log_region] / min_log_hertz) * logstep\n    elif freq >= min_log_hertz:\n        mels = min_log_mel + np.log(freq / min_log_hertz) * logstep\n\n    return mels\n\n\ndef mel_to_hertz(mels: Union[float, np.ndarray], mel_scale: str = \"htk\") -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert frequency from mels to hertz.\n\n    Args:\n        mels (`float` or `np.ndarray`):\n            The frequency, or multiple frequencies, in mels.\n        mel_scale (`str`, *optional*, `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"` or `\"slaney\"`.\n\n    Returns:\n        `float` or `np.ndarray`: The frequencies in hertz.\n    \"\"\"\n\n    if mel_scale not in [\"slaney\", \"htk\"]:\n        raise ValueError('mel_scale should be one of \"htk\" or \"slaney\".')\n\n    if mel_scale == \"htk\":\n        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\n\n    min_log_hertz = 1000.0\n    min_log_mel = 15.0\n    logstep = np.log(6.4) / 27.0\n    freq = 200.0 * mels / 3.0\n\n    if isinstance(mels, np.ndarray):\n        log_region = mels >= min_log_mel\n        freq[log_region] = min_log_hertz * np.exp(logstep * (mels[log_region] - min_log_mel))\n    elif mels >= min_log_mel:\n        freq = min_log_hertz * np.exp(logstep * (mels - min_log_mel))\n\n    return freq\n\n\ndef _create_triangular_filter_bank(fft_freqs: np.ndarray, filter_freqs: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Creates a triangular filter bank.\n\n    Adapted from *torchaudio* and *librosa*.\n\n    Args:\n        fft_freqs (`np.ndarray` of shape `(num_frequency_bins,)`):\n            Discrete frequencies of the FFT bins in Hz.\n        filter_freqs (`np.ndarray` of shape `(num_mel_filters,)`):\n            Center frequencies of the triangular filters to create, in Hz.\n\n    Returns:\n        `np.ndarray` of shape `(num_frequency_bins, num_mel_filters)`\n    \"\"\"\n    filter_diff = np.diff(filter_freqs)\n    slopes = np.expand_dims(filter_freqs, 0) - np.expand_dims(fft_freqs, 1)\n    down_slopes = -slopes[:, :-2] / filter_diff[:-1]\n    up_slopes = slopes[:, 2:] / filter_diff[1:]\n    return np.maximum(np.zeros(1), np.minimum(down_slopes, up_slopes))\n\n\ndef mel_filter_bank(\n    num_frequency_bins: int,\n    num_mel_filters: int,\n    min_frequency: float,\n    max_frequency: float,\n    sampling_rate: int,\n    norm: Optional[str] = None,\n    mel_scale: str = \"htk\",\n) -> np.ndarray:\n    \"\"\"\n    Creates a frequency bin conversion matrix used to obtain a mel spectrogram. This is called a *mel filter bank*, and\n    various implementation exist, which differ in the number of filters, the shape of the filters, the way the filters\n    are spaced, the bandwidth of the filters, and the manner in which the spectrum is warped. The goal of these\n    features is to approximate the non-linear human perception of the variation in pitch with respect to the frequency.\n\n    Different banks of mel filters were introduced in the literature. The following variations are supported:\n\n    - MFCC FB-20: introduced in 1980 by Davis and Mermelstein, it assumes a sampling frequency of 10 kHz and a speech\n      bandwidth of `[0, 4600]` Hz.\n    - MFCC FB-24 HTK: from the Cambridge HMM Toolkit (HTK) (1995) uses a filter bank of 24 filters for a speech\n      bandwidth of `[0, 8000]` Hz. This assumes sampling rate ≥ 16 kHz.\n    - MFCC FB-40: from the Auditory Toolbox for MATLAB written by Slaney in 1998, assumes a sampling rate of 16 kHz and\n      speech bandwidth of `[133, 6854]` Hz. This version also includes area normalization.\n    - HFCC-E FB-29 (Human Factor Cepstral Coefficients) of Skowronski and Harris (2004), assumes a sampling rate of\n      12.5 kHz and speech bandwidth of `[0, 6250]` Hz.\n\n    This code is adapted from *torchaudio* and *librosa*. Note that the default parameters of torchaudio's\n    `melscale_fbanks` implement the `\"htk\"` filters while librosa uses the `\"slaney\"` implementation.\n\n    Args:\n        num_frequency_bins (`int`):\n            Number of frequencies used to compute the spectrogram (should be the same as in `stft`).\n        num_mel_filters (`int`):\n            Number of mel filters to generate.\n        min_frequency (`float`):\n            Lowest frequency of interest in Hz.\n        max_frequency (`float`):\n            Highest frequency of interest in Hz. This should not exceed `sampling_rate / 2`.\n        sampling_rate (`int`):\n            Sample rate of the audio waveform.\n        norm (`str`, *optional*):\n            If `\"slaney\"`, divide the triangular mel weights by the width of the mel band (area normalization).\n        mel_scale (`str`, *optional*, defaults to `\"htk\"`):\n            The mel frequency scale to use, `\"htk\"` or `\"slaney\"`.\n\n    Returns:\n        `np.ndarray` of shape (`num_frequency_bins`, `num_mel_filters`): Triangular filter bank matrix. This is a\n        projection matrix to go from a spectrogram to a mel spectrogram.\n    \"\"\"\n    if norm is not None and norm != \"slaney\":\n        raise ValueError('norm must be one of None or \"slaney\"')\n\n    # frequencies of FFT bins in Hz\n    fft_freqs = np.linspace(0, sampling_rate // 2, num_frequency_bins)\n\n    # center points of the triangular mel filters\n    mel_min = hertz_to_mel(min_frequency, mel_scale=mel_scale)\n    mel_max = hertz_to_mel(max_frequency, mel_scale=mel_scale)\n    mel_freqs = np.linspace(mel_min, mel_max, num_mel_filters + 2)\n    filter_freqs = mel_to_hertz(mel_freqs, mel_scale=mel_scale)\n\n    mel_filters = _create_triangular_filter_bank(fft_freqs, filter_freqs)\n\n    if norm is not None and norm == \"slaney\":\n        # Slaney-style mel is scaled to be approx constant energy per channel\n        enorm = 2.0 / (filter_freqs[2 : num_mel_filters + 2] - filter_freqs[:num_mel_filters])\n        mel_filters *= np.expand_dims(enorm, 0)\n\n    if (mel_filters.max(axis=0) == 0.0).any():\n        warnings.warn(\n            \"At least one mel filter has all zero values. \"\n            f\"The value for `num_mel_filters` ({num_mel_filters}) may be set too high. \"\n            f\"Or, the value for `num_frequency_bins` ({num_frequency_bins}) may be set too low.\"\n        )\n\n    return mel_filters\n\n\ndef optimal_fft_length(window_length: int) -> int:\n    \"\"\"\n    Finds the best FFT input size for a given `window_length`. This function takes a given window length and, if not\n    already a power of two, rounds it up to the next power or two.\n\n    The FFT algorithm works fastest when the length of the input is a power of two, which may be larger than the size\n    of the window or analysis frame. For example, if the window is 400 samples, using an FFT input size of 512 samples\n    is more optimal than an FFT size of 400 samples. Using a larger FFT size does not affect the detected frequencies,\n    it simply gives a higher frequency resolution (i.e. the frequency bins are smaller).\n    \"\"\"\n    return 2 ** int(np.ceil(np.log2(window_length)))\n\n\ndef window_function(\n    window_length: int,\n    name: str = \"hann\",\n    periodic: bool = True,\n    frame_length: Optional[int] = None,\n    center: bool = True,\n) -> np.ndarray:\n    \"\"\"\n    Returns an array containing the specified window. This window is intended to be used with `stft`.\n\n    The following window types are supported:\n\n        - `\"boxcar\"`: a rectangular window\n        - `\"hamming\"`: the Hamming window\n        - `\"hann\"`: the Hann window\n\n    Args:\n        window_length (`int`):\n            The length of the window in samples.\n        name (`str`, *optional*, defaults to `\"hann\"`):\n            The name of the window function.\n        periodic (`bool`, *optional*, defaults to `True`):\n            Whether the window is periodic or symmetric.\n        frame_length (`int`, *optional*):\n            The length of the analysis frames in samples. Provide a value for `frame_length` if the window is smaller\n            than the frame length, so that it will be zero-padded.\n        center (`bool`, *optional*, defaults to `True`):\n            Whether to center the window inside the FFT buffer. Only used when `frame_length` is provided.\n\n    Returns:\n        `np.ndarray` of shape `(window_length,)` or `(frame_length,)` containing the window.\n    \"\"\"\n    length = window_length + 1 if periodic else window_length\n\n    if name == \"boxcar\":\n        window = np.ones(length)\n    elif name in [\"hamming\", \"hamming_window\"]:\n        window = np.hamming(length)\n    elif name in [\"hann\", \"hann_window\"]:\n        window = np.hanning(length)\n    else:\n        raise ValueError(f\"Unknown window function '{name}'\")\n\n    if periodic:\n        window = window[:-1]\n\n    if frame_length is None:\n        return window\n\n    if window_length > frame_length:\n        raise ValueError(\n            f\"Length of the window ({window_length}) may not be larger than frame_length ({frame_length})\"\n        )\n\n    padded_window = np.zeros(frame_length)\n    offset = (frame_length - window_length) // 2 if center else 0\n    padded_window[offset : offset + window_length] = window\n    return padded_window\n\n\n# TODO This method does not support batching yet as we are mainly focused on inference.\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes the spectrogram of a given waveform.\n\nArgs:\n    waveform (np.ndarray): The input waveform.\n    window (np.ndarray): The window function to apply to each frame.\n    frame_length (int): The length of each frame.\n    hop_length (int): The number of samples to advance between frames.\n    fft_length (Optional[int]): The length of the FFT. If not provided, it defaults to the frame_length.\n    power (Optional[float]): The exponent for the magnitude spectrogram. Defaults to 1.0.\n    center (bool): If True, the waveform is padded so that frame t is centered at waveform[t * hop_length]. Defaults to True.\n    pad_mode (str): The mode of padding to use when center is True. Defaults to \"reflect\".\n    onesided (bool): If True, only returns the positive frequency terms. Defaults to True.\n    preemphasis (Optional[float]): A pre-emphasis factor. Defaults to None.\n    mel_filters (Optional[np.ndarray]): Mel filterbank matrix. Defaults to None.\n    mel_floor (float): The minimum value for the mel spectrogram. Defaults to 1e-10.\n    log_mel (Optional[str]): If \"log\", \"log10\", or \"dB\", the mel spectrogram is converted to the corresponding log scale. Defaults to None.\n    reference (float): The reference value for dB conversion. Defaults to 1.0.\n    min_value (float): The minimum value for dB conversion. Defaults to 1e-10.\n    db_range (Optional[float]): The dynamic range for dB conversion. Defaults to None.\n    dtype (np.dtype): The data type of the output spectrogram. Defaults to np.float32.\n\nReturns:\n    np.ndarray: The computed spectrogram.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef spectrogram(\n    waveform: np.ndarray,\n    window: np.ndarray,\n    frame_length: int,\n    hop_length: int,\n    fft_length: Optional[int] = None,\n    power: Optional[float] = 1.0,\n    center: bool = True,\n    pad_mode: str = \"reflect\",\n    onesided: bool = True,\n    preemphasis: Optional[float] = None,\n    mel_filters: Optional[np.ndarray] = None,\n    mel_floor: float = 1e-10,\n    log_mel: Optional[str] = None,\n    reference: float = 1.0,\n    min_value: float = 1e-10,\n    db_range: Optional[float] = None,\n    dtype: np.dtype = np.float32,\n) -> np.ndarray:\n    window_length = len(window)\n\n    if fft_length is None:\n        fft_length = frame_length\n\n    if frame_length > fft_length:\n        raise ValueError(f\"frame_length ({frame_length}) may not be larger than fft_length ({fft_length})\")\n\n    if window_length != frame_length:\n        raise ValueError(f\"Length of the window ({window_length}) must equal frame_length ({frame_length})\")\n\n    if hop_length <= 0:\n        raise ValueError(\"hop_length must be greater than zero\")\n\n    if waveform.ndim != 1:\n        raise ValueError(f\"Input waveform must have only one dimension, shape is {waveform.shape}\")\n\n    if np.iscomplexobj(waveform):\n        raise ValueError(\"Complex-valued input waveforms are not currently supported\")\n\n    # center pad the waveform\n    if center:\n        padding = [(int(frame_length // 2), int(frame_length // 2))]\n        waveform = np.pad(waveform, padding, mode=pad_mode)\n\n    # promote to float64, since np.fft uses float64 internally\n    waveform = waveform.astype(np.float64)\n    window = window.astype(np.float64)\n\n    # split waveform into frames of frame_length size\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    num_frames = int(1 + np.floor((waveform.size - frame_length) / hop_length))\n\n    num_frequency_bins = (fft_length // 2) + 1 if onesided else fft_length\n    spectrogram = np.empty((num_frames, num_frequency_bins), dtype=np.complex64)\n\n    # rfft is faster than fft\n    fft_func = np.fft.rfft if onesided else np.fft.fft\n    buffer = np.zeros(fft_length)\n\n    timestep = 0\n    for frame_idx in range(num_frames):\n        buffer[:frame_length] = waveform[timestep : timestep + frame_length]\n\n        if preemphasis is not None:\n            buffer[1:frame_length] -= preemphasis * buffer[: frame_length - 1]\n            buffer[0] *= 1 - preemphasis\n\n        buffer[:frame_length] *= window\n\n        spectrogram[frame_idx] = fft_func(buffer)\n        timestep += hop_length\n\n    # note: ** is much faster than np.power\n    if power is not None:\n        spectrogram = np.abs(spectrogram, dtype=np.float64) ** power\n\n    spectrogram = spectrogram.T\n\n    if mel_filters is not None:\n        spectrogram = np.maximum(mel_floor, np.dot(mel_filters.T, spectrogram))\n\n    if power is not None and log_mel is not None:\n        if log_mel == \"log\":\n            spectrogram = np.log(spectrogram)\n        elif log_mel == \"log10\":\n            spectrogram = np.log10(spectrogram)\n        elif log_mel == \"dB\":\n            if power == 1.0:\n                spectrogram = amplitude_to_db(spectrogram, reference, min_value, db_range)\n            elif power == 2.0:\n                spectrogram = power_to_db(spectrogram, reference, min_value, db_range)\n            else:\n                raise ValueError(f\"Cannot use log_mel option '{log_mel}' with power {power}\")\n        else:\n            raise ValueError(f\"Unknown log_mel option: {log_mel}\")\n\n        spectrogram = np.asarray(spectrogram, dtype)\n\n    return spectrogram", "completions": ["  \n[PYTHON]\ndef spectrogram(\n    waveform: np.ndarray,\n    window: np.ndarray,\n    frame_length: int,\n    hop_length: int,\n    fft_length: Optional[int] = None,\n    power: Optional[float] = 1.0,\n    center: bool = True,\n    pad_mode: str = \"reflect\",\n    onesided: bool = True,\n    preemphasis: Optional[float] = None,\n    mel_filters: Optional[np.ndarray] = None,\n    mel_floor: float = 1e-10,\n    log_mel: Optional[str] = None,\n    reference: float = 1.0,\n    min_value: float = 1e-10,\n    db_range: Optional[float] = None,\n    dtype: np.dtype = np.float32,\n) -> np.ndarray:\n    # Implement your code here\n    pass\n[/PYTHON]\n"]}
{"id": 39, "name": "_spatial_matching", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport warnings\n\nimport numpy\nfrom sklearn.metrics import pairwise_distances\n\nfrom ._utils import _validate_geometry_input\n\n_VALID_GEOMETRY_TYPES = [\"Point\"]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is for spatial matching between two sets of geometries using the Linear Programming (LP) approach.\n\nArgs:\n    x (array-like): The first set of geometries.\n    y (array-like, optional): The second set of geometries. If not provided, the function will perform spatial matching within x.\n    n_matches (int, optional): The number of matches to find for each geometry. Default is 5.\n    metric (str or callable, optional): The distance metric to use. Default is 'euclidean'.\n    solver (str or pulp.LpSolver, optional): The solver to use for the LP problem. Default is None.\n    return_mip (bool, optional): If True, the function will return the LP problem. Default is False.\n    allow_partial_match (bool, optional): If True, the function will allow partial matches. Default is False.\n    **metric_kwargs: Additional keyword arguments for the distance metric.\n\nReturns:\n    tuple: A tuple containing the indices of the matched geometries in x and y, and the weights of the matches. If return_mip is True, the LP problem is also returned.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef _spatial_matching(\n    x,\n    y=None,\n    n_matches=5,\n    metric=\"euclidean\",\n    solver=None,\n    return_mip=False,\n    allow_partial_match=False,\n    **metric_kwargs,\n):\n    try:\n        import pulp\n    except ImportError as error:\n        raise ImportError(\"spatial matching requires the pulp library\") from error\n    if metric == \"precomputed\":\n        distance_matrix = x\n        match_between = y is not None\n    elif y is not None:\n        x, x_ids, _ = _validate_geometry_input(\n            x, ids=None, valid_geometry_types=_VALID_GEOMETRY_TYPES\n        )\n        y, y_ids, _ = _validate_geometry_input(\n            y, ids=None, valid_geometry_types=_VALID_GEOMETRY_TYPES\n        )\n        distance_matrix = pairwise_distances(x, y, metric=metric)\n        match_between = True\n    else:\n        x, x_ids, _ = _validate_geometry_input(\n            x, ids=None, valid_geometry_types=_VALID_GEOMETRY_TYPES\n        )\n        y_ids = x_ids\n        distance_matrix = pairwise_distances(x, metric=metric, **metric_kwargs)\n\n        match_between = False\n\n    n_targets, n_sources = distance_matrix.shape\n\n    if match_between:\n        row, col = numpy.meshgrid(\n            numpy.arange(n_targets), numpy.arange(n_sources), indexing=\"ij\"\n        )\n        row = row.flatten()\n        col = col.flatten()\n    else:\n        # if we are matching within, we need to\n        row, col = numpy.triu_indices(\n            n=n_targets, m=n_sources, k=int(not match_between)\n        )\n\n    mp = pulp.LpProblem(\"optimal-neargraph\", sense=pulp.LpMinimize)\n    # a match is as binary decision variable, connecting observation i to observation j\n    match_vars = pulp.LpVariable.dicts(\n        \"match\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        cat=\"Continuous\" if allow_partial_match else \"Binary\",\n    )\n    # we want to minimize the geographic distance of links in the graph\n    mp.objective = pulp.lpSum(\n        [\n            match_vars[i, j] * distance_matrix[i, j]\n            for i, j in zip(row, col, strict=True)\n        ]\n    )\n\n    # for each observation\n    for j in range(n_targets):\n        # there must be exactly k other matched observations, which might live\n        if match_between:\n            summand = pulp.lpSum(\n                [\n                    # over the whole match matrix\n                    match_vars[j, i]\n                    for i in range(n_sources)\n                ]\n            )\n            sense = 1\n        else:\n            summand = pulp.lpSum(\n                [\n                    # in the \"upper\" triangle, or \"lower\" triangle\n                    match_vars.get((i, j), match_vars.get((j, i)))\n                    for i in range(n_sources)\n                    if (i != j)\n                ]\n            )\n            sense = int(not allow_partial_match)\n        mp += pulp.LpConstraint(summand, sense=sense, rhs=n_matches)\n    if match_between:  # but, we may choose to ignore some sources\n        for i in range(n_sources):\n            summand = pulp.lpSum([match_vars[j, i] for j in range(n_targets)])\n            mp += pulp.LpConstraint(summand, sense=-1, rhs=n_matches)\n\n    status = mp.solve(solver)\n\n    if (status != 1) & (not allow_partial_match):\n        warnings.warn(\n            f\"Problem is {pulp.LpStatus[status]}, so edge weights may be non-integer!\",\n            stacklevel=2,\n        )\n\n    edges = [\n        (*key, value.value()) for key, value in match_vars.items() if value.value() > 0\n    ]\n    if not match_between:\n        edges.extend([(*tuple(reversed(edge[:-1])), edge[-1]) for edge in edges])\n\n    heads, tails, weights = map(numpy.asarray, zip(*sorted(edges), strict=True))\n\n    if return_mip:\n        return x_ids[heads], y_ids[tails], weights, mp\n    return x_ids[heads], y_ids[tails], weights", "completions": ["  ```\n    match_vars = pulp.LpVariable.dicts(\n        \"match\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a weight is a continuous decision variable, connecting observation i to observation j\n    weight_vars = pulp.LpVariable.dicts(\n        \"weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n        upBound=1,\n        indices=zip(row, col, strict=True),\n    )\n    # a total weight is a continuous decision variable, connecting observation i to all observations j\n    total_weight_vars = pulp.LpVariable.dicts(\n        \"total_weight\",\n        lowBound=0,\n"]}
{"id": 40, "name": "load", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport logging\nimport multiprocessing\nimport time\nfrom contextlib import closing\nfrom functools import partial\nfrom itertools import chain\nfrom multiprocessing.pool import Pool\nfrom typing import List, Optional, Tuple, Union\nfrom uuid import uuid1\n\nimport joblib\nimport numpy as np\nfrom scipy.sparse import coo_matrix\nfrom tqdm import tqdm\n\nfrom .dictionary import Dictionary, Entity\nfrom .dump_db import DumpDB\n\nlogger = logging.getLogger(__name__)\n\n\nclass LinkGraph:\n    def __init__(\n        self, dictionary: Dictionary, indices: np.ndarray, indptr: np.ndarray, build_params: dict, uuid: str = \"\"\n    ):\n        self.uuid = uuid\n        self.build_params = build_params\n        self._dictionary = dictionary\n        self._indptr = indptr\n        self._indices = indices\n\n        self._offset = self._dictionary.entity_offset\n\n    def neighbors(self, item: Entity) -> List[Entity]:\n        return [self._dictionary.get_entity_by_index(i) for i in self.neighbor_indices(item.index).tolist()]\n\n    def neighbor_indices(self, index: int) -> np.ndarray:\n        index -= self._offset\n        return self._indices[self._indptr[index] : self._indptr[index + 1]]\n\n    def serialize(self, shared_array: bool = False) -> dict:\n        if shared_array:\n            indices = multiprocessing.RawArray(\"i\", len(self._indices))\n            indptr = multiprocessing.RawArray(\"i\", len(self._indptr))\n\n            indices[:] = self._indices\n            indptr[:] = self._indptr\n        else:\n            indices = np.asarray(self._indices, dtype=np.int32)\n            indptr = np.asarray(self._indptr, dtype=np.int32)\n\n        return dict(indices=indices, indptr=indptr, build_params=self.build_params, uuid=self.uuid)\n\n    def save(self, out_file: str):\n        joblib.dump(self.serialize(), out_file)\n\n    @staticmethod\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function loads a link graph from a specified target, which can be either a string or a dictionary.\n\nArgs:\n    target (Union[str, dict]): The target to load the link graph from. If it's a string, it's assumed to be a file path and the function will attempt to load it using joblib. If it's a dictionary, it's assumed to be the loaded data.\n    dictionary (Dictionary): The dictionary to compare against the one used to build the link graph.\n    mmap (bool, optional): Whether to use memory mapping when loading the target. Defaults to True.\n\nReturns:\n    LinkGraph: The loaded link graph.\n\nRaises:\n    RuntimeError: If the specified dictionary is different from the one used to build this link graph.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n    def load(target: Union[str, dict], dictionary: Dictionary, mmap: bool = True) -> \"LinkGraph\":\n        if not isinstance(target, dict):\n            if mmap:\n                target = joblib.load(target, mmap_mode=\"r\")\n            else:\n                target = joblib.load(target)\n\n        if target[\"build_params\"][\"dictionary\"] != dictionary.uuid:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            raise RuntimeError(\"The specified dictionary is different from the one used to build this link graph\")\n\n        indices = target.pop(\"indices\")\n        indptr = target.pop(\"indptr\")\n        if not isinstance(indices, np.ndarray):\n            indices = np.frombuffer(indices, dtype=np.int32)\n            indptr = np.frombuffer(indptr, dtype=np.int32)\n\n        return LinkGraph(dictionary, indices, indptr, **target)", "completions": ["  \n[PYTHON]\ndef load(target: Union[str, dict], dictionary: Dictionary, mmap: bool = True) -> \"LinkGraph\":\n    if not isinstance(target, dict):\n        if mmap:\n            target = joblib.load(target, mmap_mode=\"r\")\n        else:\n            target = joblib.load(target)\n\n    if target[\"build_params\"][\"dictionary\"]!= dictionary.uuid:\n        raise RuntimeError(\"The specified dictionary is different from the one used to build this link graph.\")\n\n    return LinkGraph(dictionary, target[\"indices\"], target[\"indptr\"], target[\"build_params\"], target[\"uuid\"])\n[/PYTHON]\n"]}
{"id": 41, "name": "spherical_bessel_smooth", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom __future__ import annotations\n\nfrom functools import lru_cache\nfrom math import pi, sqrt\n\nimport sympy\nimport torch\nfrom torch import Tensor, nn\n\nimport matgl\nfrom matgl.layers._three_body import combine_sbf_shf\nfrom matgl.utils.maths import SPHERICAL_BESSEL_ROOTS, _get_lambda_func\n\n\nclass GaussianExpansion(nn.Module):\n    \"\"\"Gaussian Radial Expansion.\n\n    The bond distance is expanded to a vector of shape [m], where m is the number of Gaussian basis centers.\n    \"\"\"\n\n    def __init__(\n        self,\n        initial: float = 0.0,\n        final: float = 4.0,\n        num_centers: int = 20,\n        width: None | float = 0.5,\n    ):\n        \"\"\"\n        Args:\n            initial: Location of initial Gaussian basis center.\n            final: Location of final Gaussian basis center\n            num_centers: Number of Gaussian Basis functions\n            width: Width of Gaussian Basis functions.\n        \"\"\"\n        super().__init__()\n        self.centers = nn.Parameter(torch.linspace(initial, final, num_centers), requires_grad=False)  # type: ignore\n        if width is None:\n            self.width = 1.0 / torch.diff(self.centers).mean()\n        else:\n            self.width = width\n\n    def reset_parameters(self):\n        \"\"\"Reinitialize model parameters.\"\"\"\n        self.centers = nn.Parameter(self.centers, requires_grad=False)\n\n    def forward(self, bond_dists):\n        \"\"\"Expand distances.\n\n        Args:\n            bond_dists :\n                Bond (edge) distances between two atoms (nodes)\n\n        Returns:\n            A vector of expanded distance with shape [num_centers]\n        \"\"\"\n        diff = bond_dists[:, None] - self.centers[None, :]\n        return torch.exp(-self.width * (diff**2))\n\n\nclass SphericalBesselFunction(nn.Module):\n    \"\"\"Calculate the spherical Bessel function based on sympy + pytorch implementations.\"\"\"\n\n    def __init__(self, max_l: int, max_n: int = 5, cutoff: float = 5.0, smooth: bool = False):\n        \"\"\"Args:\n        max_l: int, max order (excluding l)\n        max_n: int, max number of roots used in each l\n        cutoff: float, cutoff radius\n        smooth: Whether to smooth the function.\n        \"\"\"\n        super().__init__()\n        self.max_l = max_l\n        self.max_n = max_n\n        self.register_buffer(\"cutoff\", torch.tensor(cutoff))\n        self.smooth = smooth\n        if smooth:\n            self.funcs = self._calculate_smooth_symbolic_funcs()\n        else:\n            self.funcs = self._calculate_symbolic_funcs()\n\n    @lru_cache(maxsize=128)\n    def _calculate_symbolic_funcs(self) -> list:\n        \"\"\"Spherical basis functions based on Rayleigh formula. This function\n        generates\n        symbolic formula.\n\n        Returns: list of symbolic functions\n        \"\"\"\n        x = sympy.symbols(\"x\")\n        funcs = [sympy.expand_func(sympy.functions.special.bessel.jn(i, x)) for i in range(self.max_l + 1)]\n        return [sympy.lambdify(x, func, torch) for func in funcs]\n\n    @lru_cache(maxsize=128)\n    def _calculate_smooth_symbolic_funcs(self) -> list:\n        return _get_lambda_func(max_n=self.max_n, cutoff=self.cutoff)\n\n    def forward(self, r: torch.Tensor) -> torch.Tensor:\n        \"\"\"Args:\n            r: torch.Tensor, distance tensor, 1D.\n\n        Returns:\n            torch.Tensor: [n, max_n * max_l] spherical Bessel function results\n        \"\"\"\n        if self.smooth:\n            return self._call_smooth_sbf(r)\n        return self._call_sbf(r)\n\n    def _call_smooth_sbf(self, r):\n        results = [i(r) for i in self.funcs]\n        return torch.t(torch.stack(results))\n\n    def _call_sbf(self, r):\n        r_c = r.clone()\n        r_c[r_c > self.cutoff] = self.cutoff\n        roots = SPHERICAL_BESSEL_ROOTS[: self.max_l, : self.max_n]\n        roots = roots.to(r.device)\n\n        results = []\n        factor = torch.tensor(sqrt(2.0 / self.cutoff**3))\n        factor = factor.to(r_c.device)\n        for i in range(self.max_l):\n            root = torch.tensor(roots[i])\n            func = self.funcs[i]\n            func_add1 = self.funcs[i + 1]\n            results.append(\n                func(r_c[:, None] * root[None, :] / self.cutoff) * factor / torch.abs(func_add1(root[None, :]))\n            )\n        return torch.cat(results, axis=1)\n\n    @staticmethod\n    def rbf_j0(r, cutoff: float = 5.0, max_n: int = 3):\n        \"\"\"Spherical Bessel function of order 0, ensuring the function value\n        vanishes at cutoff.\n\n        Args:\n            r: torch.Tensor pytorch tensors\n            cutoff: float, the cutoff radius\n            max_n: int max number of basis\n\n        Returns:\n            basis function expansion using first spherical Bessel function\n        \"\"\"\n        n = (torch.arange(1, max_n + 1)).type(dtype=matgl.float_th)[None, :]\n        r = r[:, None]\n        return sqrt(2.0 / cutoff) * torch.sin(n * pi / cutoff * r) / r\n\n\nclass RadialBesselFunction(nn.Module):\n    \"\"\"Zeroth order bessel function of the first kind.\n\n    Implements the proposed 1D radial basis function in terms of zeroth order bessel function of the first kind with\n    increasing number of roots and a given cutoff.\n\n    Details are given in: https://arxiv.org/abs/2003.03123\n\n    This is equivalent to SphericalBesselFunction class with max_l=1, i.e. only l=0 bessel functions), but with\n    optional learnable frequencies.\n    \"\"\"\n\n    def __init__(self, max_n: int, cutoff: float, learnable: bool = False):\n        \"\"\"\n        Args:\n            max_n: int, max number of roots (including max_n)\n            cutoff: float, cutoff radius\n            learnable: bool, whether to learn the location of roots.\n        \"\"\"\n        super().__init__()\n        self.max_n = max_n\n        self.inv_cutoff = 1 / cutoff\n        self.norm_const = (2 * self.inv_cutoff) ** 0.5\n\n        if learnable:\n            self.frequencies = torch.nn.Parameter(\n                data=torch.Tensor(pi * torch.arange(1, self.max_n + 1, dtype=matgl.float_th)),\n                requires_grad=True,\n            )\n        else:\n            self.register_buffer(\n                \"frequencies\",\n                pi * torch.arange(1, self.max_n + 1, dtype=matgl.float_th),\n            )\n\n    def forward(self, r: torch.Tensor) -> torch.Tensor:\n        r = r[:, None]  # (nEdges,1)\n        d_scaled = r * self.inv_cutoff\n        return self.norm_const * torch.sin(self.frequencies * d_scaled) / r\n\n\nclass FourierExpansion(nn.Module):\n    \"\"\"Fourier Expansion of a (periodic) scalar feature.\"\"\"\n\n    def __init__(self, max_f: int = 5, interval: float = pi, scale_factor: float = 1.0, learnable: bool = False):\n        \"\"\"Args:\n        max_f (int): the maximum frequency of the Fourier expansion.\n            Default = 5\n        interval (float): the interval of the Fourier expansion, such that functions\n            are orthonormal over [-interval, interval]. Default = pi\n        scale_factor (float): pre-factor to scale all values.\n            learnable (bool): whether to set the frequencies as learnable parameters\n            Default = False.\n        \"\"\"\n        super().__init__()\n        self.max_f = max_f\n        self.interval = interval\n        self.scale_factor = scale_factor\n        # Initialize frequencies at canonical\n        if learnable:\n            self.frequencies = torch.nn.Parameter(\n                data=torch.arange(0, max_f + 1, dtype=matgl.float_th),\n                requires_grad=True,\n            )\n        else:\n            self.register_buffer(\"frequencies\", torch.arange(0, max_f + 1, dtype=matgl.float_th))\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Expand x into cos and sin functions.\"\"\"\n        result = x.new_zeros(x.shape[0], 1 + 2 * self.max_f)\n        tmp = torch.outer(x, self.frequencies)\n        result[:, ::2] = torch.cos(tmp * pi / self.interval)\n        result[:, 1::2] = torch.sin(tmp[:, 1:] * pi / self.interval)\n        return result / self.interval * self.scale_factor\n\n\nclass SphericalHarmonicsFunction(nn.Module):\n    \"\"\"Spherical Harmonics function.\"\"\"\n\n    def __init__(self, max_l: int, use_phi: bool = True):\n        \"\"\"\n        Args:\n            max_l: int, max l (excluding l)\n            use_phi: bool, whether to use the polar angle. If not,\n            the function will compute `Y_l^0`.\n        \"\"\"\n        super().__init__()\n        self.max_l = max_l\n        self.use_phi = use_phi\n        funcs = []\n        theta, phi = sympy.symbols(\"theta phi\")\n        for lval in range(self.max_l):\n            m_list = range(-lval, lval + 1) if self.use_phi else [0]  # type: ignore\n            for m in m_list:\n                func = sympy.functions.special.spherical_harmonics.Znm(lval, m, theta, phi).expand(func=True)\n                funcs.append(func)\n        # replace all theta with cos(theta)\n        cos_theta = sympy.symbols(\"costheta\")\n        funcs = [i.subs({theta: sympy.acos(cos_theta)}) for i in funcs]\n        self.orig_funcs = [sympy.simplify(i).evalf() for i in funcs]\n        self.funcs = [sympy.lambdify([cos_theta, phi], i, [{\"conjugate\": torch.conj}, torch]) for i in self.orig_funcs]\n        self.funcs[0] = _y00\n\n    def __call__(self, cos_theta, phi=None):\n        \"\"\"Args:\n            cos_theta: Cosine of the azimuthal angle\n            phi: torch.Tensor, the polar angle.\n\n        Returns:\n            torch.Tensor: [n, m] spherical harmonic results, where n is the number\n            of angles. The column is arranged following\n            `[Y_0^0, Y_1^{-1}, Y_1^{0}, Y_1^1, Y_2^{-2}, ...]`\n        \"\"\"\n        # cos_theta = torch.tensor(cos_theta, dtype=torch.complex64)\n        # phi = torch.tensor(phi, dtype=torch.complex64)\n        return torch.stack([func(cos_theta, phi) for func in self.funcs], axis=1)\n        # results = results.type(dtype=DataType.torch_float)\n        # return results\n\n\ndef _y00(theta, phi):\n    r\"\"\"Spherical Harmonics with `l=m=0`.\n\n    ..math::\n        Y_0^0 = \\frac{1}{2} \\sqrt{\\frac{1}{\\pi}}\n\n    Args:\n        theta: torch.Tensor, the azimuthal angle\n        phi: torch.Tensor, the polar angle\n\n    Returns: `Y_0^0` results\n    \"\"\"\n    return 0.5 * torch.ones_like(theta) * sqrt(1.0 / pi)\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the spherical Bessel smooth function for a given tensor of radii.\n\nArgs:\n    r (Tensor): The tensor of radii.\n    cutoff (float, optional): The cutoff value. Defaults to 5.0.\n    max_n (int, optional): The maximum value of n. Defaults to 10.\n\nReturns:\n    Tensor: The spherical Bessel smooth function values for the given tensor of radii.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef spherical_bessel_smooth(r: Tensor, cutoff: float = 5.0, max_n: int = 10) -> Tensor:\n    n = torch.arange(max_n).type(dtype=matgl.float_th)[None, :]\n    r = r[:, None]\n    fnr = (\n        (-1) ** n\n        * sqrt(2.0)\n        * pi\n        / cutoff**1.5\n        * (n + 1)\n        * (n + 2)\n        / torch.sqrt(2 * n**2 + 6 * n + 5)\n        * (_sinc(r * (n + 1) * pi / cutoff) + _sinc(r * (n + 2) * pi / cutoff))\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    )\n    en = n**2 * (n + 2) ** 2 / (4 * (n + 1) ** 4 + 1)\n    dn = [torch.tensor(1.0)]\n    for i in range(1, max_n):\n        dn_value = 1 - en[0, i] / dn[-1]\n        dn.append(dn_value)\n    dn = torch.stack(dn)  # type: ignore\n    gn = [fnr[:, 0]]\n    for i in range(1, max_n):\n        gn_value = 1 / torch.sqrt(dn[i]) * (fnr[:, i] + torch.sqrt(en[0, i] / dn[i - 1]) * gn[-1])\n        gn.append(gn_value)\n\n    return torch.t(torch.stack(gn))", "completions": ["  \n[PYTHON]\ndef spherical_bessel_smooth(r: Tensor, cutoff: float = 5.0, max_n: int = 10) -> Tensor:\n    n = torch.arange(max_n).type(dtype=matgl.float_th)[None, :]\n    r = r[:, None]\n    fnr = (\n        (-1) ** n\n        * sqrt(2.0)\n        * pi\n        / cutoff**1.5\n        * (n + 1)\n        * (n + 2)\n        / torch.sqrt(2 * n**2 + 6 * n + 5)\n        * (_sinc(r * (n + 1) * pi / cutoff) + _sinc(r * (n + 2) * pi / cutoff))\n    )\n    return fnr\n[/PYTHON]\n"]}
{"id": 42, "name": "losses", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Facebook, Inc. and its affiliates.\nimport logging\nfrom typing import Dict, List, Tuple, Union\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom detectron2.config import configurable\nfrom detectron2.layers import ShapeSpec, batched_nms, cat, cross_entropy, nonzero_tuple\nfrom detectron2.modeling.box_regression import Box2BoxTransform, _dense_box_regression_loss\nfrom detectron2.structures import Boxes, Instances\nfrom detectron2.utils.events import get_event_storage\n\n__all__ = [\"fast_rcnn_inference\", \"FastRCNNOutputLayers\"]\n\n\nlogger = logging.getLogger(__name__)\n\n\"\"\"\nShape shorthand in this module:\n\n    N: number of images in the minibatch\n    R: number of ROIs, combined over all images, in the minibatch\n    Ri: number of ROIs in image i\n    K: number of foreground classes. E.g.,there are 80 foreground classes in COCO.\n\nNaming convention:\n\n    deltas: refers to the 4-d (dx, dy, dw, dh) deltas that parameterize the box2box\n    transform (see :class:`box_regression.Box2BoxTransform`).\n\n    pred_class_logits: predicted class scores in [-inf, +inf]; use\n        softmax(pred_class_logits) to estimate P(class).\n\n    gt_classes: ground-truth classification labels in [0, K], where [0, K) represent\n        foreground object classes and K represents the background class.\n\n    pred_proposal_deltas: predicted box2box transform deltas for transforming proposals\n        to detection box predictions.\n\n    gt_proposal_deltas: ground-truth box2box transform deltas\n\"\"\"\n\n\ndef fast_rcnn_inference(\n    boxes: List[torch.Tensor],\n    scores: List[torch.Tensor],\n    image_shapes: List[Tuple[int, int]],\n    score_thresh: float,\n    nms_thresh: float,\n    topk_per_image: int,\n):\n    \"\"\"\n    Call `fast_rcnn_inference_single_image` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 4) if doing\n            class-specific regression, or (Ri, 4) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputLayers.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputLayers.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"\n    result_per_image = [\n        fast_rcnn_inference_single_image(\n            boxes_per_image, scores_per_image, image_shape, score_thresh, nms_thresh, topk_per_image\n        )\n        for scores_per_image, boxes_per_image, image_shape in zip(scores, boxes, image_shapes)\n    ]\n    return [x[0] for x in result_per_image], [x[1] for x in result_per_image]\n\n\ndef _log_classification_stats(pred_logits, gt_classes, prefix=\"fast_rcnn\"):\n    \"\"\"\n    Log the classification metrics to EventStorage.\n\n    Args:\n        pred_logits: Rx(K+1) logits. The last column is for background class.\n        gt_classes: R labels\n    \"\"\"\n    num_instances = gt_classes.numel()\n    if num_instances == 0:\n        return\n    pred_classes = pred_logits.argmax(dim=1)\n    bg_class_ind = pred_logits.shape[1] - 1\n\n    fg_inds = (gt_classes >= 0) & (gt_classes < bg_class_ind)\n    num_fg = fg_inds.nonzero().numel()\n    fg_gt_classes = gt_classes[fg_inds]\n    fg_pred_classes = pred_classes[fg_inds]\n\n    num_false_negative = (fg_pred_classes == bg_class_ind).nonzero().numel()\n    num_accurate = (pred_classes == gt_classes).nonzero().numel()\n    fg_num_accurate = (fg_pred_classes == fg_gt_classes).nonzero().numel()\n\n    storage = get_event_storage()\n    storage.put_scalar(f\"{prefix}/cls_accuracy\", num_accurate / num_instances)\n    if num_fg > 0:\n        storage.put_scalar(f\"{prefix}/fg_cls_accuracy\", fg_num_accurate / num_fg)\n        storage.put_scalar(f\"{prefix}/false_negative\", num_false_negative / num_fg)\n\n\ndef fast_rcnn_inference_single_image(\n    boxes,\n    scores,\n    image_shape: Tuple[int, int],\n    score_thresh: float,\n    nms_thresh: float,\n    topk_per_image: int,\n):\n    \"\"\"\n    Single-image inference. Return bounding-box detection results by thresholding\n    on scores and applying non-maximum suppression (NMS).\n\n    Args:\n        Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference`, but for only one image.\n    \"\"\"\n    valid_mask = torch.isfinite(boxes).all(dim=1) & torch.isfinite(scores).all(dim=1)\n    if not valid_mask.all():\n        boxes = boxes[valid_mask]\n        scores = scores[valid_mask]\n\n    scores = scores[:, :-1]\n    num_bbox_reg_classes = boxes.shape[1] // 4\n    # Convert to Boxes to use the `clip` function ...\n    boxes = Boxes(boxes.reshape(-1, 4))\n    boxes.clip(image_shape)\n    boxes = boxes.tensor.view(-1, num_bbox_reg_classes, 4)  # R x C x 4\n\n    # 1. Filter results based on detection scores. It can make NMS more efficient\n    #    by filtering out low-confidence detections.\n    filter_mask = scores > score_thresh  # R x K\n    # R' x 2. First column contains indices of the R predictions;\n    # Second column contains indices of classes.\n    filter_inds = filter_mask.nonzero()\n    if num_bbox_reg_classes == 1:\n        boxes = boxes[filter_inds[:, 0], 0]\n    else:\n        boxes = boxes[filter_mask]\n    scores = scores[filter_mask]\n\n    # 2. Apply NMS for each class independently.\n    keep = batched_nms(boxes, scores, filter_inds[:, 1], nms_thresh)\n    if topk_per_image >= 0:\n        keep = keep[:topk_per_image]\n    boxes, scores, filter_inds = boxes[keep], scores[keep], filter_inds[keep]\n\n    result = Instances(image_shape)\n    result.pred_boxes = Boxes(boxes)\n    result.scores = scores\n    result.pred_classes = filter_inds[:, 1]\n    return result, filter_inds[:, 0]\n\n\nclass FastRCNNOutputLayers(nn.Module):\n    \"\"\"\n    Two linear layers for predicting Fast R-CNN outputs:\n\n    1. proposal-to-detection box regression deltas\n    2. classification scores\n    \"\"\"\n\n    @configurable\n    def __init__(\n        self,\n        input_shape: ShapeSpec,\n        *,\n        box2box_transform,\n        num_classes: int,\n        test_score_thresh: float = 0.0,\n        test_nms_thresh: float = 0.5,\n        test_topk_per_image: int = 100,\n        cls_agnostic_bbox_reg: bool = False,\n        smooth_l1_beta: float = 0.0,\n        box_reg_loss_type: str = \"smooth_l1\",\n        loss_weight: Union[float, Dict[str, float]] = 1.0,\n    ):\n        \"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature to this module\n            box2box_transform (Box2BoxTransform or Box2BoxTransformRotated):\n            num_classes (int): number of foreground classes\n            test_score_thresh (float): threshold to filter predictions results.\n            test_nms_thresh (float): NMS threshold for prediction results.\n            test_topk_per_image (int): number of top predictions to produce per image.\n            cls_agnostic_bbox_reg (bool): whether to use class agnostic for bbox regression\n            smooth_l1_beta (float): transition point from L1 to L2 loss. Only used if\n                `box_reg_loss_type` is \"smooth_l1\"\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\",\n                \"diou\", \"ciou\"\n            loss_weight (float|dict): weights to use for losses. Can be single float for weighting\n                all losses, or a dict of individual weightings. Valid dict keys are:\n                    * \"loss_cls\": applied to classification loss\n                    * \"loss_box_reg\": applied to box regression loss\n        \"\"\"\n        super().__init__()\n        if isinstance(input_shape, int):  # some backward compatibility\n            input_shape = ShapeSpec(channels=input_shape)\n        self.num_classes = num_classes\n        input_size = input_shape.channels * (input_shape.width or 1) * (input_shape.height or 1)\n        # prediction layer for num_classes foreground classes and one background class (hence + 1)\n        self.cls_score = nn.Linear(input_size, num_classes + 1)\n        num_bbox_reg_classes = 1 if cls_agnostic_bbox_reg else num_classes\n        box_dim = len(box2box_transform.weights)\n        self.bbox_pred = nn.Linear(input_size, num_bbox_reg_classes * box_dim)\n\n        nn.init.normal_(self.cls_score.weight, std=0.01)\n        nn.init.normal_(self.bbox_pred.weight, std=0.001)\n        for l in [self.cls_score, self.bbox_pred]:\n            nn.init.constant_(l.bias, 0)\n\n        self.box2box_transform = box2box_transform\n        self.smooth_l1_beta = smooth_l1_beta\n        self.test_score_thresh = test_score_thresh\n        self.test_nms_thresh = test_nms_thresh\n        self.test_topk_per_image = test_topk_per_image\n        self.box_reg_loss_type = box_reg_loss_type\n        if isinstance(loss_weight, float):\n            loss_weight = {\"loss_cls\": loss_weight, \"loss_box_reg\": loss_weight}\n        self.loss_weight = loss_weight\n\n    @classmethod\n    def from_config(cls, cfg, input_shape):\n        return {\n            \"input_shape\": input_shape,\n            \"box2box_transform\": Box2BoxTransform(weights=cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS),\n            # fmt: off\n            \"num_classes\"           : cfg.MODEL.ROI_HEADS.NUM_CLASSES,\n            \"cls_agnostic_bbox_reg\" : cfg.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG,\n            \"smooth_l1_beta\"        : cfg.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA,\n            \"test_score_thresh\"     : cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST,\n            \"test_nms_thresh\"       : cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST,\n            \"test_topk_per_image\"   : cfg.TEST.DETECTIONS_PER_IMAGE,\n            \"box_reg_loss_type\"     : cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE,\n            \"loss_weight\"           : {\"loss_box_reg\": cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT},\n            # fmt: on\n        }\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: per-region features of shape (N, ...) for N bounding boxes to predict.\n\n        Returns:\n            (Tensor, Tensor):\n            First tensor: shape (N,K+1), scores for each of the N box. Each row contains the\n            scores for K object categories and 1 background class.\n\n            Second tensor: bounding box regression deltas for each box. Shape is shape (N,Kx4),\n            or (N,4) for class-agnostic regression.\n        \"\"\"\n        if x.dim() > 2:\n            x = torch.flatten(x, start_dim=1)\n        scores = self.cls_score(x)\n        proposal_deltas = self.bbox_pred(x)\n        return scores, proposal_deltas\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the losses for a given set of predictions and proposals.\n\nArgs:\n    predictions (tuple): A tuple containing the scores and proposal deltas.\n    proposals (list): A list of proposal objects.\n\nReturns:\n    dict: A dictionary containing the calculated losses. The keys are 'loss_cls' and 'loss_box_reg', \n    and the values are the calculated losses.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def losses(self, predictions, proposals):\n        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals should not require gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation.\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            # Here we just use proposal_boxes as an arbitrary placeholder because its\n            # value won't be used in self.box_reg_loss().\n            gt_boxes = cat(\n                [(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals],\n                dim=0,\n            )\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4), device=proposal_deltas.device)\n\n        losses = {\n            \"loss_cls\": cross_entropy(scores, gt_classes, reduction=\"mean\"),\n            \"loss_box_reg\": self.box_reg_loss(\n                proposal_boxes, gt_boxes, proposal_deltas, gt_classes\n            ),\n        }\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}", "completions": ["  \n[PYTHON]\ndef losses(self, predictions, proposals):\n    scores, proposal_deltas = predictions\n    gt_classes = cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n    _log_classification_stats(scores, gt_classes)\n    if len(proposals):\n        proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)\n        assert not proposal_boxes.requires_grad, \"Proposals should not require gradients!\"\n        if \"gt_boxes\" in proposals[0]:\n            with torch.no_grad():\n                gt_boxes = cat([p.gt_boxes for p in proposals], dim=0)\n            regression_loss = smooth_l1_loss(\n                proposal_deltas,\n                gt_boxes - proposal_boxes,\n                reduction=\"none\",\n            )\n            regression_loss = regression_loss.sum(dim=1)\n            regression_loss = regression_loss.mean()\n        else:\n            regression_loss = 0.0\n        return {\"loss_cls\": cross_entropy(scores, gt_classes), \"loss_box_reg\": regression_loss}\n    else:\n        return {\"loss_cls\": cross_entropy(scores, gt_classes), \"loss_box_reg\": 0.0}\n[/PYTHON]\n"]}
{"id": 44, "name": "parse_form_metadata", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport email.message\nimport email.utils\nimport typing\n\nimport email_validator\n\nfrom packaging.metadata import (\n    _LIST_FIELDS,\n    _RAW_TO_EMAIL_MAPPING,\n    _STRING_FIELDS,\n    InvalidMetadata,\n    Metadata,\n    RawMetadata,\n    _parse_keywords,\n    _parse_project_urls,\n)\nfrom packaging.requirements import InvalidRequirement, Requirement\nfrom trove_classifiers import all_classifiers, deprecated_classifiers\nfrom webob.multidict import MultiDict\n\nfrom warehouse.utils import http\n\nSUPPORTED_METADATA_VERSIONS = {\"1.0\", \"1.1\", \"1.2\", \"2.0\", \"2.1\", \"2.2\", \"2.3\"}\n\n\n# Mapping of fields on a Metadata instance to any limits on the length of that\n# field. Fields without a limit will naturally be unlimited in length.\n_LENGTH_LIMITS = {\n    \"summary\": 512,\n}\n\n\nclass NoMetadataError(Exception):\n    pass\n\n\ndef parse(\n    content: bytes | None, *, form_data: MultiDict | None = None, backfill: bool = False\n) -> Metadata:\n    # We prefer to parse metadata from the content, which will typically come\n    # from extracting a METADATA or PKG-INFO file from an artifact.\n    if content is not None:\n        metadata = Metadata.from_email(content)\n    # If we have form data, then we'll fall back to parsing metadata out of that,\n    # which should only ever happen for sdists prior to Metadata 2.2.\n    elif form_data is not None:\n        metadata = parse_form_metadata(form_data)\n    # If we don't have contents or form data, then we don't have any metadata\n    # and the only thing we can do is error.\n    else:\n        raise NoMetadataError\n\n    # Validate the metadata using our custom rules, which we layer ontop of the\n    # built in rules to add PyPI specific constraints above and beyond what the\n    # core metadata requirements are.\n    _validate_metadata(metadata, backfill=backfill)\n\n    return metadata\n\n\ndef _validate_metadata(metadata: Metadata, *, backfill: bool = False):\n    # Add our own custom validations ontop of the standard validations from\n    # packaging.metadata.\n    errors: list[InvalidMetadata] = []\n\n    # We restrict the supported Metadata versions to the ones that we've implemented\n    # support for.\n    if metadata.metadata_version not in SUPPORTED_METADATA_VERSIONS:\n        errors.append(\n            InvalidMetadata(\n                \"metadata-version\",\n                f\"{metadata.metadata_version!r} is not a valid metadata version\",\n            )\n        )\n\n    # We don't allow the use of the \"local version\" field when releasing to PyPI\n    if metadata.version.local:\n        errors.append(\n            InvalidMetadata(\n                \"version\",\n                f\"The use of local versions in {metadata.version!r} is not allowed.\",\n            )\n        )\n\n    # We put length constraints on some fields in order to prevent pathological\n    # cases that don't really make sense in practice anyways.\n    #\n    # NOTE: We currently only support string fields.\n    for field, limit in _LENGTH_LIMITS.items():\n        value = getattr(metadata, field)\n        if isinstance(value, str):\n            if len(value) > limit:\n                email_name = _RAW_TO_EMAIL_MAPPING.get(field, field)\n                errors.append(\n                    InvalidMetadata(\n                        email_name,\n                        f\"{email_name!r} field must be {limit} characters or less.\",\n                    )\n                )\n\n    # We require that the author and maintainer emails, if they're provided, are\n    # valid RFC822 email addresses.\n    # TODO: Arguably this should added to packaging.metadata, as the core metadata\n    #       spec requires the use of RFC822 format for these fields, but since it\n    #       doesn't do that currently, we'll add it here.\n    #\n    #       One thing that does make it hard for packaging.metadata to do this, is\n    #       this validation isn't in the stdlib, and we use the email-validator\n    #       package to implement it.\n    for field in {\"author_email\", \"maintainer_email\"}:\n        if (addr := getattr(metadata, field)) is not None:\n            _, address = email.utils.parseaddr(addr)\n            if address:\n                try:\n                    email_validator.validate_email(address, check_deliverability=False)\n                except email_validator.EmailNotValidError as exc:\n                    errors.append(\n                        InvalidMetadata(\n                            _RAW_TO_EMAIL_MAPPING.get(field, field),\n                            f\"{address!r} is not a valid email address: {exc}\",\n                        )\n                    )\n\n    # Validate that the classifiers are valid classifiers\n    for classifier in sorted(set(metadata.classifiers or []) - set(all_classifiers)):\n        errors.append(\n            InvalidMetadata(\"classifier\", f\"{classifier!r} is not a valid classifier.\")\n        )\n\n    # Validate that no deprecated classifers are being used.\n    # NOTE: We only check this is we're not doing a backfill, because backfill\n    #       operations may legitimately use deprecated classifiers.\n    if not backfill:\n        for classifier in sorted(\n            set(metadata.classifiers or []) & deprecated_classifiers.keys()\n        ):\n            deprecated_by = deprecated_classifiers[classifier]\n            if deprecated_by:\n                errors.append(\n                    InvalidMetadata(\n                        \"classifier\",\n                        f\"The classifier {classifier!r} has been deprecated, \"\n                        f\"use one of {deprecated_by} instead.\",\n                    )\n                )\n            else:\n                errors.append(\n                    InvalidMetadata(\n                        \"classifier\",\n                        f\"The classifier {classifier!r} has been deprecated.\",\n                    )\n                )\n\n    # Validate that URL fields are actually URLs\n    # TODO: This is another one that it would be nice to lift this up to\n    #       packaging.metadata\n    for field in {\"home_page\", \"download_url\"}:\n        if (url := getattr(metadata, field)) is not None:\n            if not http.is_valid_uri(url, require_authority=False):\n                errors.append(\n                    InvalidMetadata(\n                        _RAW_TO_EMAIL_MAPPING.get(field, field),\n                        f\"{url!r} is not a valid url.\",\n                    )\n                )\n\n    # Validate the Project URL structure to ensure that we have real, valid,\n    # values for both labels and urls.\n    # TODO: Lift this up to packaging.metadata.\n    for label, url in (metadata.project_urls or {}).items():\n        if not label:\n            errors.append(InvalidMetadata(\"project-url\", \"Must have a label\"))\n        elif len(label) > 32:\n            errors.append(\n                InvalidMetadata(\n                    \"project-url\", f\"{label!r} must be 32 characters or less.\"\n                )\n            )\n        elif not url:\n            errors.append(InvalidMetadata(\"project-url\", \"Must have a URL\"))\n        elif not http.is_valid_uri(url, require_authority=False):\n            errors.append(InvalidMetadata(\"project-url\", f\"{url!r} is not a valid url\"))\n\n    # Validate that the *-Dist fields that packaging.metadata didn't validate are valid.\n    # TODO: This probably should be pulled up into packaging.metadata.\n    for field in {\"provides_dist\", \"obsoletes_dist\"}:\n        if (value := getattr(metadata, field)) is not None:\n            for req_str in value:\n                try:\n                    req = Requirement(req_str)\n                except InvalidRequirement as exc:\n                    errors.append(\n                        InvalidMetadata(\n                            _RAW_TO_EMAIL_MAPPING.get(field, field),\n                            f\"{req_str!r} is invalid: {exc}\",\n                        )\n                    )\n                else:\n                    # Validate that an URL isn't being listed.\n                    # NOTE: This part should not be lifted to packaging.metadata\n                    if req.url is not None:\n                        errors.append(\n                            InvalidMetadata(\n                                _RAW_TO_EMAIL_MAPPING.get(field, field),\n                                f\"Can't have direct dependency: {req_str!r}\",\n                            )\n                        )\n\n    # Ensure that the *-Dist fields are not referencing any direct dependencies.\n    # NOTE: Because packaging.metadata doesn't parse Provides-Dist and Obsoletes-Dist\n    #       we skip those here and check that elsewhere. However, if packaging.metadata\n    #       starts to parse those, then we can add them here.\n    for field in {\"requires_dist\"}:\n        if (value := getattr(metadata, field)) is not None:\n            for req in value:\n                if req.url is not None:\n                    errors.append(\n                        InvalidMetadata(\n                            _RAW_TO_EMAIL_MAPPING.get(field, field),\n                            f\"Can't have direct dependency: {req}\",\n                        )\n                    )\n\n    # If we've collected any errors, then raise an ExceptionGroup containing them.\n    if errors:\n        raise ExceptionGroup(\"invalid metadata\", errors)\n\n\n# Map Form fields to RawMetadata\n_override = {\n    \"platforms\": \"platform\",\n    \"supported_platforms\": \"supported_platform\",\n}\n_FORM_TO_RAW_MAPPING = {_override.get(k, k): k for k in _RAW_TO_EMAIL_MAPPING}\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to parse form metadata and convert it into a validated Metadata object.\n\nArgs:\n    data (MultiDict): The form data to be parsed.\n\nReturns:\n    Metadata: A validated Metadata object.\n\nRaises:\n    ExceptionGroup: If there are any unparsed data.\n    InvalidMetadata: If a specific field has invalid data.\n\nNotes:\n    - The function uses a mapping to convert form data into a RawMetadata object.\n    - It handles fields that are similar to the email format, where the same key can be used multiple times.\n    - It uses the getall() method to fetch data, even for fields that aren't multiple use.\n    - It treats an empty string as invalid for all fields.\n    - It parses string and list of string fields differently.\n    - It handles the 'keywords' and 'project_urls' fields with special data massaging.\n    - If there are any unparsed data, it raises an ExceptionGroup with InvalidMetadata exceptions.\n    - It casts the raw data to a Metadata object using the from_raw() method.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef parse_form_metadata(data: MultiDict) -> Metadata:\n    # We construct a RawMetdata using the form data, which we will later pass\n    # to Metadata to get a validated metadata.\n    #\n    # NOTE: Form data is very similiar to the email format where the only difference\n    #       between a list and a single value is whether or not the same key is used\n    #       multiple times. Thus we will handle things in a similiar way, always\n    #       fetching things as a list and then determining what to do based on the\n    #       field type and how many values we found.\n    #\n    #       In general, large parts of this have been taken directly from\n    #       packaging.metadata and adjusted to work with form data.\n    raw: dict[str, str | list[str] | dict[str, str]] = {}\n    unparsed: dict[str, list[str]] = {}\n\n    for name in frozenset(data.keys()):\n        # We have to be lenient in the face of \"extra\" data, because the data\n        # value here might contain unrelated form data, so we'll skip thing for\n        # fields that aren't in our list of values.\n        raw_name = _FORM_TO_RAW_MAPPING.get(name)\n        if raw_name is None:\n            continue\n\n        # We use getall() here, even for fields that aren't multiple use,\n        # because otherwise someone could have e.g. two Name fields, and we\n        # would just silently ignore it rather than doing something about it.\n        value = data.getall(name) or []\n\n        # An empty string is invalid for all fields, treat it as if it wasn't\n        # provided in the first place\n        if value == [\"\"]:\n            continue\n\n        # If this is one of our string fields, then we'll check to see if our\n        # value is a list of a single item. If it is then we'll assume that\n        # it was emitted as a single string, and unwrap the str from inside\n        # the list.\n        #\n        # If it's any other kind of data, then we haven't the faintest clue\n        # what we should parse it as, and we have to just add it to our list\n        # of unparsed stuff.\n        if raw_name in _STRING_FIELDS and len(value) == 1:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            raw[raw_name] = value[0]\n        # If this is one of our list of string fields, then we can just assign\n        # the value, since forms *only* have strings, and our getall() call\n        # above ensures that this is a list.\n        elif raw_name in _LIST_FIELDS:\n            raw[raw_name] = value\n        # Special Case: Keywords\n        # The keywords field is implemented in the metadata spec as a str,\n        # but it conceptually is a list of strings, and is serialized using\n        # \", \".join(keywords), so we'll do some light data massaging to turn\n        # this into what it logically is.\n        elif raw_name == \"keywords\" and len(value) == 1:\n            raw[raw_name] = _parse_keywords(value[0])\n        # Special Case: Project-URL\n        # The project urls is implemented in the metadata spec as a list of\n        # specially-formatted strings that represent a key and a value, which\n        # is fundamentally a mapping, however the email format doesn't support\n        # mappings in a sane way, so it was crammed into a list of strings\n        # instead.\n        #\n        # We will do a little light data massaging to turn this into a map as\n        # it logically should be.\n        elif raw_name == \"project_urls\":\n            try:\n                raw[raw_name] = _parse_project_urls(value)\n            except KeyError:\n                unparsed[name] = value\n        # Nothing that we've done has managed to parse this, so it'll just\n        # throw it in our unparseable data and move on.\n        else:\n            unparsed[name] = value\n\n    # If we have any unparsed data, then we treat that as an error\n    if unparsed:\n        raise ExceptionGroup(\n            \"unparsed\",\n            [InvalidMetadata(key, f\"{key!r} has invalid data\") for key in unparsed],\n        )\n\n    # We need to cast our `raw` to a metadata, because a TypedDict only support\n    # literal key names, but we're computing our key names on purpose, but the\n    # way this function is implemented, our `TypedDict` can only have valid key\n    # names.\n    return Metadata.from_raw(typing.cast(RawMetadata, raw))", "completions": ["  \n[PYTHON]\ndef parse_form_metadata(data: MultiDict) -> Metadata:\n    raw: dict[str, str | list[str] | dict[str, str]] = {}\n    unparsed: dict[str, list[str]] = {}\n\n    for name in frozenset(data.keys()):\n        raw_name = _FORM_TO_RAW_MAPPING.get(name)\n        if raw_name is None:\n            continue\n\n        value = data.getall(name) or []\n        if value == [\"\"]:\n            continue\n\n        if raw_name in _STRING_FIELDS and len(value) == 1:\n            value = value[0]\n\n        if raw_name in _LIST_FIELDS:\n            raw[raw_name] = value\n        else:\n            raw[raw_name] = value[0] if value else \"\"\n\n    return Metadata.from_raw(raw)\n[/PYTHON]\n"]}
{"id": 45, "name": "aggregate", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport copy\nfrom typing import List, Tuple\n\nimport numpy as np\n\nfrom metisfl.common.dtypes import MODEL_WEIGHTS_DTYPE\nfrom metisfl.controller.aggregation.aggregation import Aggregator\nfrom metisfl.controller.aggregation.tensor_ops import serialize_tensor\nfrom metisfl.proto.model_pb2 import Model\n\n\nclass FederatedAverage(Aggregator):\n    \"\"\"Federated Average Aggregation Algorithm.\"\"\"\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function aggregates a list of tuples, where each tuple contains a model and a float.\n             It then creates a new model by aggregating the tensors of the models in the list.\n\nArgs:\n    pairs (List[Tuple[Model, float]]): A list of tuples where each tuple contains a model and a float.\n\nReturns:\n    Model: The aggregated model.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n    def aggregate(self, pairs: List[Tuple[Model, float]]) -> Model:\n        \n        model = Model()\n\n        sample_model = pairs[0][0]\n        \n        if sample_model.encrypted:\n            raise RuntimeError(\"Cannot aggregate encrypted tensors using Federated Average.\")\n        \n        for tensor in sample_model.tensors:\n            model.tensors.append(copy.deepcopy(tensor))\n\n        total_tensors = len(model.tensors)\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        for var_idx in range(total_tensors):\n            var_num_values = model.tensors[var_idx].length\n\n            aggregated_tensor = np.zeros(var_num_values)\n            \n            for pair in pairs:\n                local_model = pair[0]\n                scaling_factor = pair[1]\n                local_tensor = local_model.tensors[var_idx]\n                \n                t2_r = np.frombuffer(local_tensor.value, dtype=MODEL_WEIGHTS_DTYPE) * scaling_factor\n                aggregated_tensor += t2_r\n                \n            model.tensors[var_idx].value = serialize_tensor(aggregated_tensor)\n\n        return model", "completions": ["  \n[PYTHON]\n```\n        for pair in pairs:\n            for i, tensor in enumerate(pair[0].tensors):\n                model.tensors[i] += tensor * pair[1]\n\n        return model\n```\n[/PYTHON]\n"]}
{"id": 46, "name": "_prepare_prompt", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport contextlib\nimport time\nfrom enum import IntEnum\nfrom typing import Dict, List, NamedTuple, Optional, Set, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nfrom vllm.attention import (AttentionMetadata, AttentionMetadataPerStage,\n                            get_attn_backend)\nfrom vllm.config import (DeviceConfig, LoadConfig, LoRAConfig, ModelConfig,\n                         ParallelConfig, SchedulerConfig, VisionLanguageConfig)\nfrom vllm.distributed import broadcast_tensor_dict, with_pynccl_for_all_reduce\nfrom vllm.distributed.device_communicators import (custom_all_reduce,\n                                                   pynccl_utils)\nfrom vllm.logger import init_logger\nfrom vllm.lora.layers import LoRAMapping\nfrom vllm.lora.request import LoRARequest\nfrom vllm.lora.worker_manager import LRUCacheWorkerLoRAManager\nfrom vllm.model_executor import SamplingMetadata\nfrom vllm.model_executor.model_loader import get_model\nfrom vllm.sampling_params import SamplingParams, SamplingType\nfrom vllm.sequence import (MultiModalData, SamplerOutput, SequenceData,\n                           SequenceGroupMetadata)\nfrom vllm.utils import (CudaMemoryProfiler, async_tensor_h2d, is_hip,\n                        is_pin_memory_available, make_tensor_with_pad,\n                        maybe_expand_dim)\n\nlogger = init_logger(__name__)\n\n_PAD_SLOT_ID = -1\nLORA_WARMUP_RANK = 8\n_BATCH_SIZE_ALIGNMENT = 8\n# Capture graphs for token size 1, 2, 4, 8, 16, 24, 32, 40, ..., 256.\n# NOTE: _get_graph_batch_size needs to be updated if this list is changed.\n_BATCH_SIZES_TO_CAPTURE = [1, 2, 4] + [\n    _BATCH_SIZE_ALIGNMENT * i for i in range(1, 33)\n]\n\n\nclass PreparePromptMetadata(NamedTuple):\n    input_tokens: List[int]\n    input_positions: List[int]\n    attn_metadata: Optional[AttentionMetadataPerStage]\n    prompt_lens: List[int]\n    subquery_lens: List[int]\n    lora_index_mapping: List[int]\n    lora_prompt_mapping: List[int]\n    lora_requests: Set[LoRARequest]\n    multi_modal_input: Optional[torch.Tensor]\n    slot_mapping: List[int]\n\n    @classmethod\n    def empty(cls):\n        return PreparePromptMetadata(\n            input_tokens=[],\n            input_positions=[],\n            attn_metadata=None,\n            prompt_lens=[],\n            subquery_lens=[],\n            lora_index_mapping=[],\n            lora_prompt_mapping=[],\n            lora_requests=set(),\n            multi_modal_input=None,\n            slot_mapping=[],\n        )\n\n\nclass PrepareDecodeMetadata(NamedTuple):\n    input_tokens: List[int]\n    input_positions: List[int]\n    attn_metadata: Optional[AttentionMetadata]\n    lora_index_mapping: List[int]\n    lora_prompt_mapping: List[int]\n    lora_requests: Set[LoRARequest]\n    slot_mapping: List[int]\n\n    @classmethod\n    def empty(cls):\n        return PrepareDecodeMetadata(\n            input_tokens=[],\n            input_positions=[],\n            attn_metadata=None,\n            lora_index_mapping=[],\n            lora_prompt_mapping=[],\n            lora_requests=set(),\n            slot_mapping=[],\n        )\n\n\n# How batches are constructed.\nclass BatchType(IntEnum):\n    # Every batch is prefill.\n    PREFILL = 0\n    # Every batch is decode.\n    DECODE = 1\n    # Batch is a mixture of prefill and decode.\n    MIXED = 2\n\n\nclass ModelRunner:\n\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        parallel_config: ParallelConfig,\n        scheduler_config: SchedulerConfig,\n        device_config: DeviceConfig,\n        load_config: LoadConfig,\n        lora_config: Optional[LoRAConfig],\n        kv_cache_dtype: Optional[str] = \"auto\",\n        is_driver_worker: bool = False,\n        vision_language_config: Optional[VisionLanguageConfig] = None,\n    ):\n        self.model_config = model_config\n        self.parallel_config = parallel_config\n        self.scheduler_config = scheduler_config\n        self.lora_config = lora_config\n        self.load_config = load_config\n        self.is_driver_worker = is_driver_worker\n\n        # model_config can be None in tests/samplers/test_sampler.py.\n        # FIXME(woosuk): This is a hack to make the tests work. Refactor this.\n        self.sliding_window = (model_config.get_sliding_window()\n                               if model_config is not None else None)\n        self.device_config = (device_config\n                              if device_config is not None else DeviceConfig())\n        self.device = self.device_config.device\n\n        # Set after load_model.\n        self.lora_manager: LRUCacheWorkerLoRAManager = None\n\n        self.graph_runners: Dict[int, CUDAGraphRunner] = {}\n        self.graph_memory_pool: Optional[Tuple[\n            int, int]] = None  # Set during graph capture.\n\n        self.max_context_len_to_capture = (\n            self.model_config.max_context_len_to_capture\n            if self.model_config is not None else 0)\n\n        self.pin_memory = is_pin_memory_available()\n        self.kv_cache_dtype = kv_cache_dtype\n        self.vision_language_config = vision_language_config\n\n        self.attn_backend = get_attn_backend(\n            self.model_config.dtype if model_config is not None else None)\n\n        # Lazy initialization\n        self.model: torch.nn.Module  # Set after load_model\n        self.block_size: int  # Set after initial profiling.\n        # When using CUDA graph, the input block tables must be padded to\n        # max_context_len_to_capture. However, creating the block table in\n        # Python can be expensive. To optimize this, we cache the block table\n        # in numpy and only copy the actual input content at every iteration.\n        # The shape of the cached block table will be\n        # (max batch size to capture, max context len to capture / block size).\n        self.graph_block_tables: torch.Tensor  # Set after initial profiling.\n\n    def load_model(self) -> None:\n        with CudaMemoryProfiler() as m:\n            self.model = get_model(\n                model_config=self.model_config,\n                device_config=self.device_config,\n                load_config=self.load_config,\n                lora_config=self.lora_config,\n                vision_language_config=self.vision_language_config,\n                parallel_config=self.parallel_config,\n                scheduler_config=self.scheduler_config,\n            )\n\n        self.model_memory_usage = m.consumed_memory\n        logger.info(f\"Loading model weights took \"\n                    f\"{self.model_memory_usage / float(2**30):.4f} GB\")\n\n        if self.lora_config:\n            assert hasattr(self.model, \"supported_lora_modules\"\n                           ) and self.model.supported_lora_modules, (\n                               \"Model does not support LoRA\")\n            assert hasattr(\n                self.model,\n                \"embedding_modules\"), \"Model does not have embedding_modules\"\n            assert hasattr(self.model, \"embedding_padding_modules\"\n                           ), \"Model does not have embedding_padding_modules\"\n            self.lora_manager = LRUCacheWorkerLoRAManager(\n                self.scheduler_config.max_num_seqs,\n                self.scheduler_config.max_num_batched_tokens, self.vocab_size,\n                self.lora_config, self.device, self.model.embedding_modules,\n                self.model.embedding_padding_modules)\n            self.model = self.lora_manager.create_lora_manager(self.model)\n\n        if self.kv_cache_dtype == \"fp8\" and is_hip():\n            # Currently scaled KV cache is only enabled on ROCm\n            if self.model_config.quantization_param_path is not None:\n                if callable(getattr(self.model, \"load_kv_cache_scales\", None)):\n                    self.model.load_kv_cache_scales(\n                        self.model_config.quantization_param_path)\n                else:\n                    raise RuntimeError(\"Using FP8 KV cache and scaling \"\n                                       \"factors provided but model \"\n                                       f\"{self.model.__class__} does not \"\n                                       \"support loading scaling factors.\")\n            else:\n                logger.warn(\"Using FP8 KV cache but no scaling factors \"\n                            \"provided. Defaulting to scaling factors of 1.0. \"\n                            \"This may lead to less accurate results!\")\n        elif self.model_config.quantization_param_path is not None:\n            logger.warn(\"KV cache scaling factors provided, \"\n                        \"but the KV cache data type is not FP8. \"\n                        \"KV cache scaling factors will not be used.\")\n\n    def set_block_size(self, block_size: int) -> None:\n        self.block_size = block_size\n\n        self.graph_block_tables = np.zeros(\n            (max(_BATCH_SIZES_TO_CAPTURE), self.get_max_block_per_batch()),\n            dtype=np.int32)\n\n    def get_max_block_per_batch(self) -> int:\n        block_size = self.block_size\n        return (self.max_context_len_to_capture + block_size - 1) // block_size\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function prepares prompt metadata for a sequence group.\n\nArgs:\n    self: The instance of the class that this function is a part of.\n    seq_group_metadata_list (List[SequenceGroupMetadata]): A list of sequence group metadata.\n\nReturns:\n    PreparePromptMetadata: An object containing the prepared prompt metadata.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n    def _prepare_prompt(\n        self,\n        seq_group_metadata_list: List[SequenceGroupMetadata],\n    ) -> PreparePromptMetadata:\n        input_tokens: List[int] = []\n        input_positions: List[int] = []\n        slot_mapping: List[int] = []\n        lora_index_mapping: List[int] = []\n        lora_prompt_mapping: List[int] = []\n        lora_requests: Set[LoRARequest] = set()\n\n        prompt_lens: List[int] = []\n        context_lens: List[int] = []\n        subquery_lens: List[int] = []\n        prefix_block_tables: List[List[int]] = []\n        multi_modal_input_list: List[torch.Tensor] = []\n\n        if len(seq_group_metadata_list) == 0:\n            return PreparePromptMetadata.empty()\n\n        for seq_group_metadata in seq_group_metadata_list:\n            assert seq_group_metadata.is_prompt\n            seq_ids = list(seq_group_metadata.seq_data.keys())\n            assert len(seq_ids) == 1\n            seq_id = seq_ids[0]\n\n            computed_block_nums = seq_group_metadata.computed_block_nums\n            if (self.scheduler_config is not None\n                    and self.scheduler_config.chunked_prefill_enabled\n                    and not (computed_block_nums is None\n                             or computed_block_nums == [])):\n                raise RuntimeError(\n                    \"chunked prefill cannot be used with prefix caching \"\n                    \"now.\")\n\n            token_chunk_size = seq_group_metadata.token_chunk_size\n            seq_data = seq_group_metadata.seq_data[seq_id]\n            computed_len = seq_data.get_num_computed_tokens()\n            # We should use get_len here because in case of preemption\n            # it contains output tokens.\n            prefill_end = min(seq_data.get_len(),\n                              computed_len + token_chunk_size)\n            prompt_tokens = seq_data.get_token_ids()[computed_len:prefill_end]\n            prompt_len = prefill_end\n            prompt_lens.append(prompt_len)\n\n            # NOTE: This only works for oooooooxxx style attention.\n            if computed_block_nums is not None and len(\n                    computed_block_nums) > 0 and self.sliding_window is None:\n                # Prefix is not supported with sliding_window\n                computed_len = len(computed_block_nums) * self.block_size\n                prompt_tokens = prompt_tokens[computed_len:]\n                prefix_block_tables.append(computed_block_nums)\n            elif self.scheduler_config.chunked_prefill_enabled:\n                if seq_group_metadata.block_tables is not None:\n                    # Prefill has chunked before.\n                    block_table = seq_group_metadata.block_tables[seq_id]\n                    prefix_block_tables.append(block_table)\n                else:\n                    # The first prefill.\n                    prefix_block_tables.append([])\n            else:\n                prefix_block_tables.append([])\n                # Right now, prefill start is always 0. However, this\n                # assumption can be changed once chunked prefill is introduced.\n                assert computed_len == 0\n\n            # actual prompt lens\n            context_lens.append(computed_len)\n            subquery_lens.append(prompt_len - computed_len)\n\n            input_tokens.extend(prompt_tokens)\n            # NOTE(woosuk): Here we assume that the first token in the prompt\n            # is always the first token in the sequence.\n            input_positions.extend(list(range(computed_len, prefill_end)))\n            lora_id = seq_group_metadata.lora_int_id\n\n            if lora_id > 0:\n                lora_requests.add(seq_group_metadata.lora_request)\n\n            lora_index_mapping += [lora_id] * (prompt_len - computed_len)\n            lora_prompt_mapping.extend(\n                [lora_id] *\n                (prompt_len - computed_len\n                 if seq_group_metadata.sampling_params.prompt_logprobs else 1))\n\n            if seq_group_metadata.multi_modal_data:\n                multi_modal_input_list.append(\n                    seq_group_metadata.multi_modal_data.data)\n\n            if seq_group_metadata.block_tables is None:\n                # During memory profiling, the block tables are not initialized\n                # yet. In this case, we just use a dummy slot mapping.\n                slot_mapping.extend([_PAD_SLOT_ID] * prompt_len)\n                continue\n\n            # Compute the slot mapping.\n            block_table = seq_group_metadata.block_tables[seq_id]\n            # Mask the [0, start_idx) tokens of the prompt with _PAD_SLOT_ID,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            # where start_idx is max(0, prompt_len - sliding_window).\n            # For example, if the prompt len is 10, sliding window is 8, and\n            # block size is 4, the first two tokens are masked and the slot\n            # mapping will be [-1, -1, 2, 3, 4, 5, 6, 7, 0, 1].\n            start_idx = 0\n            if self.sliding_window is not None:\n                assert computed_len == 0, (\n                    \"Prefix caching is currently not supported with \"\n                    \"sliding window attention\")\n                start_idx = max(0, prompt_len - self.sliding_window)\n\n            for i in range(computed_len, prefill_end):\n                if i < start_idx:\n                    slot_mapping.append(_PAD_SLOT_ID)\n                    continue\n\n                block_number = block_table[i // self.block_size]\n                block_offset = i % self.block_size\n                slot = block_number * self.block_size + block_offset\n                slot_mapping.append(slot)\n\n        max_subquery_len = max(subquery_lens)\n        max_prompt_len = max(prompt_lens)\n        assert max_subquery_len > 0\n\n        context_lens_tensor = torch.tensor(context_lens,\n                                           dtype=torch.int,\n                                           device=self.device)\n\n        if multi_modal_input_list:\n            assert self.vision_language_config, (\n                \"Multi-modal inputs are only supported by \"\n                \"vision language models.\")\n            multi_modal_input = torch.cat(multi_modal_input_list,\n                                          dim=0).to(self.device)\n        else:\n            multi_modal_input = None\n\n        # Prepare prefix block tables\n        max_prompt_block_table_len = max(len(t) for t in prefix_block_tables)\n        block_tables = make_tensor_with_pad(\n            prefix_block_tables,\n            max_len=max_prompt_block_table_len,\n            pad=0,\n            dtype=torch.int,\n            device=self.device,\n        )\n\n        # Query length can be shorter than key (i.e., prompt) when prefill\n        # is chunked or prefix cached.\n        subquery_lens_tensor = torch.tensor(subquery_lens,\n                                            dtype=torch.long,\n                                            device=self.device)\n        subquery_start_loc = torch.zeros(subquery_lens_tensor.shape[0] + 1,\n                                         dtype=torch.int32,\n                                         device=self.device)\n\n        prompt_lens_tensor = torch.tensor(prompt_lens,\n                                          dtype=torch.long,\n                                          device=self.device)\n        seq_start_loc = torch.zeros(prompt_lens_tensor.shape[0] + 1,\n                                    dtype=torch.int32,\n                                    device=self.device)\n\n        torch.cumsum(subquery_lens_tensor,\n                     dim=0,\n                     dtype=subquery_start_loc.dtype,\n                     out=subquery_start_loc[1:])\n\n        torch.cumsum(prompt_lens_tensor,\n                     dim=0,\n                     dtype=seq_start_loc.dtype,\n                     out=seq_start_loc[1:])\n\n        attn_metadata = self.attn_backend.make_metadata(\n            is_prompt=True,\n            prompt_lens=prompt_lens,\n            prompt_lens_tensor=prompt_lens_tensor,\n            max_subquery_len=max_subquery_len,\n            max_context_len=None,\n            max_prompt_len=max_prompt_len,\n            subquery_start_loc=subquery_start_loc,\n            seq_start_loc=seq_start_loc,\n            context_lens=context_lens_tensor,\n            block_tables=block_tables,\n            use_cuda_graph=False,\n        )\n\n        return PreparePromptMetadata(\n            input_tokens=input_tokens,\n            input_positions=input_positions,\n            attn_metadata=attn_metadata,\n            prompt_lens=prompt_lens,\n            subquery_lens=subquery_lens,\n            lora_index_mapping=lora_index_mapping,\n            lora_prompt_mapping=lora_prompt_mapping,\n            lora_requests=lora_requests,\n            multi_modal_input=multi_modal_input,\n            slot_mapping=slot_mapping,\n        )", "completions": ["  \n[PYTHON]\ndef _compute_slot_mapping(self, block_table, prompt_len):\n    slot_mapping = []\n    for i in range(prompt_len):\n        slot_id = block_table[i // self.block_size]\n        slot_mapping.append(slot_id)\n    return slot_mapping\n[/PYTHON]\n"]}
{"id": 47, "name": "create", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom typing import Callable\n\nfrom requests import adapters\nfrom urllib3 import util\n\nfrom up42.http import config\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function creates an HTTPAdapter instance with a Retry policy.\n\nArgs:\n    supply_settings (Callable[[], config.ResilienceSettings]): A callable that returns a ResilienceSettings object. Defaults to config.ResilienceSettings.\n    include_post (bool): A flag indicating whether to include POST method in the allowed methods for retries. Defaults to False.\n\nReturns:\n    adapters.HTTPAdapter: An HTTPAdapter instance with a Retry policy.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef create(\n    supply_settings: Callable[[], config.ResilienceSettings] = config.ResilienceSettings, include_post: bool = False\n) -> adapters.HTTPAdapter:\n    settings = supply_settings()\n    allowed_methods = set(util.Retry.DEFAULT_ALLOWED_METHODS)\n    if include_post:\n        allowed_methods.add(\"POST\")\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    retries = util.Retry(\n        total=settings.total,\n        backoff_factor=settings.backoff_factor,\n        status_forcelist=settings.statuses,\n        allowed_methods=allowed_methods,\n    )\n    return adapters.HTTPAdapter(max_retries=retries)", "completions": ["  \n[PYTHON]\n```\ndef create(\n    supply_settings: Callable[[], config.ResilienceSettings] = config.ResilienceSettings, include_post: bool = False\n) -> adapters.HTTPAdapter:\n    settings = supply_settings()\n    allowed_methods = set(util.Retry.DEFAULT_ALLOWED_METHODS)\n    if include_post:\n        allowed_methods.add(\"POST\")\n    return adapters.HTTPAdapter(max_retries=settings.max_retries, allowed_methods=allowed_methods)\n```\n[/PYTHON]\n"]}
{"id": 48, "name": "fit", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom __future__ import annotations\n\nimport warnings\nfrom typing import Literal\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom retentioneering.backend.tracker import (\n    collect_data_performance,\n    time_performance,\n    track,\n)\nfrom retentioneering.constants import DATETIME_UNITS\nfrom retentioneering.eventstream.types import EventstreamType\nfrom retentioneering.tooling.constants import BINS_ESTIMATORS\n\n\nclass UserLifetimeHist:\n    \"\"\"\n\n    Plot the distribution of user lifetimes. A ``users lifetime`` is the timedelta between\n    the first and the last events of the user.\n\n    Parameters\n    ----------\n    eventstream : EventstreamType\n\n    See Also\n    --------\n    .EventTimestampHist : Plot the distribution of events over time.\n    .TimedeltaHist : Plot the distribution of the time deltas between two events.\n    .Eventstream.describe : Show general eventstream statistics.\n    .Eventstream.describe_events : Show general eventstream events statistics.\n    .DropPaths : Filter user paths based on the path length, removing the paths that are shorter than the\n                               specified number of events or cut_off.\n\n    Notes\n    -----\n    See :ref:`Eventstream user guide<eventstream_user_lifetime>` for the details.\n\n    \"\"\"\n\n    __eventstream: EventstreamType\n    timedelta_unit: DATETIME_UNITS\n    log_scale: bool | tuple[bool, bool] | None\n    lower_cutoff_quantile: float | None\n    upper_cutoff_quantile: float | None\n    bins: int | Literal[BINS_ESTIMATORS]\n    bins_to_show: np.ndarray\n    values_to_plot: np.ndarray\n\n    @time_performance(\n        scope=\"user_lifetime_hist\",\n        event_name=\"init\",\n    )\n    def __init__(self, eventstream: EventstreamType) -> None:\n        self.__eventstream = eventstream\n        self.user_col = self.__eventstream.schema.user_id\n        self.event_col = self.__eventstream.schema.event_name\n        self.time_col = self.__eventstream.schema.event_timestamp\n\n        self.bins_to_show = np.array([])\n        self.values_to_plot = np.array([])\n\n    def _remove_cutoff_values(self, series: pd.Series) -> pd.Series:\n        idx = [True] * len(series)\n        if self.upper_cutoff_quantile is not None:\n            idx &= series <= series.quantile(self.upper_cutoff_quantile)\n        if self.lower_cutoff_quantile is not None:\n            idx &= series >= series.quantile(self.lower_cutoff_quantile)\n        return series[idx]\n\n    def __validate_input(\n        self,\n        log_scale: bool | tuple[bool, bool] | None = None,\n        lower_cutoff_quantile: float | None = None,\n        upper_cutoff_quantile: float | None = None,\n    ) -> tuple[tuple[bool, bool], float | None, float | None]:\n        if lower_cutoff_quantile is not None:\n            if not 0 < lower_cutoff_quantile < 1:\n                raise ValueError(\"lower_cutoff_quantile should be a fraction between 0 and 1.\")\n\n        if upper_cutoff_quantile is not None:\n            if not 0 < upper_cutoff_quantile < 1:\n                raise ValueError(\"upper_cutoff_quantile should be a fraction between 0 and 1.\")\n\n        if lower_cutoff_quantile is not None and upper_cutoff_quantile is not None:\n            if lower_cutoff_quantile > upper_cutoff_quantile:\n                warnings.warn(\"lower_cutoff_quantile exceeds upper_cutoff_quantile; no data passed to the histogram\")\n\n        if log_scale:\n            if isinstance(log_scale, bool):\n                log_scale = (log_scale, False)\n            else:\n                log_scale = log_scale\n        else:\n            log_scale = (False, False)\n\n        return log_scale, upper_cutoff_quantile, lower_cutoff_quantile\n\n    @time_performance(\n        scope=\"user_lifetime_hist\",\n        event_name=\"fit\",\n    )\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function fits a model to the data by calculating the time passed for each user and preparing the data for plotting.\n\nArgs:\n    timedelta_unit (DATETIME_UNITS): The unit of time to use for the time passed calculation.\n    log_scale (bool | tuple[bool, bool] | None): Whether to use a log scale for the plot. If a tuple, the first element is for the x-axis, the second for the y-axis.\n    lower_cutoff_quantile (float | None): The lower cutoff quantile for the data.\n    upper_cutoff_quantile (float | None): The upper cutoff quantile for the data.\n    bins (int | Literal[BINS_ESTIMATORS]): The number of bins to use for the histogram.\n\nReturns:\n    None: This function does not return anything.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def fit(\n        self,\n        timedelta_unit: DATETIME_UNITS = \"s\",\n        log_scale: bool | tuple[bool, bool] | None = None,\n        lower_cutoff_quantile: float | None = None,\n        upper_cutoff_quantile: float | None = None,\n        bins: int | Literal[BINS_ESTIMATORS] = 20,\n    ) -> None:\n        called_params = {\n            \"timedelta_unit\": timedelta_unit,\n            \"log_scale\": log_scale,\n            \"lower_cutoff_quantile\": lower_cutoff_quantile,\n            \"upper_cutoff_quantile\": upper_cutoff_quantile,\n            \"bins\": bins,\n        }\n        not_hash_values = [\"timedelta_unit\"]\n\n        self.log_scale, self.upper_cutoff_quantile, self.lower_cutoff_quantile = self.__validate_input(\n            log_scale,\n            lower_cutoff_quantile,\n            upper_cutoff_quantile,\n        )\n\n        self.timedelta_unit = timedelta_unit\n        self.bins = bins\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        data = self.__eventstream.to_dataframe(copy=True).groupby(self.user_col)[self.time_col].agg([\"min\", \"max\"])\n        data[\"time_passed\"] = data[\"max\"] - data[\"min\"]\n        values_to_plot = (data[\"time_passed\"] / np.timedelta64(1, self.timedelta_unit)).reset_index(  # type: ignore\n            drop=True\n        )\n\n        if self._remove_cutoff_values:  # type: ignore\n            values_to_plot = self._remove_cutoff_values(values_to_plot).to_numpy()\n        if self.log_scale[0]:\n            log_adjustment = np.timedelta64(100, \"ms\") / np.timedelta64(1, self.timedelta_unit)\n            values_to_plot = np.where(values_to_plot != 0, values_to_plot, values_to_plot + log_adjustment)  # type: ignore\n            bins_to_show = np.power(10, np.histogram_bin_edges(np.log10(values_to_plot), bins=self.bins))\n        else:\n            bins_to_show = np.histogram_bin_edges(values_to_plot, bins=self.bins)\n        if len(values_to_plot) == 0:\n            bins_to_show = np.array([])\n\n        self.bins_to_show = bins_to_show\n        self.values_to_plot = values_to_plot  # type: ignore\n        collect_data_performance(\n            scope=\"user_lifetime_hist\",\n            event_name=\"metadata\",\n            called_params=called_params,\n            not_hash_values=not_hash_values,\n            performance_data={},\n            eventstream_index=self.__eventstream._eventstream_index,\n        )", "completions": ["  \n[PYTHON]\ndef fit(\n        self,\n        timedelta_unit: DATETIME_UNITS = \"s\",\n        log_scale: bool | tuple[bool, bool] | None = None,\n        lower_cutoff_quantile: float | None = None,\n        upper_cutoff_quantile: float | None = None,\n        bins: int | Literal[BINS_ESTIMATORS] = 20,\n    ) -> None:\n        called_params = {\n            \"timedelta_unit\": timedelta_unit,\n            \"log_scale\": log_scale,\n            \"lower_cutoff_quantile\": lower_cutoff_quantile,\n            \"upper_cutoff_quantile\": upper_cutoff_quantile,\n            \"bins\": bins,\n        }\n        not_hash_values = [\"timedelta_unit\"]\n\n        self.log_scale, self.upper_cutoff_quantile, self.lower_cutoff_quantile = self.__validate_input(\n            log_scale,\n            lower_cutoff_quantile,\n            upper_cutoff_quantile,\n        )\n\n        self.timedelta_unit = timedelta_unit\n        self.bins = bins\n[/PYTHON]\n"]}
{"id": 49, "name": "transform_grid_cell", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom __future__ import annotations\n\nfrom typing import Callable, List, Literal, Optional, Sequence, Tuple, Union\n\nimport numpy as np\nimport numpy.typing as npt\nfrom scipy.ndimage import affine_transform\nfrom xarray import DataArray\n\nimport sisl\nfrom sisl import Geometry, Grid\nfrom sisl import _array as _a\nfrom sisl._lattice import cell_invert\n\nfrom .cell import infer_cell_axes, is_1D_cartesian, is_cartesian_unordered\n\n# from ...types import Axis, PathLike\n# from ..data_sources import DataSource\n\n\ndef get_grid_representation(\n    grid: Grid,\n    represent: Literal[\"real\", \"imag\", \"mod\", \"phase\", \"rad_phase\", \"deg_phase\"],\n) -> Grid:\n    \"\"\"Returns a representation of the grid\n\n    Parameters\n    ------------\n    grid: sisl.Grid\n        the grid for which we want return\n    represent: {\"real\", \"imag\", \"mod\", \"phase\", \"deg_phase\", \"rad_phase\"}\n        the type of representation. \"phase\" is equivalent to \"rad_phase\"\n\n    Returns\n    ------------\n    sisl.Grid\n    \"\"\"\n\n    def _func(\n        values: npt.NDArray[Union[np.int_, np.float_, np.complex_]]\n    ) -> npt.NDArray:\n        if represent == \"real\":\n            new_values = values.real\n        elif represent == \"imag\":\n            new_values = values.imag\n        elif represent == \"mod\":\n            new_values = np.absolute(values)\n        elif represent in [\"phase\", \"rad_phase\", \"deg_phase\"]:\n            new_values = np.angle(values, deg=represent.startswith(\"deg\"))\n        else:\n            raise ValueError(\n                f\"'{represent}' is not a valid value for the `represent` argument\"\n            )\n\n        return new_values\n\n    return grid.apply(_func)\n\n\ndef tile_grid(grid: Grid, nsc: Tuple[int, int, int] = (1, 1, 1)) -> Grid:\n    \"\"\"Tiles the grid\"\"\"\n    for ax, reps in enumerate(nsc):\n        grid = grid.tile(reps, ax)\n    return grid\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function transforms a grid cell using a provided affine transformation matrix.\n\nArgs:\n    grid (Grid): The input grid to be transformed.\n    cell (npt.NDArray[np.float_]): The cell of the grid. Defaults to the identity matrix.\n    output_shape (Optional[Tuple[int, int, int]]): The desired output shape. Defaults to the shape of the input grid.\n    mode (str): The mode of the affine transformation. Defaults to \"constant\".\n    order (int): The order of the affine transformation. Defaults to 1.\n    **kwargs: Additional keyword arguments to be passed to scipy's affine_transform.\n\nReturns:\n    Grid: The transformed grid.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef transform_grid_cell(\n    grid: Grid,\n    cell: npt.NDArray[np.float_] = np.eye(3),\n    output_shape: Optional[Tuple[int, int, int]] = None,\n    mode: str = \"constant\",\n    order: int = 1,\n    **kwargs,\n) -> Grid:\n    # Take the current shape of the grid if no output shape was provided\n    if output_shape is None:\n        output_shape = grid.shape\n\n    # Make sure the cell has type float\n    cell = np.asarray(cell, dtype=float)\n\n    # Get the current cell in coordinates of the destination axes\n    inv_cell = cell_invert(cell).T\n    projected_cell = grid.cell.dot(inv_cell)\n\n    # From that, infere how long will the bounding box of the cell be\n    lengths = abs(projected_cell).sum(axis=0)\n\n    # Create the transformation matrix. Since we want to control the shape\n    # of the output, we can not use grid.dcell directly, we need to modify it.\n    scales = output_shape / lengths\n    forward_t = (grid.dcell.dot(inv_cell) * scales).T\n\n    # Scipy's affine transform asks for the inverse transformation matrix, to\n    # map from output pixels to input pixels. By taking the inverse of our\n    # transformation matrix, we get exactly that.\n    tr = cell_invert(forward_t).T\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    # Calculate the offset of the image so that all points of the grid \"fall\" inside\n    # the output array.\n    # For this we just calculate the centers of the input and output images\n    center_input = 0.5 * (_a.asarrayd(grid.shape) - 1)\n    center_output = 0.5 * (_a.asarrayd(output_shape) - 1)\n\n    # And then make sure that the input center that is interpolated from the output\n    # falls in the actual input's center\n    offset = center_input - tr.dot(center_output)\n\n    # We pass all the parameters to scipy's affine_transform\n    transformed_image = affine_transform(\n        grid.grid,\n        tr,\n        order=1,\n        offset=offset,\n        output_shape=output_shape,\n        mode=mode,\n        **kwargs,\n    )\n\n    # Create a new grid with the new shape and the new cell (notice how the cell\n    # is rescaled from the input cell to fit the actual coordinates of the system)\n    new_grid = grid.__class__((1, 1, 1), lattice=cell * lengths.reshape(3, 1))\n    new_grid.grid = transformed_image\n    new_grid.geometry = grid.geometry\n    new_grid.lattice.origin = grid.origin + new_grid.dcell.dot(forward_t.dot(offset))\n\n    # Find the offset between the origin before and after the transformation\n    return new_grid", "completions": ["  \n[PYTHON]\ndef transform_grid_cell(\n    grid: Grid,\n    cell: npt.NDArray[np.float_] = np.eye(3),\n    output_shape: Optional[Tuple[int, int, int]] = None,\n    mode: str = \"constant\",\n    order: int = 1,\n    **kwargs,\n) -> Grid:\n    # Take the current shape of the grid if no output shape was provided\n    if output_shape is None:\n        output_shape = grid.shape\n\n    # Make sure the cell has type float\n    cell = np.asarray(cell, dtype=float)\n\n    # Get the current cell in coordinates of the destination axes\n    inv_cell = cell_invert(cell).T\n    projected_cell = grid.cell.dot(inv_cell)\n\n    # From that, infere how long will the bounding box of the cell be\n    lengths = abs(projected_cell).sum(axis=0)\n\n    # Create the transformation matrix. Since we want to control the shape\n    # of the output, we can not use grid.dcell directly, we need to modify it.\n    scales = output_shape / lengths\n    forward_t = (grid.dcell.dot(inv_cell) * scales).T\n\n    # Scipy's affine transform asks for the inverse transformation matrix, to\n    # map from output pixels to input pixels. By taking the inverse of our\n    # transformation matrix, we get exactly that.\n    tr = cell_invert(forward_t).T\n\n    # Apply the affine transformation to the grid\n    return affine_transform(grid, tr, output_shape=output_shape, mode=mode, order=order, **kwargs)\n[/PYTHON]\n"]}
{"id": 50, "name": "draw_dataset_dict", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport colorsys\nimport logging\nimport math\nimport numpy as np\nfrom enum import Enum, unique\nimport cv2\nimport matplotlib as mpl\nimport matplotlib.colors as mplc\nimport matplotlib.figure as mplfigure\nimport pycocotools.mask as mask_util\nimport torch\nfrom fvcore.common.file_io import PathManager\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg\nfrom PIL import Image\n\nfrom detectron2.structures import BitMasks, Boxes, BoxMode, Keypoints, PolygonMasks, RotatedBoxes\n\nfrom .colormap import random_color\n\nlogger = logging.getLogger(__name__)\n\n__all__ = [\"ColorMode\", \"VisImage\", \"Visualizer\"]\n\n\n_SMALL_OBJECT_AREA_THRESH = 1000\n_LARGE_MASK_AREA_THRESH = 120000\n_OFF_WHITE = (1.0, 1.0, 240.0 / 255)\n_BLACK = (0, 0, 0)\n_RED = (1.0, 0, 0)\n\n_KEYPOINT_THRESHOLD = 0.05\n\n\n@unique\nclass ColorMode(Enum):\n    \"\"\"\n    Enum of different color modes to use for instance visualizations.\n    \"\"\"\n\n    IMAGE = 0\n    \"\"\"\n    Picks a random color for every instance and overlay segmentations with low opacity.\n    \"\"\"\n    SEGMENTATION = 1\n    \"\"\"\n    Let instances of the same category have similar colors\n    (from metadata.thing_colors), and overlay them with\n    high opacity. This provides more attention on the quality of segmentation.\n    \"\"\"\n    IMAGE_BW = 2\n    \"\"\"\n    Same as IMAGE, but convert all areas without masks to gray-scale.\n    Only available for drawing per-instance mask predictions.\n    \"\"\"\n\n\nclass GenericMask:\n    \"\"\"\n    Attribute:\n        polygons (list[ndarray]): list[ndarray]: polygons for this mask.\n            Each ndarray has format [x, y, x, y, ...]\n        mask (ndarray): a binary mask\n    \"\"\"\n\n    def __init__(self, mask_or_polygons, height, width):\n        self._mask = self._polygons = self._has_holes = None\n        self.height = height\n        self.width = width\n\n        m = mask_or_polygons\n        if isinstance(m, dict):\n            # RLEs\n            assert \"counts\" in m and \"size\" in m\n            if isinstance(m[\"counts\"], list):  # uncompressed RLEs\n                h, w = m[\"size\"]\n                assert h == height and w == width\n                m = mask_util.frPyObjects(m, h, w)\n            self._mask = mask_util.decode(m)[:, :]\n            return\n\n        if isinstance(m, list):  # list[ndarray]\n            self._polygons = [np.asarray(x).reshape(-1) for x in m]\n            return\n\n        if isinstance(m, np.ndarray):  # assumed to be a binary mask\n            assert m.shape[1] != 2, m.shape\n            assert m.shape == (height, width), m.shape\n            self._mask = m.astype(\"uint8\")\n            return\n\n        raise ValueError(\"GenericMask cannot handle object {} of type '{}'\".format(m, type(m)))\n\n    @property\n    def mask(self):\n        if self._mask is None:\n            self._mask = self.polygons_to_mask(self._polygons)\n        return self._mask\n\n    @property\n    def polygons(self):\n        if self._polygons is None:\n            self._polygons, self._has_holes = self.mask_to_polygons(self._mask)\n        return self._polygons\n\n    @property\n    def has_holes(self):\n        if self._has_holes is None:\n            if self._mask is not None:\n                self._polygons, self._has_holes = self.mask_to_polygons(self._mask)\n            else:\n                self._has_holes = False  # if original format is polygon, does not have holes\n        return self._has_holes\n\n    def mask_to_polygons(self, mask):\n        # cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level\n        # hierarchy. External contours (boundary) of the object are placed in hierarchy-1.\n        # Internal contours (holes) are placed in hierarchy-2.\n        # cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.\n        mask = np.ascontiguousarray(mask)  # some versions of cv2 does not support incontiguous arr\n        res = cv2.findContours(mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        hierarchy = res[-1]\n        if hierarchy is None:  # empty mask\n            return [], False\n        has_holes = (hierarchy.reshape(-1, 4)[:, 3] >= 0).sum() > 0\n        res = res[-2]\n        res = [x.flatten() for x in res]\n        res = [x for x in res if len(x) >= 6]\n        return res, has_holes\n\n    def polygons_to_mask(self, polygons):\n        rle = mask_util.frPyObjects(polygons, self.height, self.width)\n        rle = mask_util.merge(rle)\n        return mask_util.decode(rle)[:, :]\n\n    def area(self):\n        return self.mask.sum()\n\n    def bbox(self):\n        p = mask_util.frPyObjects(self.polygons, self.height, self.width)\n        p = mask_util.merge(p)\n        bbox = mask_util.toBbox(p)\n        bbox[2] += bbox[0]\n        bbox[3] += bbox[1]\n        return bbox\n\n\nclass _PanopticPrediction:\n    def __init__(self, panoptic_seg, segments_info):\n        self._seg = panoptic_seg\n\n        self._sinfo = {s[\"id\"]: s for s in segments_info}  # seg id -> seg info\n        segment_ids, areas = torch.unique(panoptic_seg, sorted=True, return_counts=True)\n        areas = areas.numpy()\n        sorted_idxs = np.argsort(-areas)\n        self._seg_ids, self._seg_areas = segment_ids[sorted_idxs], areas[sorted_idxs]\n        self._seg_ids = self._seg_ids.tolist()\n        for sid, area in zip(self._seg_ids, self._seg_areas):\n            if sid in self._sinfo:\n                self._sinfo[sid][\"area\"] = float(area)\n\n    def non_empty_mask(self):\n        \"\"\"\n        Returns:\n            (H, W) array, a mask for all pixels that have a prediction\n        \"\"\"\n        empty_ids = []\n        for id in self._seg_ids:\n            if id not in self._sinfo:\n                empty_ids.append(id)\n        if len(empty_ids) == 0:\n            return np.zeros(self._seg.shape, dtype=np.uint8)\n        assert (\n            len(empty_ids) == 1\n        ), \">1 ids corresponds to no labels. This is currently not supported\"\n        return (self._seg != empty_ids[0]).numpy().astype(np.bool)\n\n    def semantic_masks(self):\n        for sid in self._seg_ids:\n            sinfo = self._sinfo.get(sid)\n            if sinfo is None or sinfo[\"isthing\"]:\n                # Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.\n                continue\n            yield (self._seg == sid).numpy().astype(np.bool), sinfo\n\n    def instance_masks(self):\n        for sid in self._seg_ids:\n            sinfo = self._sinfo.get(sid)\n            if sinfo is None or not sinfo[\"isthing\"]:\n                continue\n            mask = (self._seg == sid).numpy().astype(np.bool)\n            if mask.sum() > 0:\n                yield mask, sinfo\n\n\ndef _create_text_labels(classes, scores, class_names):\n    \"\"\"\n    Args:\n        classes (list[int] or None):\n        scores (list[float] or None):\n        class_names (list[str] or None):\n\n    Returns:\n        list[str] or None\n    \"\"\"\n    labels = None\n    if classes is not None and class_names is not None and len(class_names) > 1:\n        labels = [class_names[i] for i in classes]\n    if scores is not None:\n        if labels is None:\n            labels = [\"{:.0f}%\".format(s * 100) for s in scores]\n        else:\n            labels = [\"{} {:.0f}%\".format(l, s * 100) for l, s in zip(labels, scores)]\n    return labels\n\n\nclass VisImage:\n    def __init__(self, img, scale=1.0):\n        \"\"\"\n        Args:\n            img (ndarray): an RGB image of shape (H, W, 3).\n            scale (float): scale the input image\n        \"\"\"\n        self.img = img\n        self.scale = scale\n        self.width, self.height = img.shape[1], img.shape[0]\n        self._setup_figure(img)\n\n    def _setup_figure(self, img):\n        \"\"\"\n        Args:\n            Same as in :meth:`__init__()`.\n\n        Returns:\n            fig (matplotlib.pyplot.figure): top level container for all the image plot elements.\n            ax (matplotlib.pyplot.Axes): contains figure elements and sets the coordinate system.\n        \"\"\"\n        fig = mplfigure.Figure(frameon=False)\n        self.dpi = fig.get_dpi()\n        # add a small 1e-2 to avoid precision lost due to matplotlib's truncation\n        # (https://github.com/matplotlib/matplotlib/issues/15363)\n        fig.set_size_inches(\n            (self.width * self.scale + 1e-2) / self.dpi,\n            (self.height * self.scale + 1e-2) / self.dpi,\n        )\n        self.canvas = FigureCanvasAgg(fig)\n        # self.canvas = mpl.backends.backend_cairo.FigureCanvasCairo(fig)\n        ax = fig.add_axes([0.0, 0.0, 1.0, 1.0])\n        ax.axis(\"off\")\n        ax.set_xlim(0.0, self.width)\n        ax.set_ylim(self.height)\n\n        self.fig = fig\n        self.ax = ax\n\n    def save(self, filepath):\n        \"\"\"\n        Args:\n            filepath (str): a string that contains the absolute path, including the file name, where\n                the visualized image will be saved.\n        \"\"\"\n        if filepath.lower().endswith(\".jpg\") or filepath.lower().endswith(\".png\"):\n            # faster than matplotlib's imshow\n            cv2.imwrite(filepath, self.get_image()[:, :, ::-1])\n        else:\n            # support general formats (e.g. pdf)\n            self.ax.imshow(self.img, interpolation=\"nearest\")\n            self.fig.savefig(filepath)\n\n    def get_image(self):\n        \"\"\"\n        Returns:\n            ndarray:\n                the visualized image of shape (H, W, 3) (RGB) in uint8 type.\n                The shape is scaled w.r.t the input image using the given `scale` argument.\n        \"\"\"\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        if (self.width, self.height) != (width, height):\n            img = cv2.resize(self.img, (width, height))\n        else:\n            img = self.img\n\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        # imshow is slow. blend manually (still quite slow)\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n\n        try:\n            import numexpr as ne  # fuse them with numexpr\n\n            visualized_image = ne.evaluate(\"demo * (1 - alpha / 255.0) + rgb * (alpha / 255.0)\")\n        except ImportError:\n            alpha = alpha.astype(\"float32\") / 255.0\n            visualized_image = img * (1 - alpha) + rgb * alpha\n\n        visualized_image = visualized_image.astype(\"uint8\")\n\n        return visualized_image\n\n\nclass Visualizer:\n    def __init__(self, img_rgb, metadata, scale=1.0, instance_mode=ColorMode.IMAGE):\n        \"\"\"\n        Args:\n            img_rgb: a numpy array of shape (H, W, C), where H and W correspond to\n                the height and width of the image respectively. C is the number of\n                color channels. The image is required to be in RGB format since that\n                is a requirement of the Matplotlib library. The image is also expected\n                to be in the range [0, 255].\n            metadata (MetadataCatalog): image metadata.\n        \"\"\"\n        self.img = np.asarray(img_rgb).clip(0, 255).astype(np.uint8)\n        self.metadata = metadata\n        self.output = VisImage(self.img, scale=scale)\n        self.cpu_device = torch.device(\"cpu\")\n\n        # too small texts are useless, therefore clamp to 9\n        self._default_font_size = max(\n            np.sqrt(self.output.height * self.output.width) // 90, 10 // scale\n        )\n        self._instance_mode = instance_mode\n\n    def draw_instance_predictions(self, predictions):\n        \"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"\n        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n\n    def draw_sem_seg(self, sem_seg, area_threshold=None, alpha=0.8):\n        \"\"\"\n        Draw semantic segmentation predictions/labels.\n\n        Args:\n            sem_seg (Tensor or ndarray): the segmentation of shape (H, W).\n                Each value is the integer label of the pixel.\n            area_threshold (int): segments with less than `area_threshold` are not drawn.\n            alpha (float): the larger it is, the more opaque the segmentations are.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"\n        if isinstance(sem_seg, torch.Tensor):\n            sem_seg = sem_seg.numpy()\n        labels, areas = np.unique(sem_seg, return_counts=True)\n        sorted_idxs = np.argsort(-areas).tolist()\n        labels = labels[sorted_idxs]\n        for label in filter(lambda l: l < len(self.metadata.stuff_classes), labels):\n            try:\n                mask_color = [x / 255 for x in self.metadata.stuff_colors[label]]\n            except (AttributeError, IndexError):\n                mask_color = None\n\n            binary_mask = (sem_seg == label).astype(np.uint8)\n            text = self.metadata.stuff_classes[label]\n            self.draw_binary_mask(\n                binary_mask,\n                color=mask_color,\n                edge_color=_OFF_WHITE,\n                text=text,\n                alpha=alpha,\n                area_threshold=area_threshold,\n            )\n        return self.output\n\n    def draw_panoptic_seg_predictions(\n        self, panoptic_seg, segments_info, area_threshold=None, alpha=0.7\n    ):\n        \"\"\"\n        Draw panoptic prediction results on an image.\n\n        Args:\n            panoptic_seg (Tensor): of shape (height, width) where the values are ids for each\n                segment.\n            segments_info (list[dict]): Describe each segment in `panoptic_seg`.\n                Each dict contains keys \"id\", \"category_id\", \"isthing\".\n            area_threshold (int): stuff segments with less than `area_threshold` are not drawn.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"\n        pred = _PanopticPrediction(panoptic_seg, segments_info)\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(pred.non_empty_mask())\n\n        # draw mask for all semantic segments first i.e. \"stuff\"\n        for mask, sinfo in pred.semantic_masks():\n            category_idx = sinfo[\"category_id\"]\n            try:\n                mask_color = [x / 255 for x in self.metadata.stuff_colors[category_idx]]\n            except AttributeError:\n                mask_color = None\n\n            text = self.metadata.stuff_classes[category_idx]\n            self.draw_binary_mask(\n                mask,\n                color=mask_color,\n                edge_color=_OFF_WHITE,\n                text=text,\n                alpha=alpha,\n                area_threshold=area_threshold,\n            )\n\n        # draw mask for all instances second\n        all_instances = list(pred.instance_masks())\n        if len(all_instances) == 0:\n            return self.output\n        masks, sinfo = list(zip(*all_instances))\n        category_ids = [x[\"category_id\"] for x in sinfo]\n\n        try:\n            scores = [x[\"score\"] for x in sinfo]\n        except KeyError:\n            scores = None\n        labels = _create_text_labels(category_ids, scores, self.metadata.thing_classes)\n\n        try:\n            colors = [random_color(rgb=True, maximum=1) for k in category_ids]\n        except AttributeError:\n            colors = None\n        self.overlay_instances(masks=masks, labels=labels, assigned_colors=colors, alpha=alpha)\n\n        return self.output\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is for drawing a dataset dictionary.\n\nArgs:\n    dic (dict): A dictionary containing annotations, sem_seg, and sem_seg_file_name.\n\nReturns:\n    numpy.ndarray: The output image with drawn instances, segmentation, and semantic segmentation.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def draw_dataset_dict(self, dic):\n        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            labels = [x[\"category_id\"] for x in annos]\n            colors = None\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                ]\n            names = self.metadata.get(\"thing_classes\", None)\n            if names:\n                labels = [names[i] for i in labels]\n            labels = [\n                \"{}\".format(i) + (\"|crowd\" if a.get(\"iscrowd\", 0) else \"\")\n                for i, a in zip(labels, annos)\n            ]\n            self.overlay_instances(\n                labels=labels, boxes=boxes, masks=masks, keypoints=keypts, assigned_colors=colors\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n                sem_seg = Image.open(f)\n                sem_seg = np.asarray(sem_seg, dtype=\"uint8\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n        return self.output", "completions": ["  \n[PYTHON]\ndef draw_dataset_dict(dic):\n    annos = dic.get(\"annotations\", None)\n    if annos:\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n        else:\n            masks = None\n        if \"keypoints\" in annos[0]:\n            keypts = [x[\"keypoints\"] for x in annos]\n            keypts = np.array(keypts).reshape(len(annos), -1, 3)\n        else:\n            keypts = None\n\n        boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n        labels = [x[\"category_id\"] for x in annos]\n        colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels\n            ]\n        else:\n            colors = [self._jitter([x / 255 for x in self.metadata.stuff_colors[c]]) for c in labels]\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypts,\n            assigned_colors=colors,\n        )\n\n    sem_seg = dic.get(\"sem_seg\", None)\n    if sem_seg is None and \"sem_seg_file_name\" in dic:\n        with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n            sem_seg = Image.open(f)\n            sem_seg = np.asarray(sem_seg)\n\n    if sem_seg is not None:\n        self.draw_sem_seg(sem_seg, area_threshold=1, alpha=0.5)\n\n    return self.output\n[/PYTHON]\n"]}
{"id": 51, "name": "clip", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nimport math\nfrom typing import Iterator, Union\nimport torch\n\nfrom detectron2.layers.rotated_boxes import pairwise_iou_rotated\n\nfrom .boxes import Boxes\n\n\nclass RotatedBoxes(Boxes):\n    \"\"\"\n    This structure stores a list of rotated boxes as a Nx5 torch.Tensor.\n    It supports some common methods about boxes\n    (`area`, `clip`, `nonempty`, etc),\n    and also behaves like a Tensor\n    (support indexing, `to(device)`, `.device`, and iteration over all boxes)\n    \"\"\"\n\n    def __init__(self, tensor: torch.Tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor[float]): a Nx5 matrix.  Each row is\n                (x_center, y_center, width, height, angle),\n                in which angle is represented in degrees.\n                While there's no strict range restriction for it,\n                the recommended principal range is between [-180, 180) degrees.\n\n        Assume we have a horizontal box B = (x_center, y_center, width, height),\n        where width is along the x-axis and height is along the y-axis.\n        The rotated box B_rot (x_center, y_center, width, height, angle)\n        can be seen as:\n\n        1. When angle == 0:\n           B_rot == B\n        2. When angle > 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CCW;\n        3. When angle < 0:\n           B_rot is obtained by rotating B w.r.t its center by :math:`|angle|` degrees CW.\n\n        Mathematically, since the right-handed coordinate system for image space\n        is (y, x), where y is top->down and x is left->right, the 4 vertices of the\n        rotated rectangle :math:`(yr_i, xr_i)` (i = 1, 2, 3, 4) can be obtained from\n        the vertices of the horizontal rectangle (y_i, x_i) (i = 1, 2, 3, 4)\n        in the following way (:math:`\\\\theta = angle*\\\\pi/180` is the angle in radians,\n        (y_c, x_c) is the center of the rectangle):\n\n        .. math::\n\n            yr_i = \\\\cos(\\\\theta) (y_i - y_c) - \\\\sin(\\\\theta) (x_i - x_c) + y_c,\n\n            xr_i = \\\\sin(\\\\theta) (y_i - y_c) + \\\\cos(\\\\theta) (x_i - x_c) + x_c,\n\n        which is the standard rigid-body rotation transformation.\n\n        Intuitively, the angle is\n        (1) the rotation angle from y-axis in image space\n        to the height vector (top->down in the box's local coordinate system)\n        of the box in CCW, and\n        (2) the rotation angle from x-axis in image space\n        to the width vector (left->right in the box's local coordinate system)\n        of the box in CCW.\n\n        More intuitively, consider the following horizontal box ABCD represented\n        in (x1, y1, x2, y2): (3, 2, 7, 4),\n        covering the [3, 7] x [2, 4] region of the continuous coordinate system\n        which looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  |   |\n            |  D---C\n            |\n            v y\n\n        Note that each capital letter represents one 0-dimensional geometric point\n        instead of a 'square pixel' here.\n\n        In the example above, using (x, y) to represent a point we have:\n\n        .. math::\n\n            O = (0, 0), A = (3, 2), B = (7, 2), C = (7, 4), D = (3, 4)\n\n        We name vector AB = vector DC as the width vector in box's local coordinate system, and\n        vector AD = vector BC as the height vector in box's local coordinate system. Initially,\n        when angle = 0 degree, they're aligned with the positive directions of x-axis and y-axis\n        in the image space, respectively.\n\n        For better illustration, we denote the center of the box as E,\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  A---B\n            |  | E |\n            |  D---C\n            |\n            v y\n\n        where the center E = ((3+7)/2, (2+4)/2) = (5, 3).\n\n        Also,\n\n        .. math::\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Therefore, the corresponding representation for the same shape in rotated box in\n        (x_center, y_center, width, height, angle) format is:\n\n        (5, 3, 4, 2, 0),\n\n        Now, let's consider (5, 3, 4, 2, 90), which is rotated by 90 degrees\n        CCW (counter-clockwise) by definition. It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   B-C\n            |   | |\n            |   |E|\n            |   | |\n            |   A-D\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CCW with regard to E:\n        A = (4, 5), B = (4, 1), C = (6, 1), D = (6, 5)\n\n        Here, 90 degrees can be seen as the CCW angle to rotate from y-axis to\n        vector AD or vector BC (the top->down height vector in box's local coordinate system),\n        or the CCW angle to rotate from x-axis to vector AB or vector DC (the left->right\n        width vector in box's local coordinate system).\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        Next, how about (5, 3, 4, 2, -90), which is rotated by 90 degrees CW (clockwise)\n        by definition? It looks like this:\n\n        .. code:: none\n\n            O--------> x\n            |   D-A\n            |   | |\n            |   |E|\n            |   | |\n            |   C-B\n            v y\n\n        The center E is still located at the same point (5, 3), while the vertices\n        ABCD are rotated by 90 degrees CW with regard to E:\n        A = (6, 1), B = (6, 5), C = (4, 5), D = (4, 1)\n\n        .. math::\n\n            width = |AB| = |CD| = 5 - 1 = 4,\n            height = |AD| = |BC| = 6 - 4 = 2.\n\n        This covers exactly the same region as (5, 3, 4, 2, 90) does, and their IoU\n        will be 1. However, these two will generate different RoI Pooling results and\n        should not be treated as an identical box.\n\n        On the other hand, it's easy to see that (X, Y, W, H, A) is identical to\n        (X, Y, W, H, A+360N), for any integer N. For example (5, 3, 4, 2, 270) would be\n        identical to (5, 3, 4, 2, -90), because rotating the shape 270 degrees CCW is\n        equivalent to rotating the same shape 90 degrees CW.\n\n        We could rotate further to get (5, 3, 4, 2, 180), or (5, 3, 4, 2, -180):\n\n        .. code:: none\n\n            O--------> x\n            |\n            |  C---D\n            |  | E |\n            |  B---A\n            |\n            v y\n\n        .. math::\n\n            A = (7, 4), B = (3, 4), C = (3, 2), D = (7, 2),\n\n            width = |AB| = |CD| = 7 - 3 = 4,\n            height = |AD| = |BC| = 4 - 2 = 2.\n\n        Finally, this is a very inaccurate (heavily quantized) illustration of\n        how (5, 3, 4, 2, 60) looks like in case anyone wonders:\n\n        .. code:: none\n\n            O--------> x\n            |     B\\\n            |    /  C\n            |   /E /\n            |  A  /\n            |   `D\n            v y\n\n        It's still a rectangle with center of (5, 3), width of 4 and height of 2,\n        but its angle (and thus orientation) is somewhere between\n        (5, 3, 4, 2, 0) and (5, 3, 4, 2, 90).\n        \"\"\"\n        device = tensor.device if isinstance(tensor, torch.Tensor) else torch.device(\"cpu\")\n        tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n        if tensor.numel() == 0:\n            # Use reshape, so we don't end up creating a new tensor that does not depend on\n            # the inputs (and consequently confuses jit)\n            tensor = tensor.reshape((0, 5)).to(dtype=torch.float32, device=device)\n        assert tensor.dim() == 2 and tensor.size(-1) == 5, tensor.size()\n\n        self.tensor = tensor\n\n    def clone(self) -> \"RotatedBoxes\":\n        \"\"\"\n        Clone the RotatedBoxes.\n\n        Returns:\n            RotatedBoxes\n        \"\"\"\n        return RotatedBoxes(self.tensor.clone())\n\n    def to(self, device: str) -> \"RotatedBoxes\":\n        return RotatedBoxes(self.tensor.to(device))\n\n    def area(self) -> torch.Tensor:\n        \"\"\"\n        Computes the area of all the boxes.\n\n        Returns:\n            torch.Tensor: a vector with areas of each box.\n        \"\"\"\n        box = self.tensor\n        area = box[:, 2] * box[:, 3]\n        return area\n\n    def normalize_angles(self) -> None:\n        \"\"\"\n        Restrict angles to the range of [-180, 180) degrees\n        \"\"\"\n        self.tensor[:, 4] = (self.tensor[:, 4] + 180.0) % 360.0 - 180.0\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function clips bounding boxes within a given box size based on their angles.\n\nArgs:\n    self: The instance of the class containing the tensor attribute.\n    box_size (Boxes.BoxSizeType): The size of the box to clip the bounding boxes within.\n    clip_angle_threshold (float, optional): The threshold for the angles of the bounding boxes. Defaults to 1.0.\n\nReturns:\n    None: The function modifies the tensor attribute of the instance in-place.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def clip(self, box_size: Boxes.BoxSizeType, clip_angle_threshold: float = 1.0) -> None:\n        h, w = box_size\n\n        # normalize angles to be within (-180, 180] degrees\n        self.normalize_angles()\n\n        idx = torch.where(torch.abs(self.tensor[:, 4]) <= clip_angle_threshold)[0]\n\n        # convert to (x1, y1, x2, y2)\n        x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n        y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n        x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n        y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n        # clip\n        x1.clamp_(min=0, max=w)\n        y1.clamp_(min=0, max=h)\n        x2.clamp_(min=0, max=w)\n        y2.clamp_(min=0, max=h)\n\n        # convert back to (xc, yc, w, h)\n        self.tensor[idx, 0] = (x1 + x2) / 2.0\n        self.tensor[idx, 1] = (y1 + y2) / 2.0\n        # make sure widths and heights do not increase due to numerical errors\n        self.tensor[idx, 2] = torch.min(self.tensor[idx, 2], x2 - x1)\n        self.tensor[idx, 3] = torch.min(self.tensor[idx, 3], y2 - y1)", "completions": ["  \n[PYTHON]\ndef clip(self, box_size: Boxes.BoxSizeType, clip_angle_threshold: float = 1.0) -> None:\n    h, w = box_size\n\n    # normalize angles to be within (-180, 180] degrees\n    self.normalize_angles()\n\n    idx = torch.where(torch.abs(self.tensor[:, 4]) <= clip_angle_threshold)[0]\n\n    # convert to (x1, y1, x2, y2)\n    x1 = self.tensor[idx, 0] - self.tensor[idx, 2] / 2.0\n    y1 = self.tensor[idx, 1] - self.tensor[idx, 3] / 2.0\n    x2 = self.tensor[idx, 0] + self.tensor[idx, 2] / 2.0\n    y2 = self.tensor[idx, 1] + self.tensor[idx, 3] / 2.0\n\n    # clip to the given box size\n    x1 = torch.clamp(x1, min=0, max=w)\n    y1 = torch.clamp(y1, min=0, max=h)\n    x2 = torch.clamp(x2, min=0, max=w)\n    y2 = torch.clamp(y2, min=0, max=h)\n\n    # update the tensor\n    self.tensor[idx] = torch.stack([x1, y1, x2, y2, self.tensor[idx, 4]], dim=-1)\n[/PYTHON]\n"]}
{"id": 52, "name": "create_app_from_config", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom fastapi import FastAPI, HTTPException, Request\nfrom fastapi.openapi.docs import get_swagger_ui_html\nfrom fastapi.responses import FileResponse, RedirectResponse\nfrom pydantic import BaseModel\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.errors import RateLimitExceeded\nfrom slowapi.util import get_remote_address\n\nfrom mlflow.deployments.server.config import Endpoint\nfrom mlflow.deployments.server.constants import (\n    MLFLOW_DEPLOYMENTS_CRUD_ENDPOINT_BASE,\n    MLFLOW_DEPLOYMENTS_ENDPOINTS_BASE,\n    MLFLOW_DEPLOYMENTS_HEALTH_ENDPOINT,\n    MLFLOW_DEPLOYMENTS_LIMITS_BASE,\n    MLFLOW_DEPLOYMENTS_LIST_ENDPOINTS_PAGE_SIZE,\n    MLFLOW_DEPLOYMENTS_QUERY_SUFFIX,\n)\nfrom mlflow.environment_variables import (\n    MLFLOW_DEPLOYMENTS_CONFIG,\n    MLFLOW_GATEWAY_RATE_LIMITS_STORAGE_URI,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.gateway.base_models import SetLimitsModel\nfrom mlflow.gateway.config import (\n    GatewayConfig,\n    LimitsConfig,\n    Route,\n    RouteConfig,\n    RouteType,\n    _load_route_config,\n)\nfrom mlflow.gateway.constants import (\n    MLFLOW_GATEWAY_CRUD_ROUTE_BASE,\n    MLFLOW_GATEWAY_HEALTH_ENDPOINT,\n    MLFLOW_GATEWAY_LIMITS_BASE,\n    MLFLOW_GATEWAY_ROUTE_BASE,\n    MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE,\n    MLFLOW_QUERY_SUFFIX,\n)\nfrom mlflow.gateway.providers import get_provider\nfrom mlflow.gateway.schemas import chat, completions, embeddings\nfrom mlflow.gateway.utils import SearchRoutesToken, make_streaming_response\nfrom mlflow.version import VERSION\n\n\nclass GatewayAPI(FastAPI):\n    def __init__(self, config: GatewayConfig, limiter: Limiter, *args: Any, **kwargs: Any):\n        super().__init__(*args, **kwargs)\n        self.state.limiter = limiter\n        self.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n        self.dynamic_routes: Dict[str, Route] = {}\n        self.set_dynamic_routes(config, limiter)\n\n    def set_dynamic_routes(self, config: GatewayConfig, limiter: Limiter) -> None:\n        self.dynamic_routes.clear()\n        for route in config.routes:\n            self.add_api_route(\n                path=(\n                    MLFLOW_DEPLOYMENTS_ENDPOINTS_BASE + route.name + MLFLOW_DEPLOYMENTS_QUERY_SUFFIX\n                ),\n                endpoint=_route_type_to_endpoint(route, limiter, \"deployments\"),\n                methods=[\"POST\"],\n            )\n            # TODO: Remove Gateway server URLs after deprecation window elapses\n            self.add_api_route(\n                path=f\"{MLFLOW_GATEWAY_ROUTE_BASE}{route.name}{MLFLOW_QUERY_SUFFIX}\",\n                endpoint=_route_type_to_endpoint(route, limiter, \"gateway\"),\n                methods=[\"POST\"],\n                include_in_schema=False,\n            )\n            self.dynamic_routes[route.name] = route.to_route()\n\n    def get_dynamic_route(self, route_name: str) -> Optional[Route]:\n        return self.dynamic_routes.get(route_name)\n\n\ndef _create_chat_endpoint(config: RouteConfig):\n    prov = get_provider(config.model.provider)(config)\n\n    # https://slowapi.readthedocs.io/en/latest/#limitations-and-known-issues\n    async def _chat(\n        request: Request, payload: chat.RequestPayload\n    ) -> Union[chat.ResponsePayload, chat.StreamResponsePayload]:\n        if payload.stream:\n            return await make_streaming_response(prov.chat_stream(payload))\n        else:\n            return await prov.chat(payload)\n\n    return _chat\n\n\ndef _create_completions_endpoint(config: RouteConfig):\n    prov = get_provider(config.model.provider)(config)\n\n    async def _completions(\n        request: Request, payload: completions.RequestPayload\n    ) -> Union[completions.ResponsePayload, completions.StreamResponsePayload]:\n        if payload.stream:\n            return await make_streaming_response(prov.completions_stream(payload))\n        else:\n            return await prov.completions(payload)\n\n    return _completions\n\n\ndef _create_embeddings_endpoint(config: RouteConfig):\n    prov = get_provider(config.model.provider)(config)\n\n    async def _embeddings(\n        request: Request, payload: embeddings.RequestPayload\n    ) -> embeddings.ResponsePayload:\n        return await prov.embeddings(payload)\n\n    return _embeddings\n\n\nasync def _custom(request: Request):\n    return request.json()\n\n\ndef _route_type_to_endpoint(config: RouteConfig, limiter: Limiter, key: str):\n    provider_to_factory = {\n        RouteType.LLM_V1_CHAT: _create_chat_endpoint,\n        RouteType.LLM_V1_COMPLETIONS: _create_completions_endpoint,\n        RouteType.LLM_V1_EMBEDDINGS: _create_embeddings_endpoint,\n    }\n    if factory := provider_to_factory.get(config.route_type):\n        handler = factory(config)\n        if limit := config.limit:\n            limit_value = f\"{limit.calls}/{limit.renewal_period}\"\n            handler.__name__ = f\"{handler.__name__}_{config.name}_{key}\"\n            return limiter.limit(limit_value)(handler)\n        else:\n            return handler\n\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Unexpected route type {config.route_type!r} for route {config.name!r}.\",\n    )\n\n\nclass HealthResponse(BaseModel):\n    status: str\n\n\nclass ListEndpointsResponse(BaseModel):\n    endpoints: List[Endpoint]\n    next_page_token: Optional[str] = None\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"endpoints\": [\n                    {\n                        \"name\": \"openai-chat\",\n                        \"endpoint_type\": \"llm/v1/chat\",\n                        \"model\": {\n                            \"name\": \"gpt-3.5-turbo\",\n                            \"provider\": \"openai\",\n                        },\n                        \"limit\": {\"calls\": 1, \"key\": None, \"renewal_period\": \"minute\"},\n                    },\n                    {\n                        \"name\": \"anthropic-completions\",\n                        \"endpoint_type\": \"llm/v1/completions\",\n                        \"model\": {\n                            \"name\": \"claude-instant-100k\",\n                            \"provider\": \"anthropic\",\n                        },\n                    },\n                    {\n                        \"name\": \"cohere-embeddings\",\n                        \"endpoint_type\": \"llm/v1/embeddings\",\n                        \"model\": {\n                            \"name\": \"embed-english-v2.0\",\n                            \"provider\": \"cohere\",\n                        },\n                    },\n                ],\n                \"next_page_token\": \"eyJpbmRleCI6IDExfQ==\",\n            }\n        }\n\n\nclass SearchRoutesResponse(BaseModel):\n    routes: List[Route]\n    next_page_token: Optional[str] = None\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"routes\": [\n                    {\n                        \"name\": \"openai-chat\",\n                        \"route_type\": \"llm/v1/chat\",\n                        \"model\": {\n                            \"name\": \"gpt-3.5-turbo\",\n                            \"provider\": \"openai\",\n                        },\n                    },\n                    {\n                        \"name\": \"anthropic-completions\",\n                        \"route_type\": \"llm/v1/completions\",\n                        \"model\": {\n                            \"name\": \"claude-instant-100k\",\n                            \"provider\": \"anthropic\",\n                        },\n                    },\n                    {\n                        \"name\": \"cohere-embeddings\",\n                        \"route_type\": \"llm/v1/embeddings\",\n                        \"model\": {\n                            \"name\": \"embed-english-v2.0\",\n                            \"provider\": \"cohere\",\n                        },\n                    },\n                ],\n                \"next_page_token\": \"eyJpbmRleCI6IDExfQ==\",\n            }\n        }\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function creates an instance of the GatewayAPI class, which is a FastAPI application.\n\nArgs:\n    config (GatewayConfig): Configuration for the GatewayAPI instance.\n\nReturns:\n    GatewayAPI: An instance of the GatewayAPI class.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef create_app_from_config(config: GatewayConfig) -> GatewayAPI:\n    limiter = Limiter(\n        key_func=get_remote_address, storage_uri=MLFLOW_GATEWAY_RATE_LIMITS_STORAGE_URI.get()\n    )\n    app = GatewayAPI(\n        config=config,\n        limiter=limiter,\n        title=\"MLflow Deployments Server\",\n        description=\"The core deployments API for reverse proxy interface using remote inference \"\n        \"endpoints within MLflow\",\n        version=VERSION,\n        docs_url=None,\n    )\n\n    @app.get(\"/\", include_in_schema=False)\n    async def index():\n        return RedirectResponse(url=\"/docs\")\n\n    @app.get(\"/favicon.ico\", include_in_schema=False)\n    async def favicon():\n        for directory in [\"build\", \"public\"]:\n            favicon = Path(__file__).parent.parent.parent.joinpath(\n                \"server\", \"js\", directory, \"favicon.ico\"\n            )\n            if favicon.exists():\n                return FileResponse(favicon)\n        raise HTTPException(status_code=404, detail=\"favicon.ico not found\")\n\n    @app.get(\"/docs\", include_in_schema=False)\n    async def docs():\n        return get_swagger_ui_html(\n            openapi_url=\"/openapi.json\",\n            title=\"MLflow Deployments Server\",\n            swagger_favicon_url=\"/favicon.ico\",\n        )\n\n    @app.get(MLFLOW_DEPLOYMENTS_HEALTH_ENDPOINT)\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.get(MLFLOW_GATEWAY_HEALTH_ENDPOINT, include_in_schema=False)\n    async def health() -> HealthResponse:\n        return {\"status\": \"OK\"}\n\n    @app.get(MLFLOW_DEPLOYMENTS_CRUD_ENDPOINT_BASE + \"{endpoint_name}\")\n    async def get_endpoint(endpoint_name: str) -> Endpoint:\n        if matched := app.get_dynamic_route(endpoint_name):\n            return matched.to_endpoint()\n\n        raise HTTPException(\n            status_code=404,\n            detail=f\"The endpoint '{endpoint_name}' is not present or active on the server. Please \"\n            \"verify the endpoint name.\",\n        )\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.get(MLFLOW_GATEWAY_CRUD_ROUTE_BASE + \"{route_name}\", include_in_schema=False)\n    async def get_route(route_name: str) -> Route:\n        if matched := app.get_dynamic_route(route_name):\n            return matched\n\n        raise HTTPException(\n            status_code=404,\n            detail=f\"The route '{route_name}' is not present or active on the server. Please \"\n            \"verify the route name.\",\n        )\n\n    @app.get(MLFLOW_DEPLOYMENTS_CRUD_ENDPOINT_BASE)\n    async def list_endpoints(page_token: Optional[str] = None) -> ListEndpointsResponse:\n        start_idx = SearchRoutesToken.decode(page_token).index if page_token is not None else 0\n\n        end_idx = start_idx + MLFLOW_DEPLOYMENTS_LIST_ENDPOINTS_PAGE_SIZE\n        routes = list(app.dynamic_routes.values())\n        result = {\"endpoints\": [route.to_endpoint() for route in routes[start_idx:end_idx]]}\n        if len(routes[end_idx:]) > 0:\n            next_page_token = SearchRoutesToken(index=end_idx)\n            result[\"next_page_token\"] = next_page_token.encode()\n\n        return result\n\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.get(MLFLOW_GATEWAY_CRUD_ROUTE_BASE, include_in_schema=False)\n    async def search_routes(page_token: Optional[str] = None) -> SearchRoutesResponse:\n        start_idx = SearchRoutesToken.decode(page_token).index if page_token is not None else 0\n\n        end_idx = start_idx + MLFLOW_GATEWAY_SEARCH_ROUTES_PAGE_SIZE\n        routes = list(app.dynamic_routes.values())\n        result = {\"routes\": routes[start_idx:end_idx]}\n        if len(routes[end_idx:]) > 0:\n            next_page_token = SearchRoutesToken(index=end_idx)\n            result[\"next_page_token\"] = next_page_token.encode()\n\n        return result\n\n    @app.get(MLFLOW_DEPLOYMENTS_LIMITS_BASE + \"{endpoint}\")\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.get(MLFLOW_GATEWAY_LIMITS_BASE + \"{endpoint}\", include_in_schema=False)\n    async def get_limits(endpoint: str) -> LimitsConfig:\n        raise HTTPException(status_code=501, detail=\"The get_limits API is not available yet.\")\n\n    @app.post(MLFLOW_DEPLOYMENTS_LIMITS_BASE)\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.post(MLFLOW_GATEWAY_LIMITS_BASE, include_in_schema=False)\n    async def set_limits(payload: SetLimitsModel) -> LimitsConfig:\n        raise HTTPException(status_code=501, detail=\"The set_limits API is not available yet.\")\n\n    return app", "completions": ["  \n[PYTHON]\ndef create_app_from_config(config: GatewayConfig) -> GatewayAPI:\n    limiter = Limiter(\n        key_func=get_remote_address, storage_uri=MLFLOW_GATEWAY_RATE_LIMITS_STORAGE_URI.get()\n    )\n    app = GatewayAPI(\n        config=config,\n        limiter=limiter,\n        title=\"MLflow Deployments Server\",\n        description=\"The core deployments API for reverse proxy interface using remote inference \"\n        \"endpoints within MLflow\",\n        version=VERSION,\n        docs_url=None,\n    )\n\n    @app.get(\"/\", include_in_schema=False)\n    async def index():\n        return RedirectResponse(url=\"/docs\")\n\n    @app.get(\"/favicon.ico\", include_in_schema=False)\n    async def favicon():\n        for directory in [\"build\", \"public\"]:\n            favicon = Path(__file__).parent.parent.parent.joinpath(\n                \"server\", \"js\", directory, \"favicon.ico\"\n            )\n            if favicon.exists():\n                return FileResponse(favicon)\n        raise HTTPException(status_code=404, detail=\"favicon.ico not found\")\n\n    @app.get(\"/docs\", include_in_schema=False)\n    async def docs():\n        return get_swagger_ui_html(\n            openapi_url=\"/openapi.json\",\n            title=\"MLflow Deployments Server\",\n            swagger_favicon_url=\"/favicon.ico\",\n        )\n\n    @app.get(MLFLOW_DEPLOYMENTS_HEALTH_ENDPOINT)\n    # TODO: Remove Gateway server URLs after deprecation window elapses\n    @app.get(MLFLOW_GATEWAY_HEALTH_ENDPOINT, include_in_schema=False)\n    async def health() -> HealthResponse:\n        return {\"status\": \"OK\"}\n\n    @app.get(MLFLOW_DEPLOYMENTS_CRUD_ENDPOINT_BASE + \"{endpoint_name}\")\n    async def get_endpoint(endpoint_name: str) -> Endpoint:\n        if matched := app.get_dynamic_route(endpoint_name):\n            return matched.to_endpoint()\n\n        raise HTTPException(\n            status_code=404,\n            detail=f\"The endpoint '{endpoint_name}' is not present or active on the server. Please \"\n            \"verify the endpoint name.\",\n        )\n[/PYTHON]\n"]}
{"id": 53, "name": "obj_fcn_decorator", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n\n   Copyright 2014-2024 OpenEEmeter contributors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\"\"\"\n\nimport numpy as np\n\nfrom eemeter.common.utils import OoM\nfrom eemeter.common.utils import fast_std as stdev\n\n\ndef get_idx(A, B):\n    \"\"\"\n    Returns a sorted list of indices of items in A that are found in any string in B.\n\n    Parameters:\n    A (list): List of items to search for in B.\n    B (list): List of strings to search for items in A.\n\n    Returns:\n    list: Sorted list of indices of items in A that are found in any string in B.\n    \"\"\"\n\n    idx = []\n    for item in A:\n        try:\n            idx.extend([B.index(txt) for txt in B if item in txt])\n        except:\n            continue\n\n    idx.sort()\n\n    return idx\n\n\ndef no_weights_obj_fcn(X, aux_inputs):\n    \"\"\"\n    Calculates the sum of squared errors (SSE) between the model output and the observed data.\n\n    Parameters:\n        X (array-like): Input values for the model.\n        aux_inputs (tuple): A tuple containing the model function, observed data, and breakpoint indices.\n\n    Returns:\n        float: The SSE between the model output and the observed data.\n    \"\"\"\n\n    model_fcn, obs, idx_bp = aux_inputs\n\n    # flip breakpoints if they are not in the correct order\n    if (len(idx_bp) > 1) and (X[idx_bp[0]] > X[idx_bp[1]]):\n        X[idx_bp[1]], X[idx_bp[0]] = X[idx_bp[0]], X[idx_bp[1]]\n\n    model = model_fcn(X)\n    resid = model - obs\n\n    SSE = np.sum(resid**2)\n\n    return SSE\n\n\ndef model_fcn_dec(model_fcn_full, T_fit_bnds, T):\n    \"\"\"\n    Returns a function that takes only X as input and returns the output of model_fcn_full with X, T_fit_bnds, and T as inputs.\n\n    Parameters:\n    - model_fcn_full: function\n        The full model function that takes X, T_fit_bnds, and T as inputs.\n    - T_fit_bnds: tuple\n        The bounds of the temperature range.\n    - T: float\n        The temperature value.\n\n    Returns:\n    - function\n        A function that takes only X as input and returns the output of model_fcn_full with X, T_fit_bnds, and T as inputs.\n    \"\"\"\n\n    def model_fcn_X_only(X):\n        return model_fcn_full(*X, T_fit_bnds, T)\n\n    return model_fcn_X_only\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is for creating an objective function for optimization.\n\nArgs:\n    model_fcn_full (function): The full model function.\n    weight_fcn (function): The weight function.\n    TSS_fcn (function): The total sum of squares function.\n    T (array-like): The temperature array.\n    obs (array-like): The observation array.\n    settings (object): The settings object.\n    alpha (float, optional): The alpha value. Default is 2.0.\n    coef_id (list, optional): The coefficient ID list. Default is [].\n    initial_fit (bool, optional): Whether it is the initial fit. Default is True.\n\nReturns:\n    function: The objective function.\n\"\"\"\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef obj_fcn_decorator(\n    model_fcn_full,\n    weight_fcn,\n    TSS_fcn,\n    T,\n    obs,\n    settings,\n    alpha=2.0,\n    coef_id=[],\n    initial_fit=True,\n):\n\n    N = np.shape(obs)[0]\n    N_min = settings.segment_minimum_count  # N minimum for a sloped segment\n    sigma = 2.698  # 1.5 IQR\n    quantile = 0.25\n    min_weight = 0.00\n\n    T_fit_bnds = np.array([np.min(T), np.max(T)])\n    T_range = T_fit_bnds[1] - T_fit_bnds[0]\n\n    model_fcn = model_fcn_dec(model_fcn_full, T_fit_bnds, T)\n\n    lasso_a = settings.regularization_percent_lasso * settings.regularization_alpha\n    ridge_a = (\n        1 - settings.regularization_percent_lasso\n    ) * settings.regularization_alpha\n\n    idx_k = get_idx([\"dd_k\"], coef_id)\n    idx_beta = get_idx([\"dd_beta\"], coef_id)\n    idx_bp = get_idx([\"dd_bp\"], coef_id)\n    # idx_reg = get_idx([\"dd_beta\", \"dd_k\"], coef_id) # drop bps and intercept from regularization\n    idx_reg = get_idx(\n        [\"dd_beta\", \"dd_k\", \"dd_bp\"], coef_id\n    )  # drop intercept from regularization\n\n    def elastic_net_penalty(X, T_sorted, obs_sorted, weight_sorted, wRMSE):\n        \"\"\"\n        Calculates the elastic net penalty for a given set of inputs. The elastic net is a regularized\n        regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.\n\n        Parameters:\n        X (array-like): The input array.\n        T_sorted (array-like): The sorted temperature array.\n        obs_sorted (array-like): The sorted observation array.\n        weight_sorted (array-like): The sorted weight array.\n        wRMSE (float): The weighted root mean squared error.\n\n        Returns:\n        penalty (float): The elastic net penalty.\n        \"\"\"\n\n        # Elastic net\n        X_enet = np.array(X).copy()\n\n        ## Scale break points ##\n        if len(idx_bp) > 0:\n            X_enet[idx_bp] = [\n                np.min(np.abs(X_enet[idx] - T_fit_bnds)) for idx in idx_bp\n            ]\n\n            if len(idx_bp) == 2:\n                X_enet[idx_bp] += (X[idx_bp][1] - X[idx_bp][0]) / 2\n\n            X_enet[idx_bp] *= wRMSE / T_range\n\n        # Find idx for regions\n        if len(idx_bp) == 2:\n            [hdd_bp, cdd_bp] = X[idx_bp]\n\n            idx_hdd = np.argwhere(T_sorted < hdd_bp).flatten()\n            idx_tidd = np.argwhere(\n                (hdd_bp <= T_sorted) & (T_sorted <= cdd_bp)\n            ).flatten()\n            idx_cdd = np.argwhere(cdd_bp < T_sorted).flatten()\n\n        elif len(idx_bp) == 1:\n            bp = X[idx_bp]\n            if X_enet[idx_beta] < 0:  # HDD_TIDD\n                idx_hdd = np.argwhere(T_sorted <= bp).flatten()\n                idx_tidd = np.argwhere(bp < T_sorted).flatten()\n                idx_cdd = np.array([])\n\n            else:\n                idx_hdd = np.array([])  # CDD_TIDD\n                idx_tidd = np.argwhere(T_sorted < bp).flatten()\n                idx_cdd = np.argwhere(bp <= T_sorted).flatten()\n\n        else:\n            idx_hdd = np.array([])\n            idx_tidd = np.arange(0, len(T_sorted))\n            idx_cdd = np.array([])\n\n        len_hdd = len(idx_hdd)\n        len_tidd = len(idx_tidd)\n        len_cdd = len(idx_cdd)\n\n        # combine tidd with hdd/cdd if cdd/hdd are large enough to get stdev\n        if (len_hdd < N_min) and (len_cdd >= N_min):\n            idx_hdd = np.hstack([idx_hdd, idx_tidd])\n        elif (len_hdd >= N_min) and (len_cdd < N_min):\n            idx_cdd = np.hstack([idx_tidd, idx_cdd])\n\n        # change to idx_hdd and idx_cdd to int arrays\n        idx_hdd = idx_hdd.astype(int)\n        idx_cdd = idx_cdd.astype(int)\n\n        ## Normalize slopes ##\n        # calculate stdevs\n        if (len(idx_bp) == 2) and (len(idx_hdd) >= N_min) and (len(idx_cdd) >= N_min):\n            N_beta = np.array([len_hdd, len_cdd])\n            T_stdev = np.array(\n                [\n                    stdev(T_sorted[idx_hdd], weights=weight_sorted[idx_hdd]),\n                    stdev(T_sorted[idx_cdd], weights=weight_sorted[idx_cdd]),\n                ]\n            )\n            obs_stdev = np.array(\n                [\n                    stdev(obs_sorted[idx_hdd], weights=weight_sorted[idx_hdd]),\n                    stdev(obs_sorted[idx_cdd], weights=weight_sorted[idx_cdd]),\n                ]\n            )\n\n        elif (len(idx_bp) == 1) and (len(idx_hdd) >= N_min):\n            N_beta = np.array([len_hdd])\n            T_stdev = stdev(T_sorted[idx_hdd], weights=weight_sorted[idx_hdd])\n            obs_stdev = stdev(obs_sorted[idx_hdd], weights=weight_sorted[idx_hdd])\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "\n        elif (len(idx_bp) == 1) and (len(idx_cdd) >= N_min):\n            N_beta = np.array([len_cdd])\n            T_stdev = stdev(T_sorted[idx_cdd], weights=weight_sorted[idx_cdd])\n            obs_stdev = stdev(obs_sorted[idx_cdd], weights=weight_sorted[idx_cdd])\n\n        else:\n            N_beta = np.array([len_tidd])\n            T_stdev = stdev(T_sorted, weights=weight_sorted)\n            obs_stdev = stdev(obs_sorted, weights=weight_sorted)\n\n        X_enet[idx_beta] *= T_stdev / obs_stdev\n\n        # add penalty to slope for not having enough datapoints\n        X_enet[idx_beta] = np.where(\n            N_beta < N_min, X_enet[idx_beta] * 1e30, X_enet[idx_beta]\n        )\n\n        ## Scale smoothing parameter ##\n        if len(idx_k) > 0:  # reducing X_enet size allows for more smoothing\n            X_enet[idx_k] = X[idx_k]\n\n            if (len(idx_k) == 2) and (np.sum(X_enet[idx_k]) > 1):\n                X_enet[idx_k] /= np.sum(X_enet[idx_k])\n\n            X_enet[idx_k] *= (\n                X_enet[idx_beta] / 2\n            )  # uncertain what to divide by, this seems to work well\n\n        X_enet = X_enet[idx_reg]\n\n        if ridge_a == 0:\n            penalty = lasso_a * np.linalg.norm(X_enet, 1)\n        else:\n            penalty = lasso_a * np.linalg.norm(X_enet, 1) + ridge_a * np.linalg.norm(\n                X_enet, 2\n            )\n\n        return penalty\n\n    def obj_fcn(X, grad=[], optimize_flag=True):\n        \"\"\"\n        Creates an objective function having the required inputs for optimization via SciPy and NLopt. If the optimize_flag is true,\n        only return the loss. If the optimize_flag is false, return the loss and the model output parameters.\n\n        Parameters:\n        - X: array-like\n            Array of coefficients.\n        - grad: array-like, optional\n            Gradient array. Default is an empty list.\n        - optimize_flag: bool, optional\n            Whether to optimize. Default is True.\n\n        Returns:\n        - obj: float\n            Objective function value.\n        \"\"\"\n        X = np.array(X)\n\n        model = model_fcn(X)\n        idx_sorted = np.argsort(T).flatten()\n        idx_initial = np.argsort(idx_sorted).flatten()\n        resid = model - obs\n\n        T_sorted = T[idx_sorted]\n        # model_sorted = model[idx_sorted]\n        obs_sorted = obs[idx_sorted]\n        resid_sorted = resid[idx_sorted]\n        weight_sorted, c, a = weight_fcn(\n            *X, T_sorted, resid_sorted, sigma, quantile, alpha, min_weight\n        )\n\n        weight = weight_sorted[idx_initial]\n        wSSE = np.sum(weight * resid**2)\n        loss = wSSE / N\n\n        if settings.regularization_alpha != 0:\n            loss += elastic_net_penalty(\n                X, T_sorted, obs_sorted, weight_sorted, np.sqrt(loss)\n            )\n\n        if optimize_flag:\n            return loss\n\n        else:\n            if (\"r_squared\" in settings.split_selection_criteria) and callable(TSS_fcn):\n                TSS = TSS_fcn(*X, T_sorted, obs_sorted)\n            else:\n                TSS = wSSE\n\n            if initial_fit:\n                jac = None\n            else:\n                eps = 10 ** (OoM(X, method=\"floor\") - 2)\n                X_lower = X - eps\n                X_upper = X + eps\n\n                # select correct finite difference scheme based on variable type and value\n                # NOTE: finite differencing was not returning great results. Looking into switching to JAX autodiff\n                fd_type = [\"central\"] * len(X)\n                for i in range(len(X)):\n                    if i in idx_k:\n                        if X_lower[i] < 0:\n                            fd_type[i] = \"forward\"\n                        elif X_upper[i] > 1:\n                            fd_type[i] = \"backward\"\n                    elif i in idx_beta:\n                        if (X[i] > 0) and (X_lower[i] < 0):\n                            fd_type[i] = \"forward\"\n                        elif (X[i] < 0) and (X_upper[i] > 0):\n                            fd_type[i] = \"backward\"\n                    elif i in idx_bp:\n                        if X_lower[i] < T_sorted[0]:\n                            fd_type[i] = \"forward\"\n                        elif X_lower[i] > T_sorted[-1]:\n                            fd_type[i] = \"backward\"\n\n                # https://stackoverflow.com/questions/70572362/compute-efficiently-hessian-matrices-in-jax\n                # hess = jit(jacfwd(jacrev(no_weights_obj_fcn), has_aux=True), has_aux=True)(X, [model_fcn, obs, idx_bp])\n                # print(hess)\n                # obj_grad_fcn = lambda X: no_weights_obj_fcn(X, [model_fcn, obs, idx_bp])\n\n                # jac = numerical_jacobian(obj_grad_fcn, X, dx=eps, fd_type=fd_type)\n                jac = None\n\n            return X, loss, TSS, T, model, weight, resid, jac, np.mean(a), c\n\n    return obj_fcn", "completions": ["  \n```\ndef elastic_net_penalty(X, T_sorted, obs_sorted, weight_sorted, wRMSE):\n    \"\"\"\n    Calculates the elastic net penalty for a given set of inputs. The elastic net is a regularized\n    regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.\n\n    Parameters:\n    X (array-like): The input array.\n    T_sorted (array-like): The sorted temperature array.\n    obs_sorted (array-like): The sorted observation array.\n    weight_sorted (array-like): The sorted weight array.\n    wRMSE (float): The weighted root mean squared error.\n\n    Returns:\n    penalty (float): The elastic net penalty.\n    \"\"\"\n\n    # Elastic net\n    X_enet = np.array(X).copy()\n\n    ## Scale break points ##\n    if len(idx_bp) > 0:\n        X_enet[idx_bp] = [\n            np.min(np.abs(X_enet[idx] - T_fit_bnds)) for idx in idx_bp\n        ]\n\n        if len(idx_bp) == 2:\n            X_enet[idx_bp] += (X[idx_bp][1] - X[idx_bp][0]) / 2\n\n        X_enet[idx_bp] *= wRMSE / T_range\n\n    # Find idx for regions\n    if len(idx_bp) == 2:\n        [hdd_bp, cdd_bp] = X[idx_bp]\n\n        idx_hdd = np.argwhere(T_sorted < hdd_bp).flatten()\n        idx_tidd = np.argwhere(\n            (hdd_bp <= T_sorted) & (T_sorted <= cdd_bp)\n        ).flatten()\n        idx_cdd = np.argwhere(cdd_bp < T_sorted).flatten()\n\n    elif len(idx_bp) == 1:\n        bp = X[idx_bp]\n        if X_enet[idx_beta] < 0:  # HDD_TIDD\n            idx_hdd = np.argwhere(T_sorted <= bp).flatten()\n            idx_tidd = np.argwhere(bp < T_sorted).flatten()\n            idx_cdd = np.array([])\n\n        else:\n            idx_hdd = np.array([])  # CDD_TIDD\n            idx_tidd = np.argwhere(T_sorted < bp).flatten()\n            idx_cdd = np.argwhere(bp <= T_sorted).flatten()\n\n    else:\n        idx_hdd = np.array([])\n        idx_tidd = np.arange(0, len(T_sorted))\n        idx_cdd = np.array([])\n\n    len_hdd = len(idx_hdd)\n    len_tidd = len(idx_tidd)\n    len_cdd = len(idx_cdd)\n\n    # combine tidd with hdd/cdd if cdd/hdd are large enough to get stdev\n    if (len_hdd < N_min) and (len_cdd >= N_min):\n        idx_hdd = np.hstack([idx_hdd, idx_tidd])\n    elif (len_hdd >= N_min) and (len_cdd < N_min):\n        idx_cdd = np.hstack([idx_tidd, idx_cdd])\n\n    # change to idx_hdd and idx_cdd to int arrays\n    idx_hdd = idx_hdd.astype(int)\n    idx_cdd = idx_cdd.astype(int)\n\n    ## Normalize slopes ##\n    # calculate stdevs\n    if (len(idx_bp) == 2) and (len(idx_hdd) >= N_min) and (len(idx_cdd) >= N_min):\n        N_beta = np.array([len_hdd, len_cdd])\n        T_stdev = np"]}
{"id": 54, "name": "_setup_cuda_device", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nfrom typing import Optional\n\nimport torch\n\n\ndef _get_local_rank() -> Optional[int]:\n    \"\"\"Function that gets the local rank from the environment.\n\n    Returns:\n        local_rank int or None if not set.\n    \"\"\"\n    local_rank = os.environ.get(\"LOCAL_RANK\")\n    if local_rank is not None:\n        local_rank = int(local_rank)\n    return local_rank\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function sets up a CUDA device for use in a distributed computing environment.\n\nArgs:\n    device (torch.device): The device to be set up. If the index is None, it will be set to the local rank.\n\nReturns:\n    torch.device: The device that has been set up.\n\nRaises:\n    RuntimeError: If the local rank is larger than the number of available GPUs.\n\nNotes:\n    This function uses the torch.cuda.set_device API to set up the CUDA device. It first checks if the device index is None, and if so, sets it to the local rank. It then checks if the device index is within the range of available GPUs, and if not, raises a RuntimeError. Finally, it sets the device and returns it.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef _setup_cuda_device(device: torch.device) -> torch.device:\n    local_rank = _get_local_rank() or 0\n    if device.index is None:\n        device = torch.device(type=\"cuda\", index=local_rank)\n\n    # Ensure index is available before setting device\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    if device.index >= torch.cuda.device_count():\n        raise RuntimeError(\n            \"The local rank is larger than the number of available GPUs.\"\n        )\n\n    torch.cuda.set_device(device)\n    return device", "completions": ["  \n[PYTHON]\ndef _setup_cuda_device(device: torch.device) -> torch.device:\n    local_rank = _get_local_rank() or 0\n    if device.index is None:\n        device = torch.device(type=\"cuda\", index=local_rank)\n\n    # Ensure index is available before setting device\n    if device.index >= torch.cuda.device_count():\n        raise RuntimeError(\"Local rank is larger than the number of available GPUs.\")\n    torch.cuda.set_device(device)\n    return device\n[/PYTHON]\n"]}
{"id": 55, "name": "to_numpy", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2021 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Utilities for converting EventSets to numpy arrays and viceversa.\"\"\"\n\nimport numpy as np\nfrom numpy import ndarray\n\nfrom typing import Dict\nfrom temporian.implementation.numpy.data.event_set import EventSet\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function converts an EventSet to a dictionary of numpy arrays.\n\nArgs:\n    evset (EventSet): The EventSet to be converted.\n    timestamp_to_datetime (bool): If True, convert Unix timestamps to datetime64[s]. Defaults to True.\n    timestamps (bool): If True, include timestamps in the output. Defaults to True.\n\nReturns:\n    Dict[str, ndarray]: A dictionary where keys are column names and values are numpy arrays.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef to_numpy(\n    evset: EventSet,\n    timestamp_to_datetime: bool = True,\n    timestamps: bool = True,\n) -> Dict[str, ndarray]:\n    timestamp_key = \"timestamp\"\n    index_names = evset.schema.index_names()\n    feature_names = evset.schema.feature_names()\n\n    column_names = index_names + feature_names\n    if timestamps:\n        column_names += [timestamp_key]\n\n    dst = {column_name: [] for column_name in column_names}\n    for index, data in evset.data.items():\n        assert isinstance(index, tuple)\n\n        if timestamps:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            # Timestamps\n            if evset.schema.is_unix_timestamp and timestamp_to_datetime:\n                dst[timestamp_key].append(\n                    data.timestamps.astype(\"datetime64[s]\")\n                )\n            else:\n                dst[timestamp_key].append(data.timestamps)\n\n        # Features\n        for feature_name, feature in zip(feature_names, data.features):\n            dst[feature_name].append(feature)\n\n        # Indexes\n        num_timestamps = len(data.timestamps)\n        for index_name, index_item in zip(index_names, index):\n            dst[index_name].append(np.repeat(index_item, num_timestamps))\n\n    dst = {k: np.concatenate(v) for k, v in dst.items()}\n    return dst", "completions": ["  \n[PYTHON]\n```\n        if timestamps:\n            dst[timestamp_key].append(data.timestamp)\n        for feature_name in feature_names:\n            dst[feature_name].append(data.features[feature_name])\n    return dst\n```\n[/PYTHON]\n"]}
{"id": 56, "name": "_get_user_settings", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Hub manager class.\"\"\"\n\nfrom typing import Optional\n\nfrom fastapi import HTTPException\nfrom jose import JWTError\nfrom jose.exceptions import ExpiredSignatureError\nfrom jose.jwt import decode, get_unverified_header\nfrom openbb_core.app.model.abstract.error import OpenBBError\nfrom openbb_core.app.model.credentials import Credentials\nfrom openbb_core.app.model.hub.features_keys import FeaturesKeys\nfrom openbb_core.app.model.hub.hub_session import HubSession\nfrom openbb_core.app.model.hub.hub_user_settings import HubUserSettings\nfrom openbb_core.app.model.profile import Profile\nfrom openbb_core.app.model.user_settings import UserSettings\nfrom openbb_core.env import Env\nfrom pydantic import SecretStr\nfrom requests import get, post, put\n\n\nclass HubService:\n    \"\"\"Hub service class.\"\"\"\n\n    TIMEOUT = 10\n\n    def __init__(\n        self,\n        session: Optional[HubSession] = None,\n        base_url: Optional[str] = None,\n    ):\n        self._base_url = base_url or Env().HUB_BACKEND\n        self._session = session\n\n    @property\n    def base_url(self) -> str:\n        \"\"\"Get base url.\"\"\"\n        return self._base_url\n\n    @property\n    def session(self) -> Optional[HubSession]:\n        \"\"\"Get session.\"\"\"\n        return self._session\n\n    def connect(\n        self,\n        email: Optional[str] = None,\n        password: Optional[str] = None,\n        pat: Optional[str] = None,\n    ) -> HubSession:\n        \"\"\"Connect to Hub.\"\"\"\n        if email and password:\n            self._session = self._get_session_from_email_password(email, password)\n            return self._session\n        if pat:\n            self._session = self._get_session_from_platform_token(pat)\n            return self._session\n        raise OpenBBError(\"Please provide 'email' and 'password' or 'pat'\")\n\n    def disconnect(self) -> bool:\n        \"\"\"Disconnect from Hub.\"\"\"\n        if self._session:\n            result = self._post_logout(self._session)\n            self._session = None\n            return result\n        raise OpenBBError(\n            \"No session found. Login or provide a 'HubSession' on initialization.\"\n        )\n\n    def push(self, user_settings: UserSettings) -> bool:\n        \"\"\"Push user settings to Hub.\"\"\"\n        if self._session:\n            if user_settings.credentials:\n                hub_user_settings = self.platform2hub(user_settings.credentials)\n                return self._put_user_settings(self._session, hub_user_settings)\n            return False\n        raise OpenBBError(\n            \"No session found. Login or provide a 'HubSession' on initialization.\"\n        )\n\n    def pull(self) -> UserSettings:\n        \"\"\"Pull user settings from Hub.\"\"\"\n        if self._session:\n            hub_user_settings = self._get_user_settings(self._session)\n            if hub_user_settings:\n                profile = Profile(\n                    hub_session=self._session,\n                )\n                credentials = self.hub2platform(hub_user_settings)\n                return UserSettings(profile=profile, credentials=credentials)\n        raise OpenBBError(\n            \"No session found. Login or provide a 'HubSession' on initialization.\"\n        )\n\n    def _get_session_from_email_password(self, email: str, password: str) -> HubSession:\n        \"\"\"Get session from email and password.\"\"\"\n        if not email:\n            raise OpenBBError(\"Email not found.\")\n\n        if not password:\n            raise OpenBBError(\"Password not found.\")\n\n        response = post(\n            url=self._base_url + \"/login\",\n            json={\n                \"email\": email,\n                \"password\": password,\n                \"remember\": True,\n            },\n            timeout=self.TIMEOUT,\n        )\n\n        if response.status_code == 200:\n            session = response.json()\n            hub_session = HubSession(\n                access_token=session.get(\"access_token\"),\n                token_type=session.get(\"token_type\"),\n                user_uuid=session.get(\"uuid\"),\n                email=session.get(\"email\"),\n                username=session.get(\"username\"),\n                primary_usage=session.get(\"primary_usage\"),\n            )\n            return hub_session\n        status_code = response.status_code\n        detail = response.json().get(\"detail\", None)\n        raise HTTPException(status_code, detail)\n\n    def _get_session_from_platform_token(self, token: str) -> HubSession:\n        \"\"\"Get session from Platform personal access token.\"\"\"\n        if not token:\n            raise OpenBBError(\"Platform personal access token not found.\")\n\n        self.check_token_expiration(token)\n\n        response = post(\n            url=self._base_url + \"/sdk/login\",\n            json={\n                \"token\": token,\n            },\n            timeout=self.TIMEOUT,\n        )\n\n        if response.status_code == 200:\n            session = response.json()\n            hub_session = HubSession(\n                access_token=session.get(\"access_token\"),\n                token_type=session.get(\"token_type\"),\n                user_uuid=session.get(\"uuid\"),\n                username=session.get(\"username\"),\n                email=session.get(\"email\"),\n                primary_usage=session.get(\"primary_usage\"),\n            )\n            return hub_session\n        status_code = response.status_code\n        detail = response.json().get(\"detail\", None)\n        raise HTTPException(status_code, detail)\n\n    def _post_logout(self, session: HubSession) -> bool:\n        \"\"\"Post logout.\"\"\"\n        access_token = session.access_token.get_secret_value()\n        token_type = session.token_type\n        authorization = f\"{token_type.title()} {access_token}\"\n\n        response = get(\n            url=self._base_url + \"/logout\",\n            headers={\"Authorization\": authorization},\n            json={\"token\": access_token},\n            timeout=self.TIMEOUT,\n        )\n\n        if response.status_code == 200:\n            result = response.json()\n            return result.get(\"success\", False)\n        status_code = response.status_code\n        result = response.json()\n        detail = result.get(\"detail\", None)\n        raise HTTPException(status_code, detail)\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function retrieves user settings from a hub session.\n\nArgs:\n    session (HubSession): An instance of HubSession containing the access token and token type.\n\nReturns:\n    HubUserSettings: An instance of HubUserSettings containing the user settings.\n\nRaises:\n    HTTPException: If the response status code is not 200, an HTTPException is raised with the status code and detail.\n\nNotes:\n    This function uses the requests.get method to send a GET request to the specified URL. The URL is constructed by concatenating the base URL of the hub with \"/terminal/user\". The authorization header is set to the token type and access token from the session. The response is then parsed as JSON and any None values are filtered out. The filtered user settings are validated and returned as an instance of HubUserSettings. If the response status code is not 200, an HTTPException is raised with the status code and detail.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def _get_user_settings(self, session: HubSession) -> HubUserSettings:\n        access_token = session.access_token.get_secret_value()\n        token_type = session.token_type\n        authorization = f\"{token_type.title()} {access_token}\"\n\n        response = get(\n            url=self._base_url + \"/terminal/user\",\n            headers={\"Authorization\": authorization},\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            timeout=self.TIMEOUT,\n        )\n        if response.status_code == 200:\n            user_settings = response.json()\n            filtered = {k: v for k, v in user_settings.items() if v is not None}\n            return HubUserSettings.model_validate(filtered)\n        status_code = response.status_code\n        detail = response.json().get(\"detail\", None)\n        raise HTTPException(status_code, detail)", "completions": ["  \n[PYTHON]\n```\ndef _get_user_settings(self, session: HubSession) -> HubUserSettings:\n    access_token = session.access_token.get_secret_value()\n    token_type = session.token_type\n    authorization = f\"{token_type.title()} {access_token}\"\n\n    response = get(\n        url=self._base_url + \"/terminal/user\",\n        headers={\"Authorization\": authorization},\n    )\n\n    if response.status_code == 200:\n        user_settings = response.json()\n        return HubUserSettings(**user_settings)\n    status_code = response.status_code\n    detail = response.json().get(\"detail\", None)\n    raise HTTPException(status_code, detail)\n```\n[/PYTHON]\n"]}
{"id": 57, "name": "get_demo_language", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\nFunctions to manage demo database.\n\nLute db comes pre-loaded with some demo data.  User can view Tutorial,\nwipe data, etc.\n\nThe db settings table contains a record, StKey = 'IsDemoData', if the\ndata is demo.\n\"\"\"\n\nimport os\nimport re\nfrom glob import glob\nimport yaml\nfrom sqlalchemy import text\n\nfrom lute.models.language import Language, LanguageDictionary\nfrom lute.models.book import Book\nfrom lute.book.stats import refresh_stats\nfrom lute.models.setting import SystemSetting\nfrom lute.db import db\nimport lute.db.management\n\n\ndef contains_demo_data():\n    \"\"\"\n    True if IsDemoData setting is present.\n    \"\"\"\n    ss = SystemSetting.get_value(\"IsDemoData\")\n    if ss is None:\n        return False\n    return True\n\n\ndef remove_flag():\n    \"\"\"\n    Remove IsDemoData setting.\n    \"\"\"\n    if not contains_demo_data():\n        raise RuntimeError(\"Can't delete non-demo data.\")\n\n    SystemSetting.delete_key(\"IsDemoData\")\n    db.session.commit()\n\n\ndef tutorial_book_id():\n    \"\"\"\n    Return the book id of the tutorial.\n    \"\"\"\n    if not contains_demo_data():\n        return None\n    sql = \"\"\"select BkID from books\n    inner join languages on LgID = BkLgID\n    where LgName = 'English' and BkTitle = 'Tutorial'\n    \"\"\"\n    r = db.session.execute(text(sql)).first()\n    if r is None:\n        return None\n    return int(r[0])\n\n\ndef delete_demo_data():\n    \"\"\"\n    If this is a demo, wipe everything.\n    \"\"\"\n    if not contains_demo_data():\n        raise RuntimeError(\"Can't delete non-demo data.\")\n    remove_flag()\n    lute.db.management.delete_all_data()\n\n\n# Loading demo data.\n\n\ndef demo_data_path():\n    \"\"\"\n    Path to the demo data yaml files.\n    \"\"\"\n    thisdir = os.path.dirname(__file__)\n    demo_dir = os.path.join(thisdir, \"demo\")\n    return os.path.abspath(demo_dir)\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function loads a language configuration from a YAML file and returns a Language object.\n\nArgs:\n    filename (str): The path to the YAML file containing the language configuration.\n\nReturns:\n    Language: A Language object with the configuration loaded from the YAML file.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef get_demo_language(filename):\n    with open(filename, \"r\", encoding=\"utf-8\") as file:\n        d = yaml.safe_load(file)\n\n    lang = Language()\n\n    def load(key, method):\n        if key in d:\n            val = d[key]\n            # Handle boolean values\n            if isinstance(val, str):\n                temp = val.lower()\n                if temp == \"true\":\n                    val = True\n                elif temp == \"false\":\n                    val = False\n            setattr(lang, method, val)\n\n    # Define mappings for fields\n    mappings = {\n        \"name\": \"name\",\n        \"show_romanization\": \"show_romanization\",\n        \"right_to_left\": \"right_to_left\",\n        \"parser_type\": \"parser_type\",\n        \"character_substitutions\": \"character_substitutions\",\n        \"split_sentences\": \"regexp_split_sentences\",\n        \"split_sentence_exceptions\": \"exceptions_split_sentences\",\n        \"word_chars\": \"word_characters\",\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    }\n\n    for key in d.keys():\n        funcname = mappings.get(key, \"\")\n        if funcname:\n            load(key, funcname)\n\n    ld_sort = 1\n    for ld_data in d[\"dictionaries\"]:\n        dtype = ld_data[\"type\"]\n        if dtype == \"embedded\":\n            dtype = \"embeddedhtml\"\n        elif dtype == \"popup\":\n            dtype = \"popuphtml\"\n        else:\n            raise ValueError(f\"Invalid dictionary type {dtype}\")\n\n        ld = LanguageDictionary()\n        # ld.language = lang -- if you do this, the dict is added twice.\n        ld.usefor = ld_data[\"for\"]\n        ld.dicttype = dtype\n        ld.dicturi = ld_data[\"url\"]\n        ld.is_active = True\n        ld.sort_order = ld_sort\n        ld_sort += 1\n        lang.dictionaries.append(ld)\n\n    return lang", "completions": ["  \n[PYTHON]\ndef get_demo_language(filename):\n    with open(filename, \"r\", encoding=\"utf-8\") as file:\n        d = yaml.safe_load(file)\n\n    lang = Language()\n\n    def load(key, method):\n        if key in d:\n            val = d[key]\n            # Handle boolean values\n            if isinstance(val, str):\n                temp = val.lower()\n                if temp == \"true\":\n                    val = True\n                elif temp == \"false\":\n                    val = False\n            setattr(lang, method, val)\n\n    # Define mappings for fields\n    mappings = {\n        \"name\": \"name\",\n        \"show_romanization\": \"show_romanization\",\n        \"right_to_left\": \"right_to_left\",\n        \"parser_type\": \"parser_type\",\n        \"character_substitutions\": \"character_substitutions\",\n        \"split_sentences\": \"regexp_split_sentences\",\n        \"split_sentence_exceptions\": \"exceptions_split_sentences\",\n        \"word_chars\": \"word_characters\",\n    }\n\n    for key, method in mappings.items():\n        load(key, method)\n\n    return lang\n[/PYTHON]\n"]}
{"id": 58, "name": "_prepare_sample", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport contextlib\nimport time\nfrom typing import Dict, List, Optional, Tuple, Set, Union\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom loguru import logger\n\nfrom aphrodite.common.config import (\n    DeviceConfig,\n    ModelConfig,\n    LoRAConfig,\n    ParallelConfig,\n    SchedulerConfig,\n)\nfrom aphrodite.common.logger import get_loading_progress_bar\nfrom aphrodite.modeling import get_model, InputMetadata, SamplingMetadata\nfrom aphrodite.modeling.megatron import cupy_utils\nfrom aphrodite.modeling.megatron.communication_op import broadcast_tensor_dict\nfrom aphrodite.modeling.megatron.parallel_state import (\n    get_tensor_model_parallel_world_size,\n    with_cupy_nccl_for_all_reduce,\n)\nfrom aphrodite.modeling.megatron import custom_all_reduce\nfrom aphrodite.common.sampling_params import SamplingParams, SamplingType\nfrom aphrodite.common.sequence import (\n    SamplerOutput,\n    SequenceData,\n    SequenceGroupMetadata,\n)\nfrom aphrodite.modeling.sampling_metadata import PersistentMetadata\nfrom aphrodite.lora.worker_manager import LRUCacheWorkerLoRAManager\nfrom aphrodite.lora.layers import LoRAMapping\nfrom aphrodite.lora.request import LoRARequest\nfrom aphrodite.common.utils import in_wsl, measure_cuda_memory\n\nKVCache = Tuple[torch.Tensor, torch.Tensor]\n_PAD_SLOT_ID = -1\nLORA_WARMUP_RANK = 8\n# Capture graphs for batch size 1, 2, 4, 8, 16, 24, 32, 40, ..., 256.\n# NOTE: _get_graph_batch_size needs to be updated if this list is changed.\n_BATCH_SIZES_TO_CAPTURE = [1, 2, 4] + [8 * i for i in range(1, 33)]\n\n\nclass ModelRunner:\n\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        parallel_config: ParallelConfig,\n        scheduler_config: SchedulerConfig,\n        device_config: DeviceConfig,\n        lora_config: Optional[LoRAConfig],\n        kv_cache_dtype: Optional[str] = \"auto\",\n        kv_quant_params_path: Optional[str] = None,\n        is_driver_worker: bool = False,\n    ):\n        self.model_config = model_config\n        self.parallel_config = parallel_config\n        self.scheduler_config = scheduler_config\n        self.lora_config = lora_config\n        self.is_driver_worker = is_driver_worker\n\n        # model_config can be None in tests/samplers/test_sampler.py.\n        # FIXME: This is a hack to make the tests work. Refactor this.\n        self.sliding_window = (model_config.get_sliding_window()\n                               if model_config is not None else None)\n        self.device_config = (device_config\n                              if device_config is not None else DeviceConfig())\n        self.device = self.device_config.device\n        self.model = None\n        self.block_size = None  # Set after initial profiling.\n        self.lora_manager = None\n\n        self.graph_runners: Dict[int, CUDAGraphRunner] = {}\n        self.graph_memory_pool = None  # Set during graph capture.\n\n        self.max_context_len_to_capture = (\n            self.model_config.max_context_len_to_capture\n            if self.model_config is not None else 0)\n        # When using CUDA graph, the input block tables must be padded to\n        # max_context_len_to_capture. However, creating the block table in\n        # Python can be expensive. To optimize this, we cache the block table\n        # in numpy and only copy the actual input content at every iteration.\n        # The shape of the cached block table will be\n        # (max batch size to capture, max context len to capture / block size).\n        self.graph_block_tables = None  # Set after initial profiling.\n        # cache in_wsl result\n        self.in_wsl = in_wsl()\n        self.kv_cache_dtype = kv_cache_dtype\n        self.kv_quant_params = (self.load_kv_quant_params(\n            model_config, kv_quant_params_path)\n                                if self.kv_cache_dtype == \"int8\" else None)\n\n    def load_kv_quant_params(self, model_config: ModelConfig,\n                             kv_quant_params_path: str) -> List[List[float]]:\n        if model_config is None:\n            return None\n        # Remove it when all models support kv cache int8.\n        architectures = model_config.hf_config.architectures\n        for arch in architectures:\n            if arch not in [\"LlamaForCausalLM\", \"LLaMAForCausalLM\"]:\n                raise ValueError(\n                    \"KV CACHE INT8 is not supported for model architectures \"\n                    f\"{arch} for now. \"\n                    \"Supported architectures: LlamaForCausalLM and \"\n                    \"LLaMAForCausalLM.\")\n        num_layers = model_config.hf_config.num_hidden_layers\n        kv_quant_params = []\n        for i in range(num_layers):\n            if kv_quant_params_path is not None:\n                path = (kv_quant_params_path +\n                        f\"/layers.{i}.past_kv_scale.0.weight\")\n                kv_quant_param = list(np.fromfile(path, dtype=np.float32))\n            kv_quant_params.append(kv_quant_param)\n        return kv_quant_params\n\n    def load_model(self) -> None:\n        with measure_cuda_memory() as m:\n            self.model = get_model(self.model_config, self.device_config,\n                                   self.lora_config)\n        self.model_memory_usage = m.consumed_memory\n        tp = get_tensor_model_parallel_world_size()\n        logger.info(\n            \"Model weights loaded. Memory usage: \"\n            f\"{self.model_memory_usage / float(2**30):.2f} GiB x {tp} = \"\n            f\"{self.model_memory_usage * tp / float(2**30):.2f} GiB\")\n\n        vocab_size = self.model.config.vocab_size\n\n        if self.lora_config:\n            assert (hasattr(self.model, \"supported_lora_modules\")\n                    and self.model.supported_lora_modules\n                    ), \"Model does not support LoRA\"\n            assert hasattr(\n                self.model,\n                \"embedding_modules\"), \"Model does not have embedding_modules\"\n            assert hasattr(self.model, \"embedding_padding_modules\"\n                           ), \"Model does not have embedding_padding_modules\"\n            self.lora_manager = LRUCacheWorkerLoRAManager(\n                self.scheduler_config.max_num_seqs,\n                self.scheduler_config.max_num_batched_tokens +\n                self.scheduler_config.max_paddings,\n                vocab_size,\n                self.lora_config,\n                self.device,\n                self.model.embedding_modules,\n                self.model.embedding_padding_modules,\n            )\n            self.model = self.lora_manager.create_lora_manager(self.model)\n\n    def set_block_size(self, block_size: int) -> None:\n        self.block_size = block_size\n\n        max_num_blocks = (self.max_context_len_to_capture + block_size -\n                          1) // block_size\n        self.graph_block_tables = np.zeros(\n            (max(_BATCH_SIZES_TO_CAPTURE), max_num_blocks), dtype=np.int32)\n\n    def _prepare_prompt(\n        self,\n        seq_group_metadata_list: List[SequenceGroupMetadata],\n    ) -> Tuple[torch.Tensor, torch.Tensor, InputMetadata, List[int], List[int],\n               List[int], List[int], Set[LoRARequest], ]:\n        assert len(seq_group_metadata_list) > 0\n        input_tokens: List[List[int]] = []\n        input_positions: List[List[int]] = []\n        slot_mapping: List[List[int]] = []\n        lora_index_mapping: List[int] = []\n        lora_prompt_mapping: List[int] = []\n        lora_requests: Set[LoRARequest] = set()\n\n        prompt_lens: List[int] = []\n        context_lens: List[int] = []\n        subquery_lens: List[int] = []\n        prefix_block_tables: List[List[int]] = []\n        for seq_group_metadata in seq_group_metadata_list:\n            assert seq_group_metadata.is_prompt\n            seq_ids = list(seq_group_metadata.seq_data.keys())\n            assert len(seq_ids) == 1\n            seq_id = seq_ids[0]\n\n            seq_data = seq_group_metadata.seq_data[seq_id]\n            prompt_tokens = seq_data.get_token_ids()\n            prompt_len = len(prompt_tokens)\n            prompt_lens.append(prompt_len)\n            computed_len = 0\n\n            # NOTE: This only works for oooooooxxx style attention.\n            computed_block_nums = seq_group_metadata.computed_block_nums\n            if (computed_block_nums is not None\n                    and len(computed_block_nums) > 0\n                    and self.sliding_window is None):\n                # Prefix is not supported with sliding_window\n                computed_len = len(computed_block_nums) * self.block_size\n                prompt_tokens = prompt_tokens[computed_len:]\n                prefix_block_tables.append(computed_block_nums)\n            else:\n                prefix_block_tables.append([])\n            # actual prompt lens\n            context_lens.append(computed_len)\n            subquery_lens.append(prompt_len - computed_len)\n\n            input_tokens.append(prompt_tokens)\n            # NOTE: Here we assume that the first token in the prompt\n            # is always the first token in the sequence.\n            input_positions.append(\n                list(range(computed_len, computed_len + len(prompt_tokens))))\n\n            lora_id = seq_group_metadata.lora_int_id\n\n            if lora_id > 0:\n                lora_requests.add(seq_group_metadata.lora_request)\n\n            lora_index_mapping.append([lora_id] * (prompt_len - computed_len))\n            lora_prompt_mapping.extend(\n                [lora_id] *\n                (prompt_len - computed_len\n                 if seq_group_metadata.sampling_params.prompt_logprobs else 1))\n\n            if seq_group_metadata.block_tables is None:\n                # During memory profiling, the block tables are not initialized\n                # yet. In this case, we just use a dummy slot mapping.\n                slot_mapping.append([_PAD_SLOT_ID] * prompt_len)\n                continue\n\n            # Compute the slot mapping.\n            slot_mapping.append([])\n            block_table = seq_group_metadata.block_tables[seq_id]\n            # Mask the [0, start_idx) tokens of the prompt with _PAD_SLOT_ID,\n            # where start_idx is max(0, prompt_len - sliding_window).\n            # For example, if the prompt len is 10, sliding window is 8, and\n            # block size is 4, the first two tokens are masked and the slot\n            # mapping will be [-1, -1, 2, 3, 4, 5, 6, 7, 0, 1].\n            start_idx = 0\n            if self.sliding_window is not None:\n                assert computed_len == 0, (\n                    \"Prefix caching is currently not supported with \"\n                    \"sliding window attention\")\n                start_idx = max(0, prompt_len - self.sliding_window)\n            for i in range(computed_len, prompt_len):\n                if i < start_idx:\n                    slot_mapping[-1].append(_PAD_SLOT_ID)\n                    continue\n\n                block_number = block_table[i // self.block_size]\n                block_offset = i % self.block_size\n                slot = block_number * self.block_size + block_offset\n                slot_mapping[-1].append(slot)\n\n        max_prompt_len = max(subquery_lens)\n        input_tokens = _make_tensor_with_pad(\n            input_tokens,\n            max_prompt_len,\n            pad=0,\n            dtype=torch.long,\n            device=self.device,\n        )\n        input_positions = _make_tensor_with_pad(\n            input_positions,\n            max_prompt_len,\n            pad=0,\n            dtype=torch.long,\n            device=self.device,\n        )\n        slot_mapping = _make_tensor_with_pad(\n            slot_mapping,\n            max_prompt_len,\n            pad=_PAD_SLOT_ID,\n            dtype=torch.long,\n            device=self.device,\n        )\n        lora_index_mapping = [\n            _pad_to_max(mapping, max_prompt_len, pad=0)\n            for mapping in lora_index_mapping\n        ]\n        context_lens_tensor = torch.tensor(context_lens,\n                                           dtype=torch.int,\n                                           device=self.device)\n        # Prepare prefix block tables\n        max_prompt_block_table_len = max(len(t) for t in prefix_block_tables)\n        block_tables = _make_tensor_with_pad(\n            prefix_block_tables,\n            max_len=max_prompt_block_table_len,\n            pad=0,\n            dtype=torch.int,\n            device=self.device,\n        )\n        start_loc_tensor = torch.arange(\n            0,\n            len(prompt_lens) * max_prompt_len,\n            max_prompt_len,\n            dtype=torch.long,\n            device=self.device,\n        )\n        prompt_lens_tensor = torch.tensor(prompt_lens,\n                                          dtype=torch.long,\n                                          device=self.device)\n\n        input_metadata = InputMetadata(\n            is_prompt=True,\n            slot_mapping=slot_mapping,\n            prompt_lens=prompt_lens_tensor,\n            max_seq_len=max_prompt_len,\n            start_loc=start_loc_tensor,\n            max_context_len=None,\n            context_lens=context_lens_tensor,\n            block_tables=block_tables,\n            use_cuda_graph=False,\n            kv_cache_dtype=self.kv_cache_dtype,\n            kv_quant_params=self.kv_quant_params,\n        )\n        return (\n            input_tokens,\n            input_positions,\n            input_metadata,\n            prompt_lens,\n            subquery_lens,\n            lora_index_mapping,\n            lora_prompt_mapping,\n            lora_requests,\n        )\n\n    def _prepare_decode(\n        self,\n        seq_group_metadata_list: List[SequenceGroupMetadata],\n    ) -> Tuple[torch.Tensor, torch.Tensor, InputMetadata, List[int], List[int],\n               Set[LoRARequest], ]:\n        assert len(seq_group_metadata_list) > 0\n        input_tokens: List[List[int]] = []\n        input_positions: List[List[int]] = []\n        slot_mapping: List[List[int]] = []\n        context_lens: List[int] = []\n        block_tables: List[List[int]] = []\n        lora_index_mapping: List[int] = []\n        lora_prompt_mapping: List[int] = []\n        lora_requests: Set[LoRARequest] = set()\n\n        for seq_group_metadata in seq_group_metadata_list:\n            assert not seq_group_metadata.is_prompt\n\n            seq_ids = list(seq_group_metadata.seq_data.keys())\n            lora_id = seq_group_metadata.lora_int_id\n\n            if lora_id > 0:\n                lora_requests.add(seq_group_metadata.lora_request)\n\n            for seq_id in seq_ids:\n                seq_data = seq_group_metadata.seq_data[seq_id]\n                generation_token = seq_data.get_last_token_id()\n                input_tokens.append([generation_token])\n\n                seq_len = seq_data.get_len()\n                position = seq_len - 1\n                input_positions.append([position])\n\n                context_len = (seq_len if self.sliding_window is None else min(\n                    seq_len, self.sliding_window))\n                context_lens.append(context_len)\n\n                block_table = seq_group_metadata.block_tables[seq_id]\n                block_number = block_table[position // self.block_size]\n                block_offset = position % self.block_size\n                slot = block_number * self.block_size + block_offset\n                slot_mapping.append([slot])\n                lora_index_mapping.append([lora_id])\n                lora_prompt_mapping.append(lora_id)\n\n                if self.sliding_window is not None:\n                    sliding_window_blocks = (self.sliding_window //\n                                             self.block_size)\n                    block_table = block_table[-sliding_window_blocks:]\n                block_tables.append(block_table)\n\n        batch_size = len(input_tokens)\n        max_context_len = max(context_lens)\n        use_captured_graph = (\n            not self.model_config.enforce_eager\n            and batch_size <= _BATCH_SIZES_TO_CAPTURE[-1]\n            and max_context_len <= self.max_context_len_to_capture)\n        if use_captured_graph:\n            # Pad the input tokens, positions, and slot mapping to match the\n            # batch size of the captured graph.\n            graph_batch_size = _get_graph_batch_size(batch_size)\n            assert graph_batch_size >= batch_size\n            for _ in range(graph_batch_size - batch_size):\n                input_tokens.append([])\n                input_positions.append([])\n                slot_mapping.append([])\n                context_lens.append(1)\n                block_tables.append([])\n            batch_size = graph_batch_size\n\n        input_tokens = _make_tensor_with_pad(input_tokens,\n                                             max_len=1,\n                                             pad=0,\n                                             dtype=torch.long,\n                                             device=self.device)\n        input_positions = _make_tensor_with_pad(\n            input_positions,\n            max_len=1,\n            pad=0,\n            dtype=torch.long,\n            device=self.device,\n        )\n        slot_mapping = _make_tensor_with_pad(\n            slot_mapping,\n            max_len=1,\n            pad=_PAD_SLOT_ID,\n            dtype=torch.long,\n            device=self.device,\n        )\n        context_lens = torch.tensor(context_lens,\n                                    dtype=torch.int,\n                                    device=self.device)\n\n        if use_captured_graph:\n            # The shape of graph_block_tables is\n            # [max batch size, max context len // block size].\n            input_block_tables = self.graph_block_tables[:batch_size]\n            for i, block_table in enumerate(block_tables):\n                if block_table:\n                    input_block_tables[i, :len(block_table)] = block_table\n            block_tables = torch.tensor(input_block_tables, device=self.device)\n        else:\n            max_block_table_len = max(\n                len(block_table) for block_table in block_tables)\n            block_tables = _make_tensor_with_pad(\n                block_tables,\n                max_len=max_block_table_len,\n                pad=0,\n                dtype=torch.int,\n                device=self.device,\n            )\n\n        lora_index_mapping = [\n            _pad_to_max(mapping, 1, pad=0) for mapping in lora_index_mapping\n        ]\n\n        input_metadata = InputMetadata(\n            is_prompt=False,\n            slot_mapping=slot_mapping,\n            prompt_lens=None,\n            max_seq_len=None,\n            start_loc=None,\n            max_context_len=max_context_len,\n            context_lens=context_lens,\n            block_tables=block_tables,\n            use_cuda_graph=use_captured_graph,\n            kv_cache_dtype=self.kv_cache_dtype,\n            kv_quant_params=self.kv_quant_params,\n        )\n        return (\n            input_tokens,\n            input_positions,\n            input_metadata,\n            lora_index_mapping,\n            lora_prompt_mapping,\n            lora_requests,\n        )\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function prepares sample data for a sequence group.\n\nArgs:\n    self: The instance of the class that this function is a part of.\n    seq_group_metadata_list (List[SequenceGroupMetadata]): A list of sequence group metadata.\n    prompt_lens (List[int]): A list of lengths of prompts.\n    subquery_lens (Optional[List[int]]): A list of lengths of subqueries.\n\nReturns:\n    SamplingMetadata: An object containing the prepared sample data.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n    def _prepare_sample(\n        self,\n        seq_group_metadata_list: List[SequenceGroupMetadata],\n        prompt_lens: List[int],\n        subquery_lens: Optional[List[int]],\n    ) -> SamplingMetadata:\n        seq_groups: List[Tuple[List[int], SamplingParams]] = []\n        selected_token_indices: List[int] = []\n        generators: List[torch.Generator] = []\n        selected_token_start_idx = 0\n        categorized_sample_indices = {t: [] for t in SamplingType}\n        categorized_sample_indices_start_idx = 0\n\n        max_subquery_len = max(subquery_lens) if subquery_lens else 1\n        for i, seq_group_metadata in enumerate(seq_group_metadata_list):\n            seq_ids = list(seq_group_metadata.seq_data.keys())\n            sampling_params = seq_group_metadata.sampling_params\n            seq_groups.append((seq_ids, sampling_params))\n\n            if seq_group_metadata.is_prompt:\n                assert len(seq_ids) == 1\n                assert subquery_lens is not None\n                subquery_len = subquery_lens[i]\n                if sampling_params.prompt_logprobs is not None:\n                    # NOTE: prompt token positions do not need sample, skip\n                    categorized_sample_indices_start_idx += subquery_len - 1\n\n                categorized_sample_indices[\n                    sampling_params.sampling_type].append(\n                        categorized_sample_indices_start_idx)\n                categorized_sample_indices_start_idx += 1\n\n                if sampling_params.prompt_logprobs is not None:\n                    selected_token_indices.extend(\n                        range(\n                            selected_token_start_idx,\n                            selected_token_start_idx + subquery_len - 1,\n                        ))\n                selected_token_indices.append(selected_token_start_idx +\n                                              subquery_len - 1)\n                selected_token_start_idx += max_subquery_len\n                if sampling_params.seed is not None:\n                    seq_group_metadata.state.generator = torch.Generator(\n                        device=\"cuda\").manual_seed(sampling_params.seed)\n            else:\n                num_seqs = len(seq_ids)\n                selected_token_indices.extend(\n                    range(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                        selected_token_start_idx,\n                        selected_token_start_idx + num_seqs,\n                    ))\n                selected_token_start_idx += num_seqs\n\n                categorized_sample_indices[\n                    sampling_params.sampling_type].extend(\n                        range(\n                            categorized_sample_indices_start_idx,\n                            categorized_sample_indices_start_idx + num_seqs,\n                        ))\n                categorized_sample_indices_start_idx += num_seqs\n\n            if sampling_params.seed is not None:\n                generators.append(seq_group_metadata.state.generator)\n\n        selected_token_indices = _async_h2d(\n            selected_token_indices,\n            dtype=torch.long,\n            target_device=self.device,\n            pin_memory=not self.in_wsl,\n        )\n        categorized_sample_indices = {\n            t: _async_h2d(\n                seq_ids,\n                dtype=torch.int,\n                target_device=self.device,\n                pin_memory=not self.in_wsl,\n            )\n            for t, seq_ids in categorized_sample_indices.items()\n        }\n\n        seq_data: Dict[int, SequenceData] = {}\n        for seq_group_metadata in seq_group_metadata_list:\n            seq_data.update(seq_group_metadata.seq_data)\n\n        seq_persistence_data: Dict[int, dict] = {}\n        for grp in seq_group_metadata_list:\n            seq_persistence_data.update(grp.persistent_data)\n\n        sampling_metadata = SamplingMetadata(\n            seq_groups=seq_groups,\n            seq_data=seq_data,\n            prompt_lens=prompt_lens,\n            selected_token_indices=selected_token_indices,\n            categorized_sample_indices=categorized_sample_indices,\n            generators=generators,\n            persistent_metadata=PersistentMetadata(seq_persistence_data),\n        )\n        return sampling_metadata", "completions": ["  \n[PYTHON]\ndef _prepare_sample(self, seq_group_metadata_list, prompt_lens, subquery_lens):\n    seq_groups = []\n    selected_token_indices = []\n    generators = []\n    selected_token_start_idx = 0\n    categorized_sample_indices = {t: [] for t in SamplingType}\n    categorized_sample_indices_start_idx = 0\n\n    max_subquery_len = max(subquery_lens) if subquery_lens else 1\n    for i, seq_group_metadata in enumerate(seq_group_metadata_list):\n        seq_ids = list(seq_group_metadata.seq_data.keys())\n        sampling_params = seq_group_metadata.sampling_params\n        seq_groups.append((seq_ids, sampling_params))\n\n        if seq_group_metadata.is_prompt:\n            assert len(seq_ids) == 1\n            assert subquery_lens is not None\n            subquery_len = subquery_lens[i]\n            if sampling_params.prompt_logprobs is not None:\n                # NOTE: prompt token positions do not need sample, skip\n                categorized_sample_indices_start_idx += subquery_len - 1\n\n            categorized_sample_indices[\n                sampling_params.sampling_type].append(\n                    categorized_sample_indices_start_idx)\n            categorized_sample_indices_start_idx += 1\n\n            if sampling_params.prompt_logprobs is not None:\n                selected_token_indices.extend(\n                    range(\n                        selected_token_start_idx,\n                        selected_token_start_idx + subquery_len - 1,\n                    ))\n            selected_token_indices.append(selected_token_start_idx +\n                                          subquery_len - 1)\n            selected_token_start_idx += max_subquery_len\n            if sampling_params.seed is not None:\n                seq_group_metadata.state.generator = torch.Generator(\n                    device=\"cuda\").manual_seed(sampling_params.seed)\n        else:\n            num_seqs = len(seq_ids)\n            selected_token_indices.extend(\n                range(\n                    selected_token_start_idx,\n                    selected_token_start_idx + num_seqs,\n                ))\n            selected_token_start_idx += num_seqs\n            generators.extend([\n                torch.Generator(device=\"cuda\").manual_seed(sampling_params.seed)\n                for _ in range(num_seqs)\n            ])\n\n    return SamplingMetadata(\n        seq_groups=seq_groups,\n        selected_token_indices=selected_token_indices,\n        generators=generators,\n        categorized_sample_indices=categorized_sample_indices,\n    )\n[/PYTHON]\n"]}
{"id": 59, "name": "get_stress", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Stress-strain profile objects to be applied to materials in concreteproperties.\"\"\"\n\nfrom __future__ import annotations\n\nimport warnings\nfrom dataclasses import dataclass, field\nfrom typing import TYPE_CHECKING\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom rich.console import Console\nfrom rich.table import Table\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import brentq\n\nfrom concreteproperties.post import plotting_context\n\n\nif TYPE_CHECKING:\n    import matplotlib.axes\n\n\n@dataclass\nclass StressStrainProfile:\n    \"\"\"Abstract base class for a material stress-strain profile.\n\n    Implements a piecewise linear stress-strain profile. Positive stresses & strains are\n    compression.\n\n    Args:\n        strains: List of strains (must be increasing or at least equal to last)\n        stresses: List of stresses\n\n    Raises:\n        ValueError: If length of strains is not equal to length of stresses\n        ValueError: If length of strains/stresses is not greater than 1\n        ValueError: If strains do not contain increasing or equal values\n    \"\"\"\n\n    strains: list[float]\n    stresses: list[float]\n\n    def __post_init__(self) -> None:\n        \"\"\"Post init method.\n\n        Raises:\n            ValueError: If length of strains is not equal to length of stresses\n            ValueError: If length of strains/stresses is not greater than 1\n            ValueError: If strains do not contain increasing or equal values\n        \"\"\"\n        # validate input - same length lists\n        if len(self.strains) != len(self.stresses):\n            raise ValueError(\"Length of strains must equal length of stresses\")\n\n        # validate input - length > 1\n        if len(self.strains) < 2:\n            raise ValueError(\"Length of strains and stresses must be greater than 1\")\n\n        # validate input - increasing values\n        prev_strain = self.strains[0]\n\n        for idx in range(len(self.strains)):\n            if idx != 0:\n                if self.strains[idx] < prev_strain:\n                    msg = \"Strains must contain increasing or equal values.\"\n                    raise ValueError(msg)\n\n                prev_strain = self.strains[idx]\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the stress value corresponding to a given strain value using linear interpolation.\n\nArgs:\n    self: The instance of the class that this method belongs to.\n    strain (float): The strain value for which the stress value is to be calculated.\n\nReturns:\n    float: The stress value corresponding to the given strain value.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def get_stress(\n        self,\n        strain: float,\n    ) -> float:\n        # create interpolation function\n        stress_function = interp1d(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            x=self.strains,\n            y=self.stresses,\n            kind=\"linear\",\n            fill_value=\"extrapolate\",\n        )\n\n        return stress_function(strain)", "completions": ["  \n[PYTHON]\ndef get_stress(self, strain: float) -> float:\n    stress_function = interp1d(self.strains, self.stresses)\n    return stress_function(strain)\n[/PYTHON]\n"]}
{"id": 60, "name": "get_graph", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Interfaces to the Atomic Simulation Environment package for dynamic simulations.\"\"\"\n\nfrom __future__ import annotations\n\nimport collections\nimport contextlib\nimport io\nimport pickle\nimport sys\nfrom enum import Enum\nfrom typing import TYPE_CHECKING, Literal\n\nimport ase.optimize as opt\nimport numpy as np\nimport pandas as pd\nimport scipy.sparse as sp\nfrom ase import Atoms, units\nfrom ase.calculators.calculator import Calculator, all_changes\nfrom ase.constraints import ExpCellFilter\nfrom ase.md import Langevin\nfrom ase.md.andersen import Andersen\nfrom ase.md.npt import NPT\nfrom ase.md.nptberendsen import Inhomogeneous_NPTBerendsen, NPTBerendsen\nfrom ase.md.nvtberendsen import NVTBerendsen\nfrom pymatgen.core.structure import Molecule, Structure\nfrom pymatgen.io.ase import AseAtomsAdaptor\nfrom pymatgen.optimization.neighbors import find_points_in_spheres\n\nfrom matgl.graph.converters import GraphConverter\n\nif TYPE_CHECKING:\n    import dgl\n    import torch\n    from ase.io import Trajectory\n    from ase.optimize.optimize import Optimizer\n\n    from matgl.apps.pes import Potential\n\n\nclass OPTIMIZERS(Enum):\n    \"\"\"An enumeration of optimizers for used in.\"\"\"\n\n    fire = opt.fire.FIRE\n    bfgs = opt.bfgs.BFGS\n    lbfgs = opt.lbfgs.LBFGS\n    lbfgslinesearch = opt.lbfgs.LBFGSLineSearch\n    mdmin = opt.mdmin.MDMin\n    scipyfmincg = opt.sciopt.SciPyFminCG\n    scipyfminbfgs = opt.sciopt.SciPyFminBFGS\n    bfgslinesearch = opt.bfgslinesearch.BFGSLineSearch\n\n\nclass Atoms2Graph(GraphConverter):\n    \"\"\"Construct a DGL graph from ASE Atoms.\"\"\"\n\n    def __init__(\n        self,\n        element_types: tuple[str, ...],\n        cutoff: float = 5.0,\n    ):\n        \"\"\"Init Atoms2Graph from element types and cutoff radius.\n\n        Args:\n            element_types: List of elements present in dataset for graph conversion. This ensures all graphs are\n                constructed with the same dimensionality of features.\n            cutoff: Cutoff radius for graph representation\n        \"\"\"\n        self.element_types = tuple(element_types)\n        self.cutoff = cutoff\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function generates a graph from a given Atoms object.\n\nArgs:\n    atoms (Atoms): The Atoms object from which to generate the graph.\n\nReturns:\n    tuple[dgl.DGLGraph, torch.Tensor, list]: A tuple containing the generated graph, lattice matrix, and state attributes.\n\nDetails:\nThe function first checks if the Atoms object has periodic boundary conditions. If it does, it uses the find_points_in_spheres function from scipy.sparse to find the points within a certain cutoff distance. It then excludes self-interactions and interactions that are too close to the numerical tolerance. If the Atoms object does not have periodic boundary conditions, it calculates the distance between all pairs of atoms and creates an adjacency matrix. It then converts the adjacency matrix to a coordinate list format and excludes self-interactions.\n\nThe function then calls the get_graph_from_processed_structure method of the superclass to generate the graph. The superclass method takes the Atoms object, the source and destination indices of the edges, the periodic images of the edges, the lattice matrix, the element types, and the scaled positions (if periodic boundary conditions are present) or the cartesian coordinates (otherwise). It returns the generated graph, the lattice matrix, and the state attributes.\n\nThe function returns the generated graph, the lattice matrix, and the state attributes.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def get_graph(self, atoms: Atoms) -> tuple[dgl.DGLGraph, torch.Tensor, list]:\n        numerical_tol = 1.0e-8\n        pbc = np.array([1, 1, 1], dtype=int)\n        element_types = self.element_types\n        lattice_matrix = np.array(atoms.get_cell()) if atoms.pbc.all() else np.expand_dims(np.identity(3), axis=0)\n        cart_coords = atoms.get_positions()\n        if atoms.pbc.all():\n            src_id, dst_id, images, bond_dist = find_points_in_spheres(\n                cart_coords,\n                cart_coords,\n                r=self.cutoff,\n                pbc=pbc,\n                lattice=lattice_matrix,\n                tol=numerical_tol,\n            )\n            exclude_self = (src_id != dst_id) | (bond_dist > numerical_tol)\n            src_id, dst_id, images, bond_dist = (\n                src_id[exclude_self],\n                dst_id[exclude_self],\n                images[exclude_self],\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                bond_dist[exclude_self],\n            )\n        else:\n            dist = np.linalg.norm(cart_coords[:, None, :] - cart_coords[None, :, :], axis=-1)\n            adj = sp.csr_matrix(dist <= self.cutoff) - sp.eye(len(atoms.get_positions()), dtype=np.bool_)\n            adj = adj.tocoo()\n            src_id = adj.row\n            dst_id = adj.col\n        g, lat, state_attr = super().get_graph_from_processed_structure(\n            atoms,\n            src_id,\n            dst_id,\n            images if atoms.pbc.all() else np.zeros((len(adj.row), 3)),\n            [lattice_matrix] if atoms.pbc.all() else lattice_matrix,\n            element_types,\n            atoms.get_scaled_positions(False) if atoms.pbc.all() else cart_coords,\n            is_atoms=True,\n        )\n\n        return g, lat, state_attr", "completions": ["  \n```\ndef get_graph(self, atoms: Atoms) -> tuple[dgl.DGLGraph, torch.Tensor, list]:\n    numerical_tol = 1.0e-8\n    pbc = np.array([1, 1, 1], dtype=int)\n    element_types = self.element_types\n    lattice_matrix = np.array(atoms.get_cell()) if atoms.pbc.all() else np.expand_dims(np.identity(3), axis=0)\n    cart_coords = atoms.get_positions()\n    if atoms.pbc.all():\n        src_id, dst_id, images, bond_dist = find_points_in_spheres(\n            cart_coords,\n            cart_coords,\n            r=self.cutoff,\n            pbc=pbc,\n            lattice=lattice_matrix,\n            tol=numerical_tol,\n        )\n        exclude_self = (src_id!= dst_id) | (bond_dist > numerical_tol)\n        src_id, dst_id, images, bond_dist = (\n            src_id[exclude_self],\n            dst_id[exclude_self],\n            images[exclude_self],\n            bond_dist[exclude_self],\n        )\n        src_id = src_id.astype(int)\n        dst_id = dst_id.astype(int)\n        images = images.astype(int)\n        bond_dist = bond_dist.astype(float)\n        return self.get_graph_from_processed_structure(\n            atoms,\n            src_id,\n            dst_id,\n            images,\n            bond_dist,\n            lattice_matrix,\n            element_types,\n            cart_coords,\n        )\n    else:\n        adj_matrix = self.get_adjacency_matrix(atoms)\n        coords = self.get_coords(atoms)\n        return self.get_graph_from_processed_structure(\n            atoms,\n            adj_matrix,\n            coords,\n            lattice_matrix,\n            element_types,\n            cart_coords,\n        )\n```"]}
{"id": 61, "name": "permute_graph_embeddings", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright Generate Biomedicines, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Layers for building graph neural networks.\n\nThis module contains layers for building neural networks that can process\ngraph-structured data. The internal representations of these layers\nare node and edge embeddings.\n\"\"\"\n\nfrom typing import Callable, List, Optional, Tuple\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.checkpoint import checkpoint\nfrom tqdm.autonotebook import tqdm\n\nfrom chroma.layers.attention import Attention\n\n\nclass GraphNN(nn.Module):\n    \"\"\"Graph neural network with optional edge updates.\n\n    Args:\n        num_layers (int): Number of layers.\n        dim_nodes (int): Hidden dimension of node tensor.\n        dim_edges (int): Hidden dimension of edge tensor.\n        dropout (float): Dropout rate.\n        node_mlp_layers (int): Node update function, number of hidden layers.\n            Default is 1.\n        node_mlp_dim (int): Node update function, hidden dimension.\n            Default is to match MLP output dimension.\n        update_edge (Boolean): Include an edge-update step. Default: True\n        edge_mlp_layers (int): Edge update function, number of hidden layers.\n            Default is 1.\n        edge_mlp_dim (int): Edge update function, hidden dimension.\n            Default is to match MLP output dimension.\n        mlp_activation (str): MLP nonlinearity.\n            `'relu'`: Rectified linear unit.\n            `'softplus'`: Softplus.\n        norm (str): Which normalization function to apply between layers.\n            `'transformer'`: Default layernorm\n            `'layer'`: Masked Layer norm with shape (input.shape[1:])\n            `'instance'`: Masked Instance norm\n        scale (float): Scaling factor of edge input when updating node (default=1.0)\n        attentional (bool): If True, use attention for message aggregation function\n            instead of a sum. Default is False.\n        num_attention_heads (int): Number of attention heads (if attentional) to use.\n            Default is 4.\n\n    Inputs:\n        node_h (torch.Tensor): Node features with shape\n            `(num_batch, num_nodes, dim_nodes)`.\n        edge_h (torch.Tensor): Edge features with shape\n            `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n        mask_i (tensor, optional): Node mask with shape `(num_batch, num_nodes)`\n        mask_ij (tensor, optional): Edge mask with shape\n             `(num_batch, num_nodes, num_neighbors)`\n\n    Outputs:\n        node_h_out (torch.Tensor): Updated node features with shape\n            `(num_batch, num_nodes, dim_nodes)`.\n        edge_h_out (torch.Tensor): Updated edge features with shape\n            `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n    \"\"\"\n\n    def __init__(\n        self,\n        num_layers: int,\n        dim_nodes: int,\n        dim_edges: int,\n        node_mlp_layers: int = 1,\n        node_mlp_dim: Optional[int] = None,\n        edge_update: bool = True,\n        edge_mlp_layers: int = 1,\n        edge_mlp_dim: Optional[int] = None,\n        mlp_activation: str = \"relu\",\n        dropout: float = 0.0,\n        norm: str = \"transformer\",\n        scale: float = 1.0,\n        skip_connect_input: bool = False,\n        attentional: bool = False,\n        num_attention_heads: int = 4,\n        checkpoint_gradients: bool = False,\n    ):\n        super(GraphNN, self).__init__()\n\n        self.skip_connect_input = skip_connect_input\n        self.checkpoint_gradients = checkpoint_gradients\n        self.layers = nn.ModuleList(\n            [\n                GraphLayer(\n                    dim_nodes=dim_nodes,\n                    dim_edges=dim_edges,\n                    node_mlp_layers=node_mlp_layers,\n                    node_mlp_dim=node_mlp_dim,\n                    edge_update=edge_update,\n                    edge_mlp_layers=edge_mlp_layers,\n                    edge_mlp_dim=edge_mlp_dim,\n                    mlp_activation=mlp_activation,\n                    dropout=dropout,\n                    norm=norm,\n                    scale=scale,\n                    attentional=attentional,\n                    num_attention_heads=num_attention_heads,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n\n    def forward(\n        self,\n        node_h: torch.Tensor,\n        edge_h: torch.Tensor,\n        edge_idx: torch.LongTensor,\n        mask_i: Optional[torch.Tensor] = None,\n        mask_ij: Optional[torch.Tensor] = None,\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        # Run every layer sequentially\n        node_h_init = node_h\n        edge_h_init = edge_h\n        for i, layer in enumerate(self.layers):\n            if self.skip_connect_input:\n                node_h = node_h + node_h_init\n                edge_h = edge_h + edge_h_init\n\n            # Update edge and node\n            node_h, edge_h = self.checkpoint(\n                layer, node_h, edge_h, edge_idx, mask_i, mask_ij\n            )\n\n            if self.skip_connect_input:\n                node_h = node_h - node_h_init\n                edge_h = edge_h - edge_h_init\n\n            # If mask was provided, apply it\n            if mask_i is not None:\n                node_h = node_h * (mask_i.unsqueeze(-1) != 0).type(torch.float32)\n            if mask_ij is not None:\n                edge_h = edge_h * (mask_ij.unsqueeze(-1) != 0).type(torch.float32)\n        return node_h, edge_h\n\n    def checkpoint(self, layer, *args):\n        if self.checkpoint_gradients:\n            return checkpoint(layer, *args)\n        else:\n            return layer(*args)\n\n    def sequential(\n        self,\n        tensors: dict,\n        pre_step_function: Callable = None,\n        post_step_function: Callable = None,\n    ) -> dict:\n        \"\"\"Decode the GNN sequentially along the node index `t`, with callbacks.\n\n        Args:\n            tensors (dict): Initial set of state tensors. At minimum this should\n                include the arguments to `forward`, namely `node_h`, `edge_h`,\n                `edge_idx`, `mask_i`, and `mask_ij`.\n            pre_step_function (function, optional): Callback function that is\n                optionally applied to `tensors` before each sequential GNN step as\n                `tensors_new = pre_step_function(t, pre_step_function)` where `t` is\n                the node index being updated. It should update elements of the\n                `tensors` dictionary, and it can access and update the intermediate\n                GNN state cache via the keyed lists of tensors in `node_h_cache` and\n                `edge_h_cache`.\n            post_step_function (function, optional): Same as `pre_step_function`, but\n                optionally applied after each sequential GNN step.\n\n        Returns:\n            tensors (dict): Processed set of tensors.\n        \"\"\"\n\n        # Initialize the state cache\n        tensors[\"node_h_cache\"], tensors[\"edge_h_cache\"] = self.init_steps(\n            tensors[\"node_h\"], tensors[\"edge_h\"]\n        )\n\n        # Sequential iteration\n        num_steps = tensors[\"node_h\"].size(1)\n        for t in tqdm(range(num_steps), desc=\"Sequential decoding\"):\n            if pre_step_function is not None:\n                tensors = pre_step_function(t, tensors)\n\n            tensors[\"node_h_cache\"], tensors[\"edge_h_cache\"] = self.step(\n                t,\n                tensors[\"node_h_cache\"],\n                tensors[\"edge_h_cache\"],\n                tensors[\"edge_idx\"],\n                tensors[\"mask_i\"],\n                tensors[\"mask_ij\"],\n            )\n\n            if post_step_function is not None:\n                tensors = post_step_function(t, tensors)\n\n        return tensors\n\n    def init_steps(\n        self, node_h: torch.Tensor, edge_h: torch.Tensor\n    ) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n        \"\"\"Initialize cached node and edge features.\n\n        Args:\n            node_h (torch.Tensor): Node features with shape\n                `(num_batch, num_nodes, dim_nodes)`.\n            edge_h (torch.Tensor): Edge features with shape\n                `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n\n        Returns:\n            node_h_cache (torch.Tensor): List of cached node features with `num_layers + 1`\n                tensors of shape `(num_batch, num_nodes, dim_nodes)`.\n            edge_h_cache (torch.Tensor): List of cached edge features with `num_layers + 1`\n                tensors of shape `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n        \"\"\"\n        num_layers = len(self.layers)\n        node_h_cache = [node_h.clone() for _ in range(num_layers + 1)]\n        edge_h_cache = [edge_h.clone() for _ in range(num_layers + 1)]\n        return node_h_cache, edge_h_cache\n\n    def step(\n        self,\n        t: int,\n        node_h_cache: List[torch.Tensor],\n        edge_h_cache: List[torch.Tensor],\n        edge_idx: torch.LongTensor,\n        mask_i: Optional[torch.Tensor] = None,\n        mask_ij: Optional[torch.Tensor] = None,\n    ) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n        \"\"\"Process GNN update for a specific node index t from cached intermediates.\n\n        Inputs:\n            t (int): Node index to decode.\n            node_h_cache (List[torch.Tensor]): List of cached node features with\n                `num_layers + 1` tensors of shape `(num_batch, num_nodes, dim_nodes)`.\n            edge_h_cache (List[torch.Tensor]): List of cached edge features with\n                `num_layers + 1` tensors of shape\n                `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n            edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n                `(num_batch, num_nodes, num_neighbors)`.\n            mask_i (torch.Tensor, optional): Node mask with shape\n                `(num_batch, num_nodes)`.\n            mask_ij (torch.Tensor, optional): Edge mask with shape\n                `(num_batch, num_nodes, num_neighbors)`.\n\n        Outputs:\n            node_h_cache (List[torch.Tensor]): Updated list of cached node features\n                with `num_layers + 1` tensors of shape\n                `(num_batch, num_nodes, dim_nodes)`. This method updates the tensors\n                in place for memory.\n            edge_h_cache (List[torch.Tensor]): Updated list of cached edge features\n                with `num_layers + 1` tensors of shape\n                `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n        \"\"\"\n        if self.skip_connect_input:\n            raise NotImplementedError\n\n        for i, layer in enumerate(self.layers):\n            # Because the edge updates depend on the updated nodes,\n            # we need both the input node features node_h and also\n            # the previous output node states node_h\n            node_h = node_h_cache[i]\n            node_h_out = node_h_cache[i + 1]\n            edge_h = edge_h_cache[i]\n            # Update edge and node\n            node_h_t, edge_h_t = checkpoint(\n                layer.step, t, node_h, node_h_out, edge_h, edge_idx, mask_i, mask_ij\n            )\n\n            # Scatter them in place\n            node_h_cache[i + 1].scatter_(\n                1, (t * torch.ones_like(node_h_t)).long(), node_h_t\n            )\n            edge_h_cache[i + 1].scatter_(\n                1, (t * torch.ones_like(edge_h_t)).long(), edge_h_t\n            )\n\n        return node_h_cache, edge_h_cache\n\n\nclass GraphLayer(nn.Module):\n    \"\"\"Graph layer that updates each node i given adjacent nodes and edges.\n\n    Args:\n        dim_nodes (int): Hidden dimension of node tensor.\n        dim_edges (int): Hidden dimension of edge tensor.\n        node_mlp_layers (int): Node update function, number of hidden layers.\n            Default: 1.\n        node_mlp_dim (int): Node update function, hidden dimension.\n            Default: Matches MLP output dimension.\n        update_edge (Boolean): Include an edge-update step. Default: True\n        edge_mlp_layers (int): Edge update function, number of hidden layers.\n            Default: 1.\n        edge_mlp_dim (int): Edge update function, hidden dimension.\n            Default: Matches MLP output dimension.\n        mlp_activation (str): MLP nonlinearity.\n            `'relu'`: Rectified linear unit.\n            `'softplus'`: Softplus.\n        dropout (float): Dropout rate.\n        norm (str): Which normalization function to apply between layers.\n            `'transformer'`: Default layernorm\n            `'layer'`: Masked Layer norm with shape (input.shape[1:])\n            `'instance'`: Masked Instance norm\n        scale (float): Scaling factor of edge input when updating node (default=1.0)\n\n    Inputs:\n        node_h (torch.Tensor): Node features with shape\n            `(num_batch, num_nodes, dim_nodes)`.\n        edge_h (torch.Tensor): Edge features with shape\n            `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n        mask_i (tensor, optional): Node mask with shape `(num_batch, num_nodes)`\n        mask_ij (tensor, optional): Edge mask with shape\n             `(num_batch, num_nodes, num_neighbors)`\n\n    Outputs:\n        node_h_out (torch.Tensor): Updated node features with shape\n            `(num_batch, num_nodes, dim_nodes)`.\n        edge_h_out (torch.Tensor): Updated edge features with shape\n            `(num_batch, num_nodes, num_neighbors, dim_nodes)`.\n    \"\"\"\n\n    def __init__(\n        self,\n        dim_nodes: int,\n        dim_edges: int,\n        node_mlp_layers: int = 1,\n        node_mlp_dim: Optional[int] = None,\n        edge_update: bool = True,\n        edge_mlp_layers: int = 1,\n        edge_mlp_dim: Optional[int] = None,\n        mlp_activation: str = \"relu\",\n        dropout: float = 0.0,\n        norm: str = \"transformer\",\n        scale: float = 1.0,\n        attentional: bool = False,\n        num_attention_heads: int = 4,\n    ):\n        super(GraphLayer, self).__init__()\n\n        # Store scale\n        self.scale = scale\n        self.dim_nodes = dim_nodes\n        self.dim_edges = dim_edges\n        self.attentional = attentional\n\n        self.node_norm_layer = MaskedNorm(\n            dim=1, num_features=dim_nodes, affine=True, norm=norm\n        )\n\n        self.message_mlp = MLP(\n            dim_in=2 * dim_nodes + dim_edges,\n            dim_out=dim_nodes,\n            num_layers_hidden=edge_mlp_layers,\n            dim_hidden=edge_mlp_dim,\n            activation=mlp_activation,\n            dropout=dropout,\n        )\n        self.update_mlp = MLP(\n            dim_in=2 * dim_nodes,\n            dim_out=dim_nodes,\n            num_layers_hidden=node_mlp_layers,\n            dim_hidden=node_mlp_dim,\n            activation=mlp_activation,\n            dropout=dropout,\n        )\n        self.edge_update = edge_update\n        self.edge_norm_layer = MaskedNorm(\n            dim=2, num_features=dim_edges, affine=True, norm=norm\n        )\n        if self.edge_update:\n            self.edge_mlp = MLP(\n                dim_in=2 * dim_nodes + dim_edges,\n                dim_out=dim_edges,\n                num_layers_hidden=edge_mlp_layers,\n                dim_hidden=edge_mlp_dim,\n                activation=mlp_activation,\n                dropout=dropout,\n            )\n\n        if self.attentional:\n            self.attention = Attention(n_head=num_attention_heads, d_model=dim_nodes)\n\n    def attend(\n        self, node_h: torch.Tensor, messages: torch.Tensor, mask_ij: torch.Tensor\n    ) -> torch.Tensor:\n        B, L, K, D = messages.size()\n        queries = node_h.reshape(-1, 1, D)\n        keys = messages.reshape(-1, K, D)\n        values = messages.reshape(-1, K, D)\n        mask = mask_ij.reshape(-1, 1, 1, K).bool() if mask_ij is not None else None\n        return self.attention(queries, keys, values, mask=mask).reshape(B, L, D)\n\n    def _normalize(self, node_h, edge_h, mask_i=None, mask_ij=None):\n        # Normalize node and edge embeddings\n        node_h_norm = self.node_norm_layer(node_h, mask_i)\n        edge_h_norm = self.edge_norm_layer(edge_h, mask_ij)\n        return node_h_norm, edge_h_norm\n\n    def _normalize_t(\n        self, edge_node_stack_t, mask_ij_t, include_nodes=True, include_edges=True\n    ):\n        # Apply normalization (since we have only normalized time t information)\n        node_i_t = edge_node_stack_t[:, :, :, : self.dim_nodes]\n        node_j_t = edge_node_stack_t[:, :, :, self.dim_nodes : 2 * self.dim_nodes]\n        edge_h_t = edge_node_stack_t[:, :, :, 2 * self.dim_nodes :]\n        if include_nodes:\n            node_i_t = self.node_norm_layer(node_i_t, mask_ij_t)\n            node_j_t = self.node_norm_layer(node_j_t, mask_ij_t)\n        if include_edges:\n            edge_h_t = self.edge_norm_layer(edge_h_t, mask_ij_t)\n        edge_node_stack_t = torch.cat([node_i_t, node_j_t, edge_h_t], -1)\n        return edge_node_stack_t\n\n    def _update_nodes(\n        self, node_h, node_h_norm, edge_h_norm, edge_idx, mask_i=None, mask_ij=None\n    ):\n        \"\"\"Update nodes given adjacent nodes and edges\"\"\"\n        # Compute messages at each ij\n        edge_node_stack = pack_edges(node_h_norm, edge_h_norm, edge_idx)\n        messages = self.message_mlp(edge_node_stack)\n        if mask_ij is not None:\n            messages = messages * mask_ij.unsqueeze(-1)\n\n        # Aggregate messages\n        if self.attentional:\n            message = self.attend(node_h_norm, messages, mask_ij)\n        else:\n            message = messages.sum(2) / self.scale\n\n        node_stack = torch.cat([node_h_norm, message], -1)\n\n        # Update nodes given aggregated messages\n        node_h_out = node_h + self.update_mlp(node_stack)\n        if mask_i is not None:\n            node_h_out = node_h_out * mask_i.unsqueeze(-1)\n        return node_h_out\n\n    def _update_nodes_t(\n        self,\n        t,\n        node_h,\n        node_h_norm_t,\n        edge_h_norm_t,\n        edge_idx_t,\n        mask_i_t=None,\n        mask_ij_t=None,\n    ):\n        \"\"\"Update nodes at index t given adjacent nodes and edges\"\"\"\n        # Compute messages at each ij\n        edge_node_stack_t = mask_ij_t.unsqueeze(-1) * pack_edges_step(\n            t, node_h, edge_h_norm_t, edge_idx_t\n        )\n\n        # Apply normalization of gathered tensors\n        edge_node_stack_t = self._normalize_t(\n            edge_node_stack_t, mask_ij_t, include_edges=False\n        )\n\n        messages_t = self.message_mlp(edge_node_stack_t)\n        if mask_ij_t is not None:\n            messages_t = messages_t * mask_ij_t.unsqueeze(-1)\n\n        # Aggregate messages\n        if self.attentional:\n            message_t = self.attend(node_h_norm_t, messages_t, mask_ij_t)\n        else:\n            message_t = messages_t.sum(2) / self.scale\n\n        node_stack_t = torch.cat([node_h_norm_t, message_t], -1)\n        # Update nodes given aggregated messages\n        node_h_t = node_h[:, t, :].unsqueeze(1)\n        node_h_out_t = node_h_t + self.update_mlp(node_stack_t)\n        if mask_i_t is not None:\n            node_h_out_t = node_h_out_t * mask_i_t.unsqueeze(-1)\n        return node_h_out_t\n\n    def _update_edges(self, edge_h, node_h_out, edge_h_norm, edge_idx, mask_ij):\n        \"\"\"Update edges given adjacent nodes and edges\"\"\"\n        edge_node_stack = pack_edges(node_h_out, edge_h_norm, edge_idx)\n\n        edge_h_out = edge_h + self.edge_mlp(edge_node_stack)\n        if mask_ij is not None:\n            edge_h_out = edge_h_out * mask_ij.unsqueeze(-1)\n        return edge_h_out\n\n    def _update_edges_t(\n        self, t, edge_h_t, node_h_out, edge_h_t_norm, edge_idx_t, mask_ij_t\n    ):\n        \"\"\"Update edges given adjacent nodes and edges\"\"\"\n        edge_node_stack_t = pack_edges_step(t, node_h_out, edge_h_t_norm, edge_idx_t)\n\n        edge_h_out_t = edge_h_t + self.edge_mlp(edge_node_stack_t)\n        if mask_ij_t is not None:\n            edge_h_out_t = edge_h_out_t * mask_ij_t.unsqueeze(-1)\n        return edge_h_out_t\n\n    def forward(\n        self,\n        node_h: torch.Tensor,\n        edge_h: torch.Tensor,\n        edge_idx: torch.LongTensor,\n        mask_i: Optional[torch.Tensor] = None,\n        mask_ij: Optional[torch.Tensor] = None,\n    ):\n        node_h_norm, edge_h_norm = self._normalize(node_h, edge_h, mask_i, mask_ij)\n        if mask_i is not None:\n            mask_i = (mask_i != 0).type(torch.float32)\n        if mask_ij is not None:\n            mask_ij = (mask_ij != 0).type(torch.float32)\n        node_h_out = self._update_nodes(\n            node_h, node_h_norm, edge_h_norm, edge_idx, mask_i, mask_ij\n        )\n        edge_h_out = None\n        if self.edge_update:\n            edge_h_out = self._update_edges(\n                edge_h, node_h_out, edge_h_norm, edge_idx, mask_ij\n            )\n        return node_h_out, edge_h_out\n\n    def step(\n        self,\n        t: int,\n        node_h: torch.Tensor,\n        node_h_out: torch.Tensor,\n        edge_h: torch.Tensor,\n        edge_idx: torch.LongTensor,\n        mask_i: Optional[torch.Tensor] = None,\n        mask_ij: Optional[torch.Tensor] = None,\n    ):\n        \"\"\"Compute update for a single node index `t`.\n\n        This function can be useful for sequential computation of graph\n        updates, for example with autoregressive architectures.\n\n        Args:\n            t (int): Index of node dimension to update\n            node_h (torch.Tensor): Node features with shape\n                `(num_batch, num_nodes, dim_nodes)`.\n            node_h_out (torch.Tensor): Cached outputs of preceding steps with shape\n                `(num_batch, num_nodes, dim_nodes)`.\n            edge_h (torch.Tensor): Edge features with shape\n                `(num_batch, num_nodes, num_neighbors, dim_edges)`.\n            edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n                `(num_batch, num_nodes, num_neighbors)`.\n            mask_i (tensor, optional): Node mask with shape `(num_batch, num_nodes)`\n            mask_ij (tensor, optional): Edge mask with shape\n                `(num_batch, num_nodes, num_neighbors)`\n\n        Resturns:\n            node_h_t (torch.Tensor): Updated node features with shape\n                `(num_batch, 1, dim_nodes)`.\n            edge_h_t (torch.Tensor): Updated edge features with shape\n                `(num_batch, 1, num_neighbors, dim_nodes)`.\n        \"\"\"\n        node_h_t = node_h[:, t, :].unsqueeze(1)\n        edge_h_t = edge_h[:, t, :, :].unsqueeze(1)\n        edge_idx_t = edge_idx[:, t, :].unsqueeze(1)\n        mask_i_t = mask_i[:, t].unsqueeze(1)\n        mask_ij_t = mask_ij[:, t, :].unsqueeze(1)\n\n        \"\"\" For a single step we need to apply the normalization both at node t and\n            also for all of the neighborhood tensors that feed in at t.\n        \"\"\"\n        node_h_t_norm, edge_h_t_norm = self._normalize(\n            node_h_t, edge_h_t, mask_i_t, mask_ij_t\n        )\n        node_h_t = self._update_nodes_t(\n            t, node_h, node_h_t_norm, edge_h_t_norm, edge_idx_t, mask_i_t, mask_ij_t\n        )\n\n        if self.edge_update:\n            node_h_out = node_h_out.scatter(\n                1, (t * torch.ones_like(node_h_t)).long(), node_h_t\n            )\n            edge_h_t = self._update_edges_t(\n                t, edge_h_t, node_h_out, edge_h_t_norm, edge_idx_t, mask_ij_t\n            )\n        return node_h_t, edge_h_t\n\n\nclass MLP(nn.Module):\n    \"\"\"Multilayer perceptron with variable input, hidden, and output dims.\n\n    Args:\n        dim_in (int): Feature dimension of input tensor.\n        dim_hidden (int or None): Feature dimension of intermediate layers.\n            Defaults to matching output dimension.\n        dim_out (int or None): Feature dimension of output tensor.\n            Defaults to matching input dimension.\n        num_layers_hidden (int): Number of hidden MLP layers.\n        activation (str): MLP nonlinearity.\n            `'relu'`: Rectified linear unit.\n            `'softplus'`: Softplus.\n        dropout (float): Dropout rate. Default is 0.\n\n    Inputs:\n        h (torch.Tensor): Input tensor with shape `(..., dim_in)`\n\n    Outputs:\n        h (torch.Tensor): Input tensor with shape `(..., dim_in)`\n    \"\"\"\n\n    def __init__(\n        self,\n        dim_in: int,\n        dim_hidden: Optional[int] = None,\n        dim_out: Optional[int] = None,\n        num_layers_hidden: int = 1,\n        activation: str = \"relu\",\n        dropout: float = 0.0,\n    ):\n        super(MLP, self).__init__()\n\n        # Default is dimension preserving\n        dim_out = dim_out if dim_out is not None else dim_in\n        dim_hidden = dim_hidden if dim_hidden is not None else dim_out\n\n        nonlinearites = {\"relu\": nn.ReLU, \"softplus\": nn.Softplus}\n        activation_func = nonlinearites[activation]\n\n        if num_layers_hidden == 0:\n            layers = [nn.Linear(dim_in, dim_out)]\n        else:\n            layers = []\n            for i in range(num_layers_hidden):\n                d_1 = dim_in if i == 0 else dim_hidden\n                layers = layers + [\n                    nn.Linear(d_1, dim_hidden),\n                    activation_func(),\n                    nn.Dropout(dropout),\n                ]\n            layers = layers + [nn.Linear(dim_hidden, dim_out)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, h: torch.Tensor) -> torch.Tensor:\n        return self.layers(h)\n\n\ndef collect_neighbors(node_h: torch.Tensor, edge_idx: torch.Tensor) -> torch.Tensor:\n    \"\"\"Collect neighbor node features as edge features.\n\n    For each node i, collect the embeddings of neighbors {j in N(i)} as edge\n    features neighbor_ij.\n\n    Args:\n        node_h (torch.Tensor): Node features with shape\n            `(num_batch, num_nodes, num_features)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n\n    Returns:\n        neighbor_h (torch.Tensor): Edge features containing neighbor node information\n            with shape `(num_batch, num_nodes, num_neighbors, num_features)`.\n    \"\"\"\n    num_batch, num_nodes, num_neighbors = edge_idx.shape\n    num_features = node_h.shape[2]\n\n    # Flatten for the gather operation then reform the full tensor\n    idx_flat = edge_idx.reshape([num_batch, num_nodes * num_neighbors, 1])\n    idx_flat = idx_flat.expand(-1, -1, num_features)\n    neighbor_h = torch.gather(node_h, 1, idx_flat)\n    neighbor_h = neighbor_h.reshape((num_batch, num_nodes, num_neighbors, num_features))\n    return neighbor_h\n\n\ndef collect_edges(\n    edge_h_dense: torch.Tensor, edge_idx: torch.LongTensor\n) -> torch.Tensor:\n    \"\"\"Collect sparse edge features from a dense pairwise tensor.\n\n    Args:\n        edge_h_dense (torch.Tensor): Dense edges features with shape\n            `(num_batch, num_nodes, num_nodes, num_features)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n\n    Returns:\n        edge_h (torch.Tensor): Edge features with shape\n            (num_batch, num_nodes, num_neighbors, num_features)`.\n    \"\"\"\n    gather_idx = edge_idx.unsqueeze(-1).expand(-1, -1, -1, edge_h_dense.size(-1))\n    edge_h = torch.gather(edge_h_dense, 2, gather_idx)\n    return edge_h\n\n\ndef collect_edges_transpose(\n    edge_h: torch.Tensor, edge_idx: torch.LongTensor, mask_ij: torch.Tensor\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Collect edge embeddings of reversed (transposed) edges in-place.\n\n    Args:\n        edge_h (torch.Tensor): Edge features with shape\n            `(num_batch, num_nodes, num_neighbors, num_features_edges)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n        mask_ij (torch.Tensor): Edge mask with shape\n             `(num_batch, num_nodes, num_neighbors)`\n\n    Returns:\n        edge_h_transpose (torch.Tensor): Edge features of transpose with shape\n            `(num_batch, num_nodes, num_neighbors, num_features_edges)`.\n        mask_ji (torch.Tensor): Mask indicating presence of reversed edge with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n    \"\"\"\n    num_batch, num_residues, num_k, num_features = list(edge_h.size())\n\n    # Get indices of reverse edges\n    ij_to_ji, mask_ji = transpose_edge_idx(edge_idx, mask_ij)\n\n    # Gather features at reverse edges\n    edge_h_flat = edge_h.reshape(num_batch, num_residues * num_k, -1)\n    ij_to_ji = ij_to_ji.unsqueeze(-1).expand(-1, -1, num_features)\n    edge_h_transpose = torch.gather(edge_h_flat, 1, ij_to_ji)\n    edge_h_transpose = edge_h_transpose.reshape(\n        num_batch, num_residues, num_k, num_features\n    )\n    edge_h_transpose = mask_ji.unsqueeze(-1) * edge_h_transpose\n    return edge_h_transpose, mask_ji\n\n\ndef scatter_edges(edge_h: torch.Tensor, edge_idx: torch.LongTensor) -> torch.Tensor:\n    \"\"\"Scatter sparse edge features into a dense pairwise tensor.\n    Args:\n         edge_h (torch.Tensor): Edge features with shape\n            `(num_batch, num_nodes, num_neighbors, num_features_edges)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n\n    Returns:\n        edge_h_dense (torch.Tensor): Dense edge features with shape\n            `(batch_size, num_nodes, num_nodes, dimensions)`.\n    \"\"\"\n    assert edge_h.dim() == 4\n    assert edge_idx.dim() == 3\n    bs, nres, _, dim = edge_h.size()\n    edge_indices = edge_idx.unsqueeze(-1).repeat(1, 1, 1, dim)\n    result = torch.zeros(\n        size=(bs, nres, nres, dim), dtype=edge_h.dtype, device=edge_h.device,\n    )\n    return result.scatter(dim=2, index=edge_indices, src=edge_h)\n\n\ndef pack_edges(\n    node_h: torch.Tensor, edge_h: torch.Tensor, edge_idx: torch.LongTensor\n) -> torch.Tensor:\n    \"\"\"Pack nodes and edge features into edge features.\n\n    Expands each edge_ij by packing node i, node j, and edge ij into\n    {node,node,edge}_ij.\n\n    Args:\n        node_h (torch.Tensor): Node features with shape\n            `(num_batch, num_nodes, num_features_nodes)`.\n        edge_h (torch.Tensor): Edge features with shape\n            `(num_batch, num_nodes, num_neighbors, num_features_edges)`.\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n\n    Returns:\n        edge_packed (torch.Tensor): Concatenated node and edge features with shape\n            (num_batch, num_nodes, num_neighbors, num_features_nodes\n                + 2*num_features_edges)`.\n    \"\"\"\n    num_neighbors = edge_h.shape[2]\n    node_i = node_h.unsqueeze(2).expand(-1, -1, num_neighbors, -1)\n    node_j = collect_neighbors(node_h, edge_idx)\n    edge_packed = torch.cat([node_i, node_j, edge_h], -1)\n    return edge_packed\n\n\ndef pack_edges_step(\n    t: int, node_h: torch.Tensor, edge_h_t: torch.Tensor, edge_idx_t: torch.LongTensor\n) -> torch.Tensor:\n    \"\"\"Pack node and edge features into edge features for a single node index t.\n\n    Expands each edge_ij by packing node i, node j, and edge ij into\n    {node,node,edge}_ij.\n\n    Args:\n        t (int): Node index to decode.\n        node_h (torch.Tensor): Node features at all positions with shape\n            `(num_batch, num_nodes, num_features_nodes)`.\n        edge_h_t (torch.Tensor): Edge features at index `t` with shape\n            `(num_batch, 1, num_neighbors, num_features_edges)`.\n        edge_idx_t (torch.LongTensor): Edge indices at index `t` for neighbors with shape\n            `(num_batch, 1, num_neighbors)`.\n\n    Returns:\n        edge_packed (torch.Tensor): Concatenated node and edge features\n            for index `t` with shape\n            (num_batch, 1, num_neighbors, num_features_nodes\n                + 2*num_features_edges)`.\n    \"\"\"\n    num_nodes_i = node_h.shape[1]\n    num_neighbors = edge_h_t.shape[2]\n    node_h_t = node_h[:, t, :].unsqueeze(1)\n    node_i = node_h_t.unsqueeze(2).expand(-1, -1, num_neighbors, -1)\n    node_j = collect_neighbors(node_h, edge_idx_t)\n    edge_packed = torch.cat([node_i, node_j, edge_h_t], -1)\n    return edge_packed\n\n\ndef transpose_edge_idx(\n    edge_idx: torch.LongTensor, mask_ij: torch.Tensor\n) -> Tuple[torch.LongTensor, torch.Tensor]:\n    \"\"\"Collect edge indices of reverse edges in-place at each edge.\n\n    The tensor `edge_idx` stores a directed graph topology as a tensor of\n    neighbor indices, where an element `edge_idx[b,i,k]` corresponds to the\n    node index of neighbor `k` of node `i` in batch member `b`.\n\n    This function takes a directed graph topology and returns an index tensor\n    that maps, in-place, to the reversed edges (if they exist). The indices\n    correspond to the contracted dimension of `edge_index` when it is viewed as\n    `(num_batch, num_nodes * num_neighbors)`. These indices can be used in\n    conjunction with `torch.gather` to collect edge embeddings of `j->i` at\n    `i->j`. See `collect_edges_transpose` for an example.\n\n    For reverse `j->i` edges that do not exist in the directed graph, the\n    function also returns a binary mask `mask_ji` indicating which edges\n    have both `i->j` and `j->i` present in the graph.\n\n    Args:\n        edge_idx (torch.LongTensor): Edge indices for neighbors with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n        mask_ij (torch.Tensor): Edge mask with shape\n             `(num_batch, num_nodes, num_neighbors)`\n\n    Returns:\n        ij_to_ji (torch.LongTensor): Flat indices for indexing ji in-place at ij with\n            shape `(num_batch, num_nodes * num_neighbors)`.\n        mask_ji (torch.Tensor): Mask indicating presence of reversed edge with shape\n            `(num_batch, num_nodes, num_neighbors)`.\n    \"\"\"\n    num_batch, num_residues, num_k = list(edge_idx.size())\n\n    # 1. Collect neighbors of neighbors\n    edge_idx_flat = edge_idx.reshape([num_batch, num_residues * num_k, 1]).expand(\n        -1, -1, num_k\n    )\n    edge_idx_neighbors = torch.gather(edge_idx, 1, edge_idx_flat)\n    # (b,i,j,k) gives the kth neighbor of the jth neighbor of i\n    edge_idx_neighbors = edge_idx_neighbors.reshape(\n        [num_batch, num_residues, num_k, num_k]\n    )\n\n    # 2. Determine which k at j maps back to i (if it exists)\n    residue_i = torch.arange(num_residues, device=edge_idx.device).reshape(\n        (1, -1, 1, 1)\n    )\n    edge_idx_match = (edge_idx_neighbors == residue_i).type(torch.float32)\n    return_mask, return_idx = torch.max(edge_idx_match, -1)\n\n    # 3. Build flat indices\n    ij_to_ji = edge_idx * num_k + return_idx\n    ij_to_ji = ij_to_ji.reshape(num_batch, -1)\n\n    # 4. Transpose mask\n    mask_ji = torch.gather(mask_ij.reshape(num_batch, -1), -1, ij_to_ji)\n    mask_ji = mask_ji.reshape(num_batch, num_residues, num_k)\n    mask_ji = mask_ij * return_mask * mask_ji\n    return ij_to_ji, mask_ji\n\n\ndef permute_tensor(\n    tensor: torch.Tensor, dim: int, permute_idx: torch.LongTensor\n) -> torch.Tensor:\n    \"\"\"Permute a tensor along a dimension given a permutation vector.\n\n    Args:\n        tensor (torch.Tensor): Input tensor with shape\n            `([batch_dims], permutation_length, [content_dims])`.\n        dim (int): Dimension to permute along.\n        permute_idx (torch.LongTensor): Permutation index tensor with shape\n            `([batch_dims], permutation_length)`.\n\n    Returns:\n        tensor_permute (torch.Tensor): Permuted node features with shape\n            `([batch_dims], permutation_length, [content_dims])`.\n    \"\"\"\n    # Resolve absolute dimension\n    dim = range(len(list(tensor.shape)))[dim]\n\n    # Flatten content dimensions\n    shape = list(tensor.shape)\n    batch_dims, permute_length = shape[:dim], shape[dim]\n    tensor_flat = tensor.reshape(batch_dims + [permute_length] + [-1])\n\n    # Exap content dimensions\n    permute_idx_expand = permute_idx.unsqueeze(-1).expand(tensor_flat.shape)\n\n    tensor_permute_flat = torch.gather(tensor_flat, dim, permute_idx_expand)\n    tensor_permute = tensor_permute_flat.reshape(tensor.shape)\n    return tensor_permute\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function permutes the embeddings of a graph.\n\nArgs:\n    node_h (torch.Tensor): Node embeddings.\n    edge_h (torch.Tensor): Edge embeddings.\n    edge_idx (torch.LongTensor): Indices of edges.\n    mask_i (torch.Tensor): Mask for nodes.\n    mask_ij (torch.Tensor): Mask for edges.\n    permute_idx (torch.LongTensor): Permutation indices.\n\nReturns:\n    Tuple[torch.Tensor, torch.Tensor, torch.LongTensor, torch.Tensor, torch.Tensor]: \n    Permuted node embeddings, edge embeddings, edge indices, mask for nodes, and mask for edges.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef permute_graph_embeddings(\n    node_h: torch.Tensor,\n    edge_h: torch.Tensor,\n    edge_idx: torch.LongTensor,\n    mask_i: torch.Tensor,\n    mask_ij: torch.Tensor,\n    permute_idx: torch.LongTensor,\n) -> Tuple[torch.Tensor, torch.Tensor, torch.LongTensor, torch.Tensor, torch.Tensor]:\n\n    # Permuting one-dimensional objects is straightforward gathering\n    node_h_permute = permute_tensor(node_h, 1, permute_idx)\n    edge_h_permute = permute_tensor(edge_h, 1, permute_idx)\n    mask_i_permute = permute_tensor(mask_i, 1, permute_idx)\n    mask_ij_permute = permute_tensor(mask_ij, 1, permute_idx)\n\n    \"\"\"\n    For edge_idx, there are two-dimensions set each edge idx that\n    previously pointed to j to now point to the new location\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    of j which is p^(-1)[j]\n    edge^(p)[i,k] = p^(-1)[edge[p(i),k]]\n    \"\"\"\n    # First, permute on the i dimension\n    edge_idx_permute_1 = permute_tensor(edge_idx, 1, permute_idx)\n    # Second, permute on the j dimension by using the inverse\n    permute_idx_inverse = torch.argsort(permute_idx, dim=-1)\n    edge_idx_1_flat = edge_idx_permute_1.reshape([edge_idx.shape[0], -1])\n    edge_idx_permute_flat = torch.gather(permute_idx_inverse, 1, edge_idx_1_flat)\n    edge_idx_permute = edge_idx_permute_flat.reshape(edge_idx.shape)\n\n    return (\n        node_h_permute,\n        edge_h_permute,\n        edge_idx_permute,\n        mask_i_permute,\n        mask_ij_permute,\n    )", "completions": ["  \n[PYTHON]\ndef permute_graph_embeddings(\n    node_h: torch.Tensor,\n    edge_h: torch.Tensor,\n    edge_idx: torch.LongTensor,\n    mask_i: torch.Tensor,\n    mask_ij: torch.Tensor,\n    permute_idx: torch.LongTensor,\n) -> Tuple[torch.Tensor, torch.Tensor, torch.LongTensor, torch.Tensor, torch.Tensor]:\n    node_h_permute = permute_tensor(node_h, 1, permute_idx)\n    edge_h_permute = permute_tensor(edge_h, 1, permute_idx)\n    mask_i_permute = permute_tensor(mask_i, 1, permute_idx)\n    mask_ij_permute = permute_tensor(mask_ij, 1, permute_idx)\n\n    edge_idx_permute = permute_tensor(edge_idx, 1, permute_idx)\n\n    return node_h_permute, edge_h_permute, edge_idx_permute, mask_i_permute, mask_ij_permute\n[/PYTHON]\n"]}
{"id": 62, "name": "pca_calc", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT license.\n\nimport logging\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n\nfrom .config import config\nfrom .model_adapter import LayerAdapter, ModelAdapter\nfrom .model_utils import get_layer0_inputs, get_signals\nfrom .slicing_scheduler import ConfigSlicingScheduler, ConstSlicingScheduler, SlicingScheduler\nfrom .utils import cleanup_memory, map_tensors\n\n\ndef rotate_attention_inputs(layer_adapter: LayerAdapter, Q: torch.Tensor) -> None:\n    # Rotate the WQ, WK and WV matrices of the self-attention layer.\n    for W in layer_adapter.get_attention_inputs():\n        dtype = W.weight.dtype\n        W_ = W.weight.to(device=config.device, dtype=torch.float64)\n        W.weight.data = torch.matmul(W_, Q).to(device=\"cpu\", dtype=dtype)\n\n\ndef slice_attention_inputs(layer_adapter: LayerAdapter, new_embedding_dimension: int) -> None:\n    # Slice the WQ, WK and WV matrices of the self-attention layer.\n    for W in layer_adapter.get_attention_inputs():\n        W.weight.data = W.weight.data[:, :new_embedding_dimension]\n        W.in_features = new_embedding_dimension\n\n    layer_adapter.layer.attn_shortcut_Q = nn.Parameter(layer_adapter.layer.attn_shortcut_Q[:new_embedding_dimension, :])\n\n\ndef rotate_attention_output(layer_adapter: LayerAdapter, Q: torch.Tensor) -> None:\n    # Rotate output matrix of the self-attention layer.\n    W = layer_adapter.get_attention_output()\n\n    dtype = W.weight.data.dtype\n    W_ = W.weight.data.to(device=config.device, dtype=torch.float64)\n    W.weight.data = torch.matmul(Q.T, W_).to(device=\"cpu\", dtype=dtype)\n    if W.bias is not None:\n        b = W.bias.data.to(device=config.device, dtype=torch.float64)\n        W.bias.data = torch.matmul(Q.T, b).to(device=\"cpu\", dtype=dtype)\n\n\ndef slice_attention_output(layer_adapter: LayerAdapter, new_embedding_dimension: int) -> None:\n    # Slice output matrix of the self-attention layer.\n    W = layer_adapter.get_attention_output()\n    W.weight.data = W.weight.data[:new_embedding_dimension, :]\n    if W.bias is not None:\n        W.bias.data = W.bias.data[:new_embedding_dimension]\n    W.out_features = new_embedding_dimension\n\n\ndef rotate_mlp_input(layer_adapter: LayerAdapter, Q: torch.Tensor) -> None:\n    # Rotate the MLP input weights.\n    for W in layer_adapter.get_mlp_inputs():\n        dtype = W.weight.dtype\n        W_ = W.weight.data.to(device=config.device, dtype=torch.float64)\n        W.weight.data = torch.matmul(W_, Q).to(device=\"cpu\", dtype=dtype)\n\n\ndef slice_mlp_input(layer_adapter: LayerAdapter, new_embedding_dimension: int) -> None:\n    # Slice the MLP input weights.\n    for W in layer_adapter.get_mlp_inputs():\n        W.weight.data = W.weight.data[:, :new_embedding_dimension]\n        W.in_features = new_embedding_dimension\n\n\ndef rotate_mlp_output(layer_adapter: LayerAdapter, Q: torch.Tensor) -> None:\n    # Rotate the MLP output weights and bias.\n    W = layer_adapter.get_mlp_output()\n    dtype = W.weight.data.dtype\n    W_ = W.weight.data.to(device=config.device, dtype=torch.float64)\n    W.weight.data = torch.matmul(Q.T, W_).to(device=\"cpu\", dtype=dtype)\n    if W.bias is not None:\n        b = W.bias.data.to(device=config.device, dtype=torch.float64)\n        W.bias.data = torch.matmul(Q.T, b).to(device=\"cpu\", dtype=dtype)\n\n\ndef slice_mlp_output(layer_adapter: LayerAdapter, new_embedding_dimension: int) -> None:\n    # Slice the MLP output weights and bias.\n    W = layer_adapter.get_mlp_output()\n    W.weight.data = W.weight.data[:new_embedding_dimension, :]\n    if W.bias is not None:\n        W.bias.data = W.bias.data[:new_embedding_dimension]\n    W.out_features = new_embedding_dimension\n\n\ndef rotate_embeddings(model_adapter: ModelAdapter, Q: torch.Tensor) -> None:\n    # Rotate the embeddings.\n    for W in model_adapter.get_embeddings():\n        dtype = W.weight.data.dtype\n        W_ = W.weight.data.to(device=config.device, dtype=torch.float64)\n        W.weight.data = torch.matmul(W_, Q).to(device=\"cpu\", dtype=dtype)\n\n    # Run GC and cleanup GPU memory\n    cleanup_memory()\n\n\ndef slice_embeddings(model_adapter: ModelAdapter, new_embedding_dimensions: dict[int, int]) -> None:\n    # Slice the embeddings.\n    for i, W in enumerate(model_adapter.get_embeddings()):\n        W.weight.data = W.weight.data[:, : new_embedding_dimensions[i]]\n        W.embedding_dim = new_embedding_dimensions[i]\n\n\ndef rotate_head(model_adapter: ModelAdapter, Q: torch.Tensor) -> None:\n    # Rotate the head.\n    W = model_adapter.get_lm_head()\n    dtype = W.weight.data.dtype\n    W_ = W.weight.data.to(device=config.device, dtype=torch.float64)\n    W.weight.data = torch.matmul(W_, Q).to(device=\"cpu\", dtype=dtype)\n\n\ndef slice_head(model_adapter: ModelAdapter, new_embedding_dimension: int) -> None:\n    # Slice the head.\n    lm_head = model_adapter.get_lm_head()\n    lm_head.weight.data = lm_head.weight.data[:, :new_embedding_dimension]\n    lm_head.in_features = new_embedding_dimension\n\n\ndef rotate_and_slice(\n    model_adapter: ModelAdapter,\n    dataloader: torch.utils.data.DataLoader[torch.Tensor],\n    slicing_scheduler: SlicingScheduler,\n    apply_mask: bool = True,\n    final_orientation: str = 'pca',\n) -> None:\n    \"\"\"\n    Rotate and slice a model, with interleaved slicing and PCA calculations\n    \"\"\"\n    if model_adapter.parallel_blocks:\n        rotate_and_slice_parallel(model_adapter, dataloader, slicing_scheduler, apply_mask, final_orientation)\n    else:\n        rotate_and_slice_sequential(model_adapter, dataloader, slicing_scheduler, apply_mask, final_orientation)\n\n\n@torch.no_grad()\ndef rotate_and_slice_sequential(\n    model_adapter: ModelAdapter,\n    dataloader: torch.utils.data.DataLoader[torch.Tensor],\n    slicing_scheduler: SlicingScheduler,\n    apply_mask: bool = True,\n    final_orientation: str = 'pca',\n) -> None:\n    \"\"\"\n    Rotate and slice the provided model, with interleaved slicing and PCA calculations.\n\n    This method works for models where the MLP block is computed after the attention block.\n    \"\"\"\n    model_adapter.model.eval()\n    dtype = next(iter(model_adapter.model.parameters())).dtype\n\n    inps, args, kwargs, ignore_masks = [], [], [], []\n    for batch in dataloader:\n        inp_batch, args_batch, kwargs_batch = get_layer0_inputs(model_adapter, batch)\n        inps.append(inp_batch)\n        args.append(args_batch)\n        kwargs.append(kwargs_batch)\n        if apply_mask:\n            ignore_masks.append(batch[\"attention_mask\"])\n\n    layers = model_adapter.get_layers()\n    slicing_scheduler.setup(hidden_size=model_adapter.hidden_size, layers_num=len(layers), parallel_blocks=False)\n\n    # rotate and slice embeddings\n    eig_val, Q = pca_calc(inps, ignore_masks)\n    Q = Q.to(device=config.device)\n    if final_orientation == 'random':\n        R = random_orthogonal_upper_left(Q.shape[0], slicing_scheduler.get_embedding_dimensions()[0])\n        Q = Q @ R.to(Q.device)\n    rotate_embeddings(model_adapter, Q)\n    slice_embeddings(model_adapter, slicing_scheduler.get_embedding_dimensions())\n\n    logging.info(\"Rotate and slice layers\")\n    for idx, layer_adapter in enumerate(tqdm(layers, unit=\"layer\", desc=\"Rotating and slicing\")):\n        layer = layer_adapter.layer\n        layer.attn_shortcut_Q = nn.Parameter(Q.T.clone().to(dtype=dtype))\n\n        # rotate and slice the attention inputs to match previous layer\n        rotate_attention_inputs(layer_adapter, Q)\n        slice_attention_inputs(layer_adapter, slicing_scheduler.get_attention_input_dimension(idx))\n\n        # get signal between attention and mlp, rotate and slice\n        for i, inp in enumerate(inps):\n            args[i] = layer_adapter.get_updated_args(\n                torch.matmul(inp.to(device=config.device), Q.to(dtype=dtype))[\n                    :, :, : slicing_scheduler.get_attention_input_dimension(idx)\n                ].cpu(),\n                args[i],\n            )\n\n        mlp_ln_inputs, _ = get_signals(layer_adapter, args, kwargs)\n        eig_val, Q = pca_calc(mlp_ln_inputs, ignore_masks)\n        Q = Q.to(device=config.device, dtype=torch.float64)\n        if final_orientation == 'random':\n            R = random_orthogonal_upper_left(\n                Q.shape[0], slicing_scheduler.get_attention_output_dimension(idx, match_head_dim=False)\n            )\n            Q = Q @ R.to(Q.device)\n\n        layer.attn_shortcut_Q = nn.Parameter(\n            torch.matmul(\n                layer.attn_shortcut_Q,\n                Q.to(dtype=dtype)[:, : slicing_scheduler.get_attention_output_dimension(idx, match_head_dim=False)],\n            )\n        )\n        rotate_attention_output(layer_adapter, Q)\n        slice_attention_output(\n            layer_adapter, slicing_scheduler.get_attention_output_dimension(idx, match_head_dim=False)\n        )\n\n        layer.mlp_shortcut_Q = nn.Parameter(\n            Q.T.clone().to(dtype=dtype)[: slicing_scheduler.get_mlp_input_dimension(idx), :]\n        )\n        rotate_mlp_input(layer_adapter, Q)\n        slice_mlp_input(layer_adapter, slicing_scheduler.get_mlp_input_dimension(idx))\n\n        # Run GC and cleanup GPU memory\n        cleanup_memory()\n\n        # now compute the outputs of the current layer/inputs for the next layer\n        # with slicing between Attention and mlp.\n        _, inps = get_signals(layer_adapter, args, kwargs)\n        eig_val, Q = pca_calc(inps, ignore_masks)\n        if final_orientation == 'random':\n            R = random_orthogonal_upper_left(Q.shape[0], slicing_scheduler.get_mlp_output_dimension(idx))\n            Q = Q @ R.to(Q.device)\n\n        layer.mlp_shortcut_Q = nn.Parameter(torch.matmul(layer.mlp_shortcut_Q, Q.to(dtype=dtype)))\n\n        # optionally slice the mlp/head connection in the last layer\n        rotate_mlp_output(layer_adapter, Q)\n        slice_mlp_output(layer_adapter, slicing_scheduler.get_mlp_output_dimension(idx))\n        layer.mlp_shortcut_Q = nn.Parameter(layer.mlp_shortcut_Q[:, : slicing_scheduler.get_mlp_output_dimension(idx)])\n\n        layer.to('cpu')\n\n        # Run GC and cleanup GPU memory\n        cleanup_memory()\n\n    # rotate and slice head\n    rotate_head(model_adapter, Q)\n    if slicing_scheduler.do_slice_head:\n        slice_head(model_adapter, slicing_scheduler.get_head_dimension())\n\n    # update model's slicing config\n    model_adapter.slicing_conf = slicing_scheduler.slicing_conf.clone()\n    logging.info(\"Rotate and slice layers done\")\n\n\n@torch.no_grad()\ndef rotate_and_slice_parallel(\n    model_adapter: ModelAdapter,\n    dataloader: torch.utils.data.DataLoader[torch.Tensor],\n    slicing_scheduler: SlicingScheduler,\n    apply_mask: bool = True,\n    final_orientation: str = 'pca',\n) -> None:\n    \"\"\"\n    Rotate and slice a model, with interleaved slicing and PCA calculations\n\n    This version works for models where the MLP block and the attention block are computed in parallel.\n    \"\"\"\n    model_adapter.model.eval()\n    dtype = next(iter(model_adapter.model.parameters())).dtype\n\n    inps, args, kwargs, ignore_masks = [], [], [], []\n    for batch in dataloader:\n        inp_batch, args_batch, kwargs_batch = get_layer0_inputs(model_adapter, batch)\n        inps.append(inp_batch)\n        args.append(args_batch)\n        kwargs.append(kwargs_batch)\n        if apply_mask:\n            ignore_masks.append(batch[\"attention_mask\"])\n\n    layers = model_adapter.get_layers()\n    slicing_scheduler.setup(hidden_size=model_adapter.hidden_size, layers_num=len(layers), parallel_blocks=True)\n\n    # rotate and slice embeddings\n    _, Q = pca_calc(inps, ignore_masks)\n    Q = Q.to(device=config.device)\n    if final_orientation == 'random':\n        R = random_orthogonal_upper_left(Q.shape[0], slicing_scheduler.get_embedding_dimensions()[0])\n        Q = Q @ R.to(Q.device)\n    rotate_embeddings(model_adapter, Q)\n    slice_embeddings(model_adapter, slicing_scheduler.get_embedding_dimensions())\n\n    logging.info(\"Rotate and slice layers\")\n    layers = model_adapter.get_layers()\n    for idx, layer_adapter in enumerate(tqdm(layers, unit=\"layer\", desc=\"Rotating and slicing\")):\n        layer = layer_adapter.layer\n        layer.attn_shortcut_Q = nn.Parameter(Q.T.clone().to(dtype=dtype))\n\n        # rotate and slice the inputs to match previous layer (both attention and mlp)\n        rotate_attention_inputs(layer_adapter, Q)\n        rotate_mlp_input(layer_adapter, Q)\n        slice_attention_inputs(layer_adapter, slicing_scheduler.get_attention_input_dimension(idx))\n        slice_mlp_input(layer_adapter, slicing_scheduler.get_attention_input_dimension(idx))\n\n        # update the input signals to this layer, and re-run it\n        for i, inp in enumerate(inps):\n            args[i] = layer_adapter.get_updated_args(\n                torch.matmul(inp.to(device=config.device), Q.to(dtype=dtype))[\n                    :, :, : slicing_scheduler.get_attention_input_dimension(idx)\n                ].cpu(),\n                args[i],\n            )\n\n        # the simpler equivalent of get_signals\n        outputs = []\n        layer = layer.to(config.device)\n        for layer_args_batch, layer_kwargs_batch in zip(args, kwargs):\n            layer_args_batch, layer_kwargs_batch = map_tensors(\n                [layer_args_batch, layer_kwargs_batch], device=config.device\n            )\n            out = layer(*layer_args_batch, **layer_kwargs_batch)\n            if isinstance(out, tuple):\n                out = out[layer_adapter.hidden_states_output_position]\n            out = out.cpu()\n            outputs.append(out)\n\n        inps = outputs\n        _, Q = pca_calc(inps, ignore_masks)\n\n        if final_orientation == 'random':\n            R = random_orthogonal_upper_left(Q.shape[0], slicing_scheduler.get_mlp_output_dimension(idx))\n            Q = Q @ R.to(Q.device)\n\n        # update shortcut matrix\n        layer.attn_shortcut_Q = nn.Parameter(torch.matmul(layer.attn_shortcut_Q, Q.to(dtype=dtype)))\n\n        # optionally slice the mlp/head connection in the last layer\n        rotate_mlp_output(layer_adapter, Q)\n        rotate_attention_output(layer_adapter, Q)\n        slice_mlp_output(layer_adapter, slicing_scheduler.get_mlp_output_dimension(idx))\n        slice_attention_output(layer_adapter, slicing_scheduler.get_mlp_output_dimension(idx))\n\n        # slice the shortcut (there is only one, we use attn_shortcut buffer)\n        layer.attn_shortcut_Q = nn.Parameter(\n            layer.attn_shortcut_Q[:, : slicing_scheduler.get_mlp_output_dimension(idx)]\n        )\n\n        layer.to('cpu')\n\n        # Run GC and cleanup GPU memory\n        cleanup_memory()\n\n    # rotate and slice head\n    rotate_head(model_adapter, Q)\n    if slicing_scheduler.do_slice_head:\n        slice_head(model_adapter, slicing_scheduler.get_head_dimension())\n\n    # update model's slicing config\n    model_adapter.slicing_conf = slicing_scheduler.slicing_conf.clone()\n    logging.info(\"Rotate and slice layers done\")\n\n\n@torch.no_grad()\ndef rotate(model_adapter: ModelAdapter, dataloader: torch.utils.data.DataLoader[torch.Tensor]) -> None:\n    \"\"\"\n    Rotate a model.\n    TODO: Make this gpu memory efficient.\n    \"\"\"\n    model_adapter.model.eval()\n    dtype = next(iter(model_adapter.model.parameters())).dtype  # Get the dtype of the model.\n\n    # List of layers to rotate.\n    layers = model_adapter.get_layers()\n\n    # Get the input of the first layer norm and calculate the Q_1\n    inps, args, kwargs = [], [], []\n    for batch in dataloader:\n        inp_batch, args_batch, kwargs_batch = get_layer0_inputs(model_adapter, batch)\n        inps.append(inp_batch)\n        args.append(args_batch)\n        kwargs.append(kwargs_batch)\n\n    _, Q_1 = pca_calc(inps)\n    Q_1 = Q_1.to(device=config.device)\n\n    # Rotate the embeddings.\n    rotate_embeddings(model_adapter, Q_1)\n\n    # Rotate the rest of the model.\n    logging.info(\"Rotate layers\")\n    for layer_adapter in tqdm(layers, unit=\"layer\", desc=\"Rotating\"):\n        layer = layer_adapter.layer\n        # Extract the inputs and outputs of the second layernorm input and calculate the Q_3\n        for i, inp in enumerate(inps):\n            args[i] = layer_adapter.get_updated_args(inp, args[i])\n        mlp_ln_inputs, outs = get_signals(layer_adapter, args, kwargs)\n        _, Q_3 = pca_calc(mlp_ln_inputs)\n        Q_3 = Q_3.to(device=config.device)\n        _, Q_5 = pca_calc(outs)\n        Q_5 = Q_5.to(device=config.device)\n\n        # Rotate the Q, K and V matrices of the self-attention layer.\n        rotate_attention_inputs(layer_adapter, Q_1)\n\n        # Set the shortcut rotation matrix of the self-attention layer.\n        layer.attn_shortcut_Q = nn.Parameter(torch.matmul(Q_1.clone().T, Q_3.clone()).to(device=\"cpu\", dtype=dtype))\n\n        # Rotate the Attention output matrix\n        rotate_attention_output(layer_adapter, Q_3)\n\n        # Rotate the MLP input\n        rotate_mlp_input(layer_adapter, Q_3)\n\n        # Set the shortcut rotation matrix of the MLP.\n        layer.mlp_shortcut_Q = nn.Parameter(torch.matmul(Q_3.clone().T, Q_5.clone()).to(device=\"cpu\", dtype=dtype))\n\n        # Rotate MLP output\n        rotate_mlp_output(layer_adapter, Q_5)\n\n        # Run GC and cleanup GPU memory\n        cleanup_memory()\n\n        inps = outs  # The inputs to the next layer are the outputs from this one!\n        Q_1 = Q_5  # first rotation in the next layer is the last one in this...\n\n    rotate_head(model_adapter, Q_5)\n    logging.info(\"Rotate layers done\")\n\n\ndef slice_rotated_model(model_adapter: ModelAdapter, slicing_scheduler: SlicingScheduler | None = None) -> None:\n    \"\"\"\n    TODO: Make this gpu memory efficient.\n    \"\"\"\n    model_adapter.model.eval()\n    layers = model_adapter.get_layers()\n    if not slicing_scheduler:\n        if model_adapter.slicing_conf.const_dimension is not None:\n            # backward compatibility for when no config is available\n            slicing_scheduler = ConstSlicingScheduler(model_adapter.slicing_conf.const_dimension)\n            slicing_scheduler.setup(\n                hidden_size=model_adapter.hidden_size,\n                layers_num=len(layers),\n                parallel_blocks=model_adapter.parallel_blocks,\n            )\n        else:\n            slicing_scheduler = ConfigSlicingScheduler(model_adapter.slicing_conf)\n\n    # slice embeddings\n    slice_embeddings(model_adapter, slicing_scheduler.get_embedding_dimensions())\n\n    # slice layers\n    for i, layer_adapter in enumerate(layers):\n        layer = layer_adapter.layer\n        # slice attn weights 2nd dim, attn shortcut 1st dim\n        slice_attention_inputs(layer_adapter, slicing_scheduler.get_attention_input_dimension(i))\n\n        # slice mlp input 2nd dimension\n        slice_mlp_input(layer_adapter, slicing_scheduler.get_mlp_input_dimension(i))\n\n        # slice mlp shortcut 1st dimension\n        # slice mlp shortcut\n        if not model_adapter.parallel_blocks:\n            layer.mlp_shortcut_Q = nn.Parameter(layer.mlp_shortcut_Q[: slicing_scheduler.get_mlp_input_dimension(i), :])\n\n        # slice mlp weights 1st dimension\n        slice_mlp_output(layer_adapter, slicing_scheduler.get_mlp_output_dimension(i))\n\n        if model_adapter.parallel_blocks:  # parallel case\n            layer.attn_shortcut_Q = nn.Parameter(\n                layer.attn_shortcut_Q[:, : slicing_scheduler.get_attention_output_dimension(i, match_head_dim=True)]\n            )\n            slice_attention_output(\n                layer_adapter, slicing_scheduler.get_attention_output_dimension(i, match_head_dim=True)\n            )\n        else:  # sequential case\n            layer.attn_shortcut_Q = nn.Parameter(\n                layer.attn_shortcut_Q[:, : slicing_scheduler.get_attention_output_dimension(i, match_head_dim=False)]\n            )\n            layer.mlp_shortcut_Q = nn.Parameter(\n                layer.mlp_shortcut_Q[:, : slicing_scheduler.get_mlp_output_dimension(i)]\n            )\n\n            # slice attention weights 1st dimension\n            slice_attention_output(\n                layer_adapter, slicing_scheduler.get_attention_output_dimension(i, match_head_dim=False)\n            )\n\n    if slicing_scheduler.do_slice_head:\n        slice_head(model_adapter, slicing_scheduler.get_head_dimension())\n\n\ndef random_orthogonal_upper_left(total_dim, upper_block_dim):\n    \"\"\"\n    Create a square matrix where the upper left block is a random orthogonal matrix, and the remainder is the identity.\n    \"\"\"\n    A = np.random.rand(upper_block_dim, upper_block_dim)\n    Q, _ = np.linalg.qr(A)\n    R = np.eye(total_dim)\n    R[:upper_block_dim, :upper_block_dim] = Q\n    return torch.from_numpy(R)\n\n\n@torch.no_grad()\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function calculates the Principal Component Analysis (PCA) of a list of tensors.\n\nArgs:\n    X (list[torch.Tensor]): A list of tensors to be used for PCA.\n    ignore_masks (list[torch.Tensor] | None, optional): A list of masks to ignore certain elements in the tensors. Defaults to None.\n\nReturns:\n    tuple[torch.Tensor, torch.Tensor]: A tuple containing the eigenvalues and eigenvectors of the PCA.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef pca_calc(\n    X: list[torch.Tensor], ignore_masks: list[torch.Tensor] | None = None\n) -> tuple[torch.Tensor, torch.Tensor]:\n    # Run GC and cleanup GPU memory\n    cleanup_memory()\n\n    H = None\n    for idx, X_batch in enumerate(X):\n        if ignore_masks:\n            X_batch[ignore_masks[idx] == 0] = 0\n\n        X_batch = X_batch.double().to(device=config.device)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        H_batch = torch.sum(X_batch.mT @ X_batch, dim=0)  # sum over the batch dimension.\n        H = H_batch if H is None else H + H_batch\n\n    damp = 0.01 * torch.mean(torch.diag(H))\n    diag = torch.arange(H.shape[-1]).to(device=config.device)\n    H[diag, diag] = H[diag, diag] + damp\n    X_eig = torch.linalg.eigh(H)\n    del H\n    index = torch.argsort(X_eig[0], descending=True)\n    eig_val = X_eig[0][index]\n    eigen_vec = X_eig[1][:, index]\n    return eig_val, eigen_vec", "completions": ["  \n[PYTHON]\ndef pca_calc(\n    X: list[torch.Tensor], ignore_masks: list[torch.Tensor] | None = None\n) -> tuple[torch.Tensor, torch.Tensor]:\n    # Run GC and cleanup GPU memory\n    cleanup_memory()\n\n    H = None\n    for idx, X_batch in enumerate(X):\n        if ignore_masks:\n            X_batch[ignore_masks[idx] == 0] = 0\n\n        X_batch = X_batch.double().to(device=config.device)\n\n        if H is None:\n            H = X_batch.T @ X_batch\n        else:\n            H += X_batch.T @ X_batch\n\n    # Run GC and cleanup GPU memory\n    cleanup_memory()\n\n    eig_val, eig_vec = torch.symeig(H, eigenvectors=True)\n\n    # Run GC and cleanup GPU memory\n    cleanup_memory()\n\n    return eig_val, eig_vec\n[/PYTHON]\n"]}
{"id": 63, "name": "initialize_config", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"\nFunctionality for initializing a transformer model from a given path\n\"\"\"\n\nimport logging\nimport math\nimport os\nimport re\nfrom pathlib import Path\nfrom typing import Any, Optional, Union\n\nimport torch\nfrom transformers import AutoConfig, AutoModel, TrainingArguments\n\nfrom sparseml.optim import parse_recipe_variables\nfrom sparseml.transformers import SparseAutoTokenizer\nfrom sparseml.transformers.sparsification import Trainer\nfrom sparseml.transformers.utils.helpers import TaskNames\nfrom sparseml.transformers.utils.load_task_model import load_task_model\n\n\n__all__ = [\n    \"initialize_sparse_model\",\n    \"initialize_tokenizer\",\n    \"initialize_trainer\",\n    \"initialize_config\",\n]\n\n_LOGGER = logging.getLogger(__name__)\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function initializes a configuration for a model from a pretrained model path.\n\nArgs:\n    model_path (Union[str, Path]): The path to the pretrained model or the model identifier from Hugging Face's model hub.\n    trust_remote_code (bool, optional): Whether to trust the remote code. Defaults to False.\n    **config_args: Additional arguments for the configuration.\n\nReturns:\n    AutoConfig: The configuration for the model.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef initialize_config(\n    model_path: Union[str, Path], trust_remote_code: bool = False, **config_args\n) -> AutoConfig:\n    config = AutoConfig.from_pretrained(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        model_path,\n        trust_remote_code=trust_remote_code,\n        **config_args,\n    )\n    return config", "completions": ["  \n[PYTHON]\ndef initialize_config(\n    model_path: Union[str, Path], trust_remote_code: bool = False, **config_args\n) -> AutoConfig:\n    config = AutoConfig.from_pretrained(\n        model_path, trust_remote_code=trust_remote_code, **config_args\n    )\n    return config\n[/PYTHON]\n"]}
{"id": 64, "name": "find_downloaded_firmware", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\n\nimport jsonlines\nfrom loguru import logger as log\n\nfrom mpflash.common import FWInfo\nfrom mpflash.vendor.versions import clean_version\n\nfrom .config import config\n\n\n# #########################################################################################################\ndef downloaded_firmwares(fw_folder: Path) -> List[FWInfo]:\n    \"\"\"Load a list of locally downloaded firmwares from the jsonl file\"\"\"\n    firmwares: List[FWInfo] = []\n    try:\n        with jsonlines.open(fw_folder / \"firmware.jsonl\") as reader:\n            firmwares.extend(iter(reader))\n    except FileNotFoundError:\n        log.error(f\"No firmware.jsonl found in {fw_folder}\")\n    # sort by filename\n    firmwares.sort(key=lambda x: x[\"filename\"])\n    return firmwares\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to find downloaded firmware for a specific board.\n\nArgs:\n    board_id (str): The ID of the board for which to find the firmware.\n    version (str, optional): The version of the firmware to find. Defaults to an empty string.\n    port (str, optional): The port of the board. Defaults to an empty string.\n    variants (bool, optional): Whether to include variants in the search. Defaults to False.\n    fw_folder (Optional[Path], optional): The folder where the firmware is located. Defaults to the firmware folder specified in the configuration.\n    trie (int, optional): The number of attempts made to find the firmware. Defaults to 1.\n    selector (Optional[Dict[str, str]], optional): A dictionary used to select the firmware. Defaults to None.\n\nReturns:\n    List[FWInfo]: A list of FWInfo objects representing the found firmware.\n\nRaises:\n    loguru.logger.error: If no firmware files are found.\n\nNotes:\n    This function uses the information in the firmwares.jsonl file to find the firmware file.\n    It filters the firmware list by version and then attempts to find the firmware again if no match is found.\n    The board ID is modified based on the port if it does not match the expected format.\n    The firmware list is sorted by filename before it is returned.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef find_downloaded_firmware(\n    *,\n    board_id: str,\n    version: str = \"\",\n    port: str = \"\",\n    variants: bool = False,\n    fw_folder: Optional[Path] = None,\n    trie: int = 1,\n    selector: Optional[Dict[str, str]] = None,\n) -> List[FWInfo]:\n    if selector is None:\n        selector = {}\n    fw_folder = fw_folder or config.firmware_folder\n    # Use the information in firmwares.jsonl to find the firmware file\n    fw_list = downloaded_firmwares(fw_folder)\n    if not fw_list:\n        log.error(\"No firmware files found. Please download the firmware first.\")\n        return []\n    # filter by version\n    version = clean_version(version, drop_v=True)\n    fw_list = filter_downloaded_fwlist(fw_list, board_id, version, port, variants, selector)\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    if not fw_list and trie < 3:\n        log.info(f\"Try ({trie+1}) to find a firmware for the board {board_id}\")\n        if trie == 1:\n            # ESP board naming conventions have changed by adding a PORT refix\n            if port.startswith(\"esp\") and not board_id.startswith(port.upper()):\n                board_id = f\"{port.upper()}_{board_id}\"\n            # RP2 board naming conventions have changed by adding a _RPIprefix\n            if port == \"rp2\" and not board_id.startswith(\"RPI_\"):\n                board_id = f\"RPI_{board_id}\"\n        elif trie == 2:\n            board_id = board_id.replace(\"_\", \"-\")\n\n        fw_list = find_downloaded_firmware(\n            fw_folder=fw_folder,\n            board_id=board_id,\n            version=version,\n            port=port,\n            trie=trie + 1,\n            selector=selector,\n        )\n        # hope we have a match now for the board\n    # sort by filename\n    fw_list.sort(key=lambda x: x[\"filename\"])\n    return fw_list", "completions": ["  ```\ndef filter_downloaded_fwlist(fw_list: List[FWInfo], board_id: str, version: str, port: str, variants: bool, selector: Dict[str, str]) -> List[FWInfo]:\n    # filter by version\n    fw_list = [fw for fw in fw_list if fw.version == version]\n    # filter by board ID\n    fw_list = [fw for fw in fw_list if fw.board_id == board_id]\n    # filter by port\n    fw_list = [fw for fw in fw_list if fw.port == port]\n    # filter by variants\n    if variants:\n        fw_list = [fw for fw in fw_list if fw.variants == variants]\n    # filter by selector\n    if selector:\n        fw_list = [fw for fw in fw_list if all(selector[key] == fw.selector[key] for key in selector)]\n    return fw_list\n```"]}
{"id": 65, "name": "draw_gaps", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at https://mozilla.org/MPL/2.0/.\nimport itertools\nfrom typing import List, Literal, Optional, Sequence, Tuple, Union\n\nimport numpy as np\nimport xarray as xr\n\nfrom ..plotters import plot_actions\n\n\ndef filter_bands(\n    bands_data: xr.Dataset,\n    Erange: Optional[Tuple[float, float]] = None,\n    E0: float = 0,\n    bands_range: Optional[Tuple[int, int]] = None,\n    spin: Optional[int] = None,\n) -> xr.Dataset:\n    filtered_bands = bands_data.copy()\n    # Shift the energies according to the reference energy, while keeping the\n    # attributes (which contain the units, amongst other things)\n    filtered_bands[\"E\"] = bands_data.E - E0\n    continous_bands = filtered_bands.dropna(\"k\", how=\"all\")\n\n    # Get the bands that matter for the plot\n    if Erange is None:\n        if bands_range is None:\n            # If neither E range or bands_range was provided, we will just plot the 15 bands below and above the fermi level\n            CB = int(\n                continous_bands.E.where(continous_bands.E <= 0).argmax(\"band\").max()\n            )\n            bands_range = [\n                int(max(continous_bands[\"band\"].min(), CB - 15)),\n                int(min(continous_bands[\"band\"].max() + 1, CB + 16)),\n            ]\n\n        filtered_bands = filtered_bands.sel(band=slice(*bands_range))\n        continous_bands = filtered_bands.dropna(\"k\", how=\"all\")\n\n        # This is the new Erange\n        # Erange = np.array([float(f'{val:.3f}') for val in [float(continous_bands.E.min() - 0.01), float(continous_bands.E.max() + 0.01)]])\n    else:\n        filtered_bands = filtered_bands.where(\n            (filtered_bands <= Erange[1]) & (filtered_bands >= Erange[0])\n        ).dropna(\"band\", how=\"all\")\n        continous_bands = filtered_bands.dropna(\"k\", how=\"all\")\n\n        # This is the new bands range\n        # bands_range = [int(continous_bands['band'].min()), int(continous_bands['band'].max())]\n\n    # Give the filtered bands the same attributes as the full bands\n    filtered_bands.attrs = bands_data.attrs\n\n    filtered_bands.E.attrs = bands_data.E.attrs\n    filtered_bands.E.attrs[\"E0\"] = filtered_bands.E.attrs.get(\"E0\", 0) + E0\n\n    # Let's treat the spin if the user requested it\n    if not isinstance(spin, (int, type(None))):\n        if len(spin) > 0:\n            spin = spin[0]\n        else:\n            spin = None\n\n    if spin is not None:\n        # Only use the spin setting if there is a spin index\n        if \"spin\" in filtered_bands.coords:\n            filtered_bands = filtered_bands.sel(spin=spin)\n\n    return filtered_bands\n\n\ndef style_bands(\n    bands_data: xr.Dataset,\n    bands_style: dict = {\"color\": \"black\", \"width\": 1},\n    spindown_style: dict = {\"color\": \"blue\", \"width\": 1},\n) -> xr.Dataset:\n    \"\"\"Returns the bands dataset, with the style information added to it.\n\n    Parameters\n    ------------\n    bands_data: xr.Dataset\n        The dataset containing bands energy information.\n    bands_style: dict\n        Dictionary containing the style information for the bands.\n    spindown_style: dict\n        Dictionary containing the style information for the spindown bands.\n        Any style that is not present in this dictionary will be taken from\n        the \"bands_style\" dictionary.\n    \"\"\"\n    # If the user provided a styler function, apply it.\n    if bands_style.get(\"styler\") is not None:\n        if callable(bands_style[\"styler\"]):\n            bands_data = bands_style[\"styler\"](data=bands_data)\n\n    # Include default styles in bands_style, only if they are not already\n    # present in the bands dataset (e.g. because the styler included them)\n    default_styles = {\"color\": \"black\", \"width\": 1, \"opacity\": 1}\n    for key in default_styles:\n        if key not in bands_data.data_vars and key not in bands_style:\n            bands_style[key] = default_styles[key]\n\n    # If some key in bands_style is a callable, apply it\n    for key in bands_style:\n        if callable(bands_style[key]):\n            bands_style[key] = bands_style[key](data=bands_data)\n\n    # Build the style dataarrays\n    if \"spin\" in bands_data.dims:\n        spindown_style = {**bands_style, **spindown_style}\n        style_arrays = {}\n        for key in [\"color\", \"width\", \"opacity\"]:\n            if isinstance(bands_style[key], xr.DataArray):\n                if not isinstance(spindown_style[key], xr.DataArray):\n                    down_style = bands_style[key].copy(deep=True)\n                    down_style.values[:] = spindown_style[key]\n                    spindown_style[key] = down_style\n\n                style_arrays[key] = xr.concat(\n                    [bands_style[key], spindown_style[key]], dim=\"spin\"\n                )\n            else:\n                style_arrays[key] = xr.DataArray(\n                    [bands_style[key], spindown_style[key]], dims=[\"spin\"]\n                )\n    else:\n        style_arrays = {}\n        for key in [\"color\", \"width\", \"opacity\"]:\n            style_arrays[key] = xr.DataArray(bands_style[key])\n\n    # Merge the style arrays with the bands dataset and return the styled dataset\n    return bands_data.assign(style_arrays)\n\n\ndef calculate_gap(bands_data: xr.Dataset) -> dict:\n    bands_E = bands_data.E\n    # Calculate the band gap to store it\n    shifted_bands = bands_E\n    above_fermi = bands_E.where(shifted_bands > 0)\n    below_fermi = bands_E.where(shifted_bands < 0)\n    CBbot = above_fermi.min()\n    VBtop = below_fermi.max()\n\n    CB = above_fermi.where(above_fermi == CBbot, drop=True).squeeze()\n    VB = below_fermi.where(below_fermi == VBtop, drop=True).squeeze()\n\n    gap = float(CBbot - VBtop)\n\n    return {\n        \"gap\": gap,\n        \"k\": (VB[\"k\"].values, CB[\"k\"].values),\n        \"bands\": (VB[\"band\"].values, CB[\"band\"].values),\n        \"spin\": (VB[\"spin\"].values, CB[\"spin\"].values)\n        if bands_data.attrs[\"spin\"].is_polarized\n        else (0, 0),\n        \"Es\": (float(VBtop), float(CBbot)),\n    }\n\n\ndef sanitize_k(bands_data: xr.Dataset, k: Union[float, str]) -> Optional[float]:\n    \"\"\"Returns the float value of a k point in the plot.\n\n    Parameters\n    ------------\n    bands_data: xr.Dataset\n        The dataset containing bands energy information.\n    k: float or str\n        The k point that you want to sanitize.\n        If it can be parsed into a float, the result of `float(k)` will be returned.\n        If it is a string and it is a label of a k point, the corresponding k value for that\n        label will be returned\n\n    Returns\n    ------------\n    float\n        The sanitized k value.\n    \"\"\"\n    san_k = None\n\n    try:\n        san_k = float(k)\n    except ValueError:\n        if (\n            \"axis\" in bands_data.k.attrs\n            and bands_data.k.attrs[\"axis\"].get(\"ticktext\") is not None\n        ):\n            ticktext = bands_data.k.attrs[\"axis\"][\"ticktext\"]\n            tickvals = bands_data.k.attrs[\"axis\"][\"tickvals\"]\n            if k in ticktext:\n                i_tick = ticktext.index(k)\n                san_k = tickvals[i_tick]\n            else:\n                pass\n                # raise ValueError(f\"We can not interpret {k} as a k-location in the current bands plot\")\n                # This should be logged instead of raising the error\n\n    return san_k\n\n\ndef get_gap_coords(\n    bands_data: xr.Dataset,\n    bands: Tuple[int, int],\n    from_k: Union[float, str],\n    to_k: Optional[Union[float, str]] = None,\n    spin: int = 0,\n) -> Tuple[Tuple[float, float], Tuple[float, float]]:\n    \"\"\"Calculates the coordinates of a gap given some k values.\n\n    Parameters\n    -----------\n    bands_data: xr.Dataset\n        The dataset containing bands energy information.\n    bands: array-like of int\n        Length 2 array containing the band indices of the gap.\n    from_k: float or str\n        The k value where you want the gap to start (bottom limit).\n        If \"to_k\" is not provided, it will be interpreted also as the top limit.\n        If a k-value is a float, it will be directly interpreted\n        as the position in the graph's k axis.\n        If a k-value is a string, it will be attempted to be parsed\n        into a float. If not possible, it will be interpreted as a label\n        (e.g. \"Gamma\").\n    to_k: float or str, optional\n        same as \"from_k\" but in this case represents the top limit.\n        If not provided, \"from_k\" will be used.\n    spin: int, optional\n        the spin component where you want to draw the gap. Has no effect\n        if the bands are not spin-polarized.\n\n    Returns\n    -----------\n    tuple\n        A tuple containing (k_values, E_values)\n    \"\"\"\n    if to_k is None:\n        to_k = from_k\n\n    ks = [None, None]\n    # Parse the names of the kpoints into their numeric values\n    # if a string was provided.\n    for i, val in enumerate((from_k, to_k)):\n        ks[i] = sanitize_k(bands_data, val)\n\n    VB, CB = bands\n    spin_bands = (\n        bands_data.E.sel(spin=spin) if \"spin\" in bands_data.coords else bands_data.E\n    )\n    Es = [\n        spin_bands.dropna(\"k\", \"all\").sel(k=k, band=band, method=\"nearest\")\n        for k, band in zip(ks, (VB, CB))\n    ]\n    # Get the real values of ks that have been obtained\n    # because we might not have exactly the ks requested\n    ks = tuple(np.ravel(E.k)[0] for E in Es)\n    Es = tuple(np.ravel(E)[0] for E in Es)\n\n    return ks, Es\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to draw gaps in a dataset.\n\nArgs:\n    bands_data (xr.Dataset): The dataset containing the band data.\n    gap (bool): A boolean indicating whether to draw gaps.\n    gap_info (dict): A dictionary containing information about the gaps.\n    gap_tol (float): The tolerance for considering gaps as equivalent.\n    gap_color (Optional[str]): The color to use for drawing gaps.\n    gap_marker (Optional[dict]): A dictionary containing marker information for drawing gaps.\n    direct_gaps_only (bool): A boolean indicating whether to draw only direct gaps.\n    custom_gaps (Sequence[dict]): A sequence of dictionaries containing custom gap information.\n    E_axis (Literal[\"x\", \"y\"]): The axis to use for the energy values.\n\nReturns:\n    List[dict]: A list of draw actions.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef draw_gaps(\n    bands_data: xr.Dataset,\n    gap: bool,\n    gap_info: dict,\n    gap_tol: float,\n    gap_color: Optional[str],\n    gap_marker: Optional[dict],\n    direct_gaps_only: bool,\n    custom_gaps: Sequence[dict],\n    E_axis: Literal[\"x\", \"y\"],\n) -> List[dict]:\n    draw_actions = []\n\n    # Draw gaps\n    if gap:\n        gapKs = [np.atleast_1d(k) for k in gap_info[\"k\"]]\n\n        # Remove \"equivalent\" gaps\n        def clear_equivalent(ks):\n            if len(ks) == 1:\n                return ks\n\n            uniq = [ks[0]]\n            for k in ks[1:]:\n                if abs(min(np.array(uniq) - k)) > gap_tol:\n                    uniq.append(k)\n            return uniq\n\n        all_gapKs = itertools.product(*[clear_equivalent(ks) for ks in gapKs])\n\n        for gap_ks in all_gapKs:\n            if direct_gaps_only and abs(gap_ks[1] - gap_ks[0]) > gap_tol:\n                continue\n\n            ks, Es = get_gap_coords(\n                bands_data,\n                gap_info[\"bands\"],\n                *gap_ks,\n                spin=gap_info.get(\"spin\", [0])[0],\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            )\n            name = \"Gap\"\n\n            draw_actions.append(\n                draw_gap(\n                    ks, Es, color=gap_color, name=name, marker=gap_marker, E_axis=E_axis\n                )\n            )\n\n    # Draw the custom gaps. These are gaps that do not necessarily represent\n    # the maximum and the minimum of the VB and CB.\n    for custom_gap in custom_gaps:\n        requested_spin = custom_gap.get(\"spin\", None)\n        if requested_spin is None:\n            requested_spin = [0, 1]\n\n        avail_spins = bands_data.get(\"spin\", [0])\n\n        for spin in avail_spins:\n            if spin in requested_spin:\n                from_k = custom_gap[\"from\"]\n                to_k = custom_gap.get(\"to\", from_k)\n                color = custom_gap.get(\"color\", None)\n                name = f\"Gap ({from_k}-{to_k})\"\n                ks, Es = get_gap_coords(\n                    bands_data, gap_info[\"bands\"], from_k, to_k, spin=spin\n                )\n\n                draw_actions.append(\n                    draw_gap(\n                        ks,\n                        Es,\n                        color=color,\n                        name=name,\n                        marker=custom_gap.get(\"marker\", {}),\n                        E_axis=E_axis,\n                    )\n                )\n\n    return draw_actions", "completions": ["  \n[PYTHON]\ndef draw_gaps(\n    bands_data: xr.Dataset,\n    gap: bool,\n    gap_info: dict,\n    gap_tol: float,\n    gap_color: Optional[str],\n    gap_marker: Optional[dict],\n    direct_gaps_only: bool,\n    custom_gaps: Sequence[dict],\n    E_axis: Literal[\"x\", \"y\"],\n) -> List[dict]:\n    draw_actions = []\n\n    # Draw gaps\n    if gap:\n        gapKs = [np.atleast_1d(k) for k in gap_info[\"k\"]]\n\n        # Remove \"equivalent\" gaps\n        def clear_equivalent(ks):\n            if len(ks) == 1:\n                return ks\n\n            uniq = [ks[0]]\n            for k in ks[1:]:\n                if abs(min(np.array(uniq) - k)) > gap_tol:\n                    uniq.append(k)\n            return uniq\n\n        all_gapKs = itertools.product(*[clear_equivalent(ks) for ks in gapKs])\n\n        for gap_ks in all_gapKs:\n            if direct_gaps_only and abs(gap_ks[1] - gap_ks[0]) > gap_tol:\n                continue\n\n            ks, Es = get_gap_coords(\n                bands_data,\n                gap_info[\"bands\"],\n                *gap_ks,\n                spin=gap_info.get(\"spin\", [0])[0],\n            )\n\n            if E_axis == \"x\":\n                draw_actions.append(\n                    {\n                        \"type\": \"line\",\n                        \"x\": [ks[0], ks[1]],\n                        \"y\": [Es[0], Es[1]],\n                        \"color\": gap_color,\n                        \"width\": 1,\n                        \"dash\": \"dash\",\n                    }\n                )\n            else:\n                draw_actions.append(\n                    {\n                        \"type\": \"line\",\n                        \"x\": [Es[0], Es[1]],\n                        \"y\": [ks[0], ks[1]],\n                        \"color\": gap_color,\n                        \"width\": 1,\n                        \"dash\": \"dash\",\n                    }\n                )\n\n    return draw_actions\n[/PYTHON]\n"]}
{"id": 66, "name": "find_dominant_color", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Extract properties from each object mask and detect its color.\"\"\"\n\nfrom typing import Dict, List, Tuple, TypeVar, Union\n\nimport numpy as np\nimport numpy.typing as npt\nimport pandas as pd\nfrom skimage import color as skimage_color\nimport skimage.measure\nfrom sklearn import cluster as sklearn_cluster\nfrom sklearn import neighbors as sklearn_neighbors\nimport webcolors\n\nDType = TypeVar('DType', bound=np.generic)\n# Color representation as numpy array of 3 elements of float64\n# Those values could be in different scales like\n# RGB ([0.0,255.0], [0.0,255.0], [0.0 to 255.0])\n# LAB ([0.0,100], [-128,127], [-128,127])\n# NColor = Annotated[npt.NDArray[DType], Literal[3]][np.float64]\nNColor = np.ndarray\n\n\nPROPERTIES = [\n    'area',\n    'bbox',\n    'convex_area',\n    'bbox_area',\n    'major_axis_length',\n    'minor_axis_length',\n    'eccentricity',\n    'centroid',\n]\n\nGENERIC_COLORS = [\n    ('black', '#000000'),\n    ('green', '#008000'),\n    ('green', '#00ff00'),  # lime\n    ('green', '#3cb371'),  # mediumseagreen\n    ('green', '#2E8B57'),  # seagreen\n    ('green', '#8FBC8B'),  # darkseagreen\n    ('green', '#adff2f'),  # olive\n    ('green', '#008080'),  # Teal\n    ('green', '#808000'),\n    ('blue', '#000080'),  # navy\n    ('blue', '#00008b'),  # darkblue\n    ('blue', '#4682b4'),  # steelblue\n    ('blue', '#40E0D0'),  # turquoise\n    ('blue', '#00FFFF'),  # cyan\n    ('blue', '#00ffff'),  # aqua\n    ('blue', '#6495ED'),  # cornflowerBlue\n    ('blue', '#4169E1'),  # royalBlue\n    ('blue', '#87CEFA'),  # lightSkyBlue\n    ('blue', '#4682B4'),  # steelBlue\n    ('blue', '#B0C4DE'),  # lightSteelBlue\n    ('blue', '#87CEEB'),  # skyblue\n    ('blue', '#0000CD'),  # mediumBlue\n    ('blue', '#0000ff'),\n    ('purple', '#800080'),\n    ('purple', '#9370db'),  # mediumpurple\n    ('purple', '#8B008B'),  # darkMagenta\n    ('purple', '#4B0082'),  # indigo\n    ('red', '#ff0000'),\n    ('red', '#B22222'),  # fireBrick\n    ('red', '#DC143C'),  # fireBrick\n    ('red', '#8B0000'),  # crimson\n    ('red', '#CD5C5C'),  # indianred\n    ('red', '#F08080'),  # lightCoral\n    ('red', '#FA8072'),  # salmon\n    ('red', '#E9967A'),  # darkSalmon\n    ('red', '#FFA07A'),  # lightSalmon\n    ('gray', '#c0c0c0'),  # silver,\n    ('white', '#ffffff'),\n    ('white', '#F5F5DC'),  # beige\n    ('white', '#FFFAFA'),  # snow\n    ('white', '#F0F8FF'),  # aliceBlue\n    ('white', '#FFE4E1'),  # mistyRose\n    ('yellow', '#ffff00'),\n    ('yellow', '#ffffe0'),  # lightyellow\n    ('yellow', '#8B8000'),  # darkyellow,\n    ('orange', '#ffa500'),\n    ('orange', '#ff8c00'),  # darkorange\n    ('pink', '#ffc0cb'),\n    ('pink', '#ff00ff'),  # fuchsia\n    ('pink', '#C71585'),  # mediumVioletRed\n    ('pink', '#DB7093'),  # paleVioletRed\n    ('pink', '#FFB6C1'),  # lightPink\n    ('pink', '#FF69B4'),  # hotPink\n    ('pink', '#FF1493'),  # deepPink\n    ('pink', '#BC8F8F'),  # rosybrown\n    ('brown', '#a52a2a'),\n    ('brown', '#8b4513'),  # saddlebrown\n    ('brown', '#f4a460'),  # sandybrown\n    ('brown', '#800000'),  # maroon\n]\n\n\ndef extract_properties_and_object_masks(\n    final_result: Dict[str, np.ndarray],\n    height: int,\n    width: int,\n    original_image: np.ndarray,\n) -> Tuple[List[pd.DataFrame], List[np.ndarray]]:\n  \"\"\"Extract specific properties from given detection masks.\n\n  Properties that will be computed includes the area of the masks, bbox\n  coordinates, area of that bbox, convex length, major_axis_length,\n  minor_axis_length, eccentricity and centroid.\n\n  Args:\n    final_result: A dictionary containing the num_detections, detection_classes,\n      detection_scores,detection_boxes,detection_classes_names,\n      detection_masks_reframed'\n    height: The height of the original image.\n    width: The width of the original image.\n    original_image: The actual image on which the objects were detected.\n\n  Returns:\n    A tuple containing two lists:\n      1. List of dataframes where each dataframe contains properties for a\n      detected object.\n      2. List of ndarrays where each ndarray is a cropped portion of the\n      original image\n        corresponding to a detected object.\n  \"\"\"\n  list_of_df = []\n  cropped_masks = []\n\n  for i, mask in enumerate(final_result['detection_masks_reframed']):\n    mask = np.where(mask, 1, 0)\n    df = pd.DataFrame(\n        skimage.measure.regionprops_table(mask, properties=PROPERTIES)\n    )\n    list_of_df.append(df)\n\n    bb = final_result['detection_boxes'][0][i]\n    ymin, xmin, ymax, xmax = (\n        int(bb[0] * height),\n        int(bb[1] * width),\n        int(bb[2] * height),\n        int(bb[3] * width),\n    )\n    mask = np.expand_dims(mask, axis=2)\n    cropped_object = np.where(\n        mask[ymin:ymax, xmin:xmax], original_image[ymin:ymax, xmin:xmax], 0\n    )\n    cropped_masks.append(cropped_object)\n\n  return list_of_df, cropped_masks\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function finds the dominant color in an image.\n\nArgs:\n    image (np.ndarray): The image to analyze.\n    black_threshold (int, optional): The threshold for filtering out black pixels. Defaults to 50.\n\nReturns:\n    Tuple[Union[int, str], Union[int, str], Union[int, str]]: The dominant color in the image as a tuple of RGB values.\n    If no non-black pixels are found, returns a tuple of 'Na' for each color component.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef find_dominant_color(\n    image: np.ndarray, black_threshold: int = 50\n) -> Tuple[Union[int, str], Union[int, str], Union[int, str]]:\n  pixels = image.reshape(-1, 3)\n\n  # Filter out black pixels based on the threshold\n  non_black_pixels = pixels[(pixels > black_threshold).any(axis=1)]\n\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "  if non_black_pixels.size != 0:\n    kmeans = sklearn_cluster.KMeans(\n        n_clusters=1, n_init=10, random_state=0\n    ).fit(non_black_pixels)\n    dominant_color = kmeans.cluster_centers_[0].astype(int)\n\n  else:\n    dominant_color = ['Na', 'Na', 'Na']\n  return tuple(dominant_color)", "completions": ["  \n[PYTHON]\ndef find_dominant_color(\n    image: np.ndarray, black_threshold: int = 50\n) -> Tuple[Union[int, str], Union[int, str], Union[int, str]]:\n    pixels = image.reshape(-1, 3)\n\n    # Filter out black pixels based on the threshold\n    non_black_pixels = pixels[(pixels > black_threshold).any(axis=1)]\n\n    # Calculate the dominant color\n    color_count = np.bincount(non_black_pixels.astype(int))\n    dominant_color = np.argmax(color_count)\n\n    return dominant_color\n[/PYTHON]\n"]}
{"id": 67, "name": "body_from_data", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport sys\nfrom typing import List, Tuple, Union\n\nimport attr\n\nfrom openapi_python_client.parser.properties import (\n    ModelProperty,\n    Property,\n    Schemas,\n    property_from_data,\n)\n\nfrom .. import schema as oai\nfrom ..config import Config\nfrom ..utils import get_content_type\nfrom .errors import ErrorLevel, ParseError\n\nif sys.version_info >= (3, 11):\n    from enum import StrEnum\n\n    class BodyType(StrEnum):\n        JSON = \"json\"\n        DATA = \"data\"\n        FILES = \"files\"\n        CONTENT = \"content\"\nelse:\n    from enum import Enum\n\n    class BodyType(str, Enum):\n        JSON = \"json\"\n        DATA = \"data\"\n        FILES = \"files\"\n        CONTENT = \"content\"\n\n\n@attr.define\nclass Body:\n    content_type: str\n    prop: Property\n    body_type: BodyType\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is for processing the request body of an operation and extracting the necessary information.\n\nArgs:\n    *: This is a special syntax in Python that allows for variable length arguments.\n    data (oai.Operation): The operation data containing the request body.\n    schemas (Schemas): The schemas used for parsing the request body.\n    config (Config): The configuration settings for the operation.\n    endpoint_name (str): The name of the endpoint associated with the operation.\n\nReturns:\n    Tuple[List[Union[Body, ParseError]], Schemas]: A tuple containing a list of Body or ParseError objects, and the updated schemas.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef body_from_data(\n    *,\n    data: oai.Operation,\n    schemas: Schemas,\n    config: Config,\n    endpoint_name: str,\n) -> Tuple[List[Union[Body, ParseError]], Schemas]:\n    if data.request_body is None or isinstance(data.request_body, oai.Reference):\n        return [], schemas\n\n    bodies: List[Union[Body, ParseError]] = []\n    body_content = data.request_body.content\n    prefix_type_names = len(body_content) > 1\n\n    for content_type, media_type in body_content.items():\n        simplified_content_type = get_content_type(content_type, config)\n        if simplified_content_type is None:\n            bodies.append(\n                ParseError(\n                    detail=\"Invalid content type\",\n                    data=data.request_body,\n                    level=ErrorLevel.WARNING,\n                )\n            )\n            continue\n        media_type_schema = media_type.media_type_schema\n        if media_type_schema is None:\n            bodies.append(\n                ParseError(\n                    detail=\"Missing schema\",\n                    data=data.request_body,\n                    level=ErrorLevel.WARNING,\n                )\n            )\n            continue\n        if simplified_content_type == \"application/x-www-form-urlencoded\":\n            body_type = BodyType.DATA\n        elif simplified_content_type == \"multipart/form-data\":\n            body_type = BodyType.FILES\n        elif simplified_content_type == \"application/octet-stream\":\n            body_type = BodyType.CONTENT\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        elif simplified_content_type == \"application/json\" or simplified_content_type.endswith(\"+json\"):\n            body_type = BodyType.JSON\n        else:\n            bodies.append(\n                ParseError(\n                    detail=f\"Unsupported content type {simplified_content_type}\",\n                    data=data.request_body,\n                    level=ErrorLevel.WARNING,\n                )\n            )\n            continue\n        prop, schemas = property_from_data(\n            name=\"body\",\n            required=True,\n            data=media_type_schema,\n            schemas=schemas,\n            parent_name=f\"{endpoint_name}_{body_type}\" if prefix_type_names else endpoint_name,\n            config=config,\n        )\n        if isinstance(prop, ParseError):\n            bodies.append(prop)\n            continue\n        if isinstance(prop, ModelProperty) and body_type == BodyType.FILES:\n            # Regardless of if we just made this property or found it, it now needs the `to_multipart` method\n            prop = attr.evolve(prop, is_multipart_body=True)\n            schemas = attr.evolve(\n                schemas,\n                classes_by_name={\n                    **schemas.classes_by_name,\n                    prop.class_info.name: prop,\n                },\n            )\n        bodies.append(\n            Body(\n                content_type=content_type,\n                prop=prop,\n                body_type=body_type,\n            )\n        )\n\n    return bodies, schemas", "completions": ["  \n[PYTHON]\n```\nbody_prop = property_from_data(media_type_schema, schemas, config, endpoint_name)\nif isinstance(body_prop, ParseError):\n    bodies.append(body_prop)\n    continue\nbodies.append(Body(content_type, body_prop, body_type))\n```\n[/PYTHON]\n"]}
{"id": 68, "name": "convert_files", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport datetime\nimport torch\nimport os\n\nfrom loguru import logger\nfrom pathlib import Path\nfrom safetensors.torch import save_file, load_file, _find_shared_tensors, _is_complete\nfrom typing import List, Dict\nfrom collections import defaultdict\n\nfrom lorax_server.utils.errors import InfWeightsError, NanWeightsError\n\n\ndef _remove_duplicate_names(\n    state_dict: Dict[str, torch.Tensor],\n    *,\n    preferred_names: List[str] = None,\n    discard_names: List[str] = None,\n) -> Dict[str, List[str]]:\n    if preferred_names is None:\n        preferred_names = []\n    preferred_names = set(preferred_names)\n    if discard_names is None:\n        discard_names = []\n    discard_names = set(discard_names)\n\n    shareds = _find_shared_tensors(state_dict)\n    to_remove = defaultdict(list)\n    for shared in shareds:\n        complete_names = set(\n            [name for name in shared if _is_complete(state_dict[name])]\n        )\n        if not complete_names:\n            if len(shared) == 1:\n                # Force contiguous\n                name = list(shared)[0]\n                state_dict[name] = state_dict[name].clone()\n                complete_names = {name}\n            else:\n                raise RuntimeError(\n                    f\"Error while trying to find names to remove to save state dict, but found no suitable name to keep for saving amongst: {shared}. None is covering the entire storage.Refusing to save/load the model since you could be storing much more memory than needed. Please refer to https://huggingface.co/docs/safetensors/torch_shared_tensors for more information. Or open an issue.\"\n                )\n\n        keep_name = sorted(list(complete_names))[0]\n\n        # Mecanism to preferentially select keys to keep\n        # coming from the on-disk file to allow\n        # loading models saved with a different choice\n        # of keep_name\n        preferred = complete_names.difference(discard_names)\n        if preferred:\n            keep_name = sorted(list(preferred))[0]\n\n        if preferred_names:\n            preferred = preferred_names.intersection(complete_names)\n            if preferred:\n                keep_name = sorted(list(preferred))[0]\n        for name in sorted(shared):\n            if name != keep_name:\n                to_remove[keep_name].append(name)\n    return to_remove\n\n\ndef convert_file(pt_file: Path, sf_file: Path, discard_names: List[str]):\n    \"\"\"\n    Convert a pytorch file to a safetensors file\n    This will remove duplicate tensors from the file.\n\n    Unfortunately, this might not respect *transformers* convention.\n    Forcing us to check for potentially different keys during load when looking\n    for specific tensors (making tensor sharing explicit).\n    \"\"\"\n    loaded = torch.load(pt_file, map_location=\"cpu\")\n    if \"state_dict\" in loaded:\n        loaded = loaded[\"state_dict\"]\n    to_removes = _remove_duplicate_names(loaded, discard_names=discard_names)\n\n    metadata = {\"format\": \"pt\"}\n    for kept_name, to_remove_group in to_removes.items():\n        for to_remove in to_remove_group:\n            if to_remove not in metadata:\n                metadata[to_remove] = kept_name\n            del loaded[to_remove]\n    # Force tensors to be contiguous\n    loaded = {k: v.contiguous() for k, v in loaded.items()}\n\n    dirname = os.path.dirname(sf_file)\n    os.makedirs(dirname, exist_ok=True)\n    save_file(loaded, sf_file, metadata=metadata)\n    reloaded = load_file(sf_file)\n    for k in loaded:\n        pt_tensor = loaded[k]\n        sf_tensor = reloaded[k]\n        if not torch.equal(pt_tensor, sf_tensor):\n            if torch.any(torch.isnan(pt_tensor)):\n                raise NanWeightsError(f\"Weights unusuable as param {k} in file {pt_file} contains NaN values\")\n            if torch.any(torch.isinf(pt_tensor)):\n                raise InfWeightsError(f\"Weights unusuable as param {k} in file {pt_file} contains inf values\")\n            raise RuntimeError(f\"The output tensors do not match for key {k}\")\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function converts files from one format to another, skipping blacklisted files.\n\nArgs:\n    pt_files (List[Path]): A list of Path objects representing the source files to be converted.\n    sf_files (List[Path]): A list of Path objects representing the destination files to be created.\n    discard_names (List[str]): A list of strings representing the names of files to be skipped.\n\nReturns:\n    None\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef convert_files(pt_files: List[Path], sf_files: List[Path], discard_names: List[str]):\n    assert len(pt_files) == len(sf_files)\n\n    N = len(pt_files)\n    # We do this instead of using tqdm because we want to parse the logs with the launcher\n\n    for i, (pt_file, sf_file) in enumerate(zip(pt_files, sf_files)):\n        # Skip blacklisted files\n        if (\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            \"arguments\" in pt_file.name\n            or \"args\" in pt_file.name\n            or \"training\" in pt_file.name\n        ):\n            continue\n\n        start = datetime.datetime.now()\n        convert_file(pt_file, sf_file, discard_names)\n        elapsed = datetime.datetime.now() - start\n        logger.info(f\"Convert: [{i + 1}/{N}] -- Took: {elapsed}\")", "completions": ["  \n[PYTHON]\ndef convert_files(pt_files: List[Path], sf_files: List[Path], discard_names: List[str]):\n    assert len(pt_files) == len(sf_files)\n\n    N = len(pt_files)\n    # We do this instead of using tqdm because we want to parse the logs with the launcher\n\n    for i, (pt_file, sf_file) in enumerate(zip(pt_files, sf_files)):\n        # Skip blacklisted files\n        if (\n            pt_file.name in discard_names\n            or sf_file.name in discard_names\n            or pt_file.name.startswith(\".\")\n            or sf_file.name.startswith(\".\")\n        ):\n            continue\n        try:\n            convert_file(pt_file, sf_file, discard_names)\n        except (InfWeightsError, NanWeightsError) as e:\n            logger.error(f\"Error while converting file {pt_file}: {e}\")\n        except RuntimeError as e:\n            logger.error(f\"Error while converting file {pt_file}: {e}\")\n        except Exception as e:\n            logger.error(f\"Unknown error while converting file {pt_file}: {e}\")\n        finally:\n            logger.info(f\"Converted {i+1}/{N} files\")\n[/PYTHON]\n"]}
{"id": 69, "name": "compute_temperature_features", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n\n   Copyright 2014-2024 OpenEEmeter contributors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\nfrom ..models.hourly.segmentation import iterate_segmented_dataset\nfrom .transform import day_counts, overwrite_partial_rows_with_nan\nfrom .warnings import EEMeterWarning\n\n__all__ = (\n    \"compute_usage_per_day_feature\",\n    \"compute_occupancy_feature\",\n    \"compute_temperature_features\",\n    \"compute_temperature_bin_features\",\n    \"compute_time_features\",\n    \"estimate_hour_of_week_occupancy\",\n    \"fit_temperature_bins\",\n    \"get_missing_hours_of_week_warning\",\n    \"merge_features\",\n)\n\n\ndef merge_features(features, keep_partial_nan_rows=False):\n    \"\"\"\n    Combine dataframes of features which share a datetime index.\n\n    Parameters\n    ----------\n    features : :any:`list` of :any:`pandas.DataFrame`\n        List of dataframes to be concatenated to share an index.\n    keep_partial_nan_rows : :any:`bool`, default False\n        If True, don't overwrite partial rows with NaN, otherwise any row with a NaN\n        value gets changed to all NaN values.\n\n    Returns\n    -------\n    merged_features : :any:`pandas.DataFrame`\n        A single dataframe with the index of the input data and all of the columns\n        in the input feature dataframes.\n    \"\"\"\n\n    def _to_frame_if_needed(df_or_series):\n        if isinstance(df_or_series, pd.Series):\n            return df_or_series.to_frame()\n        return df_or_series\n\n    df = pd.concat([_to_frame_if_needed(feature) for feature in features], axis=1)\n\n    if not keep_partial_nan_rows:\n        df = overwrite_partial_rows_with_nan(df)\n    return df\n\n\ndef compute_usage_per_day_feature(meter_data, series_name=\"usage_per_day\"):\n    \"\"\"Compute average usage per day for billing/daily data.\n\n    Parameters\n    ----------\n    meter_data : :any:`pandas.DataFrame`\n        Meter data for which to compute usage per day.\n    series_name : :any:`str`\n        Name of the output pandas series\n\n    Returns\n    -------\n    usage_per_day_feature : :any:`pandas.Series`\n        The usage per day feature.\n    \"\"\"\n    # CalTrack 3.3.1.1\n    # convert to average daily meter values.\n    usage_per_day = meter_data.value / day_counts(meter_data.index)\n    return pd.Series(usage_per_day, name=series_name)\n\n\ndef get_missing_hours_of_week_warning(hours_of_week):\n    \"\"\"Warn if any hours of week (0-167) are missing.\n\n    Parameters\n    ----------\n    hours_of_week : :any:`pandas.Series`\n        Hour of week feature as given by :any:`eemeter.compute_time_features`.\n\n    Returns\n    -------\n    warning : :any:`eemeter.EEMeterWarning`\n        Warning with qualified name \"eemeter.hour_of_week.missing\"\n    \"\"\"\n    unique = set(hours_of_week.unique())\n    total = set(range(168))\n    missing = sorted(total - unique)\n    if len(missing) == 0:\n        return None\n    else:\n        return EEMeterWarning(\n            qualified_name=\"eemeter.hour_of_week.missing\",\n            description=\"Missing some of the (zero-indexed) 168 hours of the week.\",\n            data={\"missing_hours_of_week\": missing},\n        )\n\n\ndef compute_time_features(index, hour_of_week=True, day_of_week=True, hour_of_day=True):\n    \"\"\"Compute hour of week, day of week, or hour of day features.\n\n    Parameters\n    ----------\n    index : :any:`pandas.DatetimeIndex`\n        Datetime index with hourly frequency.\n    hour_of_week : :any:`bool`\n        Include the `hour_of_week` feature.\n    day_of_week : :any:`bool`\n        Include the `day_of_week` feature.\n    hour_of_day : :any:`bool`\n        Include the `hour_of_day` feature.\n\n    Returns\n    -------\n    time_features : :any:`pandas.DataFrame`\n        A dataframe with the input datetime index and up to three columns\n\n        - hour_of_week : Label for hour of week, 0-167, 0 is 12-1am Monday\n        - day_of_week : Label for day of week, 0-6, 0 is Monday.\n        - hour_of_day : Label for hour of day, 0-23, 0 is 12-1am.\n    \"\"\"\n    if index.freq != \"H\":\n        raise ValueError(\n            \"index must have hourly frequency (freq='H').\"\n            \" Found: {}\".format(index.freq)\n        )\n\n    dow_feature = pd.Series(index.dayofweek, index=index, name=\"day_of_week\")\n    hod_feature = pd.Series(index.hour, index=index, name=\"hour_of_day\")\n    how_feature = (dow_feature * 24 + hod_feature).rename(\"hour_of_week\")\n\n    features = []\n    warnings = []\n\n    if day_of_week:\n        features.append(dow_feature.astype(\"category\"))\n    if hour_of_day:\n        features.append(hod_feature.astype(\"category\"))\n    if hour_of_week:\n        how_feature = how_feature.astype(\"category\")\n        features.append(how_feature)\n        warning = get_missing_hours_of_week_warning(how_feature)\n        if warning is not None:\n            warnings.append(warning)\n\n    if len(features) == 0:\n        raise ValueError(\"No features selected.\")\n\n    time_features = merge_features(features)\n    return time_features\n\n\ndef _matching_groups(index, df, tolerance):\n    # convert index to df for use with merge_asof\n    index_df = pd.DataFrame({\"index_col\": index}, index=index)\n\n    # get a dataframe containing mean temperature\n    #   1) merge by matching temperature to closest previous meter start date,\n    #      up to tolerance limit, using merge_asof.\n    #   2) group by meter_index, and take the mean, ignoring all columns except\n    #      the temperature column.\n    groups = pd.merge_asof(\n        left=df, right=index_df, left_index=True, right_index=True, tolerance=tolerance\n    ).groupby(\"index_col\")\n    return groups\n\n\ndef _degree_day_columns(\n    heating_balance_points,\n    cooling_balance_points,\n    degree_day_method,\n    percent_hourly_coverage_per_day,\n    percent_hourly_coverage_per_billing_period,\n    use_mean_daily_values,\n):\n    # TODO(philngo): can this be refactored to be a more general without losing\n    # on performance?\n\n    # Not used in CalTRACK 2.0\n    if degree_day_method == \"hourly\":\n\n        def _compute_columns(temps):\n            n_temps = temps.shape[0]\n            n_temps_kept = temps.count()\n            count_cols = {\n                \"n_hours_kept\": n_temps_kept,\n                \"n_hours_dropped\": n_temps - n_temps_kept,\n            }\n            if use_mean_daily_values:\n                n_days = 1\n            else:\n                n_days = n_temps / 24.0\n            cdd_cols = {\n                \"cdd_%s\" % bp: np.maximum(temps - bp, 0).mean() * n_days\n                for bp in cooling_balance_points\n            }\n            hdd_cols = {\n                \"hdd_%s\" % bp: np.maximum(bp - temps, 0).mean() * n_days\n                for bp in heating_balance_points\n            }\n\n            columns = count_cols\n            columns.update(cdd_cols)\n            columns.update(hdd_cols)\n            return columns\n\n    # CalTRACK 2.2.2.3\n    n_limit_daily = 24 * percent_hourly_coverage_per_day\n\n    if degree_day_method == \"daily\":\n\n        def _compute_columns(temps):\n            count = temps.shape[0]\n            if count > 24:\n                day_groups = np.floor(np.arange(count) / 24)\n                daily_temps = temps.groupby(day_groups).agg([\"mean\", \"count\"])\n                n_limit_period = percent_hourly_coverage_per_billing_period * count\n                n_days_total = daily_temps.shape[0]\n\n                # CalTrack 2.2.3.2\n                if temps.notnull().sum() < n_limit_period:\n                    daily_temps = daily_temps[\"mean\"].iloc[0:0]\n                else:\n                    # CalTRACK 2.2.2.3\n                    daily_temps = daily_temps[\"mean\"][\n                        daily_temps[\"count\"] > n_limit_daily\n                    ]\n                n_days_kept = daily_temps.shape[0]\n                count_cols = {\n                    \"n_days_kept\": n_days_kept,\n                    \"n_days_dropped\": n_days_total - n_days_kept,\n                }\n\n                if use_mean_daily_values:\n                    n_days = 1\n                else:\n                    n_days = n_days_total\n\n                cdd_cols = {\n                    \"cdd_%s\" % bp: np.maximum(daily_temps - bp, 0).mean() * n_days\n                    for bp in cooling_balance_points\n                }\n                hdd_cols = {\n                    \"hdd_%s\" % bp: np.maximum(bp - daily_temps, 0).mean() * n_days\n                    for bp in heating_balance_points\n                }\n            else:  # faster route for daily case, should have same effect.\n                if count > n_limit_daily:\n                    count_cols = {\"n_days_kept\": 1, \"n_days_dropped\": 0}\n                    # CalTRACK 2.2.2.3\n                    mean_temp = temps.mean()\n                else:\n                    count_cols = {\"n_days_kept\": 0, \"n_days_dropped\": 1}\n                    mean_temp = np.nan\n\n                # CalTrack 3.3.4.1.1\n                cdd_cols = {\n                    \"cdd_%s\" % bp: np.maximum(mean_temp - bp, 0)\n                    for bp in cooling_balance_points\n                }\n\n                # CalTrack 3.3.5.1.1\n                hdd_cols = {\n                    \"hdd_%s\" % bp: np.maximum(bp - mean_temp, 0)\n                    for bp in heating_balance_points\n                }\n\n            columns = count_cols\n            columns.update(cdd_cols)\n            columns.update(hdd_cols)\n            return columns\n\n    # TODO(philngo): option to ignore the count columns?\n\n    agg_funcs = [(\"degree_day_columns\", _compute_columns)]\n    return agg_funcs\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function computes temperature features based on meter data and temperature data.\n\nArgs:\n    meter_data_index (pandas.DatetimeIndex): The index of the meter data.\n    temperature_data (pandas.Series): The temperature data.\n    heating_balance_points (list, optional): The heating balance points. Defaults to None.\n    cooling_balance_points (list, optional): The cooling balance points. Defaults to None.\n    data_quality (bool, optional): Whether to compute data quality features. Defaults to False.\n    temperature_mean (bool, optional): Whether to compute the mean temperature. Defaults to True.\n    degree_day_method (str, optional): The method to compute degree days. Defaults to \"daily\".\n    percent_hourly_coverage_per_day (float, optional): The percentage of hourly coverage per day. Defaults to 0.5.\n    percent_hourly_coverage_per_billing_period (float, optional): The percentage of hourly coverage per billing period. Defaults to 0.9.\n    use_mean_daily_values (bool, optional): Whether to use mean daily values. Defaults to True.\n    tolerance (pandas.Timedelta, optional): The tolerance for matching groups. Defaults to None.\n    keep_partial_nan_rows (bool, optional): Whether to keep partial NaN rows. Defaults to False.\n\nReturns:\n    pandas.DataFrame: The computed temperature features.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef compute_temperature_features(\n    meter_data_index,\n    temperature_data,\n    heating_balance_points=None,\n    cooling_balance_points=None,\n    data_quality=False,\n    temperature_mean=True,\n    degree_day_method=\"daily\",\n    percent_hourly_coverage_per_day=0.5,\n    percent_hourly_coverage_per_billing_period=0.9,\n    use_mean_daily_values=True,\n    tolerance=None,\n    keep_partial_nan_rows=False,\n):\n    if temperature_data.index.freq != \"H\":\n        raise ValueError(\n            \"temperature_data.index must have hourly frequency (freq='H').\"\n            \" Found: {}\".format(temperature_data.index.freq)\n        )\n\n    if not temperature_data.index.tz:\n        raise ValueError(\n            \"temperature_data.index must be timezone-aware. You can set it with\"\n            \" temperature_data.tz_localize(...).\"\n        )\n\n    if meter_data_index.freq is None and meter_data_index.inferred_freq == \"H\":\n        raise ValueError(\n            \"If you have hourly data explicitly set the frequency\"\n            \" of the dataframe by setting\"\n            \"``meter_data_index.freq =\"\n            \" pd.tseries.frequencies.to_offset('H').\"\n        )\n\n    if not meter_data_index.tz:\n        raise ValueError(\n            \"meter_data_index must be timezone-aware. You can set it with\"\n            \" meter_data.tz_localize(...).\"\n        )\n\n    if meter_data_index.duplicated().any():\n        raise ValueError(\"Duplicates found in input meter trace index.\")\n\n    temp_agg_funcs = []\n    temp_agg_column_renames = {}\n\n    if heating_balance_points is None:\n        heating_balance_points = []\n    if cooling_balance_points is None:\n        cooling_balance_points = []\n\n    if meter_data_index.freq is not None:\n        try:\n            freq_timedelta = pd.Timedelta(meter_data_index.freq)\n        except ValueError:  # freq cannot be converted to timedelta\n            freq_timedelta = None\n    else:\n        freq_timedelta = None\n\n    if tolerance is None:\n        tolerance = freq_timedelta\n\n    if not (heating_balance_points == [] and cooling_balance_points == []):\n        if degree_day_method == \"hourly\":\n            pass\n        elif degree_day_method == \"daily\":\n            if meter_data_index.freq == \"H\":\n                raise ValueError(\n                    \"degree_day_method='daily' must be used with\"\n                    \" daily meter data. Found: 'hourly'\".format(degree_day_method)\n                )\n        else:\n            raise ValueError(\"method not supported: {}\".format(degree_day_method))\n\n    if freq_timedelta == pd.Timedelta(\"1H\"):\n        # special fast route for hourly data.\n        df = temperature_data.to_frame(\"temperature_mean\").reindex(meter_data_index)\n\n        if use_mean_daily_values:\n            n_days = 1\n        else:\n            n_days = 1.0 / 24.0\n\n        df = df.assign(\n            **{\n                \"cdd_{}\".format(bp): np.maximum(df.temperature_mean - bp, 0) * n_days\n                for bp in cooling_balance_points\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            }\n        )\n        df = df.assign(\n            **{\n                \"hdd_{}\".format(bp): np.maximum(bp - df.temperature_mean, 0) * n_days\n                for bp in heating_balance_points\n            }\n        )\n        df = df.assign(\n            n_hours_dropped=df.temperature_mean.isnull().astype(int),\n            n_hours_kept=df.temperature_mean.notnull().astype(int),\n        )\n        # TODO(philngo): bad interface or maybe this is just wrong for some reason?\n        if data_quality:\n            df = df.assign(\n                temperature_null=df.n_hours_dropped,\n                temperature_not_null=df.n_hours_kept,\n            )\n        if not temperature_mean:\n            del df[\"temperature_mean\"]\n    else:\n        # daily/billing route\n        # heating/cooling degree day aggregations. Needed for n_days fields as well.\n        temp_agg_funcs.extend(\n            _degree_day_columns(\n                heating_balance_points=heating_balance_points,\n                cooling_balance_points=cooling_balance_points,\n                degree_day_method=degree_day_method,\n                percent_hourly_coverage_per_day=percent_hourly_coverage_per_day,\n                percent_hourly_coverage_per_billing_period=percent_hourly_coverage_per_billing_period,\n                use_mean_daily_values=use_mean_daily_values,\n            )\n        )\n        temp_agg_column_renames.update(\n            {(\"temp\", \"degree_day_columns\"): \"degree_day_columns\"}\n        )\n\n        if data_quality:\n            temp_agg_funcs.extend(\n                [(\"not_null\", \"count\"), (\"null\", lambda x: x.isnull().sum())]\n            )\n            temp_agg_column_renames.update(\n                {\n                    (\"temp\", \"not_null\"): \"temperature_not_null\",\n                    (\"temp\", \"null\"): \"temperature_null\",\n                }\n            )\n\n        if temperature_mean:\n            temp_agg_funcs.extend([(\"mean\", \"mean\")])\n            temp_agg_column_renames.update({(\"temp\", \"mean\"): \"temperature_mean\"})\n\n        # aggregate temperatures\n        temp_df = temperature_data.to_frame(\"temp\")\n        temp_groups = _matching_groups(meter_data_index, temp_df, tolerance)\n        temp_aggregations = temp_groups.agg({\"temp\": temp_agg_funcs})\n\n        # expand temp aggregations by faking and deleting the `meter_value` column.\n        # I haven't yet figured out a way to avoid this and get the desired\n        # structure and behavior. (philngo)\n        meter_value = pd.DataFrame({\"meter_value\": 0}, index=meter_data_index)\n        df = pd.concat([meter_value, temp_aggregations], axis=1).rename(\n            columns=temp_agg_column_renames\n        )\n        del df[\"meter_value\"]\n\n        if \"degree_day_columns\" in df:\n            if df[\"degree_day_columns\"].dropna().empty:\n                column_defaults = {\n                    column: np.full(df[\"degree_day_columns\"].shape, np.nan)\n                    for column in [\"n_days_dropped\", \"n_days_kept\"]\n                }\n                df = df.drop([\"degree_day_columns\"], axis=1).assign(**column_defaults)\n            else:\n                df = pd.concat(\n                    [\n                        df.drop([\"degree_day_columns\"], axis=1),\n                        df[\"degree_day_columns\"].dropna().apply(pd.Series),\n                    ],\n                    axis=1,\n                )\n\n    if not keep_partial_nan_rows:\n        df = overwrite_partial_rows_with_nan(df)\n\n    # nan last row\n    df = df.iloc[:-1].reindex(df.index)\n    return df", "completions": ["  \n[PYTHON]\ndef compute_temperature_features(\n    meter_data_index,\n    temperature_data,\n    heating_balance_points=None,\n    cooling_balance_points=None,\n    data_quality=False,\n    temperature_mean=True,\n    degree_day_method=\"daily\",\n    percent_hourly_coverage_per_day=0.5,\n    percent_hourly_coverage_per_billing_period=0.9,\n    use_mean_daily_values=True,\n    tolerance=None,\n    keep_partial_nan_rows=False,\n):\n    if temperature_data.index.freq!= \"H\":\n        raise ValueError(\n            \"temperature_data.index must have hourly frequency (freq='H').\"\n            \" Found: {}\".format(temperature_data.index.freq)\n        )\n\n    if not temperature_data.index.tz:\n        raise ValueError(\n            \"temperature_data.index must be timezone-aware. You can set it with\"\n            \" temperature_data.tz_localize(...).\"\n        )\n\n    if meter_data_index.freq is None and meter_data_index.inferred_freq == \"H\":\n        raise ValueError(\n            \"If you have hourly data explicitly set the frequency\"\n            \" of the dataframe by setting\"\n            \"``meter_data_index.freq =\"\n            \" pd.tseries.frequencies.to_offset('H').\"\n        )\n\n    if not meter_data_index.tz:\n        raise ValueError(\n            \"meter_data_index must be timezone-aware. You can set it with\"\n            \" meter_data.tz_localize(...).\"\n        )\n\n    if meter_data_index.duplicated().any():\n        raise ValueError(\"Duplicates found in input meter trace index.\")\n\n    temp_agg_funcs = []\n    temp_agg_column_renames = {}\n\n    if heating_balance_points is None:\n        heating_balance_points = []\n    if cooling_balance_points is None:\n        cooling_balance_points = []\n\n    if meter_data_index.freq is not None:\n        try:\n            freq_timedelta = pd.Timedelta(meter_data_index.freq)\n        except ValueError:  # freq cannot be converted to timedelta\n            freq_timedelta = None\n    else:\n        freq_timedelta = None\n\n    if tolerance is None:\n        tolerance = freq_timedelta\n\n    if not (heating_balance_points == [] and cooling_balance_points == []):\n        if degree_day_method == \"hourly\":\n            pass\n        elif degree_day_method == \"daily\":\n            if meter_data_index.freq == \"H\":\n                raise ValueError(\n                    \"degree_day_method='daily' must be used with\"\n                    \" daily meter data. Found: 'hourly'\".format(degree_day_method)\n                )\n        else:\n            raise ValueError(\"method not supported: {}\".format(degree_day_method))\n\n    if freq_timedelta == pd.Timedelta(\"1H\"):\n        # special fast route for hourly data.\n        df = temperature_data.to_frame(\"temperature_mean\").reindex(meter_data_index)\n\n        if use_mean_daily_values:\n            n_days = 1\n        else:\n            n_days = 1.0 / 24.0\n\n        df = df.assign(\n            **{\n                \"cdd_{}\".format(bp): np.maximum(df.temperature_mean - bp, 0) * n_days\n                for bp in cooling_balance_points\n            }\n        )\n\n        if temperature_mean:\n            temp_agg_funcs.append((\"temperature_mean\", \"mean\"))\n\n        if data_quality:\n            temp_agg_funcs.append((\"temperature_mean_count\","]}
{"id": 70, "name": "polyvalfromroots", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\n=================================================\nPower Series (:mod:`numpy.polynomial.polynomial`)\n=================================================\n\nThis module provides a number of objects (mostly functions) useful for\ndealing with polynomials, including a `Polynomial` class that\nencapsulates the usual arithmetic operations.  (General information\non how this module represents and works with polynomial objects is in\nthe docstring for its \"parent\" sub-package, `numpy.polynomial`).\n\nClasses\n-------\n.. autosummary::\n   :toctree: generated/\n\n   Polynomial\n\nConstants\n---------\n.. autosummary::\n   :toctree: generated/\n\n   polydomain\n   polyzero\n   polyone\n   polyx\n\nArithmetic\n----------\n.. autosummary::\n   :toctree: generated/\n\n   polyadd\n   polysub\n   polymulx\n   polymul\n   polydiv\n   polypow\n   polyval\n   polyval2d\n   polyval3d\n   polygrid2d\n   polygrid3d\n\nCalculus\n--------\n.. autosummary::\n   :toctree: generated/\n\n   polyder\n   polyint\n\nMisc Functions\n--------------\n.. autosummary::\n   :toctree: generated/\n\n   polyfromroots\n   polyroots\n   polyvalfromroots\n   polyvander\n   polyvander2d\n   polyvander3d\n   polycompanion\n   polyfit\n   polytrim\n   polyline\n\nSee Also\n--------\n`numpy.polynomial`\n\n\"\"\"\n__all__ = [\n    'polyzero', 'polyone', 'polyx', 'polydomain', 'polyline', 'polyadd',\n    'polysub', 'polymulx', 'polymul', 'polydiv', 'polypow', 'polyval',\n    'polyvalfromroots', 'polyder', 'polyint', 'polyfromroots', 'polyvander',\n    'polyfit', 'polytrim', 'polyroots', 'Polynomial', 'polyval2d', 'polyval3d',\n    'polygrid2d', 'polygrid3d', 'polyvander2d', 'polyvander3d']\n\nimport numpy as np\nimport numpy.linalg as la\nfrom numpy.core.multiarray import normalize_axis_index\n\nfrom . import polyutils as pu\nfrom ._polybase import ABCPolyBase\n\npolytrim = pu.trimcoef\n\n#\n# These are constant arrays are of integer type so as to be compatible\n# with the widest range of other types, such as Decimal.\n#\n\n# Polynomial default domain.\npolydomain = np.array([-1, 1])\n\n# Polynomial coefficients representing zero.\npolyzero = np.array([0])\n\n# Polynomial coefficients representing one.\npolyone = np.array([1])\n\n# Polynomial coefficients representing the identity x.\npolyx = np.array([0, 1])\n\n#\n# Polynomial series functions\n#\n\n\ndef polyline(off, scl):\n    \"\"\"\n    Returns an array representing a linear polynomial.\n\n    Parameters\n    ----------\n    off, scl : scalars\n        The \"y-intercept\" and \"slope\" of the line, respectively.\n\n    Returns\n    -------\n    y : ndarray\n        This module's representation of the linear polynomial ``off +\n        scl*x``.\n\n    See Also\n    --------\n    numpy.polynomial.chebyshev.chebline\n    numpy.polynomial.legendre.legline\n    numpy.polynomial.laguerre.lagline\n    numpy.polynomial.hermite.hermline\n    numpy.polynomial.hermite_e.hermeline\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> P.polyline(1,-1)\n    array([ 1, -1])\n    >>> P.polyval(1, P.polyline(1,-1)) # should be 0\n    0.0\n\n    \"\"\"\n    if scl != 0:\n        return np.array([off, scl])\n    else:\n        return np.array([off])\n\n\ndef polyfromroots(roots):\n    \"\"\"\n    Generate a monic polynomial with given roots.\n\n    Return the coefficients of the polynomial\n\n    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),\n\n    where the ``r_n`` are the roots specified in `roots`.  If a zero has\n    multiplicity n, then it must appear in `roots` n times. For instance,\n    if 2 is a root of multiplicity three and 3 is a root of multiplicity 2,\n    then `roots` looks something like [2, 2, 2, 3, 3]. The roots can appear\n    in any order.\n\n    If the returned coefficients are `c`, then\n\n    .. math:: p(x) = c_0 + c_1 * x + ... +  x^n\n\n    The coefficient of the last term is 1 for monic polynomials in this\n    form.\n\n    Parameters\n    ----------\n    roots : array_like\n        Sequence containing the roots.\n\n    Returns\n    -------\n    out : ndarray\n        1-D array of the polynomial's coefficients If all the roots are\n        real, then `out` is also real, otherwise it is complex.  (see\n        Examples below).\n\n    See Also\n    --------\n    numpy.polynomial.chebyshev.chebfromroots\n    numpy.polynomial.legendre.legfromroots\n    numpy.polynomial.laguerre.lagfromroots\n    numpy.polynomial.hermite.hermfromroots\n    numpy.polynomial.hermite_e.hermefromroots\n\n    Notes\n    -----\n    The coefficients are determined by multiplying together linear factors\n    of the form ``(x - r_i)``, i.e.\n\n    .. math:: p(x) = (x - r_0) (x - r_1) ... (x - r_n)\n\n    where ``n == len(roots) - 1``; note that this implies that ``1`` is always\n    returned for :math:`a_n`.\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> P.polyfromroots((-1,0,1)) # x(x - 1)(x + 1) = x^3 - x\n    array([ 0., -1.,  0.,  1.])\n    >>> j = complex(0,1)\n    >>> P.polyfromroots((-j,j)) # complex returned, though values are real\n    array([1.+0.j,  0.+0.j,  1.+0.j])\n\n    \"\"\"\n    return pu._fromroots(polyline, polymul, roots)\n\n\ndef polyadd(c1, c2):\n    \"\"\"\n    Add one polynomial to another.\n\n    Returns the sum of two polynomials `c1` + `c2`.  The arguments are\n    sequences of coefficients from lowest order term to highest, i.e.,\n    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``.\n\n    Parameters\n    ----------\n    c1, c2 : array_like\n        1-D arrays of polynomial coefficients ordered from low to high.\n\n    Returns\n    -------\n    out : ndarray\n        The coefficient array representing their sum.\n\n    See Also\n    --------\n    polysub, polymulx, polymul, polydiv, polypow\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c1 = (1,2,3)\n    >>> c2 = (3,2,1)\n    >>> sum = P.polyadd(c1,c2); sum\n    array([4.,  4.,  4.])\n    >>> P.polyval(2, sum) # 4 + 4(2) + 4(2**2)\n    28.0\n\n    \"\"\"\n    return pu._add(c1, c2)\n\n\ndef polysub(c1, c2):\n    \"\"\"\n    Subtract one polynomial from another.\n\n    Returns the difference of two polynomials `c1` - `c2`.  The arguments\n    are sequences of coefficients from lowest order term to highest, i.e.,\n    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``.\n\n    Parameters\n    ----------\n    c1, c2 : array_like\n        1-D arrays of polynomial coefficients ordered from low to\n        high.\n\n    Returns\n    -------\n    out : ndarray\n        Of coefficients representing their difference.\n\n    See Also\n    --------\n    polyadd, polymulx, polymul, polydiv, polypow\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c1 = (1,2,3)\n    >>> c2 = (3,2,1)\n    >>> P.polysub(c1,c2)\n    array([-2.,  0.,  2.])\n    >>> P.polysub(c2,c1) # -P.polysub(c1,c2)\n    array([ 2.,  0., -2.])\n\n    \"\"\"\n    return pu._sub(c1, c2)\n\n\ndef polymulx(c):\n    \"\"\"Multiply a polynomial by x.\n\n    Multiply the polynomial `c` by x, where x is the independent\n    variable.\n\n\n    Parameters\n    ----------\n    c : array_like\n        1-D array of polynomial coefficients ordered from low to\n        high.\n\n    Returns\n    -------\n    out : ndarray\n        Array representing the result of the multiplication.\n\n    See Also\n    --------\n    polyadd, polysub, polymul, polydiv, polypow\n\n    Notes\n    -----\n\n    .. versionadded:: 1.5.0\n\n    \"\"\"\n    # c is a trimmed copy\n    [c] = pu.as_series([c])\n    # The zero series needs special treatment\n    if len(c) == 1 and c[0] == 0:\n        return c\n\n    prd = np.empty(len(c) + 1, dtype=c.dtype)\n    prd[0] = c[0]*0\n    prd[1:] = c\n    return prd\n\n\ndef polymul(c1, c2):\n    \"\"\"\n    Multiply one polynomial by another.\n\n    Returns the product of two polynomials `c1` * `c2`.  The arguments are\n    sequences of coefficients, from lowest order term to highest, e.g.,\n    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2.``\n\n    Parameters\n    ----------\n    c1, c2 : array_like\n        1-D arrays of coefficients representing a polynomial, relative to the\n        \"standard\" basis, and ordered from lowest order term to highest.\n\n    Returns\n    -------\n    out : ndarray\n        Of the coefficients of their product.\n\n    See Also\n    --------\n    polyadd, polysub, polymulx, polydiv, polypow\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c1 = (1,2,3)\n    >>> c2 = (3,2,1)\n    >>> P.polymul(c1,c2)\n    array([  3.,   8.,  14.,   8.,   3.])\n\n    \"\"\"\n    # c1, c2 are trimmed copies\n    [c1, c2] = pu.as_series([c1, c2])\n    ret = np.convolve(c1, c2)\n    return pu.trimseq(ret)\n\n\ndef polydiv(c1, c2):\n    \"\"\"\n    Divide one polynomial by another.\n\n    Returns the quotient-with-remainder of two polynomials `c1` / `c2`.\n    The arguments are sequences of coefficients, from lowest order term\n    to highest, e.g., [1,2,3] represents ``1 + 2*x + 3*x**2``.\n\n    Parameters\n    ----------\n    c1, c2 : array_like\n        1-D arrays of polynomial coefficients ordered from low to high.\n\n    Returns\n    -------\n    [quo, rem] : ndarrays\n        Of coefficient series representing the quotient and remainder.\n\n    See Also\n    --------\n    polyadd, polysub, polymulx, polymul, polypow\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c1 = (1,2,3)\n    >>> c2 = (3,2,1)\n    >>> P.polydiv(c1,c2)\n    (array([3.]), array([-8., -4.]))\n    >>> P.polydiv(c2,c1)\n    (array([ 0.33333333]), array([ 2.66666667,  1.33333333])) # may vary\n\n    \"\"\"\n    # c1, c2 are trimmed copies\n    [c1, c2] = pu.as_series([c1, c2])\n    if c2[-1] == 0:\n        raise ZeroDivisionError()\n\n    # note: this is more efficient than `pu._div(polymul, c1, c2)`\n    lc1 = len(c1)\n    lc2 = len(c2)\n    if lc1 < lc2:\n        return c1[:1]*0, c1\n    elif lc2 == 1:\n        return c1/c2[-1], c1[:1]*0\n    else:\n        dlen = lc1 - lc2\n        scl = c2[-1]\n        c2 = c2[:-1]/scl\n        i = dlen\n        j = lc1 - 1\n        while i >= 0:\n            c1[i:j] -= c2*c1[j]\n            i -= 1\n            j -= 1\n        return c1[j+1:]/scl, pu.trimseq(c1[:j+1])\n\n\ndef polypow(c, pow, maxpower=None):\n    \"\"\"Raise a polynomial to a power.\n\n    Returns the polynomial `c` raised to the power `pow`. The argument\n    `c` is a sequence of coefficients ordered from low to high. i.e.,\n    [1,2,3] is the series  ``1 + 2*x + 3*x**2.``\n\n    Parameters\n    ----------\n    c : array_like\n        1-D array of array of series coefficients ordered from low to\n        high degree.\n    pow : integer\n        Power to which the series will be raised\n    maxpower : integer, optional\n        Maximum power allowed. This is mainly to limit growth of the series\n        to unmanageable size. Default is 16\n\n    Returns\n    -------\n    coef : ndarray\n        Power series of power.\n\n    See Also\n    --------\n    polyadd, polysub, polymulx, polymul, polydiv\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> P.polypow([1,2,3], 2)\n    array([ 1., 4., 10., 12., 9.])\n\n    \"\"\"\n    # note: this is more efficient than `pu._pow(polymul, c1, c2)`, as it\n    # avoids calling `as_series` repeatedly\n    return pu._pow(np.convolve, c, pow, maxpower)\n\n\ndef polyder(c, m=1, scl=1, axis=0):\n    \"\"\"\n    Differentiate a polynomial.\n\n    Returns the polynomial coefficients `c` differentiated `m` times along\n    `axis`.  At each iteration the result is multiplied by `scl` (the\n    scaling factor is for use in a linear change of variable).  The\n    argument `c` is an array of coefficients from low to high degree along\n    each axis, e.g., [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``\n    while [[1,2],[1,2]] represents ``1 + 1*x + 2*y + 2*x*y`` if axis=0 is\n    ``x`` and axis=1 is ``y``.\n\n    Parameters\n    ----------\n    c : array_like\n        Array of polynomial coefficients. If c is multidimensional the\n        different axis correspond to different variables with the degree\n        in each axis given by the corresponding index.\n    m : int, optional\n        Number of derivatives taken, must be non-negative. (Default: 1)\n    scl : scalar, optional\n        Each differentiation is multiplied by `scl`.  The end result is\n        multiplication by ``scl**m``.  This is for use in a linear change\n        of variable. (Default: 1)\n    axis : int, optional\n        Axis over which the derivative is taken. (Default: 0).\n\n        .. versionadded:: 1.7.0\n\n    Returns\n    -------\n    der : ndarray\n        Polynomial coefficients of the derivative.\n\n    See Also\n    --------\n    polyint\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c = (1,2,3,4) # 1 + 2x + 3x**2 + 4x**3\n    >>> P.polyder(c) # (d/dx)(c) = 2 + 6x + 12x**2\n    array([  2.,   6.,  12.])\n    >>> P.polyder(c,3) # (d**3/dx**3)(c) = 24\n    array([24.])\n    >>> P.polyder(c,scl=-1) # (d/d(-x))(c) = -2 - 6x - 12x**2\n    array([ -2.,  -6., -12.])\n    >>> P.polyder(c,2,-1) # (d**2/d(-x)**2)(c) = 6 + 24x\n    array([  6.,  24.])\n\n    \"\"\"\n    c = np.array(c, ndmin=1, copy=True)\n    if c.dtype.char in '?bBhHiIlLqQpP':\n        # astype fails with NA\n        c = c + 0.0\n    cdt = c.dtype\n    cnt = pu._deprecate_as_int(m, \"the order of derivation\")\n    iaxis = pu._deprecate_as_int(axis, \"the axis\")\n    if cnt < 0:\n        raise ValueError(\"The order of derivation must be non-negative\")\n    iaxis = normalize_axis_index(iaxis, c.ndim)\n\n    if cnt == 0:\n        return c\n\n    c = np.moveaxis(c, iaxis, 0)\n    n = len(c)\n    if cnt >= n:\n        c = c[:1]*0\n    else:\n        for i in range(cnt):\n            n = n - 1\n            c *= scl\n            der = np.empty((n,) + c.shape[1:], dtype=cdt)\n            for j in range(n, 0, -1):\n                der[j - 1] = j*c[j]\n            c = der\n    c = np.moveaxis(c, 0, iaxis)\n    return c\n\n\ndef polyint(c, m=1, k=[], lbnd=0, scl=1, axis=0):\n    \"\"\"\n    Integrate a polynomial.\n\n    Returns the polynomial coefficients `c` integrated `m` times from\n    `lbnd` along `axis`.  At each iteration the resulting series is\n    **multiplied** by `scl` and an integration constant, `k`, is added.\n    The scaling factor is for use in a linear change of variable.  (\"Buyer\n    beware\": note that, depending on what one is doing, one may want `scl`\n    to be the reciprocal of what one might expect; for more information,\n    see the Notes section below.) The argument `c` is an array of\n    coefficients, from low to high degree along each axis, e.g., [1,2,3]\n    represents the polynomial ``1 + 2*x + 3*x**2`` while [[1,2],[1,2]]\n    represents ``1 + 1*x + 2*y + 2*x*y`` if axis=0 is ``x`` and axis=1 is\n    ``y``.\n\n    Parameters\n    ----------\n    c : array_like\n        1-D array of polynomial coefficients, ordered from low to high.\n    m : int, optional\n        Order of integration, must be positive. (Default: 1)\n    k : {[], list, scalar}, optional\n        Integration constant(s).  The value of the first integral at zero\n        is the first value in the list, the value of the second integral\n        at zero is the second value, etc.  If ``k == []`` (the default),\n        all constants are set to zero.  If ``m == 1``, a single scalar can\n        be given instead of a list.\n    lbnd : scalar, optional\n        The lower bound of the integral. (Default: 0)\n    scl : scalar, optional\n        Following each integration the result is *multiplied* by `scl`\n        before the integration constant is added. (Default: 1)\n    axis : int, optional\n        Axis over which the integral is taken. (Default: 0).\n\n        .. versionadded:: 1.7.0\n\n    Returns\n    -------\n    S : ndarray\n        Coefficient array of the integral.\n\n    Raises\n    ------\n    ValueError\n        If ``m < 1``, ``len(k) > m``, ``np.ndim(lbnd) != 0``, or\n        ``np.ndim(scl) != 0``.\n\n    See Also\n    --------\n    polyder\n\n    Notes\n    -----\n    Note that the result of each integration is *multiplied* by `scl`.  Why\n    is this important to note?  Say one is making a linear change of\n    variable :math:`u = ax + b` in an integral relative to `x`. Then\n    :math:`dx = du/a`, so one will need to set `scl` equal to\n    :math:`1/a` - perhaps not what one would have first thought.\n\n    Examples\n    --------\n    >>> from numpy.polynomial import polynomial as P\n    >>> c = (1,2,3)\n    >>> P.polyint(c) # should return array([0, 1, 1, 1])\n    array([0.,  1.,  1.,  1.])\n    >>> P.polyint(c,3) # should return array([0, 0, 0, 1/6, 1/12, 1/20])\n     array([ 0.        ,  0.        ,  0.        ,  0.16666667,  0.08333333, # may vary\n             0.05      ])\n    >>> P.polyint(c,k=3) # should return array([3, 1, 1, 1])\n    array([3.,  1.,  1.,  1.])\n    >>> P.polyint(c,lbnd=-2) # should return array([6, 1, 1, 1])\n    array([6.,  1.,  1.,  1.])\n    >>> P.polyint(c,scl=-2) # should return array([0, -2, -2, -2])\n    array([ 0., -2., -2., -2.])\n\n    \"\"\"\n    c = np.array(c, ndmin=1, copy=True)\n    if c.dtype.char in '?bBhHiIlLqQpP':\n        # astype doesn't preserve mask attribute.\n        c = c + 0.0\n    cdt = c.dtype\n    if not np.iterable(k):\n        k = [k]\n    cnt = pu._deprecate_as_int(m, \"the order of integration\")\n    iaxis = pu._deprecate_as_int(axis, \"the axis\")\n    if cnt < 0:\n        raise ValueError(\"The order of integration must be non-negative\")\n    if len(k) > cnt:\n        raise ValueError(\"Too many integration constants\")\n    if np.ndim(lbnd) != 0:\n        raise ValueError(\"lbnd must be a scalar.\")\n    if np.ndim(scl) != 0:\n        raise ValueError(\"scl must be a scalar.\")\n    iaxis = normalize_axis_index(iaxis, c.ndim)\n\n    if cnt == 0:\n        return c\n\n    k = list(k) + [0]*(cnt - len(k))\n    c = np.moveaxis(c, iaxis, 0)\n    for i in range(cnt):\n        n = len(c)\n        c *= scl\n        if n == 1 and np.all(c[0] == 0):\n            c[0] += k[i]\n        else:\n            tmp = np.empty((n + 1,) + c.shape[1:], dtype=cdt)\n            tmp[0] = c[0]*0\n            tmp[1] = c[0]\n            for j in range(1, n):\n                tmp[j + 1] = c[j]/(j + 1)\n            tmp[0] += k[i] - polyval(lbnd, tmp)\n            c = tmp\n    c = np.moveaxis(c, 0, iaxis)\n    return c\n\n\ndef polyval(x, c, tensor=True):\n    \"\"\"\n    Evaluate a polynomial at points x.\n\n    If `c` is of length `n + 1`, this function returns the value\n\n    .. math:: p(x) = c_0 + c_1 * x + ... + c_n * x^n\n\n    The parameter `x` is converted to an array only if it is a tuple or a\n    list, otherwise it is treated as a scalar. In either case, either `x`\n    or its elements must support multiplication and addition both with\n    themselves and with the elements of `c`.\n\n    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If\n    `c` is multidimensional, then the shape of the result depends on the\n    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +\n    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that\n    scalars have shape (,).\n\n    Trailing zeros in the coefficients will be used in the evaluation, so\n    they should be avoided if efficiency is a concern.\n\n    Parameters\n    ----------\n    x : array_like, compatible object\n        If `x` is a list or tuple, it is converted to an ndarray, otherwise\n        it is left unchanged and treated as a scalar. In either case, `x`\n        or its elements must support addition and multiplication with\n        with themselves and with the elements of `c`.\n    c : array_like\n        Array of coefficients ordered so that the coefficients for terms of\n        degree n are contained in c[n]. If `c` is multidimensional the\n        remaining indices enumerate multiple polynomials. In the two\n        dimensional case the coefficients may be thought of as stored in\n        the columns of `c`.\n    tensor : boolean, optional\n        If True, the shape of the coefficient array is extended with ones\n        on the right, one for each dimension of `x`. Scalars have dimension 0\n        for this action. The result is that every column of coefficients in\n        `c` is evaluated for every element of `x`. If False, `x` is broadcast\n        over the columns of `c` for the evaluation.  This keyword is useful\n        when `c` is multidimensional. The default value is True.\n\n        .. versionadded:: 1.7.0\n\n    Returns\n    -------\n    values : ndarray, compatible object\n        The shape of the returned array is described above.\n\n    See Also\n    --------\n    polyval2d, polygrid2d, polyval3d, polygrid3d\n\n    Notes\n    -----\n    The evaluation uses Horner's method.\n\n    Examples\n    --------\n    >>> from numpy.polynomial.polynomial import polyval\n    >>> polyval(1, [1,2,3])\n    6.0\n    >>> a = np.arange(4).reshape(2,2)\n    >>> a\n    array([[0, 1],\n           [2, 3]])\n    >>> polyval(a, [1,2,3])\n    array([[ 1.,   6.],\n           [17.,  34.]])\n    >>> coef = np.arange(4).reshape(2,2) # multidimensional coefficients\n    >>> coef\n    array([[0, 1],\n           [2, 3]])\n    >>> polyval([1,2], coef, tensor=True)\n    array([[2.,  4.],\n           [4.,  7.]])\n    >>> polyval([1,2], coef, tensor=False)\n    array([2.,  7.])\n\n    \"\"\"\n    c = np.array(c, ndmin=1, copy=False)\n    if c.dtype.char in '?bBhHiIlLqQpP':\n        # astype fails with NA\n        c = c + 0.0\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if isinstance(x, np.ndarray) and tensor:\n        c = c.reshape(c.shape + (1,)*x.ndim)\n\n    c0 = c[-1] + x*0\n    for i in range(2, len(c) + 1):\n        c0 = c[-i] + c0*x\n    return c0\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function evaluates a polynomial from its roots using numpy.prod.\n\nArgs:\n    x (array_like): The array of points at which to evaluate the polynomial.\n    r (array_like): The array of roots of the polynomial.\n    tensor (bool, optional): If True, the roots are treated as a tensor. Defaults to True.\n\nReturns:\n    ndarray: The value of the polynomial at the given points.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef polyvalfromroots(x, r, tensor=True):\n    r = np.array(r, ndmin=1, copy=False)\n    if r.dtype.char in '?bBhHiIlLqQpP':\n        r = r.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    if isinstance(x, np.ndarray):\n        if tensor:\n            r = r.reshape(r.shape + (1,)*x.ndim)\n        elif x.ndim >= r.ndim:\n            raise ValueError(\"x.ndim must be < r.ndim when tensor == False\")\n    return np.prod(x - r, axis=0)", "completions": ["  \n[PYTHON]\ndef polyvalfromroots(x, r, tensor=True):\n    r = np.array(r, ndmin=1, copy=False)\n    if r.dtype.char in '?bBhHiIlLqQpP':\n        r = r.astype(np.double)\n    if isinstance(x, (tuple, list)):\n        x = np.asarray(x)\n    if tensor:\n        r = r.reshape(r.shape + (1,)*x.ndim)\n    return np.prod(x - r, axis=0)\n[/PYTHON]\n"]}
{"id": 71, "name": "run_query_expansion_node", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport logging\nimport os\nimport pathlib\nfrom typing import List, Callable, Dict, Optional\nfrom copy import deepcopy\n\nimport pandas as pd\n\nfrom autorag.nodes.retrieval.run import evaluate_retrieval_node\nfrom autorag.strategy import measure_speed, filter_by_threshold, select_best_average\nfrom autorag.utils.util import make_combinations, explode\nfrom autorag.support import get_support_modules\n\nlogger = logging.getLogger(\"AutoRAG\")\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function runs query expansion on a given list of modules and parameters, evaluates the results, and selects the best one.\n\nArgs:\n    modules (List[Callable]): A list of callable modules to run query expansion.\n    module_params (List[Dict]): A list of dictionaries containing parameters for each module.\n    previous_result (pd.DataFrame): The previous result dataframe.\n    node_line_dir (str): The directory path for the node line.\n    strategies (Dict): A dictionary containing strategies for evaluation and filtering.\n\nReturns:\n    pd.DataFrame: The best result dataframe after running query expansion and evaluation.\n\nRaises:\n    ValueError: If no metrics are provided in the strategies for evaluation.\n\nNotes:\n    This function uses pandas.merge to merge dataframes and pandas.read_parquet to read parquet files.\n    It also uses other pandas functions like to_parquet, to_csv, and to_list.\n\"\"\"\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef run_query_expansion_node(modules: List[Callable],\n                             module_params: List[Dict],\n                             previous_result: pd.DataFrame,\n                             node_line_dir: str,\n                             strategies: Dict,\n                             ) -> pd.DataFrame:\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    if not os.path.exists(node_dir):\n        os.makedirs(node_dir)\n    project_dir = pathlib.PurePath(node_line_dir).parent.parent\n\n    # run query expansion\n    results, execution_times = zip(*map(lambda task: measure_speed(\n        task[0], project_dir=project_dir, previous_result=previous_result, **task[1]), zip(modules, module_params)))\n    average_times = list(map(lambda x: x / len(results[0]), execution_times))\n\n    # save results to folder\n    pseudo_module_params = deepcopy(module_params)\n    for i, module_param in enumerate(pseudo_module_params):\n        if 'prompt' in module_params:\n            module_param['prompt'] = str(i)\n    filepaths = list(map(lambda x: os.path.join(node_dir, f'{x}.parquet'), range(len(modules))))\n    list(map(lambda x: x[0].to_parquet(x[1], index=False), zip(results, filepaths)))  # execute save to parquet\n    filenames = list(map(lambda x: os.path.basename(x), filepaths))\n\n    # make summary file\n    summary_df = pd.DataFrame({\n        'filename': filenames,\n        'module_name': list(map(lambda module: module.__name__, modules)),\n        'module_params': module_params,\n        'execution_time': average_times,\n    })\n\n    # Run evaluation when there are more than one module.\n    if len(modules) > 1:\n        # pop general keys from strategies (e.g. metrics, speed_threshold)\n        general_key = ['metrics', 'speed_threshold']\n        general_strategy = dict(filter(lambda x: x[0] in general_key, strategies.items()))\n        extra_strategy = dict(filter(lambda x: x[0] not in general_key, strategies.items()))\n\n        # first, filter by threshold if it is enabled.\n        if general_strategy.get('speed_threshold') is not None:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            results, filenames = filter_by_threshold(results, average_times, general_strategy['speed_threshold'],\n                                                     filenames)\n\n        # check metrics in strategy\n        if general_strategy.get('metrics') is None:\n            raise ValueError(\"You must at least one metrics for query expansion evaluation.\")\n\n        if extra_strategy.get('top_k') is None:\n            extra_strategy['top_k'] = 10  # default value\n\n        # get retrieval modules from strategy\n        retrieval_callables, retrieval_params = make_retrieval_callable_params(extra_strategy)\n\n        # get retrieval_gt\n        retrieval_gt = pd.read_parquet(os.path.join(project_dir, \"data\", \"qa.parquet\"))['retrieval_gt'].tolist()\n\n        # run evaluation\n        evaluation_results = list(map(lambda result: evaluate_one_query_expansion_node(\n            retrieval_callables, retrieval_params, result['queries'].tolist(), retrieval_gt,\n            general_strategy['metrics'], project_dir, previous_result), results))\n\n        evaluation_df = pd.DataFrame({\n            'filename': filenames,\n            **{f'query_expansion_{metric_name}': list(map(lambda x: x[metric_name].mean(), evaluation_results))\n               for metric_name in general_strategy['metrics']}\n        })\n        summary_df = pd.merge(on='filename', left=summary_df, right=evaluation_df, how='left')\n\n        best_result, best_filename = select_best_average(evaluation_results, general_strategy['metrics'], filenames)\n        # change metric name columns to query_expansion_metric_name\n        best_result = best_result.rename(columns={\n            metric_name: f'query_expansion_{metric_name}' for metric_name in strategies['metrics']})\n        best_result = best_result.drop(columns=['retrieved_contents', 'retrieved_ids', 'retrieve_scores'])\n    else:\n        best_result, best_filename = results[0], filenames[0]\n        best_result = pd.concat([previous_result, best_result], axis=1)\n\n    # add 'is_best' column at summary file\n    summary_df['is_best'] = summary_df['filename'] == best_filename\n\n    # save files\n    summary_df.to_csv(os.path.join(node_dir, \"summary.csv\"), index=False)\n    best_result.to_parquet(os.path.join(node_dir, f\"best_{os.path.splitext(best_filename)[0]}.parquet\"), index=False)\n\n    return best_result", "completions": ["  \n```\ndef run_query_expansion_node(modules: List[Callable],\n                             module_params: List[Dict],\n                             previous_result: pd.DataFrame,\n                             node_line_dir: str,\n                             strategies: Dict,\n                             ) -> pd.DataFrame:\n    # Your code here\n```"]}
{"id": 72, "name": "notify_webhook_subscribers", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport typing\nimport requests\nimport logging\nfrom datetime import datetime\nfrom django.conf import settings\nfrom django.db.models import Q\nfrom django.contrib.auth import get_user_model\n\nfrom karrio.core import utils\nfrom karrio.server.core.utils import identity\nfrom karrio.server.serializers import Context\nfrom karrio.server.events import models\nimport karrio.server.events.serializers.event as serializers\n\nlogger = logging.getLogger(__name__)\nNotificationResponse = typing.Tuple[str, requests.Response]\nUser = get_user_model()\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to notify webhook subscribers about a specific event.\n\nArgs:\n    event (str): The event that is being notified.\n    data (dict): The data associated with the event.\n    event_at (datetime): The timestamp of the event.\n    ctx (dict): The context of the event.\n    **kwargs: Additional keyword arguments.\n\nReturns:\n    None: This function does not return any value.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef notify_webhook_subscribers(\n    event: str,\n    data: dict,\n    event_at: datetime,\n    ctx: dict,\n    **kwargs,\n):\n    logger.info(f\"> starting {event} subscribers notification\")\n    context = retrieve_context(ctx)\n    query = (\n        (Q(enabled_events__icontains=event) | Q(enabled_events__icontains=\"all\")),\n        (Q(disabled__isnull=True) | Q(disabled=False)),\n    )\n\n    webhooks = models.Webhook.access_by(context).filter(*query)\n    serializers.EventSerializer.map(\n        data=dict(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            type=event,\n            data=data,\n            test_mode=context.test_mode,\n            pending_webhooks=webhooks.count(),\n        ),\n        context=context,\n    ).save()\n\n    if any(webhooks):\n        payload = dict(event=event, data=data)\n        responses: typing.List[NotificationResponse] = notify_subscribers(\n            webhooks, payload\n        )\n        update_notified_webhooks(webhooks, responses, event_at)\n    else:\n        logger.info(\"no subscribers found\")\n\n    logger.info(f\"> ending {event} subscribers notification\")", "completions": ["  \n[PYTHON]\n```\ndef notify_webhook_subscribers(\n    event: str,\n    data: dict,\n    event_at: datetime,\n    ctx: dict,\n    **kwargs,\n):\n    logger.info(f\"> starting {event} subscribers notification\")\n    context = retrieve_context(ctx)\n    query = (\n        (Q(enabled_events__icontains=event) | Q(enabled_events__icontains=\"all\")),\n        (Q(disabled__isnull=True) | Q(disabled=False)),\n    )\n\n    webhooks = models.Webhook.access_by(context).filter(*query)\n    serializers.EventSerializer.map(\n        data=dict(\n            event=event,\n            data=data,\n            event_at=event_at,\n            ctx=ctx,\n            **kwargs,\n        ),\n        webhooks=webhooks,\n    )\n```\n[/PYTHON]\n"]}
{"id": 73, "name": "sample", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport numpy as np\n\n\nclass SampleTree:\n\n  def __init__(self, branching=16, seed=0):\n    assert 2 <= branching\n    self.branching = branching\n    self.root = Node()\n    self.last = None\n    self.entries = {}\n    self.rng = np.random.default_rng(seed)\n\n  def __len__(self):\n    return len(self.entries)\n\n  def insert(self, key, uprob):\n    if not self.last:\n      node = self.root\n    else:\n      ups = 0\n      node = self.last.parent\n      while node and len(node) >= self.branching:\n        node = node.parent\n        ups += 1\n      if not node:\n        node = Node()\n        node.append(self.root)\n        self.root = node\n      for _ in range(ups):\n        below = Node()\n        node.append(below)\n        node = below\n    entry = Entry(key, uprob)\n    node.append(entry)\n    self.entries[key] = entry\n    self.last = entry\n\n  def remove(self, key):\n    entry = self.entries.pop(key)\n    entry_parent = entry.parent\n    last_parent = self.last.parent\n    entry.parent.remove(entry)\n    if entry is not self.last:\n      entry_parent.append(self.last)\n    node = last_parent\n    ups = 0\n    while node.parent and not len(node):\n      above = node.parent\n      above.remove(node)\n      node = above\n      ups += 1\n    if not len(node):\n      self.last = None\n      return\n    while isinstance(node, Node):\n      node = node.children[-1]\n    self.last = node\n\n  def update(self, key, uprob):\n    entry = self.entries[key]\n    entry.uprob = uprob\n    entry.parent.recompute()\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to traverse a tree structure and select a node based on the probabilities of its children.\n\nArgs:\n    self (object): The instance of the class that contains the root node and the random number generator.\n\nReturns:\n    str: The key of the selected node.\n\nRaises:\n    ValueError: If the root node is not an instance of Node.\n\nNotes:\n    This function uses the numpy library to handle numerical operations. The numpy.isfinite function is used to check if the values in the array are finite. If not, the function creates a new array with the finite values and their corresponding probabilities. If the total sum of the probabilities is zero, the function assigns equal probabilities to all children. Otherwise, it calculates the probabilities based on the uprob values of the children. The numpy.choice function is then used to select a child based on these probabilities. The process continues until a node that is not an instance of Node is found.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\n  def sample(self):\n    node = self.root\n    while isinstance(node, Node):\n      uprobs = np.array([x.uprob for x in node.children])\n      total = uprobs.sum()\n      if not np.isfinite(total):\n        finite = np.isinf(uprobs)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        probs = finite / finite.sum()\n      elif total == 0:\n        probs = np.ones(len(uprobs)) / len(uprobs)\n      else:\n        probs = uprobs / total\n      choice = self.rng.choice(np.arange(len(uprobs)), p=probs)\n      node = node.children[choice.item()]\n    return node.key", "completions": ["  \n```\n      if not np.isfinite(total):\n        finite = np.isinf(uprobs)\n        uprobs = uprobs[finite]\n        total = uprobs.sum()\n        if total == 0:\n          uprobs = np.ones(len(uprobs))\n        else:\n          uprobs /= total\n      choice = np.random.choice(len(uprobs), p=uprobs)\n      node = node.children[choice]\n    return node.key\n```"]}
{"id": 74, "name": "download", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Iterable, List, Optional, Tuple, Type, Union\n\nimport builtins\nimport importlib\nimport json\nimport logging\nimport platform\nimport posixpath\nimport tempfile\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom dataclasses import asdict\nfrom pathlib import Path\n\nimport cloudpickle\nimport numpy as np\nimport pandas as pd\nimport yaml\n\nfrom giskard.client.dtos import ModelMetaInfo\nfrom giskard.core.errors import GiskardInstallationError\n\nfrom ...client.giskard_client import GiskardClient\nfrom ...core.core import ModelMeta, ModelType, SupportedModelTypes\nfrom ...core.validation import configured_validate_arguments\nfrom ...datasets.base import Dataset\nfrom ...exceptions.giskard_exception import GiskardException, python_env_exception_helper\nfrom ...models.cache import ModelCache\nfrom ...path_utils import get_size\nfrom ...registry.utils import dump_by_value\nfrom ...settings import settings\nfrom ...utils.logging_utils import Timer\nfrom ..cache import get_cache_enabled\nfrom ..utils import np_types_to_native\nfrom .model_prediction import ModelPredictionResults\n\nif TYPE_CHECKING:\n    from ...scanner.report import ScanReport\n\nMETA_FILENAME = \"giskard-model-meta.yaml\"\n\nMODEL_CLASS_PKL = \"ModelClass.pkl\"\n\nlogger = logging.getLogger(__name__)\n\n\ndef _validate_text_generation_params(name, description, feature_names):\n    if not name or not description:\n        raise ValueError(\n            \"The parameters 'name' and 'description' are required for 'text_generation' models, please make sure you \"\n            \"pass them when wrapping your model. Both are very important in order for the LLM-assisted testing and \"\n            \"scan to work properly. Name and description should briefly describe the expected behavior of your model. \"\n            \"Check our documentation for more information.\"\n        )\n\n    if not feature_names:\n        raise ValueError(\n            \"The parameter 'feature_names' is required for 'text_generation' models. It is a list of the input \"\n            \"variables for your model, e.g. ['question', 'user_language']. Please make sure to set this parameter \"\n            \"when wrapping your model.\"\n        )\n\n\nclass BaseModel(ABC):\n    \"\"\"\n    The BaseModel class is an abstract base class that defines the common interface for all the models used in this project.\n\n    Attributes:\n       model (Any):\n            Could be any function or ML model. The standard model output required for Giskard is:\n\n            * if classification:\n                an array (nxm) of probabilities corresponding to n data entries (rows of pandas.DataFrame)\n                and m classification_labels. In the case of binary classification, an array of (nx1) probabilities is\n                also accepted.\n                Make sure that the probability provided is for the second label provided in classification_labels.\n            * if regression or text_generation:\n                an array of predictions corresponding to data entries\n                (rows of pandas.DataFrame) and outputs.\n\n       name (Optional[str]):\n            the name of the model.\n       model_type (ModelType):\n           The type of the model: regression, classification or text_generation.\n       feature_names (Optional[Iterable[str]]):\n           list of feature names matching the column names in the data that correspond to the features which the model\n           trained on. By default, feature_names are all the Dataset columns except from target.\n       classification_threshold (float):\n           represents the classification model threshold, for binary\n           classification models.\n       classification_labels (Optional[Iterable[str]]):\n           that represents the classification labels, if model_type is\n           classification. Make sure the labels have the same order as the column output of clf.\n\n    Raises:\n        ValueError\n            If an invalid model type is specified.\n            If duplicate values are found in the classification_labels.\n    \"\"\"\n\n    should_save_model_class = False\n    id: uuid.UUID\n    _cache: ModelCache\n\n    @configured_validate_arguments\n    def __init__(\n        self,\n        model_type: ModelType,\n        name: Optional[str] = None,\n        description: Optional[str] = None,\n        feature_names: Optional[Iterable] = None,\n        classification_threshold: Optional[float] = 0.5,\n        classification_labels: Optional[Iterable] = None,\n        id: Optional[str] = None,\n        **kwargs,\n    ) -> None:\n        \"\"\"\n        Initialize a new instance of the BaseModel class.\n\n        Parameters:\n            model_type (ModelType): Type of the model, either ModelType.REGRESSION or ModelType.CLASSIFICATION.\n            name (Optional[str]): Name of the model. If not provided, defaults to the class name.\n            description (Optional[str]): Description of the model's task. Mandatory for non-langchain text_generation models.\n            feature_names (Optional[Iterable]): A list of names of the input features.\n            classification_threshold (Optional[float]): Threshold value used for classification models. Defaults to 0.5.\n            classification_labels (Optional[Iterable]): A list of labels for classification models.\n\n        Raises:\n            ValueError: If an invalid model_type value is provided.\n            ValueError: If duplicate values are found in the classification_labels list.\n\n        Notes:\n            This class uses the @configured_validate_arguments decorator to validate the input arguments.\n            The initialized object contains the following attributes:\n\n            - meta: a ModelMeta object containing metadata about the model.\n\n        \"\"\"\n        self.id = uuid.UUID(id) if id is not None else uuid.UUID(kwargs.get(\"id\", uuid.uuid4().hex))\n        if isinstance(model_type, str):\n            try:\n                model_type = SupportedModelTypes(model_type)\n            except ValueError as e:\n                available_values = {i.value for i in SupportedModelTypes}\n                raise ValueError(\n                    f'Invalid model type value \"{model_type}\". Available values are: {available_values}'\n                ) from e\n\n        if classification_labels is not None:\n            classification_labels = list(classification_labels)\n            if len(classification_labels) != len(set(classification_labels)):\n                raise ValueError(\"Duplicates are found in 'classification_labels', please only provide unique values.\")\n\n        self._cache = ModelCache(\n            model_type,\n            str(self.id),\n            persist_cache=kwargs.get(\"persist_cache\", False),\n            cache_dir=kwargs.get(\"prediction_cache_dir\"),\n        )\n\n        # sklearn and catboost will fill classification_labels before this check\n        if model_type == SupportedModelTypes.CLASSIFICATION and not classification_labels:\n            raise ValueError(\"The parameter 'classification_labels' is required if 'model_type' is 'classification'.\")\n\n        if model_type == SupportedModelTypes.TEXT_GENERATION:\n            _validate_text_generation_params(name, description, feature_names)\n\n        self.meta = ModelMeta(\n            name=name if name is not None else self.__class__.__name__,\n            description=description if description is not None else \"No description\",\n            model_type=model_type,\n            feature_names=list(feature_names) if feature_names is not None else None,\n            classification_labels=np_types_to_native(classification_labels),\n            loader_class=self.__class__.__name__,\n            loader_module=self.__module__,\n            classification_threshold=classification_threshold,\n        )\n\n    @property\n    def name(self):\n        return self.meta.name if self.meta.name is not None else self.__class__.__name__\n\n    @property\n    def description(self):\n        return self.meta.description\n\n    @property\n    def model_type(self):\n        return self.meta.model_type\n\n    @property\n    def feature_names(self):\n        return self.meta.feature_names\n\n    @property\n    def classification_labels(self):\n        return self.meta.classification_labels\n\n    @property\n    def loader_class(self):\n        return self.meta.loader_class\n\n    @property\n    def loader_module(self):\n        return self.meta.loader_module\n\n    @property\n    def classification_threshold(self):\n        return self.meta.classification_threshold\n\n    @property\n    def is_classification(self) -> bool:\n        \"\"\"Compute if the model is of type classification.\n\n        Returns:\n            bool: True if the model is of type classification, False otherwise\n        \"\"\"\n        return self.model_type == SupportedModelTypes.CLASSIFICATION\n\n    @property\n    def is_binary_classification(self) -> bool:\n        \"\"\"Compute if the model is of type binary classification.\n\n        Returns:\n            bool: True if the model is of type binary classification, False otherwise.\n        \"\"\"\n\n        return self.is_classification and len(self.classification_labels) == 2\n\n    @property\n    def is_regression(self) -> bool:\n        \"\"\"Compute if the model is of type regression.\n\n        Returns:\n            bool: True if the model is of type regression, False otherwise.\n        \"\"\"\n        return self.model_type == SupportedModelTypes.REGRESSION\n\n    @property\n    def is_text_generation(self) -> bool:\n        \"\"\"Compute if the model is of type text generation.\n\n        Returns:\n            bool: True if the model is of type text generation, False otherwise.\n        \"\"\"\n        return self.model_type == SupportedModelTypes.TEXT_GENERATION\n\n    @classmethod\n    def get_model_class(cls, class_file: Path, model_py_ver: Optional[Tuple[str, str, str]] = None):\n        with open(class_file, \"rb\") as f:\n            try:\n                # According to https://github.com/cloudpipe/cloudpickle#cloudpickle:\n                # Cloudpickle can only be used to send objects between the exact same version of Python.\n                clazz = cloudpickle.load(f)\n            except Exception as e:\n                raise python_env_exception_helper(cls.__name__, e, required_py_ver=model_py_ver)\n            if not issubclass(clazz, BaseModel):\n                raise ValueError(f\"Unknown model class: {clazz}. Models should inherit from 'BaseModel' class\")\n            return clazz\n\n    @classmethod\n    def determine_model_class(\n        cls, meta, local_dir, model_py_ver: Optional[Tuple[str, str, str]] = None, *_args, **_kwargs\n    ):\n        class_file = Path(local_dir) / MODEL_CLASS_PKL\n        if class_file.exists():\n            return cls.get_model_class(class_file, model_py_ver)\n        else:\n            return getattr(importlib.import_module(meta.loader_module), meta.loader_class)\n\n    def save_meta(self, local_path, *_args, **_kwargs):\n        with (Path(local_path) / META_FILENAME).open(mode=\"w\", encoding=\"utf-8\") as f:\n            yaml.dump(\n                {\n                    \"language_version\": platform.python_version(),\n                    \"language\": \"PYTHON\",\n                    \"model_type\": self.model_type.name.upper(),\n                    \"threshold\": self.classification_threshold,\n                    \"feature_names\": self.feature_names,\n                    \"classification_labels\": self.classification_labels,\n                    \"loader_module\": self.loader_module,\n                    \"loader_class\": self.loader_class,\n                    \"id\": str(self.id),\n                    \"name\": self.name,\n                    \"description\": self.description,\n                    \"size\": get_size(local_path),\n                },\n                f,\n                default_flow_style=False,\n            )\n\n    def save(self, local_path: Union[str, Path], *_args, **_kwargs) -> None:\n        if self.should_save_model_class:\n            self.save_model_class(local_path)\n        self.save_meta(local_path)\n\n    def save_model_class(self, local_path, *_args, **_kwargs):\n        class_file = Path(local_path) / MODEL_CLASS_PKL\n        with open(class_file, \"wb\") as f:\n            dump_by_value(self.__class__, f)\n\n    def prepare_dataframe(self, df, column_dtypes=None, target=None, *_args, **_kwargs):\n        \"\"\"\n        Prepares a Pandas DataFrame for inference by ensuring the correct columns are present and have the correct data types.\n\n        Args:\n            dataset (Dataset): The dataset to prepare.\n\n        Returns:\n            pd.DataFrame: The prepared Pandas DataFrame.\n\n        Raises:\n            ValueError: If the target column is found in the dataset.\n            ValueError: If a specified feature name is not found in the dataset.\n        \"\"\"\n        df = df.copy()\n        column_dtypes = dict(column_dtypes) if column_dtypes else None\n\n        if column_dtypes:\n            for cname, ctype in column_dtypes.items():\n                if cname not in df:\n                    df[cname] = np.nan\n\n        if target:\n            if target in df.columns:\n                df.drop(target, axis=1, inplace=True)\n            if column_dtypes and target in column_dtypes:\n                del column_dtypes[target]\n            if target and self.feature_names and target in self.feature_names:\n                self.feature_names.remove(target)\n\n        if self.feature_names:\n            if set(self.feature_names) > set(df.columns):\n                column_names = set(self.feature_names) - set(df.columns)\n                raise ValueError(\n                    f\"The following columns are not found in the dataset: {', '.join(sorted(column_names))}\"\n                )\n            df = df[self.feature_names]\n            if column_dtypes:\n                column_dtypes = {k: v for k, v in column_dtypes.items() if k in self.feature_names}\n\n        for cname, ctype in column_dtypes.items():\n            if cname not in df:\n                df[cname] = np.nan\n\n        if column_dtypes:\n            df = Dataset.cast_column_to_dtypes(df, column_dtypes)\n        return df\n\n    def predict(self, dataset: Dataset, *_args, **_kwargs) -> ModelPredictionResults:\n        \"\"\"Generates predictions for the input giskard dataset.\n        This method uses the `prepare_dataframe()` method to preprocess the input dataset before making predictions.\n        The `predict_df()` method is used to generate raw predictions for the preprocessed data.\n        The type of predictions generated by this method depends on the model type:\n\n        * For regression models, the `prediction` field of the returned `ModelPredictionResults` object will contain the same\n            values as the `raw_prediction` field.\n        * For binary or multiclass classification models, the `prediction` field of the returned `ModelPredictionResults` object\n            will contain the predicted class labels for each example in the input dataset.\n            The `probabilities` field will contain the predicted probabilities for the predicted class label.\n            The `all_predictions` field will contain the predicted probabilities for all class labels for each example in the input dataset.\n\n\n        Args:\n            dataset (Dataset): The input dataset to make predictions on.\n\n        Raises:\n            ValueError: If the prediction task is not supported by the model.\n\n        Returns:\n            ModelPredictionResults: The prediction results for the input dataset.\n        \"\"\"\n        if not len(dataset.df):\n            return ModelPredictionResults()\n        timer = Timer()\n\n        if get_cache_enabled():\n            raw_prediction = self._predict_from_cache(dataset)\n        else:\n            raw_prediction = self.predict_df(\n                self.prepare_dataframe(dataset.df, column_dtypes=dataset.column_dtypes, target=dataset.target)\n            )\n\n        if self.is_regression or self.is_text_generation:\n            result = ModelPredictionResults(\n                prediction=raw_prediction, raw_prediction=raw_prediction, raw=raw_prediction\n            )\n        elif self.is_classification:\n            labels = np.array(self.classification_labels)\n            threshold = self.classification_threshold\n\n            if threshold is not None and len(labels) == 2:\n                predicted_lbl_idx = (raw_prediction[:, 1] > threshold).astype(int)\n            else:\n                predicted_lbl_idx = raw_prediction.argmax(axis=1)\n\n            all_predictions = pd.DataFrame(raw_prediction, columns=labels)\n\n            predicted_labels = labels[predicted_lbl_idx]\n            probability = raw_prediction[range(len(predicted_lbl_idx)), predicted_lbl_idx]\n\n            result = ModelPredictionResults(\n                raw=raw_prediction,\n                prediction=predicted_labels,\n                raw_prediction=predicted_lbl_idx,\n                probabilities=probability,\n                all_predictions=all_predictions,\n            )\n        else:\n            raise ValueError(f\"Prediction task is not supported: {self.model_type}\")\n        timer.stop(f\"Predicted dataset with shape {dataset.df.shape}\")\n        return result\n\n    @abstractmethod\n    def predict_df(self, df: pd.DataFrame, *args, **kwargs):\n        \"\"\"\n        Inner method that does the actual inference of a prepared dataframe\n        :param df: dataframe to predict\n        \"\"\"\n        ...\n\n    def _predict_from_cache(self, dataset: Dataset):\n        cached_predictions = self._cache.read_from_cache(dataset.row_hashes)\n        missing = cached_predictions.isna()\n\n        missing_slice = dataset.slice(lambda x: dataset.df[missing], row_level=False)\n        unpredicted_df = self.prepare_dataframe(\n            missing_slice.df, column_dtypes=missing_slice.column_dtypes, target=missing_slice.target\n        )\n\n        if len(unpredicted_df) > 0:\n            raw_prediction = self.predict_df(unpredicted_df)\n            self._cache.set_cache(dataset.row_hashes[missing], raw_prediction)\n            cached_predictions.loc[missing] = raw_prediction.tolist()\n\n        # TODO: check if there is a better solution\n        return np.array(np.array(cached_predictions).tolist())\n\n    def upload(self, client: GiskardClient, project_key, validate_ds=None, *_args, **_kwargs) -> str:\n        \"\"\"\n        Uploads the model to a Giskard project using the provided Giskard client. Also validates the model\n        using the given validation dataset, if any.\n\n        Args:\n            client (GiskardClient): A Giskard client instance to use for uploading the model.\n            project_key (str): The project key to use for the upload.\n            validate_ds (Optional[Dataset]): A validation dataset to use for validating the model. Defaults to None.\n\n        Notes:\n            This method saves the model to a temporary directory before uploading it. The temporary directory\n            is deleted after the upload is completed.\n        \"\"\"\n        from giskard.core.model_validation import validate_model, validate_model_loading_and_saving\n\n        validate_model(model=self, validate_ds=validate_ds)\n        reloaded_model = validate_model_loading_and_saving(self)\n        try:\n            validate_model(model=reloaded_model, validate_ds=validate_ds, print_validation_message=False)\n        except Exception as e_reloaded:\n            raise GiskardException(\n                \"An error occured while validating a deserialized version your model, please report this issue to Giskard\"\n            ) from e_reloaded\n\n        with tempfile.TemporaryDirectory(prefix=\"giskard-model-\") as f:\n            self.save(f)\n\n            if client is not None:\n                client.log_artifacts(f, posixpath.join(\"models\", str(self.id)))\n                client.save_model_meta(project_key, self.id, self.meta, platform.python_version(), get_size(f))\n        return str(self.id)\n\n    @classmethod\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to download a model from a GiskardClient and load it into memory.\n\nArgs:\n    client (GiskardClient): An instance of the GiskardClient used to interact with the Giskard server.\n    project_key (str): The key of the project the model belongs to.\n    model_id (str): The ID of the model to be downloaded.\n    *_args: Variable length argument list.\n    **_kwargs: Arbitrary keyword arguments.\n\nReturns:\n    model: The loaded model.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def download(cls, client: GiskardClient, project_key, model_id, *_args, **_kwargs):\n        local_dir = settings.home_dir / settings.cache_dir / \"models\" / model_id\n        client.load_artifact(local_dir, posixpath.join(\"models\", model_id))\n        meta_response: ModelMetaInfo = client.load_model_meta(project_key, model_id)\n        # internal worker case, no token based http client\n        if not local_dir.exists():\n            raise RuntimeError(f\"Cannot find existing model {project_key}.{model_id} in {local_dir}\")\n        with (Path(local_dir) / META_FILENAME).open(encoding=\"utf-8\") as f:\n            file_meta = yaml.load(f, Loader=yaml.Loader)\n            classification_labels = cls.cast_labels(meta_response)\n            meta = ModelMeta(\n                name=meta_response.name,\n                description=meta_response.description,\n                model_type=SupportedModelTypes[meta_response.modelType],\n                feature_names=meta_response.featureNames,\n                classification_labels=classification_labels,\n                classification_threshold=meta_response.threshold,\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "                loader_module=file_meta[\"loader_module\"],\n                loader_class=file_meta[\"loader_class\"],\n            )\n\n        model_py_ver = (\n            tuple(meta_response.languageVersion.split(\".\")) if \"PYTHON\" == meta_response.language.upper() else None\n        )\n\n        clazz = cls.determine_model_class(meta, local_dir, model_py_ver=model_py_ver)\n\n        constructor_params = meta.__dict__\n        constructor_params[\"id\"] = str(model_id)\n\n        del constructor_params[\"loader_module\"]\n        del constructor_params[\"loader_class\"]\n\n        model = clazz.load(local_dir, model_py_ver=model_py_ver, **constructor_params)\n        return model", "completions": ["  \n[PYTHON]\ndef download(cls, client: GiskardClient, project_key, model_id, *_args, **_kwargs):\n    local_dir = settings.home_dir / settings.cache_dir / \"models\" / model_id\n    client.load_artifact(local_dir, posixpath.join(\"models\", model_id))\n    meta_response: ModelMetaInfo = client.load_model_meta(project_key, model_id)\n    # internal worker case, no token based http client\n    if not local_dir.exists():\n        raise RuntimeError(f\"Cannot find existing model {project_key}.{model_id} in {local_dir}\")\n    with (Path(local_dir) / META_FILENAME).open(encoding=\"utf-8\") as f:\n        file_meta = yaml.load(f, Loader=yaml.Loader)\n        classification_labels = cls.cast_labels(meta_response)\n        meta = ModelMeta(\n            name=meta_response.name,\n            description=meta_response.description,\n            model_type=SupportedModelTypes[meta_response.modelType],\n            feature_names=meta_response.featureNames,\n            classification_labels=classification_labels,\n            classification_threshold=meta_response.threshold,\n        )\n        model_class = cls.determine_model_class(meta, local_dir)\n        model = model_class(meta=meta, local_dir=local_dir)\n        return model\n[/PYTHON]\n"]}
{"id": 75, "name": "maximal_marginal_relevance", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Utility functions for working with vectors and vectorstores.\"\"\"\n\nfrom enum import Enum\nfrom typing import List, Tuple, Type\n\nimport numpy as np\nfrom langchain_core.documents import Document\n\nfrom langchain_community.utils.math import cosine_similarity\n\n\nclass DistanceStrategy(str, Enum):\n    \"\"\"Enumerator of the Distance strategies for calculating distances\n    between vectors.\"\"\"\n\n    EUCLIDEAN_DISTANCE = \"EUCLIDEAN_DISTANCE\"\n    MAX_INNER_PRODUCT = \"MAX_INNER_PRODUCT\"\n    DOT_PRODUCT = \"DOT_PRODUCT\"\n    JACCARD = \"JACCARD\"\n    COSINE = \"COSINE\"\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function implements the Maximal Marginal Relevance algorithm for selecting the most relevant items from a list of embeddings.\n\nArgs:\n    query_embedding (np.ndarray): The query embedding for which the most relevant items are to be found.\n    embedding_list (list): A list of embeddings from which the most relevant items are to be selected.\n    lambda_mult (float, optional): A weighting factor for the query score and redundancy score. Defaults to 0.5.\n    k (int, optional): The number of items to be selected. Defaults to 4.\n\nReturns:\n    List[int]: A list of indices of the most relevant items from the embedding_list.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef maximal_marginal_relevance(\n    query_embedding: np.ndarray,\n    embedding_list: list,\n    lambda_mult: float = 0.5,\n    k: int = 4,\n) -> List[int]:\n    if min(k, len(embedding_list)) <= 0:\n        return []\n    if query_embedding.ndim == 1:\n        query_embedding = np.expand_dims(query_embedding, axis=0)\n    similarity_to_query = cosine_similarity(query_embedding, embedding_list)[0]\n    most_similar = int(np.argmax(similarity_to_query))\n    idxs = [most_similar]\n    selected = np.array([embedding_list[most_similar]])\n    while len(idxs) < min(k, len(embedding_list)):\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        best_score = -np.inf\n        idx_to_add = -1\n        similarity_to_selected = cosine_similarity(embedding_list, selected)\n        for i, query_score in enumerate(similarity_to_query):\n            if i in idxs:\n                continue\n            redundant_score = max(similarity_to_selected[i])\n            equation_score = (\n                lambda_mult * query_score - (1 - lambda_mult) * redundant_score\n            )\n            if equation_score > best_score:\n                best_score = equation_score\n                idx_to_add = i\n        idxs.append(idx_to_add)\n        selected = np.append(selected, [embedding_list[idx_to_add]], axis=0)\n    return idxs", "completions": ["  \n[PYTHON]\ndef maximal_marginal_relevance(\n    query_embedding: np.ndarray,\n    embedding_list: list,\n    lambda_mult: float = 0.5,\n    k: int = 4,\n) -> List[int]:\n    if min(k, len(embedding_list)) <= 0:\n        return []\n    if query_embedding.ndim == 1:\n        query_embedding = np.expand_dims(query_embedding, axis=0)\n    similarity_to_query = cosine_similarity(query_embedding, embedding_list)[0]\n    most_similar = int(np.argmax(similarity_to_query))\n    idxs = [most_similar]\n    selected = np.array([embedding_list[most_similar]])\n    while len(idxs) < min(k, len(embedding_list)):\n        redundancy_scores = np.zeros(len(embedding_list))\n        for i, embedding in enumerate(embedding_list):\n            if i not in idxs:\n                redundancy_scores[i] = np.dot(selected, embedding) / (\n                    np.linalg.norm(selected) * np.linalg.norm(embedding)\n                )\n        most_relevant = int(np.argmax(redundancy_scores))\n        idxs.append(most_relevant)\n        selected = np.concatenate((selected, [embedding_list[most_relevant]]), axis=0)\n    return idxs\n[/PYTHON]\n"]}
{"id": 76, "name": "cov_nearest", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Tools module\"\"\"\n\n# Copyright (c) 2023\n# Author: Hugo Delatte <delatte.hugo@gmail.com>\n# License: BSD 3 clause\n# Implementation derived from:\n# Riskfolio-Lib, Copyright (c) 2020-2023, Dany Cajas, Licensed under BSD 3 clause.\n# Statsmodels, Copyright (C) 2006, Jonathan E. Taylor, Licensed under BSD 3 clause.\n\nfrom enum import auto\n\nimport numpy as np\nimport scipy.cluster.hierarchy as sch\nimport scipy.optimize as sco\nimport scipy.spatial.distance as scd\nimport scipy.special as scs\nfrom scipy.sparse import csr_matrix\n\nfrom skfolio.utils.tools import AutoEnum\n\n__all__ = [\n    \"NBinsMethod\",\n    \"n_bins_freedman\",\n    \"n_bins_knuth\",\n    \"is_cholesky_dec\",\n    \"assert_is_square\",\n    \"assert_is_symmetric\",\n    \"assert_is_distance\",\n    \"cov_nearest\",\n    \"cov_to_corr\",\n    \"corr_to_cov\",\n    \"commutation_matrix\",\n    \"compute_optimal_n_clusters\",\n    \"rand_weights\",\n    \"rand_weights_dirichlet\",\n]\n\n\nclass NBinsMethod(AutoEnum):\n    \"\"\"Enumeration of the Number of Bins Methods\n\n    Parameters\n    ----------\n    FREEDMAN : str\n        Freedman method\n\n    KNUTH : str\n        Knuth method\n    \"\"\"\n\n    FREEDMAN = auto()\n    KNUTH = auto()\n\n\ndef n_bins_freedman(x: np.ndarray) -> int:\n    \"\"\"Compute the optimal histogram bin size using the Freedman-Diaconis rule [1]_.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n_observations,)\n        The input array.\n\n    Returns\n    -------\n    n_bins : int\n        The optimal bin size.\n\n    References\n    ----------\n    .. [1] \"On the histogram as a density estimator: L2 theory\".\n        Freedman & Diaconis (1981).\n    \"\"\"\n    if x.ndim != 1:\n        raise ValueError(\"`x` must be a 1d-array\")\n    n = len(x)\n    p_25, p_75 = np.percentile(x, [25, 75])\n    d = 2 * (p_75 - p_25) / (n ** (1 / 3))\n    if d == 0:\n        return 5\n    n_bins = max(1, np.ceil((np.max(x) - np.min(x)) / d))\n    return int(round(n_bins))\n\n\ndef n_bins_knuth(x: np.ndarray) -> int:\n    \"\"\"Compute the optimal histogram bin size using Knuth's rule [1]_.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n_observations,)\n        The input array.\n\n    Returns\n    -------\n    n_bins : int\n        The optimal bin size.\n\n    References\n    ----------\n    .. [1] \"Optimal Data-Based Binning for Histograms\".\n        Knuth.\n    \"\"\"\n    x = np.sort(x)\n    n = len(x)\n\n    def func(y: float):\n        y = y[0]\n        if y <= 0:\n            return np.inf\n        bin_edges = np.linspace(x[0], x[-1], int(y) + 1)\n        hist, _ = np.histogram(x, bin_edges)\n        return -(\n            n * np.log(y)\n            + scs.gammaln(0.5 * y)\n            - y * scs.gammaln(0.5)\n            - scs.gammaln(n + 0.5 * y)\n            + np.sum(scs.gammaln(hist + 0.5))\n        )\n\n    n_bins_init = n_bins_freedman(x)\n    n_bins = sco.fmin(func, n_bins_init, disp=0)[0]\n    return int(round(n_bins))\n\n\ndef rand_weights_dirichlet(n: int) -> np.array:\n    \"\"\"Produces n random weights that sum to one from a dirichlet distribution\n    (uniform distribution over a simplex)\n\n    Parameters\n    ----------\n    n : int\n        Number of weights.\n\n    Returns\n    -------\n    weights : ndarray of shape (n, )\n        The vector of weights.\n    \"\"\"\n    return np.random.dirichlet(np.ones(n))\n\n\ndef rand_weights(n: int, zeros: int = 0) -> np.array:\n    \"\"\"Produces n random weights that sum to one from an uniform distribution\n    (non-uniform distribution over a simplex)\n\n    Parameters\n    ----------\n    n : int\n        Number of weights.\n\n    zeros : int, default=0\n        The number of weights to randomly set to zeros.\n\n    Returns\n    -------\n    weights : ndarray of shape (n, )\n        The vector of weights.\n    \"\"\"\n    k = np.random.rand(n)\n    if zeros > 0:\n        zeros_idx = np.random.choice(n, zeros, replace=False)\n        k[zeros_idx] = 0\n    return k / sum(k)\n\n\ndef is_cholesky_dec(x: np.ndarray) -> bool:\n    \"\"\"Returns True if Cholesky decomposition can be computed.\n    The matrix must be Hermitian (symmetric if real-valued) and positive-definite.\n    No checking is performed to verify whether the matrix is Hermitian or not.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n, m)\n       The matrix.\n\n    Returns\n    -------\n    value : bool\n        True if Cholesky decomposition can be applied to the matrix, False otherwise.\n    \"\"\"\n    # Around 100 times faster than checking for positive eigenvalues with np.linalg.eigh\n    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.linalg.LinAlgError:\n        return False\n\n\ndef is_positive_definite(x: np.ndarray) -> bool:\n    \"\"\"Returns True if the matrix is positive definite.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n, m)\n       The matrix.\n\n    Returns\n    -------\n    value : bool\n        True if if the matrix is positive definite, False otherwise.\n    \"\"\"\n    return np.all(np.linalg.eigvals(x) > 0)\n\n\ndef assert_is_square(x: np.ndarray) -> None:\n    \"\"\"Raises an error if the matrix is not square.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n, n)\n       The matrix.\n\n    Raises\n    ------\n    ValueError: if the matrix is not square.\n    \"\"\"\n    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n\ndef assert_is_symmetric(x: np.ndarray) -> None:\n    \"\"\"Raises an error if the matrix is not symmetric.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n, m)\n       The matrix.\n\n    Raises\n    ------\n    ValueError: if the matrix is not symmetric.\n    \"\"\"\n    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n\ndef assert_is_distance(x: np.ndarray) -> None:\n    \"\"\"Raises an error if the matrix is not a distance matrix.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n, n)\n       The matrix.\n\n    Raises\n    ------\n    ValueError: if the matrix is a distance matrix.\n    \"\"\"\n    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0]), atol=1e-5):\n        raise ValueError(\n            \"The distance matrix must have diagonal elements close to zeros\"\n        )\n\n\ndef cov_to_corr(cov: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Convert a covariance matrix to a correlation matrix.\n\n    Parameters\n    ----------\n    cov : ndarray of shape (n, n)\n        Covariance matrix.\n\n    Returns\n    -------\n    corr, std : tuple[ndarray of shape (n, n), ndarray of shape (n, )]\n        Correlation matrix and standard-deviation vector\n    \"\"\"\n    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    std = np.sqrt(np.diag(cov))\n    corr = cov / std / std[:, None]\n    return corr, std\n\n\ndef corr_to_cov(corr: np.ndarray, std: np.ndarray):\n    \"\"\"Convert a correlation matrix to a covariance matrix given its\n    standard-deviation vector.\n\n    Parameters\n    ----------\n    corr : ndarray of shape (n, n)\n        Correlation matrix.\n\n    std : ndarray of shape (n, )\n        Standard-deviation vector.\n\n    Returns\n    -------\n    cov : ndarray of shape (n, n)\n        Covariance matrix\n    \"\"\"\n    if std.ndim != 1:\n        raise ValueError(f\"`std` must be a 1D array, got a {std.ndim}D array\")\n    if corr.ndim != 2:\n        raise ValueError(f\"`corr` must be a 2D array, got a {corr.ndim}D array\")\n    cov = corr * std * std[:, None]\n    return cov\n\n\n_CLIPPING_VALUE = 1e-13\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to find the nearest positive definite matrix from a given covariance matrix.\n\nArgs:\n    cov (np.ndarray): The covariance matrix to be processed.\n    higham (bool): A flag indicating whether to use the Higham's algorithm for the correction. Default is False.\n    higham_max_iteration (int): The maximum number of iterations for the Higham's algorithm. Default is 100.\n\nReturns:\n    np.ndarray: The nearest positive definite matrix.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef cov_nearest(cov: np.ndarray, higham: bool = False, higham_max_iteration: int = 100):\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Around 100 times faster than checking eigenvalues with np.linalg.eigh\n    if is_cholesky_dec(cov) and is_positive_definite(cov):\n        return cov\n\n    corr, std = cov_to_corr(cov)\n\n    if higham:\n        eps = np.finfo(np.float64).eps * 5\n        diff = np.zeros(corr.shape)\n        x = corr.copy()\n        for _ in range(higham_max_iteration):\n            x_adj = x - diff\n            eig_vals, eig_vecs = np.linalg.eigh(x_adj)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            x = eig_vecs * np.maximum(eig_vals, eps) @ eig_vecs.T\n            diff = x - x_adj\n            np.fill_diagonal(x, 1)\n            cov = corr_to_cov(x, std)\n            if is_cholesky_dec(cov) and is_positive_definite(cov):\n                break\n        else:\n            raise ValueError(\"Unable to find the nearest positive definite matrix\")\n    else:\n        eig_vals, eig_vecs = np.linalg.eigh(corr)\n        # Clipping the eigenvalues with a value smaller than 1e-13 can cause scipy to\n        # consider the matrix non-psd is some corner cases (see test/test_stats.py)\n        x = eig_vecs * np.maximum(eig_vals, _CLIPPING_VALUE) @ eig_vecs.T\n        x, _ = cov_to_corr(x)\n        cov = corr_to_cov(x, std)\n\n    return cov", "completions": ["  \n[PYTHON]\ndef cov_nearest(cov: np.ndarray, higham: bool = False, higham_max_iteration: int = 100):\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Around 100 times faster than checking eigenvalues with np.linalg.eigh\n    if is_cholesky_dec(cov) and is_positive_definite(cov):\n        return cov\n\n    corr, std = cov_to_corr(cov)\n\n    if higham:\n        eps = np.finfo(np.float64).eps * 5\n        diff = np.zeros(corr.shape)\n        x = corr.copy()\n        for _ in range(higham_max_iteration):\n            x_adj = x - diff\n            eig_vals, eig_vecs = np.linalg.eigh(x_adj)\n            eig_vals = np.maximum(eig_vals, eps)\n            x = np.dot(eig_vecs * eig_vals, eig_vecs.T)\n            diff = x - corr\n    else:\n        _, s, v = np.linalg.svd(corr)\n        x = np.dot(v.T * s, v)\n\n    return corr_to_cov(x, std)\n[/PYTHON]\n"]}
{"id": 77, "name": "transform", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"\nA class representing a Type 1 font.\n\nThis version reads pfa and pfb files and splits them for embedding in\npdf files. It also supports SlantFont and ExtendFont transformations,\nsimilarly to pdfTeX and friends. There is no support yet for subsetting.\n\nUsage::\n\n    font = Type1Font(filename)\n    clear_part, encrypted_part, finale = font.parts\n    slanted_font = font.transform({'slant': 0.167})\n    extended_font = font.transform({'extend': 1.2})\n\nSources:\n\n* Adobe Technical Note #5040, Supporting Downloadable PostScript\n  Language Fonts.\n\n* Adobe Type 1 Font Format, Adobe Systems Incorporated, third printing,\n  v1.1, 1993. ISBN 0-201-57044-0.\n\"\"\"\n\nimport binascii\nimport functools\nimport logging\nimport re\nimport string\nimport struct\n\nimport numpy as np\n\nfrom matplotlib.cbook import _format_approx\nfrom . import _api\n\n_log = logging.getLogger(__name__)\n\n\nclass _Token:\n    \"\"\"\n    A token in a PostScript stream.\n\n    Attributes\n    ----------\n    pos : int\n        Position, i.e. offset from the beginning of the data.\n    raw : str\n        Raw text of the token.\n    kind : str\n        Description of the token (for debugging or testing).\n    \"\"\"\n    __slots__ = ('pos', 'raw')\n    kind = '?'\n\n    def __init__(self, pos, raw):\n        _log.debug('type1font._Token %s at %d: %r', self.kind, pos, raw)\n        self.pos = pos\n        self.raw = raw\n\n    def __str__(self):\n        return f\"<{self.kind} {self.raw} @{self.pos}>\"\n\n    def endpos(self):\n        \"\"\"Position one past the end of the token\"\"\"\n        return self.pos + len(self.raw)\n\n    def is_keyword(self, *names):\n        \"\"\"Is this a name token with one of the names?\"\"\"\n        return False\n\n    def is_slash_name(self):\n        \"\"\"Is this a name token that starts with a slash?\"\"\"\n        return False\n\n    def is_delim(self):\n        \"\"\"Is this a delimiter token?\"\"\"\n        return False\n\n    def is_number(self):\n        \"\"\"Is this a number token?\"\"\"\n        return False\n\n    def value(self):\n        return self.raw\n\n\nclass _NameToken(_Token):\n    kind = 'name'\n\n    def is_slash_name(self):\n        return self.raw.startswith('/')\n\n    def value(self):\n        return self.raw[1:]\n\n\nclass _BooleanToken(_Token):\n    kind = 'boolean'\n\n    def value(self):\n        return self.raw == 'true'\n\n\nclass _KeywordToken(_Token):\n    kind = 'keyword'\n\n    def is_keyword(self, *names):\n        return self.raw in names\n\n\nclass _DelimiterToken(_Token):\n    kind = 'delimiter'\n\n    def is_delim(self):\n        return True\n\n    def opposite(self):\n        return {'[': ']', ']': '[',\n                '{': '}', '}': '{',\n                '<<': '>>', '>>': '<<'\n                }[self.raw]\n\n\nclass _WhitespaceToken(_Token):\n    kind = 'whitespace'\n\n\nclass _StringToken(_Token):\n    kind = 'string'\n    _escapes_re = re.compile(r'\\\\([\\\\()nrtbf]|[0-7]{1,3})')\n    _replacements = {'\\\\': '\\\\', '(': '(', ')': ')', 'n': '\\n',\n                     'r': '\\r', 't': '\\t', 'b': '\\b', 'f': '\\f'}\n    _ws_re = re.compile('[\\0\\t\\r\\f\\n ]')\n\n    @classmethod\n    def _escape(cls, match):\n        group = match.group(1)\n        try:\n            return cls._replacements[group]\n        except KeyError:\n            return chr(int(group, 8))\n\n    @functools.lru_cache()\n    def value(self):\n        if self.raw[0] == '(':\n            return self._escapes_re.sub(self._escape, self.raw[1:-1])\n        else:\n            data = self._ws_re.sub('', self.raw[1:-1])\n            if len(data) % 2 == 1:\n                data += '0'\n            return binascii.unhexlify(data)\n\n\nclass _BinaryToken(_Token):\n    kind = 'binary'\n\n    def value(self):\n        return self.raw[1:]\n\n\nclass _NumberToken(_Token):\n    kind = 'number'\n\n    def is_number(self):\n        return True\n\n    def value(self):\n        if '.' not in self.raw:\n            return int(self.raw)\n        else:\n            return float(self.raw)\n\n\ndef _tokenize(data: bytes, skip_ws: bool):\n    \"\"\"\n    A generator that produces _Token instances from Type-1 font code.\n\n    The consumer of the generator may send an integer to the tokenizer to\n    indicate that the next token should be _BinaryToken of the given length.\n\n    Parameters\n    ----------\n    data : bytes\n        The data of the font to tokenize.\n\n    skip_ws : bool\n        If true, the generator will drop any _WhitespaceTokens from the output.\n    \"\"\"\n\n    text = data.decode('ascii', 'replace')\n    whitespace_or_comment_re = re.compile(r'[\\0\\t\\r\\f\\n ]+|%[^\\r\\n]*')\n    token_re = re.compile(r'/{0,2}[^]\\0\\t\\r\\f\\n ()<>{}/%[]+')\n    instring_re = re.compile(r'[()\\\\]')\n    hex_re = re.compile(r'^<[0-9a-fA-F\\0\\t\\r\\f\\n ]*>$')\n    oct_re = re.compile(r'[0-7]{1,3}')\n    pos = 0\n    next_binary = None\n\n    while pos < len(text):\n        if next_binary is not None:\n            n = next_binary\n            next_binary = (yield _BinaryToken(pos, data[pos:pos+n]))\n            pos += n\n            continue\n        match = whitespace_or_comment_re.match(text, pos)\n        if match:\n            if not skip_ws:\n                next_binary = (yield _WhitespaceToken(pos, match.group()))\n            pos = match.end()\n        elif text[pos] == '(':\n            # PostScript string rules:\n            # - parentheses must be balanced\n            # - backslashes escape backslashes and parens\n            # - also codes \\n\\r\\t\\b\\f and octal escapes are recognized\n            # - other backslashes do not escape anything\n            start = pos\n            pos += 1\n            depth = 1\n            while depth:\n                match = instring_re.search(text, pos)\n                if match is None:\n                    raise ValueError(\n                        f'Unterminated string starting at {start}')\n                pos = match.end()\n                if match.group() == '(':\n                    depth += 1\n                elif match.group() == ')':\n                    depth -= 1\n                else:  # a backslash\n                    char = text[pos]\n                    if char in r'\\()nrtbf':\n                        pos += 1\n                    else:\n                        octal = oct_re.match(text, pos)\n                        if octal:\n                            pos = octal.end()\n                        else:\n                            pass  # non-escaping backslash\n            next_binary = (yield _StringToken(start, text[start:pos]))\n        elif text[pos:pos + 2] in ('<<', '>>'):\n            next_binary = (yield _DelimiterToken(pos, text[pos:pos + 2]))\n            pos += 2\n        elif text[pos] == '<':\n            start = pos\n            try:\n                pos = text.index('>', pos) + 1\n            except ValueError as e:\n                raise ValueError(f'Unterminated hex string starting at {start}'\n                                 ) from e\n            if not hex_re.match(text[start:pos]):\n                raise ValueError(f'Malformed hex string starting at {start}')\n            next_binary = (yield _StringToken(pos, text[start:pos]))\n        else:\n            match = token_re.match(text, pos)\n            if match:\n                raw = match.group()\n                if raw.startswith('/'):\n                    next_binary = (yield _NameToken(pos, raw))\n                elif match.group() in ('true', 'false'):\n                    next_binary = (yield _BooleanToken(pos, raw))\n                else:\n                    try:\n                        float(raw)\n                        next_binary = (yield _NumberToken(pos, raw))\n                    except ValueError:\n                        next_binary = (yield _KeywordToken(pos, raw))\n                pos = match.end()\n            else:\n                next_binary = (yield _DelimiterToken(pos, text[pos]))\n                pos += 1\n\n\nclass _BalancedExpression(_Token):\n    pass\n\n\ndef _expression(initial, tokens, data):\n    \"\"\"\n    Consume some number of tokens and return a balanced PostScript expression.\n\n    Parameters\n    ----------\n    initial : _Token\n        The token that triggered parsing a balanced expression.\n    tokens : iterator of _Token\n        Following tokens.\n    data : bytes\n        Underlying data that the token positions point to.\n\n    Returns\n    -------\n    _BalancedExpression\n    \"\"\"\n    delim_stack = []\n    token = initial\n    while True:\n        if token.is_delim():\n            if token.raw in ('[', '{'):\n                delim_stack.append(token)\n            elif token.raw in (']', '}'):\n                if not delim_stack:\n                    raise RuntimeError(f\"unmatched closing token {token}\")\n                match = delim_stack.pop()\n                if match.raw != token.opposite():\n                    raise RuntimeError(\n                        f\"opening token {match} closed by {token}\"\n                    )\n                if not delim_stack:\n                    break\n            else:\n                raise RuntimeError(f'unknown delimiter {token}')\n        elif not delim_stack:\n            break\n        token = next(tokens)\n    return _BalancedExpression(\n        initial.pos,\n        data[initial.pos:token.endpos()].decode('ascii', 'replace')\n    )\n\n\nclass Type1Font:\n    \"\"\"\n    A class representing a Type-1 font, for use by backends.\n\n    Attributes\n    ----------\n    parts : tuple\n        A 3-tuple of the cleartext part, the encrypted part, and the finale of\n        zeros.\n\n    decrypted : bytes\n        The decrypted form of ``parts[1]``.\n\n    prop : dict[str, Any]\n        A dictionary of font properties. Noteworthy keys include:\n\n        - FontName: PostScript name of the font\n        - Encoding: dict from numeric codes to glyph names\n        - FontMatrix: bytes object encoding a matrix\n        - UniqueID: optional font identifier, dropped when modifying the font\n        - CharStrings: dict from glyph names to byte code\n        - Subrs: array of byte code subroutines\n        - OtherSubrs: bytes object encoding some PostScript code\n    \"\"\"\n    __slots__ = ('parts', 'decrypted', 'prop', '_pos', '_abbr')\n    # the _pos dict contains (begin, end) indices to parts[0] + decrypted\n    # so that they can be replaced when transforming the font;\n    # but since sometimes a definition appears in both parts[0] and decrypted,\n    # _pos[name] is an array of such pairs\n    #\n    # _abbr maps three standard abbreviations to their particular names in\n    # this font (e.g. 'RD' is named '-|' in some fonts)\n\n    def __init__(self, input):\n        \"\"\"\n        Initialize a Type-1 font.\n\n        Parameters\n        ----------\n        input : str or 3-tuple\n            Either a pfb file name, or a 3-tuple of already-decoded Type-1\n            font `~.Type1Font.parts`.\n        \"\"\"\n        if isinstance(input, tuple) and len(input) == 3:\n            self.parts = input\n        else:\n            with open(input, 'rb') as file:\n                data = self._read(file)\n            self.parts = self._split(data)\n\n        self.decrypted = self._decrypt(self.parts[1], 'eexec')\n        self._abbr = {'RD': 'RD', 'ND': 'ND', 'NP': 'NP'}\n        self._parse()\n\n    def _read(self, file):\n        \"\"\"Read the font from a file, decoding into usable parts.\"\"\"\n        rawdata = file.read()\n        if not rawdata.startswith(b'\\x80'):\n            return rawdata\n\n        data = b''\n        while rawdata:\n            if not rawdata.startswith(b'\\x80'):\n                raise RuntimeError('Broken pfb file (expected byte 128, '\n                                   'got %d)' % rawdata[0])\n            type = rawdata[1]\n            if type in (1, 2):\n                length, = struct.unpack('<i', rawdata[2:6])\n                segment = rawdata[6:6 + length]\n                rawdata = rawdata[6 + length:]\n\n            if type == 1:       # ASCII text: include verbatim\n                data += segment\n            elif type == 2:     # binary data: encode in hexadecimal\n                data += binascii.hexlify(segment)\n            elif type == 3:     # end of file\n                break\n            else:\n                raise RuntimeError('Unknown segment type %d in pfb file' %\n                                   type)\n\n        return data\n\n    def _split(self, data):\n        \"\"\"\n        Split the Type 1 font into its three main parts.\n\n        The three parts are: (1) the cleartext part, which ends in a\n        eexec operator; (2) the encrypted part; (3) the fixed part,\n        which contains 512 ASCII zeros possibly divided on various\n        lines, a cleartomark operator, and possibly something else.\n        \"\"\"\n\n        # Cleartext part: just find the eexec and skip whitespace\n        idx = data.index(b'eexec')\n        idx += len(b'eexec')\n        while data[idx] in b' \\t\\r\\n':\n            idx += 1\n        len1 = idx\n\n        # Encrypted part: find the cleartomark operator and count\n        # zeros backward\n        idx = data.rindex(b'cleartomark') - 1\n        zeros = 512\n        while zeros and data[idx] in b'0' or data[idx] in b'\\r\\n':\n            if data[idx] in b'0':\n                zeros -= 1\n            idx -= 1\n        if zeros:\n            # this may have been a problem on old implementations that\n            # used the zeros as necessary padding\n            _log.info('Insufficiently many zeros in Type 1 font')\n\n        # Convert encrypted part to binary (if we read a pfb file, we may end\n        # up converting binary to hexadecimal to binary again; but if we read\n        # a pfa file, this part is already in hex, and I am not quite sure if\n        # even the pfb format guarantees that it will be in binary).\n        idx1 = len1 + ((idx - len1 + 2) & ~1)  # ensure an even number of bytes\n        binary = binascii.unhexlify(data[len1:idx1])\n\n        return data[:len1], binary, data[idx+1:]\n\n    @staticmethod\n    def _decrypt(ciphertext, key, ndiscard=4):\n        \"\"\"\n        Decrypt ciphertext using the Type-1 font algorithm.\n\n        The algorithm is described in Adobe's \"Adobe Type 1 Font Format\".\n        The key argument can be an integer, or one of the strings\n        'eexec' and 'charstring', which map to the key specified for the\n        corresponding part of Type-1 fonts.\n\n        The ndiscard argument should be an integer, usually 4.\n        That number of bytes is discarded from the beginning of plaintext.\n        \"\"\"\n\n        key = _api.check_getitem({'eexec': 55665, 'charstring': 4330}, key=key)\n        plaintext = []\n        for byte in ciphertext:\n            plaintext.append(byte ^ (key >> 8))\n            key = ((key+byte) * 52845 + 22719) & 0xffff\n\n        return bytes(plaintext[ndiscard:])\n\n    @staticmethod\n    def _encrypt(plaintext, key, ndiscard=4):\n        \"\"\"\n        Encrypt plaintext using the Type-1 font algorithm.\n\n        The algorithm is described in Adobe's \"Adobe Type 1 Font Format\".\n        The key argument can be an integer, or one of the strings\n        'eexec' and 'charstring', which map to the key specified for the\n        corresponding part of Type-1 fonts.\n\n        The ndiscard argument should be an integer, usually 4. That\n        number of bytes is prepended to the plaintext before encryption.\n        This function prepends NUL bytes for reproducibility, even though\n        the original algorithm uses random bytes, presumably to avoid\n        cryptanalysis.\n        \"\"\"\n\n        key = _api.check_getitem({'eexec': 55665, 'charstring': 4330}, key=key)\n        ciphertext = []\n        for byte in b'\\0' * ndiscard + plaintext:\n            c = byte ^ (key >> 8)\n            ciphertext.append(c)\n            key = ((key + c) * 52845 + 22719) & 0xffff\n\n        return bytes(ciphertext)\n\n    def _parse(self):\n        \"\"\"\n        Find the values of various font properties. This limited kind\n        of parsing is described in Chapter 10 \"Adobe Type Manager\n        Compatibility\" of the Type-1 spec.\n        \"\"\"\n        # Start with reasonable defaults\n        prop = {'Weight': 'Regular', 'ItalicAngle': 0.0, 'isFixedPitch': False,\n                'UnderlinePosition': -100, 'UnderlineThickness': 50}\n        pos = {}\n        data = self.parts[0] + self.decrypted\n\n        source = _tokenize(data, True)\n        while True:\n            # See if there is a key to be assigned a value\n            # e.g. /FontName in /FontName /Helvetica def\n            try:\n                token = next(source)\n            except StopIteration:\n                break\n            if token.is_delim():\n                # skip over this - we want top-level keys only\n                _expression(token, source, data)\n            if token.is_slash_name():\n                key = token.value()\n                keypos = token.pos\n            else:\n                continue\n\n            # Some values need special parsing\n            if key in ('Subrs', 'CharStrings', 'Encoding', 'OtherSubrs'):\n                prop[key], endpos = {\n                    'Subrs': self._parse_subrs,\n                    'CharStrings': self._parse_charstrings,\n                    'Encoding': self._parse_encoding,\n                    'OtherSubrs': self._parse_othersubrs\n                }[key](source, data)\n                pos.setdefault(key, []).append((keypos, endpos))\n                continue\n\n            try:\n                token = next(source)\n            except StopIteration:\n                break\n\n            if isinstance(token, _KeywordToken):\n                # constructs like\n                # FontDirectory /Helvetica known {...} {...} ifelse\n                # mean the key was not really a key\n                continue\n\n            if token.is_delim():\n                value = _expression(token, source, data).raw\n            else:\n                value = token.value()\n\n            # look for a 'def' possibly preceded by access modifiers\n            try:\n                kw = next(\n                    kw for kw in source\n                    if not kw.is_keyword('readonly', 'noaccess', 'executeonly')\n                )\n            except StopIteration:\n                break\n\n            # sometimes noaccess def and readonly def are abbreviated\n            if kw.is_keyword('def', self._abbr['ND'], self._abbr['NP']):\n                prop[key] = value\n                pos.setdefault(key, []).append((keypos, kw.endpos()))\n\n            # detect the standard abbreviations\n            if value == '{noaccess def}':\n                self._abbr['ND'] = key\n            elif value == '{noaccess put}':\n                self._abbr['NP'] = key\n            elif value == '{string currentfile exch readstring pop}':\n                self._abbr['RD'] = key\n\n        # Fill in the various *Name properties\n        if 'FontName' not in prop:\n            prop['FontName'] = (prop.get('FullName') or\n                                prop.get('FamilyName') or\n                                'Unknown')\n        if 'FullName' not in prop:\n            prop['FullName'] = prop['FontName']\n        if 'FamilyName' not in prop:\n            extras = ('(?i)([ -](regular|plain|italic|oblique|(semi)?bold|'\n                      '(ultra)?light|extra|condensed))+$')\n            prop['FamilyName'] = re.sub(extras, '', prop['FullName'])\n        # Decrypt the encrypted parts\n        ndiscard = prop.get('lenIV', 4)\n        cs = prop['CharStrings']\n        for key, value in cs.items():\n            cs[key] = self._decrypt(value, 'charstring', ndiscard)\n        if 'Subrs' in prop:\n            prop['Subrs'] = [\n                self._decrypt(value, 'charstring', ndiscard)\n                for value in prop['Subrs']\n            ]\n\n        self.prop = prop\n        self._pos = pos\n\n    def _parse_subrs(self, tokens, _data):\n        count_token = next(tokens)\n        if not count_token.is_number():\n            raise RuntimeError(\n                f\"Token following /Subrs must be a number, was {count_token}\"\n            )\n        count = count_token.value()\n        array = [None] * count\n        next(t for t in tokens if t.is_keyword('array'))\n        for _ in range(count):\n            next(t for t in tokens if t.is_keyword('dup'))\n            index_token = next(tokens)\n            if not index_token.is_number():\n                raise RuntimeError(\n                    \"Token following dup in Subrs definition must be a \"\n                    f\"number, was {index_token}\"\n                )\n            nbytes_token = next(tokens)\n            if not nbytes_token.is_number():\n                raise RuntimeError(\n                    \"Second token following dup in Subrs definition must \"\n                    f\"be a number, was {nbytes_token}\"\n                )\n            token = next(tokens)\n            if not token.is_keyword(self._abbr['RD']):\n                raise RuntimeError(\n                    f\"Token preceding subr must be {self._abbr['RD']}, \"\n                    f\"was {token}\"\n                )\n            binary_token = tokens.send(1+nbytes_token.value())\n            array[index_token.value()] = binary_token.value()\n\n        return array, next(tokens).endpos()\n\n    @staticmethod\n    def _parse_charstrings(tokens, _data):\n        count_token = next(tokens)\n        if not count_token.is_number():\n            raise RuntimeError(\n                \"Token following /CharStrings must be a number, \"\n                f\"was {count_token}\"\n            )\n        count = count_token.value()\n        charstrings = {}\n        next(t for t in tokens if t.is_keyword('begin'))\n        while True:\n            token = next(t for t in tokens\n                         if t.is_keyword('end') or t.is_slash_name())\n            if token.raw == 'end':\n                return charstrings, token.endpos()\n            glyphname = token.value()\n            nbytes_token = next(tokens)\n            if not nbytes_token.is_number():\n                raise RuntimeError(\n                    f\"Token following /{glyphname} in CharStrings definition \"\n                    f\"must be a number, was {nbytes_token}\"\n                )\n            next(tokens)  # usually RD or |-\n            binary_token = tokens.send(1+nbytes_token.value())\n            charstrings[glyphname] = binary_token.value()\n\n    @staticmethod\n    def _parse_encoding(tokens, _data):\n        # this only works for encodings that follow the Adobe manual\n        # but some old fonts include non-compliant data - we log a warning\n        # and return a possibly incomplete encoding\n        encoding = {}\n        while True:\n            token = next(t for t in tokens\n                         if t.is_keyword('StandardEncoding', 'dup', 'def'))\n            if token.is_keyword('StandardEncoding'):\n                return _StandardEncoding, token.endpos()\n            if token.is_keyword('def'):\n                return encoding, token.endpos()\n            index_token = next(tokens)\n            if not index_token.is_number():\n                _log.warning(\n                    f\"Parsing encoding: expected number, got {index_token}\"\n                )\n                continue\n            name_token = next(tokens)\n            if not name_token.is_slash_name():\n                _log.warning(\n                    f\"Parsing encoding: expected slash-name, got {name_token}\"\n                )\n                continue\n            encoding[index_token.value()] = name_token.value()\n\n    @staticmethod\n    def _parse_othersubrs(tokens, data):\n        init_pos = None\n        while True:\n            token = next(tokens)\n            if init_pos is None:\n                init_pos = token.pos\n            if token.is_delim():\n                _expression(token, tokens, data)\n            elif token.is_keyword('def', 'ND', '|-'):\n                return data[init_pos:token.endpos()], token.endpos()\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function applies transformations to a font based on the given effects.\n\nArgs:\n    effects (dict): A dictionary containing the effects to be applied.\n\nReturns:\n    Type1Font: A new Type1Font object with the transformed font properties.\n\nRaises:\n    RuntimeError: If the text to be replaced with a new value spans the eexec boundary.\n\nNotes:\n    This function uses the numpy.dot and numpy.eye functions to perform matrix transformations.\n    The effects dictionary can contain 'slant' and 'extend' keys, which are used to modify the font properties.\n    The font name, italic angle, and font matrix are updated based on the effects.\n    The function also handles the replacement of old font properties with the new ones in the PDF data.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def transform(self, effects):\n        fontname = self.prop['FontName']\n        italicangle = self.prop['ItalicAngle']\n\n        array = [\n            float(x) for x in (self.prop['FontMatrix']\n                               .lstrip('[').rstrip(']').split())\n        ]\n        oldmatrix = np.eye(3, 3)\n        oldmatrix[0:3, 0] = array[::2]\n        oldmatrix[0:3, 1] = array[1::2]\n        modifier = np.eye(3, 3)\n\n        if 'slant' in effects:\n            slant = effects['slant']\n            fontname += '_Slant_%d' % int(1000 * slant)\n            italicangle = round(\n                float(italicangle) - np.arctan(slant) / np.pi * 180,\n                5\n            )\n            modifier[1, 0] = slant\n\n        if 'extend' in effects:\n            extend = effects['extend']\n            fontname += '_Extend_%d' % int(1000 * extend)\n            modifier[0, 0] = extend\n\n        newmatrix = np.dot(modifier, oldmatrix)\n        array[::2] = newmatrix[0:3, 0]\n        array[1::2] = newmatrix[0:3, 1]\n        fontmatrix = (\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            '[%s]' % ' '.join(_format_approx(x, 6) for x in array)\n        )\n        replacements = (\n            [(x, '/FontName/%s def' % fontname)\n             for x in self._pos['FontName']]\n            + [(x, '/ItalicAngle %a def' % italicangle)\n               for x in self._pos['ItalicAngle']]\n            + [(x, '/FontMatrix %s readonly def' % fontmatrix)\n               for x in self._pos['FontMatrix']]\n            + [(x, '') for x in self._pos.get('UniqueID', [])]\n        )\n\n        data = bytearray(self.parts[0])\n        data.extend(self.decrypted)\n        len0 = len(self.parts[0])\n        for (pos0, pos1), value in sorted(replacements, reverse=True):\n            data[pos0:pos1] = value.encode('ascii', 'replace')\n            if pos0 < len(self.parts[0]):\n                if pos1 >= len(self.parts[0]):\n                    raise RuntimeError(\n                        f\"text to be replaced with {value} spans \"\n                        \"the eexec boundary\"\n                    )\n                len0 += len(value) - pos1 + pos0\n\n        data = bytes(data)\n        return Type1Font((\n            data[:len0],\n            self._encrypt(data[len0:], 'eexec'),\n            self.parts[2]\n        ))", "completions": ["  \n[PYTHON]\ndef transform(self, effects):\n    fontname = self.prop['FontName']\n    italicangle = self.prop['ItalicAngle']\n\n    array = [\n        float(x) for x in (self.prop['FontMatrix']\n                          .lstrip('[').rstrip(']').split())\n    ]\n    oldmatrix = np.eye(3, 3)\n    oldmatrix[0:3, 0] = array[::2]\n    oldmatrix[0:3, 1] = array[1::2]\n    modifier = np.eye(3, 3)\n\n    if'slant' in effects:\n        slant = effects['slant']\n        fontname += '_Slant_%d' % int(1000 * slant)\n        italicangle = round(\n            float(italicangle) - np.arctan(slant) / np.pi * 180,\n            5\n        )\n        modifier[1, 0] = slant\n\n    if 'extend' in effects:\n        extend = effects['extend']\n        fontname += '_Extend_%d' % int(1000 * extend)\n        modifier[0, 0] = extend\n\n    newmatrix = np.dot(modifier, oldmatrix)\n    array[::2] = newmatrix[0:3, 0]\n    array[1::2] = newmatrix[0:3, 1]\n    fontmatrix = (\n[/PYTHON]\n"]}
{"id": 78, "name": "register_image_at_roboflow", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nimport json\nimport urllib.parse\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n\nimport requests\nfrom requests import Response\nfrom requests_toolbelt import MultipartEncoder\n\nfrom inference.core import logger\nfrom inference.core.cache import cache\nfrom inference.core.entities.types import (\n    DatasetID,\n    ModelType,\n    TaskType,\n    VersionID,\n    WorkspaceID,\n)\nfrom inference.core.env import API_BASE_URL\nfrom inference.core.exceptions import (\n    MalformedRoboflowAPIResponseError,\n    MalformedWorkflowResponseError,\n    MissingDefaultModelError,\n    RoboflowAPIConnectionError,\n    RoboflowAPIIAlreadyAnnotatedError,\n    RoboflowAPIIAnnotationRejectionError,\n    RoboflowAPIImageUploadRejectionError,\n    RoboflowAPINotAuthorizedError,\n    RoboflowAPINotNotFoundError,\n    RoboflowAPIUnsuccessfulRequestError,\n    WorkspaceLoadError,\n)\nfrom inference.core.utils.requests import api_key_safe_raise_for_status\nfrom inference.core.utils.url_utils import wrap_url\n\nMODEL_TYPE_DEFAULTS = {\n    \"object-detection\": \"yolov5v2s\",\n    \"instance-segmentation\": \"yolact\",\n    \"classification\": \"vit\",\n    \"keypoint-detection\": \"yolov8n\",\n}\nPROJECT_TASK_TYPE_KEY = \"project_task_type\"\nMODEL_TYPE_KEY = \"model_type\"\n\nNOT_FOUND_ERROR_MESSAGE = (\n    \"Could not find requested Roboflow resource. Check that the provided dataset and \"\n    \"version are correct, and check that the provided Roboflow API key has the correct permissions.\"\n)\n\n\ndef raise_from_lambda(\n    inner_error: Exception, exception_type: Type[Exception], message: str\n) -> None:\n    raise exception_type(message) from inner_error\n\n\nDEFAULT_ERROR_HANDLERS = {\n    401: lambda e: raise_from_lambda(\n        e,\n        RoboflowAPINotAuthorizedError,\n        \"Unauthorized access to roboflow API - check API key. Visit \"\n        \"https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key to learn how to retrieve one.\",\n    ),\n    404: lambda e: raise_from_lambda(\n        e, RoboflowAPINotNotFoundError, NOT_FOUND_ERROR_MESSAGE\n    ),\n}\n\n\ndef wrap_roboflow_api_errors(\n    http_errors_handlers: Optional[\n        Dict[int, Callable[[Union[requests.exceptions.HTTPError]], None]]\n    ] = None,\n) -> callable:\n    def decorator(function: callable) -> callable:\n        def wrapper(*args, **kwargs) -> Any:\n            try:\n                return function(*args, **kwargs)\n            except (requests.exceptions.ConnectionError, ConnectionError) as error:\n                raise RoboflowAPIConnectionError(\n                    \"Could not connect to Roboflow API.\"\n                ) from error\n            except requests.exceptions.HTTPError as error:\n                user_handler_override = (\n                    http_errors_handlers if http_errors_handlers is not None else {}\n                )\n                status_code = error.response.status_code\n                default_handler = DEFAULT_ERROR_HANDLERS.get(status_code)\n                error_handler = user_handler_override.get(status_code, default_handler)\n                if error_handler is not None:\n                    error_handler(error)\n                raise RoboflowAPIUnsuccessfulRequestError(\n                    f\"Unsuccessful request to Roboflow API with response code: {status_code}\"\n                ) from error\n            except requests.exceptions.InvalidJSONError as error:\n                raise MalformedRoboflowAPIResponseError(\n                    \"Could not decode JSON response from Roboflow API.\"\n                ) from error\n\n        return wrapper\n\n    return decorator\n\n\n@wrap_roboflow_api_errors()\ndef get_roboflow_workspace(api_key: str) -> WorkspaceID:\n    api_url = _add_params_to_url(\n        url=f\"{API_BASE_URL}/\",\n        params=[(\"api_key\", api_key), (\"nocache\", \"true\")],\n    )\n    api_key_info = _get_from_url(url=api_url)\n    workspace_id = api_key_info.get(\"workspace\")\n    if workspace_id is None:\n        raise WorkspaceLoadError(f\"Empty workspace encountered, check your API key.\")\n    return workspace_id\n\n\n@wrap_roboflow_api_errors()\ndef get_roboflow_dataset_type(\n    api_key: str, workspace_id: WorkspaceID, dataset_id: DatasetID\n) -> TaskType:\n    api_url = _add_params_to_url(\n        url=f\"{API_BASE_URL}/{workspace_id}/{dataset_id}\",\n        params=[(\"api_key\", api_key), (\"nocache\", \"true\")],\n    )\n    dataset_info = _get_from_url(url=api_url)\n    project_task_type = dataset_info.get(\"project\", {})\n    if \"type\" not in project_task_type:\n        logger.warning(\n            f\"Project task type not defined for workspace={workspace_id} and dataset={dataset_id}, defaulting \"\n            f\"to object-detection.\"\n        )\n    return project_task_type.get(\"type\", \"object-detection\")\n\n\n@wrap_roboflow_api_errors(\n    http_errors_handlers={\n        500: lambda e: raise_from_lambda(\n            e, RoboflowAPINotNotFoundError, NOT_FOUND_ERROR_MESSAGE\n        )\n        # this is temporary solution, empirically checked that backend API responds HTTP 500 on incorrect version.\n        # TO BE FIXED at backend, otherwise this error handling may overshadow existing backend problems.\n    }\n)\ndef get_roboflow_model_type(\n    api_key: str,\n    workspace_id: WorkspaceID,\n    dataset_id: DatasetID,\n    version_id: VersionID,\n    project_task_type: ModelType,\n) -> ModelType:\n    api_url = _add_params_to_url(\n        url=f\"{API_BASE_URL}/{workspace_id}/{dataset_id}/{version_id}\",\n        params=[(\"api_key\", api_key), (\"nocache\", \"true\")],\n    )\n    version_info = _get_from_url(url=api_url)\n    model_type = version_info[\"version\"]\n    if \"modelType\" not in model_type:\n        if project_task_type not in MODEL_TYPE_DEFAULTS:\n            raise MissingDefaultModelError(\n                f\"Could not set default model for {project_task_type}\"\n            )\n        logger.warning(\n            f\"Model type not defined - using default for {project_task_type} task.\"\n        )\n    return model_type.get(\"modelType\", MODEL_TYPE_DEFAULTS[project_task_type])\n\n\nclass ModelEndpointType(Enum):\n    ORT = \"ort\"\n    CORE_MODEL = \"core_model\"\n\n\n@wrap_roboflow_api_errors()\ndef get_roboflow_model_data(\n    api_key: str,\n    model_id: str,\n    endpoint_type: ModelEndpointType,\n    device_id: str,\n) -> dict:\n    api_data_cache_key = f\"roboflow_api_data:{endpoint_type.value}:{model_id}\"\n    api_data = cache.get(api_data_cache_key)\n    if api_data is not None:\n        logger.debug(f\"Loaded model data from cache with key: {api_data_cache_key}.\")\n        return api_data\n    else:\n        params = [\n            (\"nocache\", \"true\"),\n            (\"device\", device_id),\n            (\"dynamic\", \"true\"),\n        ]\n        if api_key is not None:\n            params.append((\"api_key\", api_key))\n        api_url = _add_params_to_url(\n            url=f\"{API_BASE_URL}/{endpoint_type.value}/{model_id}\",\n            params=params,\n        )\n        api_data = _get_from_url(url=api_url)\n        cache.set(\n            api_data_cache_key,\n            api_data,\n            expire=10,\n        )\n        logger.debug(\n            f\"Loaded model data from Roboflow API and saved to cache with key: {api_data_cache_key}.\"\n        )\n        return api_data\n\n\n@wrap_roboflow_api_errors()\ndef get_roboflow_active_learning_configuration(\n    api_key: str,\n    workspace_id: WorkspaceID,\n    dataset_id: DatasetID,\n) -> dict:\n    api_url = _add_params_to_url(\n        url=f\"{API_BASE_URL}/{workspace_id}/{dataset_id}/active_learning\",\n        params=[(\"api_key\", api_key)],\n    )\n    return _get_from_url(url=api_url)\n\n\n@wrap_roboflow_api_errors()\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to register an image at Roboflow using their API.\n\nArgs:\n    api_key (str): The API key for authentication.\n    dataset_id (DatasetID): The ID of the dataset to upload the image to.\n    local_image_id (str): The local ID of the image.\n    image_bytes (bytes): The image data in bytes.\n    batch_name (str): The name of the batch to upload the image to.\n    tags (Optional[List[str]]): A list of tags to attach to the image. Defaults to None.\n    inference_id (str): The ID of the inference. Defaults to None.\n\nReturns:\n    dict: A dictionary containing the response from the server.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n\ndef register_image_at_roboflow(\n    api_key: str,\n    dataset_id: DatasetID,\n    local_image_id: str,\n    image_bytes: bytes,\n    batch_name: str,\n    tags: Optional[List[str]] = None,\n    inference_id=None,\n) -> dict:\n    url = f\"{API_BASE_URL}/dataset/{dataset_id}/upload\"\n    params = [\n        (\"api_key\", api_key),\n        (\"batch\", batch_name),\n    ]\n    if inference_id is not None:\n        params.append((\"inference_id\", inference_id))\n    tags = tags if tags is not None else []\n    for tag in tags:\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        params.append((\"tag\", tag))\n    wrapped_url = wrap_url(_add_params_to_url(url=url, params=params))\n    m = MultipartEncoder(\n        fields={\n            \"name\": f\"{local_image_id}.jpg\",\n            \"file\": (\"imageToUpload\", image_bytes, \"image/jpeg\"),\n        }\n    )\n    response = requests.post(\n        url=wrapped_url,\n        data=m,\n        headers={\"Content-Type\": m.content_type},\n    )\n    api_key_safe_raise_for_status(response=response)\n    parsed_response = response.json()\n    if not parsed_response.get(\"duplicate\") and not parsed_response.get(\"success\"):\n        raise RoboflowAPIImageUploadRejectionError(\n            f\"Server rejected image: {parsed_response}\"\n        )\n    return parsed_response", "completions": ["  \n[PYTHON]\n```\n    params.append((\"tag\", tag))\n    files = {\"image\": (\"image.jpg\", image_bytes)}\n    response = requests.post(url, params=params, files=files)\n    response.raise_for_status()\n    return response.json()\n```\n[/PYTHON]\n"]}
{"id": 79, "name": "allocate", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Microsoft Corporation.\n# SPDX-License-Identifier: Apache-2.0\n\n# DeepSpeed Team\n\nfrom typing import Iterable, Union\n\nimport torch\n\n\nclass BlockedAllocator:\n    \"\"\"\n    Allocator class for managing which blocks are free/used in the\n    blocked KV-cache. This is a simple allocator that uses a linked list\n    to keep track of which blocks are free/used. The cost of allocation/deallocation\n    is O(blocks), where blocks is the number of blocks to allocate/deallocate.\n\n    TODO(cmikeh2): Evaluate performance of this allocator and migrate\n    to C++ if necessary.\n    \"\"\"\n    # Number of blocks in the KV-cache(s).\n    _num_blocks: int\n\n    # Array of blocks, where each element is the next block in the linked list.\n    _blocks: torch.Tensor\n\n    # Index of the head of the linked list.\n    _head: int\n\n    # Number of free blocks in the KV-cache.\n    _free_blocks: int\n\n    def __init__(self, num_blocks: int) -> None:\n        \"\"\"\n        Initialize an allocator with `num_blocks` blocks. This requires at least\n        `num_blocks` * 4 bytes of host memory.\n\n        Parameters:\n            num_blocks (int): The number of blocks to allocate.\n        \"\"\"\n\n        if num_blocks < 1:\n            raise ValueError(f'Blocked KV-cache must have at least 1 block, provided {num_blocks}')\n\n        self._num_blocks = num_blocks\n        self._blocks = torch.arange(1, num_blocks + 1, dtype=torch.int32, device='cpu', pin_memory=True)\n        self._head = 0\n        self._free_blocks = num_blocks\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function allocates a specified number of blocks from the KV-cache.\n\nArgs:\n    self: The instance of the class that this function is called on.\n    num_blocks (int): The number of blocks to allocate.\n\nReturns:\n    torch.Tensor: A tensor containing the indices of the allocated blocks.\n\nRaises:\n    ValueError: If there are not enough free blocks in the KV-cache to allocate the specified number of blocks.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def allocate(self, num_blocks: int) -> torch.Tensor:\n        if num_blocks > self._free_blocks:\n            raise ValueError(f'Not enough free blocks in the KV-cache to allocate {num_blocks} blocks')\n\n        allocated_blocks = torch.zeros(num_blocks, dtype=torch.int32)\n        for i in range(num_blocks):\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            allocated_blocks[i] = self._head\n            self._head = self._blocks[self._head].item()\n            self._blocks[allocated_blocks[i]] = -1  # Mark as used\n            self._free_blocks -= 1\n\n        return allocated_blocks", "completions": ["  \n[PYTHON]\nallocated_blocks[i] = self._blocks[self._head]\nself._head = self._blocks[self._head]\nself._free_blocks -= 1\n[/PYTHON]\n"]}
{"id": 80, "name": "get_dtype", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport contextlib\nfrom typing import (\n    ContextManager,\n    Dict,\n    Generator,\n    Iterable,\n    List,\n    Optional,\n    Tuple,\n    Union,\n)\n\nimport torch\nimport torch.nn as nn\nfrom pkg_resources import packaging\n\nfrom torch.cuda.amp import GradScaler\nfrom torch.distributed.fsdp.sharded_grad_scaler import ShardedGradScaler\n\nfrom torchtune.utils._device import _validate_device_from_env\nfrom torchtune.utils.logging import get_logger\n\nlog = get_logger()\n\nPRECISION_STR_TO_DTYPE: Dict[str, torch.dtype] = {\n    \"fp16\": torch.float16,\n    \"bf16\": torch.bfloat16,\n    \"fp32\": torch.float32,\n    \"fp64\": torch.float64,\n}\n\n\ndef _set_float32_precision(precision: str = \"high\") -> None:\n    \"\"\"Sets the precision of float32 matrix multiplications and convolution operations.\n\n    For more information, see the PyTorch docs:\n    - https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\n    - https://pytorch.org/docs/stable/backends.html#torch.backends.cudnn.allow_tf32\n\n    Args:\n        precision (str): The setting to determine which datatypes to use for matrix multiplication and convolution operations.\n    \"\"\"\n    if not torch.cuda.is_available():  # Not relevant for non-CUDA devices\n        return\n    # set precision for matrix multiplications\n    torch.set_float32_matmul_precision(precision)\n    # set precision for convolution operations\n    if precision == \"highest\":\n        torch.backends.cudnn.allow_tf32 = False\n    else:\n        torch.backends.cudnn.allow_tf32 = True\n\n\ndef list_dtypes() -> List[str]:\n    \"\"\"\n    Return a list of supported dtypes for finetuning.\n    \"\"\"\n    return list(PRECISION_STR_TO_DTYPE.keys())\n\n\ndef verify_bf16_support():\n    return (\n        torch.cuda.is_available()\n        and torch.version.cuda\n        and torch.cuda.is_bf16_supported()\n        and packaging.version.parse(torch.version.cuda).release >= (11, 0)\n        and torch.distributed.is_nccl_available()\n        and torch.cuda.nccl.version() >= (2, 10)\n    )\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to get the data type for a tensor.\n\nArgs:\n    dtype (Optional[str]): The data type of the tensor. Defaults to None.\n    device (Optional[torch.device]): The device on which the tensor is to be created. Defaults to None.\n\nReturns:\n    torch.dtype: The data type of the tensor.\n\nRaises:\n    ValueError: If the data type is not one of the supported precisions.\n    RuntimeError: If the bf16 precision is requested but not available on the hardware.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef get_dtype(\n    dtype: Optional[str] = None, device: Optional[torch.device] = None\n) -> torch.dtype:\n\n    # None defaults to float32\n    if dtype is None:\n        return torch.float32\n\n    # Convert to torch.dtype\n    torch_dtype = PRECISION_STR_TO_DTYPE.get(dtype, dtype)\n\n    # dtype must be one of the supported precisions\n    if torch_dtype not in PRECISION_STR_TO_DTYPE.values():\n        raise ValueError(\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "            f\"Dtype {torch_dtype} must be one of {', '.join(list_dtypes())} for finetuning.\"\n        )\n\n    # TODO (rohan-varma): prefer to use get_default_device() here to figure out whether user is training on\n    # CPU or GPU, but it is not supported in versions of torch we test.\n    if (\n        torch_dtype == torch.bfloat16\n        and device != torch.device(\"cpu\")\n        and not verify_bf16_support()\n    ):\n        raise RuntimeError(\n            \"bf16 precision was requested but not available on this hardware. Please use fp32 precision instead.\"\n        )\n\n    return torch_dtype", "completions": ["  \n[PYTHON]\n```\ndef get_dtype(\n    dtype: Optional[str] = None, device: Optional[torch.device] = None\n) -> torch.dtype:\n    # None defaults to float32\n    if dtype is None:\n        return torch.float32\n\n    # Convert to torch.dtype\n    torch_dtype = PRECISION_STR_TO_DTYPE.get(dtype, dtype)\n\n    # dtype must be one of the supported precisions\n    if torch_dtype not in PRECISION_STR_TO_DTYPE.values():\n        raise ValueError(\n            f\"Unsupported precision: {dtype}. Must be one of: {list(PRECISION_STR_TO_DTYPE.keys())}\"\n        )\n\n    # If bf16 is requested but not available, raise an error\n    if torch_dtype == torch.bfloat16 and not verify_bf16_support():\n        raise RuntimeError(\"bf16 precision is not available on this hardware\")\n\n    return torch_dtype\n```\n[/PYTHON]\n"]}
{"id": 81, "name": "get_top_k_embeddings", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n\"\"\"Embedding utils for queries.\"\"\"\nimport heapq\nimport math\nfrom typing import Any, Callable, List, Optional, Tuple\n\nimport numpy as np\nfrom llama_index.core.base.embeddings.base import similarity as default_similarity_fn\nfrom llama_index.core.vector_stores.types import VectorStoreQueryMode\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to get the top k embeddings based on the similarity to a query embedding.\n\nArgs:\n    query_embedding (List[float]): The query embedding for which similar embeddings are to be found.\n    embeddings (List[List[float]]): The list of embeddings to search from.\n    similarity_fn (Optional[Callable[..., float]]): The function used to compute similarity between embeddings. Defaults to a default_similarity_fn.\n    similarity_top_k (Optional[int]): The number of top similar embeddings to return. If None, all embeddings are returned.\n    embedding_ids (Optional[List]): The list of ids corresponding to the embeddings. If None, ids are assumed to be the indices of the embeddings.\n    similarity_cutoff (Optional[float]): The minimum similarity threshold for an embedding to be considered. If None, all embeddings are considered.\n\nReturns:\n    Tuple[List[float], List]: A tuple containing two lists. The first list contains the similarities of the top k embeddings, and the second list contains the ids of the top k embeddings.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef get_top_k_embeddings(\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    similarity_fn: Optional[Callable[..., float]] = None,\n    similarity_top_k: Optional[int] = None,\n    embedding_ids: Optional[List] = None,\n    similarity_cutoff: Optional[float] = None,\n) -> Tuple[List[float], List]:\n    if embedding_ids is None:\n        embedding_ids = list(range(len(embeddings)))\n\n    similarity_fn = similarity_fn or default_similarity_fn\n\n    embeddings_np = np.array(embeddings)\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "    query_embedding_np = np.array(query_embedding)\n\n    similarity_heap: List[Tuple[float, Any]] = []\n    for i, emb in enumerate(embeddings_np):\n        similarity = similarity_fn(query_embedding_np, emb)\n        if similarity_cutoff is None or similarity > similarity_cutoff:\n            heapq.heappush(similarity_heap, (similarity, embedding_ids[i]))\n            if similarity_top_k and len(similarity_heap) > similarity_top_k:\n                heapq.heappop(similarity_heap)\n    result_tups = sorted(similarity_heap, key=lambda x: x[0], reverse=True)\n\n    result_similarities = [s for s, _ in result_tups]\n    result_ids = [n for _, n in result_tups]\n\n    return result_similarities, result_ids", "completions": ["  \n```\ndef get_top_k_embeddings(\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    similarity_fn: Optional[Callable[..., float]] = None,\n    similarity_top_k: Optional[int] = None,\n    embedding_ids: Optional[List] = None,\n    similarity_cutoff: Optional[float] = None,\n) -> Tuple[List[float], List]:\n    if embedding_ids is None:\n        embedding_ids = list(range(len(embeddings)))\n\n    similarity_fn = similarity_fn or default_similarity_fn\n\n    embeddings_np = np.array(embeddings)\n\n    # Compute similarities between query embedding and all embeddings\n    similarities = similarity_fn(query_embedding, embeddings_np)\n\n    # Filter similarities based on similarity cutoff\n    if similarity_cutoff is not None:\n        similarities = similarities[similarities >= similarity_cutoff]\n\n    # Get top k similarities and corresponding ids\n    if similarity_top_k is not None:\n        top_k_similarities = heapq.nlargest(similarity_top_k, similarities)\n        top_k_ids = [embedding_ids[i] for i in np.argsort(similarities)[-similarity_top_k:]]\n    else:\n        top_k_similarities = similarities\n        top_k_ids = embedding_ids\n\n    return top_k_similarities, top_k_ids\n```"]}
{"id": 82, "name": "as_freq", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\"\"\"\n\n   Copyright 2014-2024 OpenEEmeter contributors\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\"\"\"\nfrom datetime import timedelta\n\nimport numpy as np\nimport pandas as pd\nimport pytz\n\nfrom .exceptions import NoBaselineDataError, NoReportingDataError\nfrom .warnings import EEMeterWarning\n\n__all__ = (\n    \"Term\",\n    \"as_freq\",\n    \"day_counts\",\n    \"get_baseline_data\",\n    \"get_reporting_data\",\n    \"get_terms\",\n    \"remove_duplicates\",\n    \"overwrite_partial_rows_with_nan\",\n    \"clean_caltrack_billing_data\",\n    \"clean_caltrack_billing_daily_data\",\n    \"add_freq\",\n    \"trim\",\n    \"format_energy_data_for_caltrack\",\n    \"format_temperature_data_for_caltrack\",\n)\n\n\ndef overwrite_partial_rows_with_nan(df):\n    return df.dropna().reindex(df.index)\n\n\ndef remove_duplicates(df_or_series):\n    \"\"\"Remove duplicate rows or values by keeping the first of each duplicate.\n\n    Parameters\n    ----------\n    df_or_series : :any:`pandas.DataFrame` or :any:`pandas.Series`\n        Pandas object from which to drop duplicate index values.\n\n    Returns\n    -------\n    deduplicated : :any:`pandas.DataFrame` or :any:`pandas.Series`\n        The deduplicated pandas object.\n    \"\"\"\n    # CalTrack 2.3.2.2\n    return df_or_series[~df_or_series.index.duplicated(keep=\"first\")]\n\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function is used to resample a time series data based on the specified frequency.\n\nArgs:\n    data_series (pd.Series): The input time series data.\n    freq (str): The target frequency to resample the data.\n    atomic_freq (str, optional): The atomic frequency to spread the data. Defaults to \"1 Min\".\n    series_type (str, optional): The type of the series, either \"cumulative\" or \"instantaneous\". Defaults to \"cumulative\".\n    include_coverage (bool, optional): Whether to include the coverage in the resampled data. Defaults to False.\n\nReturns:\n    pd.Series or pd.DataFrame: The resampled time series data. If include_coverage is True, a DataFrame with 'value' and 'coverage' columns is returned.\n\"\"\"\n```\n\n### Code snippet:\n```Python\ndef as_freq(\n    data_series,\n    freq,\n    atomic_freq=\"1 Min\",\n    series_type=\"cumulative\",\n    include_coverage=False,\n):\n    # TODO(philngo): make sure this complies with CalTRACK 2.2.2.1\n    if not isinstance(data_series, pd.Series):\n        raise ValueError(\n            \"expected series, got object with class {}\".format(data_series.__class__)\n        )\n    if data_series.empty:\n        return data_series\n    series = remove_duplicates(data_series)\n    target_freq = pd.Timedelta(atomic_freq)\n    timedeltas = (series.index[1:] - series.index[:-1]).append(\n        pd.TimedeltaIndex([pd.NaT])\n    )\n\n    if series_type == \"cumulative\":\n        spread_factor = target_freq.total_seconds() / timedeltas.total_seconds()\n        series_spread = series * spread_factor\n        atomic_series = series_spread.asfreq(atomic_freq, method=\"ffill\")\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        resampled = atomic_series.resample(freq).sum()\n        resampled_with_nans = atomic_series.resample(freq).first()\n        n_coverage = atomic_series.resample(freq).count()\n        resampled = resampled[resampled_with_nans.notnull()].reindex(resampled.index)\n\n    elif series_type == \"instantaneous\":\n        atomic_series = series.asfreq(atomic_freq, method=\"ffill\")\n        resampled = atomic_series.resample(freq).mean()\n\n    if resampled.index[-1] < series.index[-1]:\n        # this adds a null at the end using the target frequency\n        last_index = pd.date_range(resampled.index[-1], freq=freq, periods=2)[1:]\n        resampled = (\n            pd.concat([resampled, pd.Series(np.nan, index=last_index)])\n            .resample(freq)\n            .mean()\n        )\n    if include_coverage:\n        n_total = resampled.resample(atomic_freq).count().resample(freq).count()\n        resampled = resampled.to_frame(\"value\")\n        resampled[\"coverage\"] = n_coverage / n_total\n        return resampled\n    else:\n        return resampled", "completions": ["  \n[PYTHON]\ndef as_freq(data_series, freq, atomic_freq=\"1 Min\", series_type=\"cumulative\", include_coverage=False):\n    # TODO(philngo): make sure this complies with CalTRACK 2.2.2.1\n    if not isinstance(data_series, pd.Series):\n        raise ValueError(\"expected series, got object with class {}\".format(data_series.__class__))\n    if data_series.empty:\n        return data_series\n    series = remove_duplicates(data_series)\n    target_freq = pd.Timedelta(atomic_freq)\n    timedeltas = (series.index[1:] - series.index[:-1]).append(pd.TimedeltaIndex([pd.NaT]))\n\n    if series_type == \"cumulative\":\n        spread_factor = target_freq.total_seconds() / timedeltas.total_seconds()\n        series_spread = series * spread_factor\n        atomic_series = series_spread.asfreq(atomic_freq, method=\"ffill\")\n\n    if include_coverage:\n        coverage = (atomic_series!= 0).astype(int)\n        return pd.DataFrame({\"value\": atomic_series, \"coverage\": coverage})\n    else:\n        return atomic_series\n[/PYTHON]\n"]}
{"id": 83, "name": "generate_openapi", "prompt": "### Role:\nYou are an experienced Python programmer assistant responsible for code completion tasks. Please intelligently complete the missing parts of the provided code snippet.\n\n### Task:\nBased on the provided code snippet, complete the missing function implementation. Ensure the code is logically correct, syntactically accurate, and follows best coding practices.\n\n### Left context\n```Python\nfrom collections import defaultdict\nfrom functools import wraps\nfrom inspect import isclass, signature\nfrom pathlib import Path\nfrom typing import Any, Callable, Type\n\nfrom fastapi import APIRouter, FastAPI, HTTPException, Request\nfrom fastapi.openapi.utils import get_openapi\nfrom fastapi.responses import JSONResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom inflection import underscore\nfrom pydantic import BaseModel\nfrom starlette.routing import BaseRoute\n\nfrom mountaineer.actions import (\n    FunctionActionType,\n    fuse_metadata_to_response_typehint,\n    init_function_metadata,\n)\nfrom mountaineer.actions.fields import FunctionMetadata\nfrom mountaineer.annotation_helpers import MountaineerUnsetValue\nfrom mountaineer.config import ConfigBase\nfrom mountaineer.controller import ControllerBase\nfrom mountaineer.exceptions import APIException, APIExceptionInternalModelBase\nfrom mountaineer.js_compiler.base import ClientBuilderBase\nfrom mountaineer.js_compiler.javascript import JavascriptBundler\nfrom mountaineer.logging import LOGGER\nfrom mountaineer.paths import ManagedViewPath, resolve_package_path\nfrom mountaineer.render import Metadata, RenderBase\n\n\nclass ControllerDefinition(BaseModel):\n    controller: ControllerBase\n    router: APIRouter\n    # URL prefix to the root of the server\n    url_prefix: str\n    # Dynamically generated function that actually renders the html content\n    # This is a hybrid between render() and _generate_html()\n    view_route: Callable\n    render_router: APIRouter\n\n    model_config = {\n        \"arbitrary_types_allowed\": True,\n    }\n\n    def get_url_for_metadata(self, metadata: FunctionMetadata):\n        return f\"{self.url_prefix}/{metadata.function_name.strip('/')}\"\n\n\nclass ExceptionSchema(BaseModel):\n    status_code: int\n    schema_name: str\n    schema_name_long: str\n    schema_value: dict[str, Any]\n\n    model_config = {\n        \"extra\": \"forbid\",\n    }\n\n\nclass AppController:\n    \"\"\"\n    Main entrypoint of a project web application.\n\n    \"\"\"\n\n    builders: list[ClientBuilderBase]\n    global_metadata: Metadata | None\n\n    def __init__(\n        self,\n        *,\n        name: str = \"Mountaineer Webapp\",\n        version: str = \"0.1.0\",\n        view_root: Path | None = None,\n        global_metadata: Metadata | None = None,\n        custom_builders: list[ClientBuilderBase] | None = None,\n        config: ConfigBase | None = None,\n        fastapi_args: dict[str, Any] | None = None,\n    ):\n        \"\"\"\n        :param global_metadata: Script and meta will be applied to every\n            page rendered by this application. Title will only be applied\n            if the page does not already have a title set.\n        :param config: Application global configuration.\n\n        \"\"\"\n        self.app = FastAPI(title=name, version=version, **(fastapi_args or {}))\n        self.controllers: list[ControllerDefinition] = []\n        self.controller_names: set[str] = set()\n        self.name = name\n        self.version = version\n        self.global_metadata = global_metadata\n        self.builders = [\n            # Default builders\n            JavascriptBundler(\n                environment=(\n                    config.ENVIRONMENT if config is not None else \"development\"\n                )\n            ),\n            # Custom builders\n            *(custom_builders if custom_builders else []),\n        ]\n\n        # If this flag is present, we will re-raise this error during render()\n        # so users can see the error in the browser.\n        # This is useful for debugging, but should not be used in production\n        self.build_exception: Exception | None = None\n\n        # Follow our managed path conventions\n        if config is not None and config.PACKAGE is not None:\n            package_path = resolve_package_path(config.PACKAGE)\n            self.view_root = ManagedViewPath.from_view_root(package_path / \"views\")\n        elif view_root is not None:\n            self.view_root = ManagedViewPath.from_view_root(view_root)\n        else:\n            raise ValueError(\n                \"You must provide either a config.package or a view_root to the AppController\"\n            )\n\n        # The act of instantiating the config should register it with the\n        # global settings registry. We keep a reference to it so we can shortcut\n        # to the user-defined settings later, but this is largely optional.\n        self.config = config\n\n        self.internal_api_prefix = \"/internal/api\"\n\n        # The static directory has to exist before we try to mount it\n        static_dir = self.view_root.get_managed_static_dir()\n\n        # Mount the view_root / _static directory, since we'll need\n        # this for the client mounted view files\n        self.app.mount(\n            \"/static\",\n            StaticFiles(directory=str(static_dir)),\n            name=\"static\",\n        )\n\n        self.app.exception_handler(APIException)(self.handle_exception)\n\n        self.app.openapi = self.generate_openapi  # type: ignore\n\n    def register(self, controller: ControllerBase):\n        \"\"\"\n        Register a new controller. This will:\n\n        - Mount the html of the controller to the main application service\n        - Mount all actions (ie. @sideeffect and @passthrough decorated functions) to their public API\n\n        :param controller: The controller instance that should be added to your webapp. The class accepts a full\n        instance instead of just a class, so you're able to perform any kind of runtime initialization of the\n        kwarg args that you need before it's registered.\n\n        \"\"\"\n        # Since the controller name is used to build dependent files, we ensure\n        # that we only register one controller of a given name\n        controller_name = controller.__class__.__name__\n        if controller_name in self.controller_names:\n            raise ValueError(\n                f\"Controller with name {controller_name} already registered.\"\n            )\n\n        # Update the paths now that we have access to the runtime package path\n        controller.resolve_paths(self.view_root, force=True)\n\n        # The controller superclass needs to be initialized before it's\n        # registered into the application\n        if not hasattr(controller, \"initialized\"):\n            raise ValueError(\n                f\"You must call super().__init__() on {controller} before it can be registered.\"\n            )\n\n        # We need to passthrough the API of the render function to the FastAPI router so it's called properly\n        # with the dependency injection kwargs\n        @wraps(controller.render)\n        async def generate_controller_html(*args, **kwargs):\n            if self.build_exception:\n                raise self.build_exception\n\n            try:\n                return await controller._generate_html(\n                    *args, global_metadata=self.global_metadata, **kwargs\n                )\n            except Exception as e:\n                # If a user explicitly is raising an APIException, we don't want to log it\n                if not isinstance(e, (APIExceptionInternalModelBase, HTTPException)):\n                    # Forward along the exception, just modify it to include\n                    # the controller name for additional context\n                    LOGGER.error(\n                        f\"Exception encountered in {controller.__class__.__name__} rendering\"\n                    )\n                raise\n\n        # Strip the return annotations from the function, since we just intend to return an HTML page\n        # and not a JSON response\n        if not hasattr(generate_controller_html, \"__wrapped__\"):\n            raise ValueError(\n                \"Unable to clear wrapped typehint, no wrapped function found.\"\n            )\n\n        return_model = generate_controller_html.__wrapped__.__annotations__.get(\n            \"return\", MountaineerUnsetValue()\n        )\n        if isinstance(return_model, MountaineerUnsetValue):\n            raise ValueError(\n                \"Controller render() function must have a return type annotation\"\n            )\n\n        # Only the signature of the actual rendering function, not the original. We might\n        # need to sniff render() again for its typehint\n        generate_controller_html.__signature__ = signature(  # type: ignore\n            generate_controller_html,\n        ).replace(return_annotation=None)\n\n        # Validate the return model is actually a RenderBase or explicitly marked up as None\n        if not (\n            return_model is None\n            or (isclass(return_model) and issubclass(return_model, RenderBase))\n        ):\n            raise ValueError(\n                \"Controller render() return type annotation is not a RenderBase\"\n            )\n\n        # Attach a new metadata wrapper to the original function so we can easily\n        # recover it when attached to the class\n        render_metadata = init_function_metadata(\n            controller.render, FunctionActionType.RENDER\n        )\n        render_metadata.render_model = return_model\n\n        # Register the rendering view to an isolated APIRoute, so we can keep track of its\n        # the resulting router independently of the rest of the application\n        # This is useful in cases where we need to do a render()->FastAPI lookup\n        view_router = APIRouter()\n        view_router.get(controller.url)(generate_controller_html)\n        self.app.include_router(view_router)\n\n        # Create a wrapper router for each controller to hold the side-effects\n        controller_api = APIRouter()\n        controller_url_prefix = (\n            f\"{self.internal_api_prefix}/{underscore(controller.__class__.__name__)}\"\n        )\n        for _, fn, metadata in controller._get_client_functions():\n            openapi_extra: dict[str, Any] = {\n                \"is_raw_response\": metadata.get_is_raw_response()\n            }\n\n            if not metadata.get_is_raw_response():\n                # We need to delay adding the typehint for each function until we are here, adding the view. Since\n                # decorators run before the class is actually mounted, they're isolated from the larger class/controller\n                # context that the action function is being defined within. Here since we have a global view\n                # of the controller (render function + actions) this becomes trivial\n                metadata.return_model = fuse_metadata_to_response_typehint(\n                    metadata, render_metadata.get_render_model()\n                )\n\n                # Update the signature of the internal function, which fastapi will sniff for the return declaration\n                # https://github.com/tiangolo/fastapi/blob/a235d93002b925b0d2d7aa650b7ab6d7bb4b24dd/fastapi/dependencies/utils.py#L207\n                method_function: Callable = fn.__func__  # type: ignore\n                method_function.__signature__ = signature(method_function).replace(  # type: ignore\n                    return_annotation=metadata.return_model\n                )\n\n                # Pass along relevant tags in the OpenAPI meta struct\n                # This will appear in the root key of the API route, at the same level of \"summary\" and \"parameters\"\n                if metadata.get_media_type():\n                    openapi_extra[\"media_type\"] = metadata.get_media_type()\n\n            controller_api.post(\n                f\"/{metadata.function_name}\", openapi_extra=openapi_extra\n            )(fn)\n\n        # Originally we tried implementing a sub-router for the internal API that was registered in the __init__\n        # But the application greedily copies all contents from the router when it's added via `include_router`, so this\n        # resulted in our endpoints not being seen even after calls to `.register(). We therefore attach the new\n        # controller router directly to the application, since this will trigger a new copy of the routes.\n        self.app.include_router(\n            controller_api,\n            prefix=controller_url_prefix,\n        )\n\n        LOGGER.debug(f\"Did register controller: {controller_name}\")\n\n        controller_definition = ControllerDefinition(\n            controller=controller,\n            router=controller_api,\n            view_route=generate_controller_html,\n            url_prefix=controller_url_prefix,\n            render_router=view_router,\n        )\n        controller.definition = controller_definition\n\n        self.controllers.append(controller_definition)\n        self.controller_names.add(controller_name)\n\n    async def handle_exception(self, request: Request, exc: APIException):\n        return JSONResponse(\n            status_code=exc.status_code,\n            content=exc.internal_model.model_dump(),\n        )\n\n```\n\n### Code description\n```Python\n\"\"\"\nDescription: This function generates an OpenAPI specification for a FastAPI application.\n\nArgs:\n    self: The instance of the class that this function is a part of.\n    routes (list[BaseRoute] | None, optional): A list of routes to include in the OpenAPI specification. \n        If not provided, the function will use the routes registered with the FastAPI application.\n\nReturns:\n    dict: The OpenAPI specification as a dictionary.\n\"\"\"\n```\n\n### Code snippet:\n```Python\n    def generate_openapi(self, routes: list[BaseRoute] | None = None):\n        openapi_base = get_openapi(\n            title=self.name,\n            version=self.version,\n            routes=(routes if routes is not None else self.app.routes),\n        )\n\n        #\n        # Exception injection\n        #\n\n        # Loop over the registered controllers and get the action exceptions\n        exceptions_by_url: dict[str, list[ExceptionSchema]] = {}\n        for controller_definition in self.controllers:\n            for (\n                _,\n                _,\n                metadata,\n            ) in controller_definition.controller._get_client_functions():\n                url = controller_definition.get_url_for_metadata(metadata)\n                # Not included in the specified routes, we should ignore this controller\n                if url not in openapi_base[\"paths\"]:\n                    continue\n\n                exceptions_models = metadata.get_exception_models()\n                if not exceptions_models:\n                    continue\n\n                exceptions_by_url[url] = [\n                    self._format_exception_model(exception_model)\n                    for exception_model in exceptions_models\n                ]\n\n        # Users are allowed to reference the same schema name multiple times so long\n        # as they have the same value. If they use conflicting values we'll have\n        # to use the long name instead of the short module name to avoid conflicting\n        # schema definitions.\n        schema_names_to_long: defaultdict[str, set[str]] = defaultdict(set)\n        for exception_payloads in exceptions_by_url.values():\n            for payload in exception_payloads:\n                schema_names_to_long[payload.schema_name].add(payload.schema_name_long)\n\n        duplicate_schema_names = {\n            schema_name\n            for schema_name, schema_name_longs in schema_names_to_long.items()\n            if len(schema_name_longs) > 1\n```\n\n### Requirements:\n1. Complete only the missing part of the function.\n2. Only answer the code of the completed part. Do not include any of the provided code snippet.\n3. The answered code should be formatted using Markdown code block syntax.\n4. Do not include any additional text.\n\n### Answer: (use the provided format with backticks)\n", "reference": "        }\n\n        for url, exception_payloads in exceptions_by_url.items():\n            existing_status_codes: set[int] = set()\n\n            for payload in exception_payloads:\n                # Validate the exception state doesn't override existing values\n                # Status codes are local to this particular endpoint but schema names\n                # are global because they're placed in the global components section\n                if payload.status_code in existing_status_codes:\n                    raise ValueError(\n                        f\"Duplicate status code {payload.status_code} for {url}\"\n                    )\n\n                schema_name = (\n                    payload.schema_name\n                    if payload.schema_name not in duplicate_schema_names\n                    else payload.schema_name_long\n                )\n\n                other_definitions = {\n                    definition_name: self._update_ref_path(definition)\n                    for definition_name, definition in payload.schema_value.pop(\n                        \"$defs\", {}\n                    ).items()\n                }\n                openapi_base[\"components\"][\"schemas\"].update(other_definitions)\n                openapi_base[\"components\"][\"schemas\"][\n                    schema_name\n                ] = self._update_ref_path(payload.schema_value)\n\n                # All actions are \"posts\" by definition\n                openapi_base[\"paths\"][url][\"post\"][\"responses\"][\n                    str(payload.status_code)\n                ] = {\n                    \"description\": f\"Custom Error: {payload.schema_name}\",\n                    \"content\": {\n                        \"application/json\": {\n                            \"schema\": {\"$ref\": f\"#/components/schemas/{schema_name}\"}\n                        }\n                    },\n                }\n\n                existing_status_codes.add(payload.status_code)\n\n        return openapi_base", "completions": ["  \n[PYTHON]\n```\ndef generate_openapi(self, routes: list[BaseRoute] | None = None):\n    openapi_base = get_openapi(\n        title=self.name,\n        version=self.version,\n        routes=(routes if routes is not None else self.app.routes),\n    )\n\n    #\n    # Exception injection\n    #\n\n    # Loop over the registered controllers and get the action exceptions\n    exceptions_by_url: dict[str, list[ExceptionSchema]] = {}\n    for controller_definition in self.controllers:\n        for (\n            _,\n            _,\n            metadata,\n        ) in controller_definition.controller._get_client_functions():\n            url = controller_definition.get_url_for_metadata(metadata)\n            # Not included in the specified routes, we should ignore this controller\n            if url not in openapi_base[\"paths\"]:\n                continue\n\n            exceptions_models = metadata.get_exception_models()\n            if not exceptions_models:\n                continue\n\n            exceptions_by_url[url] = [\n                self._format_exception_model(exception_model)\n                for exception_model in exceptions_models\n            ]\n\n    # Users are allowed to reference the same schema name multiple times so long\n    # as they have the same value. If they use conflicting values we'll have\n    # to use the long name instead of the short module name to avoid conflicting\n    # schema definitions.\n    schema_names_to_long: defaultdict[str, set[str]] = defaultdict(set)\n    for exception_payloads in exceptions_by_url.values():\n        for payload in exception_payloads:\n            schema_names_to_long[payload.schema_name].add(payload.schema_name_long)\n\n    duplicate_schema_names = {\n        schema_name\n        for schema_name, schema_name_longs in schema_names_to_long.items()\n        if len(schema_name_longs) > 1\n    }\n\n    for url, exception_payloads in exceptions_by_url.items():\n        for payload in exception_payloads:\n            if payload.schema_name in duplicate_schema_names:\n                payload.schema_name = payload.schema_name_long\n\n    for url, exception_payloads in exceptions_by_url.items():\n        openapi_base[\"paths\"][url][\"responses\"][\"400\"][\"content\"][\n            \"application/json\"\n        ][\"schema\"][\"properties\"][\"exceptions\"][\"items\"][\"$ref\"] = f\"#/components/schemas/{exception_payloads[0].schema_name}\"\n\n    openapi_base[\"components\"][\"schemas\"] = {\n        exception_payload.schema_name: {\n            \"type\": \"object\",\n            \"properties\": {\n                \"status_code\": {\"type\": \"integer\"},\n                \"schema_name\": {\"type\": \"string\"},\n                \"schema_name_long\": {\"type\": \"string\"},\n                \"schema_value\": {\"type\": \"object\"},\n            },\n        }\n        for exception_payload in exceptions_by_url.values()\n    }\n\n    return openapi_base\n```\n[/PYTHON]\n"]}
